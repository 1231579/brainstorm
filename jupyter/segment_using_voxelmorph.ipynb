{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataset_utils import adni_loader\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras.backend as K\n",
    "gpu_ids = [3]\n",
    "# set gpu id and tf settings\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(g) for g in gpu_ids])\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "load_params_from_exp = './experiments/FewShotSeg_adni-unnorm-masked_100ul_subj-l_ims160-192-1_arch32-32-64-64-128-128_augflow-amp200_blur12_randmult0.5_flowaug-gen'\n",
    "\n",
    "data_params_file = os.path.join(load_params_from_exp, 'data_params.json')\n",
    "with open(data_params_file, 'r') as f:\n",
    "    data_params = json.load(f)\n",
    "data_params['vte_epoch'] = 500\n",
    "arch_params_file = os.path.join(load_params_from_exp, 'arch_params.json')\n",
    "with open(arch_params_file, 'r') as f:\n",
    "    arch_params = json.load(f)\n",
    "\n",
    "data_params['scale'] = 1  # always load full-scale data for evaluation\n",
    "data_params['n_unlabeled'] = 1  # just load one for training, we only want the validation set\n",
    "data_params['load_vols'] = False\n",
    "ds = adni_loader.ADNIDataset(data_params)\n",
    "_ = ds.load_dataset(debug=False)\n",
    "vol_shape = (160, 192, 224, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_glt_model = False\n",
    "\n",
    "if use_glt_model:\n",
    "    load_data_from_exp = './experiments/FewShotSeg_adni_all-ul_atlas-l_ims160-192-1_arch32-32-64-64-128-128_augflow-amp150_blur10_flowaug-gen'\n",
    "    load_data_from_exp = './experiments/FewShotSeg_adni-unnorm-masked_100ul_atlas-l_ims160-192-1_arch32-32-64-64-128-128_vteaug-gen-halfres_wrapper_unets_seq_train_wrapper-e1000'\n",
    "    load_data_from_exp = './experiments/GLT_adni-unnorm-masked_100ul_atlas-l-to-subjs_ims160-192-224-1_voxelmorph_flow_color_unet16-16-32-32-32-32_dec64-64-32-32-32-32_lr0.0005_cc_grad_l2_regfwt1_cc_wt1_win9_grad-si-l2-predgrad_regcwt0.5_l2_sigI0.1'\n",
    "    #load_data_from_exp = './experiments/GLT_adni-unnorm-masked_100ul_atlas-l-to-subjs_ims160-192-224-1_voxelmorph_flow_color_unet16-16-32-32-32-32_dec64-64-32-32-32-32_lr0.0005_cc_vm_grad_l2_regfwt1_cc_vm_wt1_win9_grad-si-l2-predgrad_regcwt0.5_l2_sigI0.1'\n",
    "    #load_data_from_exp = './experiments/GLT_adni-unnorm-masked_100ul_atlas-l-to-subjs_ims160-192-224-1_voxelmorph2_flow_color_unet16-32-32-32_dec64-64-32-32-32_lr0.0005_cc_grad_l2_regfwt1_cc_wt1_win9_grad-si-l2-predgrad_regcwt0.5_l2_sigI0.1'\n",
    "    load_data_from_exp = './experiments/GLT_adni-unnorm-masked_100ul_atlas-l-to-subjs_ims160-192-224-1_voxelmorph2_flow_color_unet16-32-32-32_dec64-64-32-32-32_lr0.0005_cc_vm_grad_l2_regfwt1_cc_vm_wt1_win9_grad-si-l2-predgrad_regcwt0.5_l2_sigI0.1'\n",
    "    load_data_from_exp = './experiments/GLT_adni-sf0.5-unnorm-masked_100ul_atlas-l-to-subjs_ims160-192-224-1_voxelmorph2_flow_color_unet16-32-32-32_dec64-64-32-32-32_lr0.0005_cc_vm_grad_l2_regfwt1_cc_vm_wt1_win5_grad-si-l2-predgrad_regcwt0.5_l2_sigI0.1'\n",
    "    \n",
    "    \n",
    "    data_params_file = os.path.join(load_data_from_exp, 'data_params.json')\n",
    "    with open(data_params_file, 'r') as f:\n",
    "        data_params = json.load(f)\n",
    "    data_params['vte_epoch'] = 500\n",
    "    arch_params_file = os.path.join(load_data_from_exp, 'arch_params.json')\n",
    "    with open(arch_params_file, 'r') as f:\n",
    "        arch_params = json.load(f)\n",
    "\n",
    "    sys.path.append('../cnn_utils')\n",
    "    import file_utils, vis_utils\n",
    "\n",
    "    # load segmenter because it has the half-res wrapper logic\n",
    "    from experiments_VTE import FewShotSegmentationExperimentClass, GLTExperimentClass\n",
    "    #exp = FewShotSegmentationExperimentClass.ExperimentSegmenter(data_params, arch_params)\n",
    "    exp = GLTExperimentClass.ExperimentGlobalLocalTransforms(data_params, arch_params)\n",
    "\n",
    "    model_name, exp_dir, figures_dir, logs_dir, models_dir = file_utils.make_output_dirs(exp.get_model_name(), exp_root='./experiments/', prompt_delete=False)\n",
    "    exp.save_exp_info(exp_dir, figures_dir, models_dir, logs_dir)\n",
    "\n",
    "    exp.load_data(load_fewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from networks import transform_network_utils\n",
    "\n",
    "if not use_glt_model:\n",
    "    sys.path.append('../voxelmorph')\n",
    "    sys.path.append('../voxelmorph/src')\n",
    "    import src.networks as vm_networks\n",
    "    from dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "    voxelmorph_model = load_model(\n",
    "    #     #'/afs/csail.mit.edu/u/x/xamyzhao/voxelmorph/models/vm2_l2.h5',\n",
    "    #     '/afs/csail.mit.edu/u/x/xamyzhao/LPAT/experiments/voxelmorph/vm2_cc_AtoS_iter54000.h5',\n",
    "        '/afs/csail.mit.edu/u/x/xamyzhao/LPAT/experiments/voxelmorph/vm2_cc_AtoUMS_iter15000.h5',\n",
    "    #     #'/afs/csail.mit.edu/u/x/xamyzhao/LPAT/experiments/voxelmorph/vm2_l2_StoS_ftiter9500.h5',\n",
    "        custom_objects={'Dense3DSpatialTransformer': Dense3DSpatialTransformer},\n",
    "        compile=False,\n",
    "    )\n",
    "    voxelmorph_model.summary()\n",
    "elif 'sf0.5' in exp.model_name:\n",
    "    exp.create_models()\n",
    "    exp.load_models(models_dir, 500)\n",
    "    voxelmorph_model = transform_network_utils.vm_halfres_wrapper(\n",
    "        full_img_shape=(160, 192, 224, 1),\n",
    "        model=exp.unet_flow,\n",
    "        upsample_outputs=[True, False],\n",
    "        scale_outputs=[2, 1],\n",
    "    )\n",
    "elif 'GLT' in exp.model_name:\n",
    "    exp.create_models()\n",
    "    exp.load_models(models_dir, 'latest')\n",
    "    voxelmorph_model = exp.unet_flow\n",
    "    \n",
    "vol_warp_model = transform_network_utils.warp_model(\n",
    "    img_shape=vol_shape,\n",
    "    interp_mode='linear'\n",
    ")\n",
    "\n",
    "seg_warp_model = transform_network_utils.warp_model(\n",
    "    img_shape=vol_shape[:-1] + (1,),\n",
    "    interp_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv3D\n",
    "for l in voxelmorph_model.layers:\n",
    "    \n",
    "    if isinstance(l, Conv3D):\n",
    "        print(l.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import medipy_metrics\n",
    "import classification_utils\n",
    "import IPython\n",
    "import PIL\n",
    "import vte_runner\n",
    "import vis_utils\n",
    "label_mapping = vte_runner.voxelmorph_labels\n",
    "# load each subject, then evaluate each slice\n",
    "n_test_examples = len(ds.files_labeled_valid)\n",
    "n_test_examples = 50\n",
    "dice_per_label = np.zeros((len(label_mapping,)))\n",
    "\n",
    "source_X = ds.X_atlas\n",
    "source_Y = ds.Y_atlas\n",
    "\n",
    "# source_X, source_Y =  adni_loader._load_vol_and_seg(ds.files_labeled_train[0])\n",
    "# source_X = source_X[np.newaxis]\n",
    "# source_Y = source_Y[np.newaxis]\n",
    "\n",
    "for bi in range(n_test_examples):\n",
    "    print('Evaluating test subject {} of {}'.format(bi, n_test_examples))\n",
    "    target_X, target_Y =  adni_loader._load_vol_and_seg(ds.files_labeled_valid[bi], mask_vol = ds.params['masked'])\n",
    "    n_slices = target_X.shape[2]\n",
    "    preds = np.zeros(target_Y.shape)\n",
    "\n",
    "    preds = voxelmorph_model.predict([source_X, target_X[np.newaxis]])\n",
    "\n",
    "    if use_glt_model:\n",
    "        # GLT rather than voxelmorph\n",
    "        warped, warp = preds[-1], preds[0]\n",
    "    else:\n",
    "        warped, warp = preds\n",
    "        warp = warp[..., [1, 0, 2]]  # since voxelmorph uses a different SpatialTransformer\n",
    "    \n",
    "    warped = vol_warp_model.predict([source_X, warp])\n",
    "    #warped, warp = preds[0], preds[1]\n",
    "    slice_idx = np.random.choice(source_X.shape[-2], 1)[0]\n",
    "    IPython.display.display(PIL.Image.fromarray(\n",
    "        vis_utils.label_ims(\n",
    "            np.concatenate([source_X[:, :, :, slice_idx] , target_X[np.newaxis, :, :, slice_idx], warped[:, :, :, slice_idx]], axis=0),\n",
    "            concat_axis=1\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    pred = seg_warp_model.predict([source_Y[..., np.newaxis], warp])\n",
    "    \n",
    "    subject_dice_per_label = medipy_metrics.dice(target_Y[np.newaxis], pred, labels=label_mapping)[0, :]\n",
    "    dice_per_label += subject_dice_per_label\n",
    "    print(subject_dice_per_label)\n",
    "dice_per_label /= float(n_test_examples)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean dice: {}'.format(np.mean(dice_per_label[1:])))\n",
    "print('Dice per label: {}'.format(dice_per_label))\n",
    "for li, l in enumerate(ds.label_mapping):\n",
    "    print('{}: {}'.format(l, dice_per_label[li]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # now try subject-to-atlas just once\n",
    "# source_X, source_Y =  adni_loader._load_vol_and_seg(ds.files_labeled_valid[bi])\n",
    "\n",
    "# target_X, target_Y =  ds.X_atlas, ds.Y_atlas\n",
    "# n_slices = target_X.shape[2]\n",
    "# preds = np.zeros(target_Y.shape)\n",
    "\n",
    "# print(source_X.shape)\n",
    "# print(target_X.shape)\n",
    "# print(source_Y.shape)\n",
    "# warped, warp = voxelmorph_model.predict([source_X[np.newaxis], target_X])\n",
    "# pred = seg_warp_model.predict([source_Y[np.newaxis,..., np.newaxis], warp])\n",
    "\n",
    "# subject_dice_per_label = medipy_metrics.dice(target_Y[np.newaxis], pred, labels=label_mapping)[0, :]\n",
    "\n",
    "# print(subject_dice_per_label)\n",
    "# print(np.mean(subject_dice_per_label[1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
