{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[(None, 160, 192, 224, 1), (None, 160, 192, 224, 3)]\n",
      "[(None, 160, 192, 224, 1), (None, 160, 192, 224, 3)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The name \"model_2\" is used 2 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7b812a0629c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mbck_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbck_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mindexing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bidir_wrapper_fwd20k_bck40k'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[0mbidir_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bidir_wrapper_fwd20k_bck40k.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LPAT/networks/voxelmorph_networks.py\u001b[0m in \u001b[0;36mbidir_wrapper\u001b[0;34m(img_shape, fwd_model, bck_model, indexing, model_name)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtransformed_bck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_bck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_src\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \treturn Model(inputs=[input_src, input_tgt], outputs=[transformed_fwd, transformed_bck, flow_fwd, flow_bck],\n\u001b[0;32m---> 73\u001b[0;31m \t\tname=model_name)\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cvenv36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cvenv36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cvenv36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 231\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cvenv36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1453\u001b[0m             raise ValueError('The name \"' + name + '\" is used ' +\n\u001b[1;32m   1454\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                              \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m                              'All layer names should be unique.')\n\u001b[1;32m   1457\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnetwork_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"model_2\" is used 2 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset_utils import adni_loader\n",
    "#from networks import transform_network_utils\n",
    "\n",
    "sys.path.append('../neuron')\n",
    "sys.path.append('../voxelmorph')\n",
    "import src.losses as vm_losses\n",
    "\n",
    "gpu_ids = [0]\n",
    "# set gpu id and tf settings\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(g) for g in gpu_ids])\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "import sys\n",
    "sys.path.append('../voxelmorph-sandbox')\n",
    "import voxelmorph.networks as vm_networks\n",
    "import tensorflow as tf\n",
    "from voxelmorph import dense_3D_spatial_transformer\n",
    "from keras.models import load_model\n",
    " \n",
    "sys.path.append('../neuron')\n",
    "import neuron.layers as nrn_layers\n",
    "import neuron.utils as nrn_utils\n",
    "sys.path.append('../voxelmorph-sandbox')\n",
    "import voxelmorph.networks as vm_networks\n",
    "from voxelmorph.dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "\n",
    "fwd_model = load_model(\n",
    "    './experiments/voxelmorph/vm2_cc_AtoUMS_100k_CStoUMS_xy_iter20000.h5',\n",
    "    custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "                    'interp_upsampling': vm_networks.interp_upsampling,\n",
    "                    'meshgrid': vm_networks.meshgrid,\n",
    "                    'tf': tf,\n",
    "                    \n",
    "                    'VecInt': nrn_layers.VecInt,\n",
    "                    'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "                    'nrn_utils': nrn_utils,\n",
    "                    'nrn_layers': nrn_layers,\n",
    "                   },\n",
    "    compile=False,\n",
    ")\n",
    "\n",
    "bck_model = load_model(\n",
    "    './experiments/voxelmorph/vm2_cc_AtoUMS_100k_UMStoCS_xy_iter40000.h5',\n",
    "    custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "                    'interp_upsampling': vm_networks.interp_upsampling,\n",
    "                    'meshgrid': vm_networks.meshgrid,\n",
    "                    'tf': tf,\n",
    "                    \n",
    "                    'VecInt': nrn_layers.VecInt,\n",
    "                    'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "                    'nrn_utils': nrn_utils,\n",
    "                    'nrn_layers': nrn_layers,\n",
    "                   },\n",
    "    compile=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cnn_utils/vis_utils.py:14: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  mpl.use('Agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adni dataset adni-unnorm-masked_100ul_subj-OASIS_OAS1_0327-l\n",
      "Params: {'dataset_name': 'adni', 'source_name': 'atl', 'target_name': 'subjs', 'unnormalized': True, 'masked': True, 'n_shot': 1, 'use_atlas_as_source': False, 'use_subject': 'OASIS_OAS1_0327_MR1_mri_talairach_orig', 'img_shape': (160, 192, 224, 1), 'pred_img_shape': (160, 192, 1), 'aug_img_shape': (160, 192, 224, 1), 'n_unlabeled': 100, 'n_validation': 50, 'load_vols': True, 'aug_in_gen': True, 'n_vte_aug': None, 'n_flow_aug': None, 'use_labels': [0, 16, 10, 49, 8, 47, 4, 43, 7, 46, 12, 51, 2, 41, 28, 60, 11, 50, 13, 52, 17, 53, 14, 15, 18, 54, 24, 3, 42, 31, 63], 'final_test': False, 'warp_labels': True, 'n_dims': 3, 'orig_img_shape': (160, 192, 224, 1), 'scale': 1.0, 'split_id': None}\n",
      "Got list of 7329 files from /data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/*.npz:\n",
      "ADNI_ADNI-3T-FS-5.3-Long_293689.long.016_S_4591_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_78841.long.016_S_1326_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_436815.long.094_S_1330_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_296323.long.068_S_2168_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_388923.long.135_S_5273_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_272700.long.009_S_4388_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_394785.long.027_S_0408_base_mri_talairach_orig.npz\n",
      "PPMI_3519_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_119158.long.053_S_0507_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_63306.long.007_S_0249_base_mri_talairach_orig.npz\n",
      "ABIDE_50685_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_121666.long.041_S_1423_base_mri_talairach_orig.npz\n",
      "GSP_120719_TT88SP_FS_mri_talairach_orig.npz\n",
      "COBRE_0040043_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_416015.long.021_S_2124_base_mri_talairach_orig.npz\n",
      "...\n",
      "Got 102 training and 50 validation files!\n",
      "Loaded 0 of 2 files\n",
      "Labeled train vols:\n",
      "X_labeled_train: (2, 160, 192, 224, 1)\n",
      "Y_labeled_train: (2, 160, 192, 224)\n",
      "ids_labeled_train: ['OASIS_OAS1_0327_MR1_mri_talairach_orig', 'OASIS_OAS1_0327_MR1_mri_talairach_orig']\n",
      "Loaded 0 of 50 files\n",
      "Loaded 0 of 100 files\n",
      "Filtering labels to [0, 16, 10, 49, 8, 47, 4, 43, 7, 46, 12, 51, 2, 41, 28, 60, 11, 50, 13, 52, 17, 53, 14, 15, 18, 54, 24, 3, 42, 31, 63]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 160, 192, 224, 1)\n",
      "(2, 160, 192, 224, 1)\n",
      "(50, 160, 192, 224, 1)\n",
      "['/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz']\n",
      "True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x160 at 0x7FE1D010AB00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAACgCAAAAAB/QzyBAAAZkUlEQVR4nO2cX3cdR3Lkf5FZF9TsOfbMSCT+ktTY3/8zedemSAKkZkb2Hq+G6MqMfai+IGVrCFCidl9YLyQuLroru6oyIyMjG76ML+PL+DK+jC/jy/gyvowv48v4Mr6M/z9D/0/uchrh+fY3ufT4Ta4KT4BwkcQ1HAL78fe/xY1+GwNODzJSi5EAEXTqyVuubPTqc97qtzHgkFYAgwMNmIzJOA9C7s96q89uwBNMCilMhrIAbMdhSuFG8Vnv99kMOPfNumAbtVIK0P68bUJRigpbz158rpvyuQx4ii3gfMhqhC1ClucUPEYisJukSwB/+l+f5c6fwYALFLEbIALJYCNJru0VMFKoa2sCDGc3EP/0P3/1reEzGPAUIyEL6CAUNiAB3l4CHELCNV/xbCITwL98+2vvvMYvPVGPn6x/r7BibRfgpqqscXJIIeFZAJcoMlwFtqv6NcC/fo7p/1IDnpwe8snxCgpJogGut9utWjkyhFwNXAWEJAzfGb96+XmmvsYv20InH0AQGUJeBnAD592HGEjrd0gKYUvAZ508/OIzIDnu/tcRoDr+7hq+PQRASwDKwNy32mcxw6b//Gkz+WQDnoStPqjXE1coEFEy8DjlG2BGysByTWsBvEewS9mvf+bCv4stWvz4ifP51DNwcXI4nKQifL0MUIwU2AAh4gJAy5Ee/ZERKC7g8ukI5QcXfPwH4OmfHjMjPZUnnzihT1yB8wiQgn0BUBC2wAW8uQRddoxoZO0nRVgSRVxEaPewx/HVBrhP+O6fmXbnf73lZzXgDImQ5PoAUmbL+M2aKxBjRFvh9euFJkKpKSUN/uCSYUA9wNKID3/12Q04G9EQgau3/TM7HOAPJqUYYQzad6gbE0phqfF3H1zz2TJZgg7l2nR8M/qh6c+nGJCBjFC9u76brSTv/hIuWillqpcXXStio7BM4K6fIrkXPAX+7TnPf0SRXgZ8lX1289kNOHcHVBrfzR+F1NYRNhMaoX3TtzDwgisFtlHP3dleyK/hD1/1G8b5NXSeFBoqvoMnj4S+eqAFD/dCVymFYFZ/kJJIy0WmLgAyMjK0u06F3n9Lkqv9EuBy5ACUhydnHqfQ8nDm1gAnIcd4oDt68ApcSZKiKfK9Ac8D0T7ONWJkrL0vLEVyoZAiU9DVXmc/sxsYxFfueHR20620ZyVwPkCpePbjQ5LoBxsgJUhZKr93gxESRBNZcDlWTFg7HznGPzUp4rjQC0lc5YJOKZSd+LxnZJYzJwRyBHqYR3qwAZaRMjTpOwOWD5FcGv0t5AB63dnYDuEQR6P2cQjUwPWlaIihd7gH7X7BmZyGdj2I8nm4Ad2EHAetmAVAZkodRHtkRNu751lAAkIY3A7pGBFAQQXAO5wn5YgT96GrZTiRRE/3lg85xw824FZyVB5y3M3/4pBCIEfTCkU1EXsIkL1HY3chsxwucO6wA3gc3W1mjkezAyvMVRKyCw3p6bz+uxP6VAO+f8xbOPNJHHK7KIgxRmBjtxnGOGzaCMtEW3QAy4yVbHKWka42kCddqrQ7MhZCuZAzbRPDFXXPpPgF1OKzw3C5LUUmWO7GfdB63tg72JHKQmp5XxLqXQXKQ9TWKxw/x7cDpJOUt+omc+ScEFlb9GdagT9mctyOL55HHAyBXctZpnEPY7GDZu+gAeiOldkIxUkFkdFrAYCZjFBJdcCNkwjV7BRt17ifBHuIAd+MDK52F842EkVbgNuM6JAjsNu7B7WlXgcfjzuAqTHkdFe7eTI8+/YwQlYHDVERKFWOpHs9ms9hQCbvsSXeRjS0IGwbY0fY3UUEjXEEyGobl+IOV4fVqmr7DGVuc0ZKqg6OpIwiMqKQeEgkeIgBbhR9h59t+Z2EycArGU7PCUQK2orlcUJVBLXOBA1qHF1a2ZnSvYmIXPYKyCCgLVma9yOdhxjw35BtuxIvBgthYj/VonvntACJcme4w8jdFpKq/B1cyThOttrSOAMRgSP2S1iucj7/t89gwE+HAnMQzuh1NKt7HoYdontWR6YkI2b5djwKEJqzkE/kWS/hVEirhCC6/ZVEpInoueB5Va14/fHx6bzQOMmITAXGhm5Xhxe/6Oq53W5bG7nnVv32dUkoem5V39VmejEURiEUmbnwtxuNcHfbs7pbKen5fdP5tNmf5ThJrScjQja0E9GoJWzewtPuoKtnGeokRM/5GnDVWFijEXJxkOlO3LZldbslY0Wox72n4GEG/ENKUmgoT6KtiG6BbQeLkJ4NeXQbQXfPWSt4WHLPVwAdldlAO8ISoeq77KF3IsyRRoRx3zfBhxnwvx9HREiREd45lF74wGHA3m55lPY6vg71Efuvb9VCBa+e1WKQXIDDljpCIyyzMIREgCg12/xMh/j7s6GQlGLtfS/gGe5G0pwv4BkrLLBw2/EARog+ZnGOauAsFzDKMijIaED2WhW1RELOe6HOPQb8Hv4dgJvzAaaIgR1qtNM7Ts9aqXqHF0aIgN5p0Kv8MB/oQxc8USbGPTQJBVjWDj2soCWEIu51Mh814B8epTjZfgC4Bq6AJLwH5l6cVtes74CnEYoyLDLuGEUXTXqcyatn9ktySLK7O7MZwr1XFXouSqyFlT7ci0c/asDhqxCVT46R7CVwmYOVxyM3oqrqFXC10ksani5gDcDVfkDjfAHLW4snSUVI6lIGiResDXVZuGPVBd26F0x8zIB/PAmFU+NidvuH48dxh49l7Lm9Aq7ITKosg3D1/uxyUaNxxGU3QHqiE5OyiVV2IvZsTriRqkPdfd8Z/qgBIzssxEjbX+EbuIwIFwqtm1bNV8AzxxjM6qi103zng2ywYuipkfwdkMsBLU4maCzLSu8kcBv67kD9CgOkVFgNAtNXEJlVO7i0XD1fwsVBiqSmo17CiLjzQZe7FWgsU569gODQ4Y5SrMKNdhqAFSBFOEYXdb+T/Ng3gggpFAbRi5Ud1ML667M2l5xEhKnZ2l7B85CqdgI098jQrbDchtOA0SqwSa08aDfThI1pAloPwEIfMeCbkEuLo2ItQt08FRHVA7QS9fFPYWVUtxX7ju2ud+t/V6wDKqkld3tDbjnIsFgsULewek+lIduCkB+QEHzEgD8/CQoTuVeKBBfqHHPm4nqsgFRvMTc3+/wLer6Bb6eFtVPXyu6m+5qZNSqIMCIEvapsNm0hhFoIPYQZ+tgWevvNkG84PxlBG8UhVzzKjJUKiOhOqWr2HeP7kqd9Dd8CHUgLuBm38StoHEYVKBSiJSFaxkaORRnTe/H5lxvAqrctfYaxZSvlWP6TwBKlONxW/8RjxCWHnG6tLMU03UY9gdj+46K8nP+AncToCqDpfdE6XH4A2n8AFgppEZXGaLG5wi1351rynv0TgiYyJIsgIgxtbHfMGyALeZKyu6NZ+Rosl7vX1tTpLeLeMPAQA1LyShR3INq2aMvTU4eh8iN36+quBjwfDbG1A+3JCra76oazE949usBtSZbc64GL0F4W1OI2ak49gJ6+34DzCHmrfSVUUrdl3N3z5lyB+/C7qvLlMe+3Tc9iELsfaHs2byDEUJBW0Hsxs+FYB98rg7FW4yHSqPsNiAhqbis3+ZNIbDfY/RJoo1EHhap3uIN6RhUhLb5XuKv9Fk6zczhWYXMBtqaFmzBotF2iRedhbH9/Vu+nd98XTgXdxxre7O7udru7J5BIit6scRhxvr51PW//9qKdrWTO6m5X8xYYc5oQ4xCQmSFj8LZVzTbKkSNo247xkJLrvX7qbIxB1Xz3F4DLIcJW265ruIzDSbe7Roqa5ffV14uMepTb5gh51irDAleRDpVR3KUU/j8+ESE6Qu5mPTVt91Kj928hiZVh7/YuRRbGBRcR2bdl44pU2le13/MqRWYbdan7vdRvO3RiafGqRznC8qDdGbF89CiUDzgE9xqQ6t19AhcBtCzUXQsHbNPt7DkIAnPZ18DlSe+JwAv4+jC2Ow3HmycKC0tl9U5ZDtOv4EnQFQHdkjt/ZSQGeNx95AiBkGybgJenBZK3Zm2bywbhpABOrAjP5UlieALwe/0AM0uDGTRNSJaPdcN10hxZvQ3B/PUG7J74m/4rAC17d/dvgI51FABeXbVkWJlMc6h2ed4AJ7r9K8CZx1db9LGOINqQXrDw8Kxm95QsFKo6aHuAG3ogK7FvgP8qV3rFBXfn7CUXlnr9bP5m5o6H1044HaNHJ9uedGFjEcslx5CobmSiW4fiCMk/On4z8feZ38BZfKAzvoqsML51HmLOQ8wiIscMsXWk3XY3b+Bb19geplD+5arFJ1rb6EzucLKLmM4U1M3Kfbnh6fs/sNs9KmLa7kr5+lxSd1qOBUoJNZ8kCPzFBjxOiEvkDiuWAO00d4XWHag41bOqjlHXsB3swUqn9/Q9tLiBxUqAf17M9VkN2EX034x9sg4WKgBiF8dxF0IP2Ro+QtVFtkTaZAdFyyycy8qP3sswzuthgptPNOAKn/otfHNI7YIaESzq8FRakoidEzp9wxYxXK58/D1vn+ik01YaslaA1J5cSJK1q22uuD3k4WEzesAhPk/J/Qq4SEWXmc6MVZJ3SOnwNm/JMQbyVrtrPX0D549SNVvrk/Ox6o6O3ByzcmhEt6oURHVNUpDMDL1T/ffi0KcacBa5ai3dBEjpsrql0CJyJQ1Ct1szxlCXiz1UnB/6JeePhvoOJF1kOBxmeOJSaoRb3iS4nfWXJ4dFIgSFtrG9+djs4J4tdHaQVo6xl7yAjO5cEu+lOQh29kWZ0TXtPRQwMuD6aSqy95j648kI29AxGjWhJZ2g3fPt0j3KTnW64XBv38rHuVHF4ggqU7Zj6TcEcrOi7KnVGZFYoarZ/R5B7jn5e0kaP3CmUoeqFeEZqSgga+K3sETYjlTErYf06J75f9yAjpBRqjpGr54ArGFUvdPnHWOkPLBC2zY/EJjM3OfvroKn9RpQlJZKMw8aC+tCTO2pibWkvsOO9P20xMcNYFMqFFpaGxaXEt3uBc8ep8aIRf/Eh6Q6wPVzA41cU5cDLl8tnn3pK6aG9uTaKHeFIyEyjMu8F+j8QgOuT1EeQpFVTYZVnREOl80TYigij3yFhBSnHxw7L/RNb294vqut1RXu7hDtlVpKrbDin6tN5KoyzKZl35sxfjwOvOEbw4gYUV4TLUGEnXuFXTR4BdUmOdYBYA9vod5uACd69uLcG9FlV8aKBMsThryiiELqbq3yyf1i9/sC2Z+/7vZAikJddFQTCw4okCGhhJDb4V6gIq7vDKAnXDoC+pzp32lOZ0qxSMUwOHSUWVebF5xfw7MHzP/+SFwm0shEdDerfBeKXZRlCdSybMK2zm44XRnonqV4/0ba+ZKvN3WToYx1pT1HdZigq+qaVdF6ULPTfQb8QYqMpBxStqSlFF1lMCN6Eb2NUdhruqnz6x2RFgeuDN0joi9e521kxFoAepcIruOvdD9g23+KAX8c0gjajat1ULeSPqKzVU/adX2dQqsCLr0vL84+idutFLRGTQ6T0EjhKq8wSTuixY6TnrFdc5YdPCAluMfcw+FwGOGq7jm3aUWG1P2+VOxYihXh6pX/w3WvauX5Fbyd1hjhZfagQmTgnsaxINXKBO6k+To8+zaViqcfnx3ctwJfj1QsKs5tsR1iaMmZOD58Y7GXX3zXDYSA04yn37EdRiomKLYWN3Ahr2pgZheDIx2qJWFpjWk18QB2/R4DIiITd7lmfw9cnmT2UoMuWZmXLRLu5RHdQKDzZoSAm6vIVDjCvaT3xg3l0GxWWR4vwdMKzXbLaOry3k30cQOERFXNnn8BoJcW0SD1Uln1LgfVHpUWyiZHH2urt4ckwqqtll+0qU4i3J1aMsddmmmicCOHpb5/Ce4xwGX1rDpiwhiUjuUZL5mid9C2Jh6xG5CVWhKJJdXybANXL4Hud8ohvHSy8kozHXZEq1so+kFipnu8UNF4O6YVVxrDilWMXg+c1l4W6uUJI31ZIoMIb9VAhOx915/rmeacXh9KqwS6WmcWjpIs6ESkfJnMj6bJ90GJD8ZZapxA0qbbsbdVGcktH3tjUhWr16cZo5/jPIl2sycCB0KtE3XHUtio57GRaDkxyWoveNe6J+d6eE58mnE4wQb3apk87GEg5lTEcqqwd6Fji9xTfoSyq+H6aU7SkXYoZXX0xvGvBWiJSXov7dzXQP1gA84zx1C7aXe/AHg2hiTcWyVgr83lRfrLVXMqRPnRI6QuvQQdYvObc8kh3BVjlqzY59pWNiYW4UhYH68SPNSA84xxiG6X5xHkvHieq3ypjKUrU4BcCRa3/2fbjEQzI+nbl8+BaiGuuZLkbgZGnrmEEpJZLFM4pFpQ71cb8CQUmRnuqjnvDsbzISjlfpFQ7y17HaJu//PHvRvONPIs/m1VyqXLV3SUo/vAJmF1sL4YLXUad9D23g346ww4z9VwWO5duwfwdIzQ0XEsGaJ2IRqGd/9x69VU3ESEehErEasnAjN7RMRU0pXqtYkgdqQoVak8fvUK/P53GRERXrXWu3wlD7vArwnLe+PGXnpx/W3zriMzKHYp15UOeyGyQqul8dBqhXslxzuFIxFtQ9c9hbL7Dcj9oitnyb0cfH5YbYMtdkXAohMALNqRDfLSkh7LYZcaJ3ZEweaUyImhg64MW2aFjEBR0btf+3UGCLusQxpI0n8ybnLJT6w7yHUE9mATj2ql/UtijTWedkgHdZR0+YpKKnpGZXdWsxQJwkv44cPajV3xUf30/QYYOhSUIvbg3l7xCi8xjvHawscFIDghftzzaJAVJ7bJFWYtDjpYMWPOg4VjNft56e8x3ZRjJXp//OuvMWCJg2Jhy9VnEs3SCSjbVrnUpdDqHjAKOb8aeXvbtslHJzsRbHm1kza5QpbeTcZY6Rl710MkhUolpCh/NLW834B/52KJZmgfsZq8knm6Qt1d7qnMMXQX+RWhR7db2Rz+x6PFqIglsh7TVw0u8RL+UVrij9UEUQ5Jjg66I0IfV14+xI2+vhSWZrcjcsi12MUFRml7PaSznjl2ekutGHkybSvG6m+wNCVEdtsRveUr4NDR5YhY0dc9R2iKCHfV8MdTggcFsldXZShvlsYYuVD/quNaOhbcb84UfYilOFk0aoRbdofAdr+T0kLyNZf17ge4ODS3GR6p1bFidR0kUlnZtd1Tan0YlOgw3mH16eFkxB4he/X6W8/qFXADFz6MJepe7ujYFoRkzdsXXJYiFcGesR+qugcavViartDUcKcUDs173nLwMA7jdXXdvlppQc9avtWet1ut7OyDb87e2zdoa5c6ASgGG7zqdldz9Xj9wd9+nA7iwKyFAt+8pGcd73Kv4OOBYO4D0UWOcIe7q7siZiWK5hih3cVevVnY7D2e7wjgFZcJRzKaN7+PR+jAtlpHAZyu6O4lZ7+nofKTamSnY/WMgGtbr0g5d5If0ECXwWodAWK3IDCUFXlydgO84jzUCxN+c+hx8PDtFuqIIJ687UPPMTwDRvc9/PSnGHCeBBky8txWonfNZSQ6PudLRQhq11+tzS+r6l+ea+ikFs1wt6BP8hCy/e52HgZIZPLyWxVjuoK8VzT3KTyebZKqlqruHsyrKnMULUqZGXMr49q2uTyO3ZOa24xHcXH+4SW/OontPzeV38RA5YA85W/NtsqX96s9PmUFbs7DTCKo+QFKL51wh7mENDdCrmrFYUierebKfvmMw8nmK09pX4MXl/MNV8VLFAvXFsnNk0FBzr6/nfWTzkDHaht29QcGdMP7ji+rtk2HntWvuYwh6rYiQtO8eMrQ/Img9RWc5e019DxURcrEN39++/hQhOp+wdan9ZGZpWj4UIAFZm5H3a6V6nlz7a7yqn97bvPFvxIjzvnutvMwMuM98f/HyxMmEMHtVDuDhO+Lfkgb3CcaMNt2rVa19xe3d48E56vFBuasnWfZa7TlyDxnzo67zm4AvlLN74FHB81pptXjCbzp1HxA+8CnGfDXrbpsr87V46jt7ki3ctX5rl+13yyix5GCajLE623rn1YCX/8YAr5OpDZsFTr5Gq5v//bjQ9QSn6aV+DNnScv+8NUnd7H+VHnQsTvizSkL8FUR8OoZ6YKXV4r4ic76L4cT4FEjy1b376aSn2lB/RwGwM2Z/Hfw4XnkUEXuRE6cXyPhHY11j9DF69Vq9pO9cQMwOdTbbyjHZBfo/TYGcPPkw5/OFO+lQXGIckbk+TWX7CmAa9W+Xz7rEBcLfv/3y749z6ZBWVvuVPhvY8BPlvac1NNd2Wbj6oB0n+cHJ3X/t+fJ6B0F/gzdmQ5WqeTTXob5a16Udx4i0LPJa8DuTXIpMk2ozd7d/c2xDyGz5Xb7Z/z7u3ngr3994gfErs9lwJV2zC8uXq98BVmdcSJiyUfdYxRP/P0CIqNx/Xx4WhWIT38r7K94d+bLWceUJYCjTguTj07GEp+5OsYY4/Qx7Ovxy2/4s+PXbKFrOItoZQv44Zv9jX/dceQDKyoy2xGF5WmpSeDi53bRLxq/8mWRN8D57hZndCB6OrxrhSqjFLn6PFlJlpqvRz5AVPyw8TlX9A+HXCqmJTPqfsnpiBFd7fnmMqi9WYOTmJ/ma/7++JyvrP0BOLU91MZJwJsL1+pkpFXrpbCnKd/f3PPQ8VtIj78esiOl2zc8OSx53e1v8s5mfpu3Hq84ehZq2AhF27/V/H878TffBG+BP6TAn/gKyy/jy/gyvowv48v4Mr6ML+PL+DK+jC/jy/jtx/8FXFRTqZVbPMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x160 at 0x7FE1D010AB00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 160, 192, 224, 1), (None, 160, 192, 224, 3)]\n"
     ]
    }
   ],
   "source": [
    "# create diffeomorphic model\n",
    "sys.path.append('../voxelmorph')\n",
    "import src.networks as vm_networks\n",
    "\n",
    "nf_enc = [16, 32, 32, 32]\n",
    "nf_dec = [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "# vm2 model\n",
    "vm_new_model = vm_networks.cvpr2018_net(\n",
    "    vol_size=(160, 192, 224),\n",
    "    enc_nf=nf_enc, \n",
    "    dec_nf=nf_dec,\n",
    "    indexing='xy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 192, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 160, 192, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 160, 192, 224 0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 80, 96, 112,  880         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 80, 96, 112,  0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 40, 48, 56, 3 13856       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 40, 48, 56, 3 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 20, 24, 28, 3 27680       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 20, 24, 28, 3 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 10, 12, 14, 3 27680       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 10, 12, 14, 3 0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 10, 12, 14, 3 27680       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 10, 12, 14, 3 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 20, 24, 28, 3 0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 20, 24, 28, 6 0           up_sampling3d_1[0][0]            \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 20, 24, 28, 3 55328       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 20, 24, 28, 3 0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 40, 48, 56, 3 0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40, 48, 56, 6 0           up_sampling3d_2[0][0]            \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 40, 48, 56, 3 55328       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 40, 48, 56, 3 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 80, 96, 112,  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 80, 96, 112,  0           up_sampling3d_3[0][0]            \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 80, 96, 112,  41504       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 80, 96, 112,  0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 80, 96, 112,  27680       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 80, 96, 112,  0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_4 (UpSampling3D)  (None, 160, 192, 224 0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 160, 192, 224 0           up_sampling3d_4[0][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 160, 192, 224 14704       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 160, 192, 224 0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 160, 192, 224 6928        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 160, 192, 224 0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flow (Conv3D)                   (None, 160, 192, 224 1299        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_transformer_1 (SpatialT [(None, 160, 192, 22 0           input_1[0][0]                    \n",
      "                                                                 flow[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 300,547\n",
      "Trainable params: 300,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vm_new_model.summary()\n",
    "import data_utils\n",
    "import src.losses as vm_losses\n",
    "\n",
    "# just train voxelmorph\n",
    "vm_new_model.compile(\n",
    "    #loss=['mean_squared_error', vm_losses.gradientLoss('l2')],\n",
    "    #loss=[vm_losses.cc3D(), vm_losses.gradientLoss('l2')],\n",
    "    loss=[vm_losses.NCC().loss, vm_losses.Grad('l2').loss],\n",
    "          #vm_losses.gradientLoss('l2')],\n",
    "    #loss_weights=[1.0, ,0.01],\n",
    "    loss_weights=[1.0, 1.],#0.01],\n",
    "    #loss_weights=[1., 1., 1., 0.],#0.01],\n",
    "    optimizer=Adam(0.0001)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "input_1\n",
      "input_2\n",
      "input_2\n",
      "concatenate_1\n",
      "concatenate_1\n",
      "conv3d_1\n",
      "conv3d_1\n",
      "leaky_re_lu_1\n",
      "leaky_re_lu_1\n",
      "conv3d_2\n",
      "conv3d_2\n",
      "leaky_re_lu_2\n",
      "leaky_re_lu_2\n",
      "conv3d_3\n",
      "conv3d_3\n",
      "leaky_re_lu_3\n",
      "leaky_re_lu_3\n",
      "conv3d_4\n",
      "conv3d_4\n",
      "leaky_re_lu_4\n",
      "leaky_re_lu_4\n",
      "conv3d_5\n",
      "conv3d_5\n",
      "leaky_re_lu_5\n",
      "leaky_re_lu_5\n",
      "up_sampling3d_1\n",
      "up_sampling3d_1\n",
      "concatenate_2\n",
      "concatenate_2\n",
      "conv3d_6\n",
      "conv3d_6\n",
      "leaky_re_lu_6\n",
      "leaky_re_lu_6\n",
      "up_sampling3d_2\n",
      "up_sampling3d_2\n",
      "concatenate_3\n",
      "concatenate_3\n",
      "conv3d_7\n",
      "conv3d_7\n",
      "leaky_re_lu_7\n",
      "leaky_re_lu_7\n",
      "up_sampling3d_3\n",
      "up_sampling3d_3\n",
      "concatenate_4\n",
      "concatenate_4\n",
      "conv3d_8\n",
      "conv3d_8\n",
      "leaky_re_lu_8\n",
      "leaky_re_lu_8\n",
      "conv3d_9\n",
      "conv3d_9\n",
      "leaky_re_lu_9\n",
      "leaky_re_lu_9\n",
      "up_sampling3d_4\n",
      "up_sampling3d_4\n",
      "concatenate_5\n",
      "concatenate_5\n",
      "conv3d_10\n",
      "conv3d_10\n",
      "leaky_re_lu_10\n",
      "leaky_re_lu_10\n",
      "conv3d_11\n",
      "conv3d_11\n",
      "leaky_re_lu_11\n",
      "leaky_re_lu_11\n",
      "flow\n",
      "flow\n",
      "spatial_transformer_1\n",
      "spatial_transformer_1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# copy weights from regular voxelmorph as initialization\n",
    "for li, l in enumerate(vm_new_model.layers):\n",
    "    print(l.name)\n",
    "    if l.name == voxelmorph_model.layers[li].name:\n",
    "        print(l.name)\n",
    "        vm_new_model.layers[li].set_weights(voxelmorph_model.layers[li].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x160 at 0x7FE16836FC18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ds.files_labeled_train[0])\n",
    "# source_X = ds.X_atlas\n",
    "source_X, _ = adni_loader._load_vol_and_seg(ds.files_labeled_train[0], load_seg=False, mask_vol=ds.params['masked'])\n",
    "source_X = source_X[np.newaxis]\n",
    "IPython.display.display(PIL.Image.fromarray((source_X[0, :, :, 64, 0]*255).astype(np.uint8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_263697.long.153_S_4077_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223532.long.153_S_2109_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_76615.long.021_S_0984_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_451346.long.009_S_0751_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100329_NW33DK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_282668.long.002_S_4270_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110314_JD99RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50558_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_424046.long.073_S_2225_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123092.long.036_S_0672_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_65343.long.027_S_0850_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_254813.long.116_S_4209_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_45933.long.137_S_0972_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_394756.long.011_S_4235_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118902.long.023_S_0926_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119324.long.123_S_0113_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_370676.long.033_S_0741_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349295.long.021_S_2142_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3787_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121812.long.029_S_1218_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036143_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3407_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119395.long.128_S_0310_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51305_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_313580.long.006_S_4546_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119656.long.133_S_1170_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_62599.long.005_S_0324_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_59923.long.007_S_1304_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50351_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3809_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120628_DZ38NB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0061_MR2_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121072.long.002_S_1070_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100627_BA34XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_64609.long.016_S_0702_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3650_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10120_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100920_GJ38UU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_342548.long.099_S_2042_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_416009.long.019_S_5012_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_96119.long.033_S_0723_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100916_QR67XU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59697.long.116_S_0649_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_357718.long.130_S_4641_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120621_KM56MK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_2559559_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_277027.long.153_S_2148_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_3466651_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_2123983_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100121_GF37CB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_377050.long.036_S_4736_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_376948.long.131_S_0384_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091222_EV77WH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100218_PX88NU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102414.long.128_S_0200_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349822.long.022_S_5004_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432130.long.037_S_4706_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0331_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_79126.long.002_S_1261_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_3994098_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_130240.long.068_S_0401_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_3004580_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_142044.long.037_S_0588_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3816_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090914_DJ48AU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_308100.long.041_S_4720_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101208_DQ73BH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0291_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100328_CA87HH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_103333.long.032_S_0147_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090709_WE83EH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398370.long.126_S_2405_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50243_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_111236.long.031_S_1066_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_7333005_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090914_WJ88NK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59725.long.116_S_0382_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10068_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100128_RX68QB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_140604_UW83SK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_300291.long.041_S_1425_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_335944.long.031_S_4476_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_363274.long.033_S_4508_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090923_PH66XU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100526_TE48VB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_66051.long.094_S_1188_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3612_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100308_CQ45RU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_69606.long.022_S_0544_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036298_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119090.long.032_S_0479_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119144.long.053_S_0389_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_294850.long.027_S_0408_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090724_ZN86HH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_140800.long.007_S_1222_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_122662.long.006_S_1130_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118706.long.010_S_0067_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_163740.long.136_S_0429_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_85547.long.002_S_0955_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_217623.long.023_S_0625_base_mri_talairach_orig.npz']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, loss [-0.21234852, -0.25739086, 0.045042332]\n",
      "Iter 1, loss [-0.21624011, -0.2545602, 0.038320087]\n",
      "Iter 2, loss [-0.20601569, -0.24747671, 0.041461017]\n",
      "Iter 3, loss [-0.21138331, -0.25193274, 0.04054942]\n",
      "Iter 4, loss [-0.20652282, -0.25439268, 0.04786987]\n",
      "Iter 5, loss [-0.2106624, -0.2544796, 0.0438172]\n",
      "Iter 6, loss [-0.22022071, -0.28127357, 0.06105286]\n",
      "Iter 7, loss [-0.21124049, -0.25080326, 0.03956278]\n",
      "Iter 8, loss [-0.22321016, -0.29491305, 0.07170289]\n",
      "Iter 9, loss [-0.20890798, -0.2563321, 0.04742412]\n",
      "Iter 10, loss [-0.20539476, -0.24757071, 0.042175945]\n",
      "Iter 11, loss [-0.2216606, -0.26128465, 0.03962405]\n",
      "Iter 12, loss [-0.21018745, -0.26935843, 0.059170976]\n",
      "Iter 13, loss [-0.21722451, -0.25247008, 0.035245564]\n",
      "Iter 14, loss [-0.20843962, -0.25550202, 0.04706239]\n",
      "Iter 15, loss [-0.20231612, -0.24190521, 0.03958909]\n",
      "Iter 16, loss [-0.23010048, -0.28717598, 0.057075497]\n",
      "Iter 17, loss [-0.20207629, -0.24315381, 0.041077524]\n",
      "Iter 18, loss [-0.2398288, -0.30603513, 0.06620633]\n",
      "Iter 19, loss [-0.21449272, -0.25511625, 0.040623527]\n",
      "Iter 20, loss [-0.2063165, -0.24606898, 0.039752487]\n",
      "Iter 21, loss [-0.23667774, -0.31164235, 0.074964605]\n",
      "Iter 22, loss [-0.21051756, -0.24759136, 0.037073806]\n",
      "Iter 23, loss [-0.2190541, -0.25733557, 0.038281467]\n",
      "Iter 24, loss [-0.20734292, -0.25414303, 0.046800107]\n",
      "Iter 25, loss [-0.21306087, -0.28765577, 0.0745949]\n",
      "Iter 26, loss [-0.2134899, -0.25201818, 0.03852828]\n",
      "Iter 27, loss [-0.2060824, -0.24334863, 0.03726623]\n",
      "Iter 28, loss [-0.21145587, -0.24960686, 0.038150996]\n",
      "Iter 29, loss [-0.21593963, -0.25545156, 0.03951193]\n",
      "Iter 30, loss [-0.21874185, -0.26103327, 0.042291414]\n",
      "Iter 31, loss [-0.21194711, -0.2567298, 0.04478269]\n",
      "Iter 32, loss [-0.22960463, -0.26773784, 0.03813321]\n",
      "Iter 33, loss [-0.21261203, -0.25220388, 0.03959184]\n",
      "Iter 34, loss [-0.21100235, -0.24979997, 0.038797617]\n",
      "Iter 35, loss [-0.20231684, -0.23916015, 0.036843315]\n",
      "Iter 36, loss [-0.22400162, -0.26367277, 0.039671145]\n",
      "Iter 37, loss [-0.21318382, -0.25209343, 0.03890961]\n",
      "Iter 38, loss [-0.21945909, -0.25599864, 0.036539555]\n",
      "Iter 39, loss [-0.20741284, -0.24450342, 0.037090592]\n",
      "Iter 40, loss [-0.20853612, -0.2493101, 0.040773988]\n",
      "Iter 41, loss [-0.20961598, -0.25864932, 0.04903334]\n",
      "Iter 42, loss [-0.22126833, -0.25943148, 0.038163155]\n",
      "Iter 43, loss [-0.19626352, -0.24463719, 0.048373662]\n",
      "Iter 44, loss [-0.21034871, -0.25604522, 0.04569651]\n",
      "Iter 45, loss [-0.21953645, -0.25982055, 0.040284105]\n",
      "Iter 46, loss [-0.23026115, -0.26824254, 0.037981384]\n",
      "Iter 47, loss [-0.23426725, -0.30986914, 0.07560189]\n",
      "Iter 48, loss [-0.22092342, -0.26591462, 0.044991195]\n",
      "Iter 49, loss [-0.22687835, -0.29690674, 0.07002839]\n",
      "Iter 50, loss [-0.20384642, -0.2950944, 0.091247976]\n",
      "Iter 51, loss [-0.21451434, -0.24878742, 0.03427308]\n",
      "Iter 52, loss [-0.21407726, -0.24782853, 0.03375127]\n",
      "Iter 53, loss [-0.20587854, -0.2426049, 0.03672635]\n",
      "Iter 54, loss [-0.21950059, -0.2655036, 0.046002995]\n",
      "Iter 55, loss [-0.20104176, -0.24150936, 0.040467612]\n",
      "Iter 56, loss [-0.21701862, -0.25949842, 0.0424798]\n",
      "Iter 57, loss [-0.21928953, -0.26938286, 0.050093338]\n",
      "Iter 58, loss [-0.2248114, -0.26545665, 0.040645238]\n",
      "Iter 59, loss [-0.21304259, -0.25554588, 0.04250329]\n",
      "Iter 60, loss [-0.20973884, -0.2583982, 0.048659366]\n",
      "Iter 61, loss [-0.21040232, -0.24813402, 0.037731692]\n",
      "Iter 62, loss [-0.22078153, -0.27916756, 0.05838602]\n",
      "Iter 63, loss [-0.2247106, -0.26059854, 0.035887945]\n",
      "Iter 64, loss [-0.21031475, -0.25292054, 0.04260578]\n",
      "Iter 65, loss [-0.22508174, -0.26299074, 0.037909]\n",
      "Iter 66, loss [-0.21708098, -0.26092038, 0.043839388]\n",
      "Iter 67, loss [-0.20772839, -0.2583515, 0.050623115]\n",
      "Iter 68, loss [-0.22515352, -0.2894493, 0.06429578]\n",
      "Iter 69, loss [-0.2141231, -0.25664434, 0.042521246]\n",
      "Iter 70, loss [-0.20919256, -0.24759556, 0.038403004]\n",
      "Iter 71, loss [-0.21488956, -0.25406134, 0.03917178]\n",
      "Iter 72, loss [-0.2182844, -0.2558506, 0.03756621]\n",
      "Iter 73, loss [-0.22469106, -0.2654165, 0.040725432]\n",
      "Iter 74, loss [-0.2406681, -0.30118537, 0.060517266]\n",
      "Iter 75, loss [-0.21233869, -0.25342482, 0.041086134]\n",
      "Iter 76, loss [-0.21239977, -0.2489174, 0.03651763]\n",
      "Iter 77, loss [-0.21487512, -0.2555792, 0.040704086]\n",
      "Iter 78, loss [-0.21615039, -0.26301122, 0.04686083]\n",
      "Iter 79, loss [-0.21596292, -0.2556475, 0.039684586]\n",
      "Iter 80, loss [-0.20367995, -0.25311524, 0.049435288]\n",
      "Iter 81, loss [-0.23700832, -0.31186712, 0.0748588]\n",
      "Iter 82, loss [-0.21697286, -0.25447723, 0.037504382]\n",
      "Iter 83, loss [-0.19678128, -0.24229258, 0.045511298]\n",
      "Iter 84, loss [-0.2162108, -0.25290897, 0.036698174]\n",
      "Iter 85, loss [-0.20961106, -0.24749081, 0.037879758]\n",
      "Iter 86, loss [-0.21874294, -0.2581153, 0.03937235]\n",
      "Iter 87, loss [-0.24527028, -0.28816834, 0.04289805]\n",
      "Iter 88, loss [-0.21598342, -0.2541357, 0.03815227]\n",
      "Iter 89, loss [-0.2132769, -0.2537284, 0.040451497]\n",
      "Iter 90, loss [-0.20885211, -0.25813413, 0.049282014]\n",
      "Iter 91, loss [-0.21074472, -0.25629112, 0.045546398]\n",
      "Iter 92, loss [-0.22261958, -0.26117286, 0.038553283]\n",
      "Iter 93, loss [-0.20455135, -0.25358236, 0.049031004]\n",
      "Iter 94, loss [-0.21932152, -0.25823203, 0.038910504]\n",
      "Iter 95, loss [-0.21494474, -0.2540923, 0.03914757]\n",
      "Iter 96, loss [-0.21660405, -0.2560202, 0.03941614]\n",
      "Iter 97, loss [-0.22638917, -0.27142894, 0.045039773]\n",
      "Iter 98, loss [-0.20950247, -0.24790838, 0.03840591]\n",
      "Iter 99, loss [-0.2095421, -0.25789437, 0.04835227]\n",
      "Iter 100, loss [-0.21602198, -0.2612566, 0.045234617]\n",
      "Iter 101, loss [-0.21631978, -0.26177377, 0.045453977]\n",
      "Iter 102, loss [-0.22709925, -0.26510957, 0.038010314]\n",
      "Iter 103, loss [-0.22233921, -0.26113358, 0.03879437]\n",
      "Iter 104, loss [-0.2197924, -0.26060227, 0.040809862]\n",
      "Iter 105, loss [-0.2228531, -0.26051506, 0.037661977]\n",
      "Iter 106, loss [-0.21014242, -0.25737715, 0.047234725]\n",
      "Iter 107, loss [-0.21682297, -0.25286663, 0.036043663]\n",
      "Iter 108, loss [-0.22649923, -0.27029437, 0.04379514]\n",
      "Iter 109, loss [-0.23951212, -0.30185625, 0.06234413]\n",
      "Iter 110, loss [-0.22772262, -0.29800513, 0.07028252]\n",
      "Iter 111, loss [-0.2116724, -0.25228065, 0.04060825]\n",
      "Iter 112, loss [-0.21541667, -0.25635222, 0.04093555]\n",
      "Iter 113, loss [-0.30550566, -0.31527546, 0.009769784]\n",
      "Iter 114, loss [-0.22622429, -0.2703074, 0.0440831]\n",
      "Iter 115, loss [-0.24618167, -0.28891405, 0.042732388]\n",
      "Iter 116, loss [-0.17923433, -0.22615875, 0.046924435]\n",
      "Iter 117, loss [-0.20629585, -0.24644235, 0.040146496]\n",
      "Iter 118, loss [-0.21639442, -0.25402364, 0.037629217]\n",
      "Iter 119, loss [-0.21114986, -0.25564113, 0.044491276]\n",
      "Iter 120, loss [-0.3068863, -0.31642848, 0.00954221]\n",
      "Iter 121, loss [-0.20777147, -0.24808186, 0.040310394]\n",
      "Iter 122, loss [-0.20361064, -0.25234163, 0.04873098]\n",
      "Iter 123, loss [-0.19638449, -0.24227488, 0.045890387]\n",
      "Iter 124, loss [-0.22387245, -0.26217398, 0.038301528]\n",
      "Iter 125, loss [-0.20937821, -0.24482119, 0.035442986]\n",
      "Iter 126, loss [-0.22306983, -0.2654812, 0.042411372]\n",
      "Iter 127, loss [-0.24148682, -0.3038575, 0.062370688]\n",
      "Iter 128, loss [-0.21721229, -0.25808898, 0.04087668]\n",
      "Iter 129, loss [-0.21032405, -0.24982505, 0.039501]\n",
      "Iter 130, loss [-0.225853, -0.27326795, 0.04741495]\n",
      "Iter 131, loss [-0.21711607, -0.26206383, 0.044947755]\n",
      "Iter 132, loss [-0.2259688, -0.26628557, 0.040316775]\n",
      "Iter 133, loss [-0.21148795, -0.256372, 0.044884052]\n",
      "Iter 134, loss [-0.22194013, -0.25949845, 0.03755831]\n",
      "Iter 135, loss [-0.20921814, -0.24900019, 0.039782047]\n",
      "Iter 136, loss [-0.21462339, -0.25509638, 0.040472984]\n",
      "Iter 137, loss [-0.20129469, -0.24376781, 0.04247312]\n",
      "Iter 138, loss [-0.21154553, -0.25351787, 0.041972335]\n",
      "Iter 139, loss [-0.20979366, -0.25819868, 0.048405014]\n",
      "Iter 140, loss [-0.21693054, -0.25523558, 0.03830504]\n",
      "Iter 141, loss [-0.18052898, -0.22942723, 0.04889825]\n",
      "Iter 142, loss [-0.2018627, -0.24457295, 0.042710267]\n",
      "Iter 143, loss [-0.20786628, -0.24555016, 0.037683878]\n",
      "Iter 144, loss [-0.22624715, -0.2629662, 0.03671904]\n",
      "Iter 145, loss [-0.2161509, -0.25434706, 0.038196158]\n",
      "Iter 146, loss [-0.20168567, -0.24116875, 0.039483085]\n",
      "Iter 147, loss [-0.21468435, -0.25437036, 0.039686006]\n",
      "Iter 148, loss [-0.20664893, -0.24932869, 0.042679757]\n",
      "Iter 149, loss [-0.2174736, -0.25878742, 0.041313834]\n",
      "Iter 150, loss [-0.22694445, -0.2660649, 0.039120466]\n",
      "Iter 151, loss [-0.22048724, -0.26016113, 0.039673895]\n",
      "Iter 152, loss [-0.20169023, -0.2926669, 0.09097668]\n",
      "Iter 153, loss [-0.20329112, -0.24389325, 0.04060213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 154, loss [-0.22189176, -0.2601011, 0.03820934]\n",
      "Iter 155, loss [-0.2258253, -0.27148715, 0.045661848]\n",
      "Iter 156, loss [-0.22622812, -0.2718654, 0.045637272]\n",
      "Iter 157, loss [-0.19676277, -0.24353157, 0.0467688]\n",
      "Iter 158, loss [-0.20954782, -0.24691318, 0.037365355]\n",
      "Iter 159, loss [-0.22323926, -0.2917369, 0.06849764]\n",
      "Iter 160, loss [-0.21941909, -0.25638688, 0.036967784]\n",
      "Iter 161, loss [-0.2094814, -0.24586858, 0.036387175]\n",
      "Iter 162, loss [-0.20586583, -0.24677044, 0.040904604]\n",
      "Iter 163, loss [-0.20563918, -0.2469995, 0.041360315]\n",
      "Iter 164, loss [-0.21618742, -0.25557163, 0.039384216]\n",
      "Iter 165, loss [-0.23458765, -0.29867697, 0.06408931]\n",
      "Iter 166, loss [-0.21195534, -0.2579979, 0.04604256]\n",
      "Iter 167, loss [-0.20424744, -0.25499606, 0.05074861]\n",
      "Iter 168, loss [-0.22620496, -0.2652235, 0.039018538]\n",
      "Iter 169, loss [-0.20846756, -0.24989069, 0.041423127]\n",
      "Iter 170, loss [-0.22526664, -0.26415414, 0.03888751]\n",
      "Iter 171, loss [-0.20506316, -0.25541043, 0.05034727]\n",
      "Iter 172, loss [-0.22711346, -0.26934183, 0.042228363]\n",
      "Iter 173, loss [-0.21126065, -0.24929944, 0.038038787]\n",
      "Iter 174, loss [-0.20711276, -0.24323185, 0.036119085]\n",
      "Iter 175, loss [-0.21676783, -0.25372103, 0.036953196]\n",
      "Iter 176, loss [-0.22702453, -0.2698591, 0.04283458]\n",
      "Iter 177, loss [-0.20824848, -0.24754126, 0.039292783]\n",
      "Iter 178, loss [-0.21404168, -0.25482982, 0.04078815]\n",
      "Iter 179, loss [-0.21708506, -0.26136783, 0.04428276]\n",
      "Iter 180, loss [-0.22675279, -0.27249175, 0.045738965]\n",
      "Iter 181, loss [-0.21804696, -0.25625813, 0.038211174]\n",
      "Iter 182, loss [-0.20517305, -0.24326591, 0.03809287]\n",
      "Iter 183, loss [-0.20111749, -0.23919016, 0.038072668]\n",
      "Iter 184, loss [-0.21943662, -0.2576767, 0.038240068]\n",
      "Iter 185, loss [-0.21138352, -0.25173837, 0.04035484]\n",
      "Iter 186, loss [-0.1957199, -0.24249625, 0.04677635]\n",
      "Iter 187, loss [-0.22768912, -0.2714181, 0.04372897]\n",
      "Iter 188, loss [-0.21344773, -0.2550356, 0.041587874]\n",
      "Iter 189, loss [-0.21581455, -0.2545656, 0.03875105]\n",
      "Iter 190, loss [-0.1963528, -0.24418113, 0.04782833]\n",
      "Iter 191, loss [-0.20795715, -0.25019553, 0.04223838]\n",
      "Iter 192, loss [-0.21683036, -0.25504807, 0.038217705]\n",
      "Iter 193, loss [-0.22416183, -0.26161256, 0.03745074]\n",
      "Iter 194, loss [-0.21763547, -0.25596613, 0.038330656]\n",
      "Iter 195, loss [-0.21783036, -0.2574531, 0.03962275]\n",
      "Iter 196, loss [-0.21778978, -0.25444332, 0.036653534]\n",
      "Iter 197, loss [-0.24000698, -0.2764144, 0.03640742]\n",
      "Iter 198, loss [-0.20541942, -0.24656543, 0.041146018]\n",
      "Iter 199, loss [-0.2071435, -0.24753289, 0.04038939]\n",
      "Iter 200, loss [-0.20780985, -0.2467084, 0.03889854]\n",
      "Iter 201, loss [-0.20915629, -0.24777596, 0.038619664]\n",
      "Iter 202, loss [-0.24267252, -0.3067055, 0.06403299]\n",
      "Iter 203, loss [-0.22347265, -0.2628964, 0.03942374]\n",
      "Iter 204, loss [-0.22613338, -0.28632867, 0.060195304]\n",
      "Iter 205, loss [-0.20976673, -0.25634754, 0.046580806]\n",
      "Iter 206, loss [-0.21794212, -0.25664222, 0.03870011]\n",
      "Iter 207, loss [-0.23822056, -0.31079295, 0.072572395]\n",
      "Iter 208, loss [-0.215453, -0.25560218, 0.04014919]\n",
      "Iter 209, loss [-0.20439881, -0.24409327, 0.039694455]\n",
      "Iter 210, loss [-0.2061995, -0.24983771, 0.043638222]\n",
      "Iter 211, loss [-0.2091186, -0.24863598, 0.03951738]\n",
      "Iter 212, loss [-0.21475391, -0.25462693, 0.039873015]\n",
      "Iter 213, loss [-0.21073729, -0.25405192, 0.043314636]\n",
      "Iter 214, loss [-0.22295517, -0.26499242, 0.04203725]\n",
      "Iter 215, loss [-0.21579847, -0.25838575, 0.042587288]\n",
      "Iter 216, loss [-0.21748567, -0.25844643, 0.04096076]\n",
      "Iter 217, loss [-0.21550168, -0.2558547, 0.04035301]\n",
      "Iter 218, loss [-0.20967118, -0.24921256, 0.03954138]\n",
      "Iter 219, loss [-0.23781171, -0.31049716, 0.07268545]\n",
      "Iter 220, loss [-0.2193481, -0.26173362, 0.04238552]\n",
      "Iter 221, loss [-0.22658151, -0.2667639, 0.040182374]\n",
      "Iter 222, loss [-0.21044497, -0.25676078, 0.046315804]\n",
      "Iter 223, loss [-0.22545205, -0.26423457, 0.03878252]\n",
      "Iter 224, loss [-0.21589956, -0.25502405, 0.03912448]\n",
      "Iter 225, loss [-0.20707558, -0.24465147, 0.037575882]\n",
      "Iter 226, loss [-0.220032, -0.25809926, 0.038067248]\n",
      "Iter 227, loss [-0.20645249, -0.24705942, 0.040606923]\n",
      "Iter 228, loss [-0.22637454, -0.26307446, 0.036699913]\n",
      "Iter 229, loss [-0.21614102, -0.2551779, 0.039036863]\n",
      "Iter 230, loss [-0.23657863, -0.3081564, 0.07157777]\n",
      "Iter 231, loss [-0.22202343, -0.30340627, 0.08138283]\n",
      "Iter 232, loss [-0.20971859, -0.24986322, 0.040144645]\n",
      "Iter 233, loss [-0.20694567, -0.24436696, 0.037421282]\n",
      "Iter 234, loss [-0.2090899, -0.24896662, 0.039876707]\n",
      "Iter 235, loss [-0.22568925, -0.26306173, 0.03737249]\n",
      "Iter 236, loss [-0.22247119, -0.25976166, 0.03729047]\n",
      "Iter 237, loss [-0.21761827, -0.25396162, 0.036343347]\n",
      "Iter 238, loss [-0.18025063, -0.2289287, 0.04867807]\n",
      "Iter 239, loss [-0.22445533, -0.26438206, 0.039926734]\n",
      "Iter 240, loss [-0.2121197, -0.24794602, 0.035826325]\n",
      "Iter 241, loss [-0.21791437, -0.25540322, 0.037488855]\n",
      "Iter 242, loss [-0.230075, -0.2678434, 0.0377684]\n",
      "Iter 243, loss [-0.226485, -0.2658724, 0.03938739]\n",
      "Iter 244, loss [-0.21188697, -0.24971223, 0.03782526]\n",
      "Iter 245, loss [-0.22703063, -0.26688263, 0.039851986]\n",
      "Iter 246, loss [-0.20803049, -0.24660656, 0.038576066]\n",
      "Iter 247, loss [-0.20497854, -0.24231781, 0.037339266]\n",
      "Iter 248, loss [-0.20928791, -0.25849184, 0.04920393]\n",
      "Iter 249, loss [-0.22772843, -0.2670352, 0.039306767]\n",
      "Iter 250, loss [-0.23448434, -0.29736963, 0.06288528]\n",
      "Iter 251, loss [-0.22857419, -0.26600268, 0.03742849]\n",
      "Iter 252, loss [-0.20692413, -0.24493311, 0.038008984]\n",
      "Iter 253, loss [-0.20753662, -0.24586016, 0.038323533]\n",
      "Iter 254, loss [-0.2173295, -0.2545073, 0.037177797]\n",
      "Iter 255, loss [-0.20794755, -0.24893486, 0.04098732]\n",
      "Iter 256, loss [-0.21766059, -0.25495726, 0.037296668]\n",
      "Iter 257, loss [-0.24244484, -0.3078756, 0.06543076]\n",
      "Iter 258, loss [-0.23815118, -0.3115103, 0.07335912]\n",
      "Iter 259, loss [-0.21665658, -0.2609526, 0.04429601]\n",
      "Iter 260, loss [-0.20973252, -0.25684005, 0.04710753]\n",
      "Iter 261, loss [-0.20137885, -0.23953064, 0.038151793]\n",
      "Iter 262, loss [-0.222181, -0.26000503, 0.037824024]\n",
      "Iter 263, loss [-0.20771465, -0.24552375, 0.037809096]\n",
      "Iter 264, loss [-0.20790572, -0.25108448, 0.04317875]\n",
      "Iter 265, loss [-0.30614528, -0.31607705, 0.009931763]\n",
      "Iter 266, loss [-0.21689036, -0.25593764, 0.039047267]\n",
      "Iter 267, loss [-0.2163333, -0.26158836, 0.045255065]\n",
      "Iter 268, loss [-0.2159313, -0.255807, 0.039875723]\n",
      "Iter 269, loss [-0.2126134, -0.25651148, 0.043898072]\n",
      "Iter 270, loss [-0.21052477, -0.24967527, 0.039150514]\n",
      "Iter 271, loss [-0.22445169, -0.2627407, 0.03828901]\n",
      "Iter 272, loss [-0.21082357, -0.25062624, 0.039802678]\n",
      "Iter 273, loss [-0.3066537, -0.31618848, 0.009534764]\n",
      "Iter 274, loss [-0.21026278, -0.2477324, 0.037469633]\n",
      "Iter 275, loss [-0.23505646, -0.3058108, 0.07075436]\n",
      "Iter 276, loss [-0.20877334, -0.24697244, 0.038199093]\n",
      "Iter 277, loss [-0.22272813, -0.26138648, 0.03865835]\n",
      "Iter 278, loss [-0.21604103, -0.3008592, 0.084818184]\n",
      "Iter 279, loss [-0.21971947, -0.26628324, 0.046563767]\n",
      "Iter 280, loss [-0.20403266, -0.24030712, 0.03627446]\n",
      "Iter 281, loss [-0.20393038, -0.23975985, 0.035829477]\n",
      "Iter 282, loss [-0.22283484, -0.2605017, 0.03766687]\n",
      "Iter 283, loss [-0.21680732, -0.25671357, 0.03990625]\n",
      "Iter 284, loss [-0.23138355, -0.29153013, 0.060146585]\n",
      "Iter 285, loss [-0.2194112, -0.25790283, 0.038491644]\n",
      "Iter 286, loss [-0.20226125, -0.25231007, 0.05004881]\n",
      "Iter 287, loss [-0.20853063, -0.25417492, 0.045644276]\n",
      "Iter 288, loss [-0.20788626, -0.24940723, 0.041520964]\n",
      "Iter 289, loss [-0.21619363, -0.25920993, 0.0430163]\n",
      "Iter 290, loss [-0.20809194, -0.2477393, 0.039647356]\n",
      "Iter 291, loss [-0.21513525, -0.2546016, 0.039466348]\n",
      "Iter 292, loss [-0.22654642, -0.2646019, 0.03805547]\n",
      "Iter 293, loss [-0.19663005, -0.24292412, 0.046294075]\n",
      "Iter 294, loss [-0.21145767, -0.25612924, 0.044671565]\n",
      "Iter 295, loss [-0.20641723, -0.24234009, 0.03592285]\n",
      "Iter 296, loss [-0.21719283, -0.2569369, 0.039744075]\n",
      "Iter 297, loss [-0.21702996, -0.2546079, 0.037577923]\n",
      "Iter 298, loss [-0.21919687, -0.25769895, 0.03850208]\n",
      "Iter 299, loss [-0.22508654, -0.263387, 0.03830045]\n",
      "Iter 300, loss [-0.21346276, -0.2528546, 0.03939183]\n",
      "Iter 301, loss [-0.22263198, -0.26135287, 0.038720887]\n",
      "Iter 302, loss [-0.21012649, -0.24850573, 0.038379237]\n",
      "Iter 303, loss [-0.20635843, -0.24380532, 0.037446894]\n",
      "Iter 304, loss [-0.20641999, -0.24858381, 0.042163815]\n",
      "Iter 305, loss [-0.2091472, -0.25708652, 0.04793931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 306, loss [-0.22451597, -0.2651618, 0.04064583]\n",
      "Iter 307, loss [-0.21963844, -0.2585978, 0.038959347]\n",
      "Iter 308, loss [-0.21655025, -0.25476623, 0.03821598]\n",
      "Iter 309, loss [-0.2090751, -0.24686255, 0.03778746]\n",
      "Iter 310, loss [-0.22708994, -0.2646188, 0.037528876]\n",
      "Iter 311, loss [-0.21615444, -0.25482076, 0.038666323]\n",
      "Iter 312, loss [-0.21099782, -0.25563127, 0.044633444]\n",
      "Iter 313, loss [-0.20994847, -0.24782132, 0.037872855]\n",
      "Iter 314, loss [-0.2084174, -0.2521114, 0.043694]\n",
      "Iter 315, loss [-0.21575785, -0.25652364, 0.040765796]\n",
      "Iter 316, loss [-0.2124128, -0.24965662, 0.03724382]\n",
      "Iter 317, loss [-0.21315771, -0.2523711, 0.039213397]\n",
      "Iter 318, loss [-0.20916604, -0.24929339, 0.040127352]\n",
      "Iter 319, loss [-0.20998102, -0.2496902, 0.039709173]\n",
      "Iter 320, loss [-0.21740817, -0.25657204, 0.03916387]\n",
      "Iter 321, loss [-0.20749915, -0.24516644, 0.037667297]\n",
      "Iter 322, loss [-0.21514589, -0.25502717, 0.039881296]\n",
      "Iter 323, loss [-0.21706343, -0.25569835, 0.03863492]\n",
      "Iter 324, loss [-0.23561615, -0.31132755, 0.07571139]\n",
      "Iter 325, loss [-0.21975404, -0.25935978, 0.03960573]\n",
      "Iter 326, loss [-0.21553713, -0.25481993, 0.039282806]\n",
      "Iter 327, loss [-0.22449884, -0.26597077, 0.04147192]\n",
      "Iter 328, loss [-0.2147395, -0.25352493, 0.038785435]\n",
      "Iter 329, loss [-0.2205774, -0.2653244, 0.044747006]\n",
      "Iter 330, loss [-0.22049844, -0.25759003, 0.037091576]\n",
      "Iter 331, loss [-0.2104564, -0.24973519, 0.039278798]\n",
      "Iter 332, loss [-0.21217608, -0.2541991, 0.042022996]\n",
      "Iter 333, loss [-0.20293558, -0.2425091, 0.03957352]\n",
      "Iter 334, loss [-0.19726612, -0.24425092, 0.046984803]\n",
      "Iter 335, loss [-0.22379771, -0.26731694, 0.04351922]\n",
      "Iter 336, loss [-0.21658218, -0.25370142, 0.037119232]\n",
      "Iter 337, loss [-0.21799755, -0.257646, 0.03964844]\n",
      "Iter 338, loss [-0.21745953, -0.25699392, 0.039534386]\n",
      "Iter 339, loss [-0.21189232, -0.25256342, 0.040671095]\n",
      "Iter 340, loss [-0.22768624, -0.2674186, 0.03973235]\n",
      "Iter 341, loss [-0.21852557, -0.25986677, 0.0413412]\n",
      "Iter 342, loss [-0.217769, -0.2573995, 0.039630502]\n",
      "Iter 343, loss [-0.22242543, -0.26067257, 0.038247142]\n",
      "Iter 344, loss [-0.21008308, -0.24978292, 0.03969984]\n",
      "Iter 345, loss [-0.2267485, -0.27190566, 0.045157164]\n",
      "Iter 346, loss [-0.21586657, -0.25408766, 0.038221087]\n",
      "Iter 347, loss [-0.22812817, -0.26644778, 0.038319618]\n",
      "Iter 348, loss [-0.22303489, -0.2604996, 0.037464708]\n",
      "Iter 349, loss [-0.19598778, -0.28618443, 0.090196654]\n",
      "Iter 350, loss [-0.20396993, -0.24167138, 0.037701458]\n",
      "Iter 351, loss [-0.21141958, -0.2537626, 0.042343013]\n",
      "Iter 352, loss [-0.20608531, -0.2515595, 0.045474187]\n",
      "Iter 353, loss [-0.2174097, -0.25911218, 0.041702487]\n",
      "Iter 354, loss [-0.20156333, -0.24482284, 0.043259513]\n",
      "Iter 355, loss [-0.21741363, -0.25320074, 0.035787098]\n",
      "Iter 356, loss [-0.22229739, -0.26142573, 0.039128352]\n",
      "Iter 357, loss [-0.21220666, -0.24911185, 0.036905184]\n",
      "Iter 358, loss [-0.2192442, -0.25541234, 0.036168143]\n",
      "Iter 359, loss [-0.23320481, -0.30021647, 0.06701165]\n",
      "Iter 360, loss [-0.2044236, -0.24548478, 0.041061174]\n",
      "Iter 361, loss [-0.22332135, -0.26548082, 0.042159475]\n",
      "Iter 362, loss [-0.20147705, -0.2401607, 0.038683645]\n",
      "Iter 363, loss [-0.21511611, -0.25497377, 0.039857656]\n",
      "Iter 364, loss [-0.21520239, -0.25463057, 0.039428182]\n",
      "Iter 365, loss [-0.22109666, -0.25885463, 0.037757967]\n",
      "Iter 366, loss [-0.20965865, -0.2477185, 0.038059838]\n",
      "Iter 367, loss [-0.2117982, -0.25366876, 0.041870546]\n",
      "Iter 368, loss [-0.20643476, -0.24540743, 0.038972676]\n",
      "Iter 369, loss [-0.21408808, -0.2856382, 0.07155012]\n",
      "Iter 370, loss [-0.22171038, -0.25979874, 0.03808835]\n",
      "Iter 371, loss [-0.2244049, -0.26250282, 0.038097918]\n",
      "Iter 372, loss [-0.24222468, -0.28717348, 0.044948798]\n",
      "Iter 373, loss [-0.20199561, -0.23908666, 0.037091043]\n",
      "Iter 374, loss [-0.19891414, -0.24429409, 0.04537996]\n",
      "Iter 375, loss [-0.21619394, -0.25724688, 0.041052938]\n",
      "Iter 376, loss [-0.21356648, -0.25541764, 0.041851155]\n",
      "Iter 377, loss [-0.21595623, -0.25769612, 0.041739892]\n",
      "Iter 378, loss [-0.20207128, -0.2438477, 0.041776415]\n",
      "Iter 379, loss [-0.19349211, -0.23399496, 0.040502846]\n",
      "Iter 380, loss [-0.2091492, -0.24692696, 0.03777777]\n",
      "Iter 381, loss [-0.21392173, -0.2518329, 0.03791117]\n",
      "Iter 382, loss [-0.20907243, -0.24757189, 0.03849946]\n",
      "Iter 383, loss [-0.22204326, -0.26170877, 0.039665505]\n",
      "Iter 384, loss [-0.22196333, -0.28569707, 0.06373374]\n",
      "Iter 385, loss [-0.21497968, -0.25165746, 0.036677778]\n",
      "Iter 386, loss [-0.17868845, -0.22618051, 0.047492053]\n",
      "Iter 387, loss [-0.23888774, -0.2742575, 0.035369772]\n",
      "Iter 388, loss [-0.21952882, -0.25938737, 0.03985855]\n",
      "Iter 389, loss [-0.23421432, -0.2925088, 0.05829449]\n",
      "Iter 390, loss [-0.20883156, -0.25829974, 0.049468175]\n",
      "Iter 391, loss [-0.22639182, -0.265239, 0.03884717]\n",
      "Iter 392, loss [-0.22457047, -0.26465207, 0.0400816]\n",
      "Iter 393, loss [-0.20058456, -0.24001224, 0.03942768]\n",
      "Iter 394, loss [-0.19835092, -0.23442423, 0.036073312]\n",
      "Iter 395, loss [-0.21196674, -0.25356764, 0.0416009]\n",
      "Iter 396, loss [-0.22358435, -0.2668949, 0.043310553]\n",
      "Iter 397, loss [-0.20954835, -0.24674216, 0.037193805]\n",
      "Iter 398, loss [-0.21528032, -0.25575733, 0.040477]\n",
      "Iter 399, loss [-0.22099131, -0.25862244, 0.037631124]\n",
      "Iter 400, loss [-0.22343802, -0.2619868, 0.038548768]\n",
      "Iter 401, loss [-0.22076935, -0.26842573, 0.047656395]\n",
      "Iter 402, loss [-0.22408554, -0.26907897, 0.044993427]\n",
      "Iter 403, loss [-0.22734958, -0.26707226, 0.039722677]\n",
      "Iter 404, loss [-0.2170421, -0.25526297, 0.038220864]\n",
      "Iter 405, loss [-0.22004344, -0.29839006, 0.078346625]\n",
      "Iter 406, loss [-0.2085877, -0.25136536, 0.042777658]\n",
      "Iter 407, loss [-0.20970365, -0.2575676, 0.047863968]\n",
      "Iter 408, loss [-0.20113698, -0.24162607, 0.04048909]\n",
      "Iter 409, loss [-0.23349011, -0.30707553, 0.07358541]\n",
      "Iter 410, loss [-0.21724099, -0.25540107, 0.038160093]\n",
      "Iter 411, loss [-0.18034822, -0.22821105, 0.04786282]\n",
      "Iter 412, loss [-0.20916498, -0.25619668, 0.047031693]\n",
      "Iter 413, loss [-0.21199766, -0.25061262, 0.038614955]\n",
      "Iter 414, loss [-0.21468693, -0.25296098, 0.038274042]\n",
      "Iter 415, loss [-0.2454598, -0.28949103, 0.04403124]\n",
      "Iter 416, loss [-0.2091871, -0.24852008, 0.039332967]\n",
      "Iter 417, loss [-0.21324077, -0.25351465, 0.040273875]\n",
      "Iter 418, loss [-0.23404074, -0.29070616, 0.056665413]\n",
      "Iter 419, loss [-0.21399781, -0.2533606, 0.03936278]\n",
      "Iter 420, loss [-0.22455609, -0.26677358, 0.04221749]\n",
      "Iter 421, loss [-0.20822528, -0.25201192, 0.04378664]\n",
      "Iter 422, loss [-0.21412934, -0.25449964, 0.0403703]\n",
      "Iter 423, loss [-0.21791843, -0.25944048, 0.04152206]\n",
      "Iter 424, loss [-0.22208679, -0.26083654, 0.03874976]\n",
      "Iter 425, loss [-0.22691403, -0.26553532, 0.03862129]\n",
      "Iter 426, loss [-0.20968086, -0.24929819, 0.039617326]\n",
      "Iter 427, loss [-0.2101438, -0.24929234, 0.03914853]\n",
      "Iter 428, loss [-0.2064099, -0.24344131, 0.03703141]\n",
      "Iter 429, loss [-0.22528711, -0.26353288, 0.038245767]\n",
      "Iter 430, loss [-0.20284408, -0.24203824, 0.039194148]\n",
      "Iter 431, loss [-0.21011795, -0.2473881, 0.037270144]\n",
      "Iter 432, loss [-0.22790065, -0.26542056, 0.037519906]\n",
      "Iter 433, loss [-0.20482609, -0.25295177, 0.048125684]\n",
      "Iter 434, loss [-0.21672484, -0.25462735, 0.037902504]\n",
      "Iter 435, loss [-0.20513459, -0.25349447, 0.048359882]\n",
      "Iter 436, loss [-0.21053375, -0.24791251, 0.03737876]\n",
      "Iter 437, loss [-0.21029428, -0.24975844, 0.03946417]\n",
      "Iter 438, loss [-0.2281475, -0.2673547, 0.03920719]\n",
      "Iter 439, loss [-0.20785758, -0.24596573, 0.038108163]\n",
      "Iter 440, loss [-0.21141075, -0.24976642, 0.038355675]\n",
      "Iter 441, loss [-0.20506908, -0.24278793, 0.03771885]\n",
      "Iter 442, loss [-0.20921908, -0.24900965, 0.039790574]\n",
      "Iter 443, loss [-0.20360246, -0.24260274, 0.03900027]\n",
      "Iter 444, loss [-0.22542474, -0.26189762, 0.036472887]\n",
      "Iter 445, loss [-0.20243649, -0.24529533, 0.04285884]\n",
      "Iter 446, loss [-0.21767716, -0.25580817, 0.038131017]\n",
      "Iter 447, loss [-0.22152907, -0.2677816, 0.04625251]\n",
      "Iter 448, loss [-0.21997294, -0.2608187, 0.040845755]\n",
      "Iter 449, loss [-0.24527952, -0.3084611, 0.06318158]\n",
      "Iter 450, loss [-0.22862242, -0.26788282, 0.039260402]\n",
      "Iter 451, loss [-0.2213119, -0.30492604, 0.08361413]\n",
      "Iter 452, loss [-0.19767159, -0.24481909, 0.047147505]\n",
      "Iter 453, loss [-0.22708133, -0.26458576, 0.037504435]\n",
      "Iter 454, loss [-0.30689165, -0.31667957, 0.009787903]\n",
      "Iter 455, loss [-0.21190205, -0.25313804, 0.041235976]\n",
      "Iter 456, loss [-0.20439892, -0.25167334, 0.047274422]\n",
      "Iter 457, loss [-0.21807292, -0.25536022, 0.037287287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 458, loss [-0.18056248, -0.22848915, 0.04792666]\n",
      "Iter 459, loss [-0.217662, -0.25449172, 0.03682971]\n",
      "Iter 460, loss [-0.20452747, -0.24060592, 0.03607846]\n",
      "Iter 461, loss [-0.21202426, -0.25133544, 0.03931118]\n",
      "Iter 462, loss [-0.22659308, -0.2644666, 0.037873544]\n",
      "Iter 463, loss [-0.21797699, -0.25947195, 0.041494973]\n",
      "Iter 464, loss [-0.20952585, -0.24914598, 0.039620124]\n",
      "Iter 465, loss [-0.21313232, -0.25541052, 0.042278208]\n",
      "Iter 466, loss [-0.20703346, -0.24489668, 0.037863225]\n",
      "Iter 467, loss [-0.21072318, -0.24869344, 0.037970256]\n",
      "Iter 468, loss [-0.217072, -0.25511718, 0.038045183]\n",
      "Iter 469, loss [-0.20623054, -0.24692732, 0.040696785]\n",
      "Iter 470, loss [-0.21717422, -0.28057283, 0.063398615]\n",
      "Iter 471, loss [-0.21485214, -0.25591454, 0.041062396]\n",
      "Iter 472, loss [-0.22290707, -0.26802498, 0.045117907]\n",
      "Iter 473, loss [-0.21008132, -0.25519568, 0.04511435]\n",
      "Iter 474, loss [-0.21500975, -0.25559735, 0.04058761]\n",
      "Iter 475, loss [-0.21983962, -0.25964987, 0.039810255]\n",
      "Iter 476, loss [-0.22302935, -0.26206577, 0.039036416]\n",
      "Iter 477, loss [-0.2153257, -0.25531688, 0.039991185]\n",
      "Iter 478, loss [-0.22687097, -0.26460674, 0.03773577]\n",
      "Iter 479, loss [-0.21139073, -0.25165612, 0.04026539]\n",
      "Iter 480, loss [-0.21242131, -0.2528003, 0.040378973]\n",
      "Iter 481, loss [-0.21583304, -0.25390404, 0.038071014]\n",
      "Iter 482, loss [-0.20984569, -0.24826363, 0.03841793]\n",
      "Iter 483, loss [-0.23616713, -0.31067255, 0.07450542]\n",
      "Iter 484, loss [-0.23901336, -0.31184372, 0.072830364]\n",
      "Iter 485, loss [-0.20110765, -0.24035403, 0.039246377]\n",
      "Iter 486, loss [-0.21122241, -0.25118306, 0.039960653]\n",
      "Iter 487, loss [-0.22565567, -0.2623241, 0.036668427]\n",
      "Iter 488, loss [-0.20354101, -0.24337761, 0.039836604]\n",
      "Iter 489, loss [-0.21085653, -0.24902722, 0.038170695]\n",
      "Iter 490, loss [-0.22661467, -0.26434335, 0.037728686]\n",
      "Iter 491, loss [-0.21243991, -0.2578084, 0.045368474]\n",
      "Iter 492, loss [-0.20880398, -0.27094302, 0.062139034]\n",
      "Iter 493, loss [-0.2059683, -0.24713781, 0.041169506]\n",
      "Iter 494, loss [-0.21476308, -0.25762498, 0.0428619]\n",
      "Iter 495, loss [-0.2167633, -0.25596845, 0.03920515]\n",
      "Iter 496, loss [-0.21708754, -0.25543967, 0.03835213]\n",
      "Iter 497, loss [-0.22433725, -0.26202834, 0.037691087]\n",
      "Iter 498, loss [-0.23185863, -0.2874834, 0.05562477]\n",
      "Iter 499, loss [-0.21726787, -0.25319564, 0.03592778]\n",
      "Iter 500, loss [-0.20243964, -0.2405862, 0.03814657]\n",
      "Iter 501, loss [-0.21883166, -0.25729865, 0.038466997]\n",
      "Iter 502, loss [-0.20825195, -0.2458339, 0.037581943]\n",
      "Iter 503, loss [-0.21870418, -0.25836834, 0.039664164]\n",
      "Iter 504, loss [-0.21590021, -0.25464487, 0.038744666]\n",
      "Iter 505, loss [-0.18032642, -0.23019302, 0.049866598]\n",
      "Iter 506, loss [-0.21771307, -0.25443554, 0.036722463]\n",
      "Iter 507, loss [-0.21445611, -0.25363833, 0.03918221]\n",
      "Iter 508, loss [-0.21088445, -0.25127405, 0.040389605]\n",
      "Iter 509, loss [-0.22452217, -0.26615113, 0.041628957]\n",
      "Iter 510, loss [-0.21938117, -0.25922903, 0.039847866]\n",
      "Iter 511, loss [-0.21487306, -0.25408518, 0.039212123]\n",
      "Iter 512, loss [-0.23482725, -0.30740622, 0.07257896]\n",
      "Iter 513, loss [-0.20714964, -0.24529095, 0.03814131]\n",
      "Iter 514, loss [-0.19702068, -0.24368683, 0.046666145]\n",
      "Iter 515, loss [-0.2120236, -0.24830315, 0.036279544]\n",
      "Iter 516, loss [-0.21655811, -0.2544864, 0.037928294]\n",
      "Iter 517, loss [-0.22711796, -0.26527584, 0.03815788]\n",
      "Iter 518, loss [-0.21820936, -0.25520942, 0.03700006]\n",
      "Iter 519, loss [-0.20497008, -0.24183778, 0.036867708]\n",
      "Iter 520, loss [-0.2033634, -0.24280255, 0.039439138]\n",
      "Iter 521, loss [-0.22672814, -0.2702277, 0.043499555]\n",
      "Iter 522, loss [-0.20157173, -0.24389102, 0.04231928]\n",
      "Iter 523, loss [-0.24586608, -0.29033002, 0.044463944]\n",
      "Iter 524, loss [-0.22114627, -0.28260675, 0.061460476]\n",
      "Iter 525, loss [-0.22660263, -0.2631691, 0.036566477]\n",
      "Iter 526, loss [-0.20998973, -0.2489231, 0.03893336]\n",
      "Iter 527, loss [-0.21639788, -0.26106793, 0.04467004]\n",
      "Iter 528, loss [-0.21776477, -0.25827238, 0.040507607]\n",
      "Iter 529, loss [-0.20180525, -0.24160036, 0.039795116]\n",
      "Iter 530, loss [-0.20385966, -0.24572714, 0.041867487]\n",
      "Iter 531, loss [-0.21536615, -0.25613835, 0.040772207]\n",
      "Iter 532, loss [-0.20485684, -0.25445595, 0.04959911]\n",
      "Iter 533, loss [-0.21955375, -0.2601375, 0.040583745]\n",
      "Iter 534, loss [-0.20868498, -0.24862254, 0.039937563]\n",
      "Iter 535, loss [-0.21041939, -0.24956498, 0.039145585]\n",
      "Iter 536, loss [-0.22534943, -0.26233235, 0.036982924]\n",
      "Iter 537, loss [-0.21664457, -0.2615837, 0.044939112]\n",
      "Iter 538, loss [-0.21997362, -0.25844812, 0.0384745]\n",
      "Iter 539, loss [-0.2053594, -0.24209888, 0.03673949]\n",
      "Iter 540, loss [-0.20759374, -0.24572301, 0.03812927]\n",
      "Iter 541, loss [-0.20387721, -0.24363503, 0.039757818]\n",
      "Iter 542, loss [-0.20522037, -0.2541696, 0.04894924]\n",
      "Iter 543, loss [-0.22805801, -0.26785162, 0.03979361]\n",
      "Iter 544, loss [-0.21338695, -0.25279447, 0.039407514]\n",
      "Iter 545, loss [-0.20265044, -0.24645242, 0.043801975]\n",
      "Iter 546, loss [-0.22501945, -0.2936979, 0.068678446]\n",
      "Iter 547, loss [-0.21089095, -0.2511762, 0.040285252]\n",
      "Iter 548, loss [-0.2155379, -0.25494182, 0.039403915]\n",
      "Iter 549, loss [-0.21448216, -0.2558487, 0.041366547]\n",
      "Iter 550, loss [-0.20535351, -0.24182394, 0.036470424]\n",
      "Iter 551, loss [-0.20456809, -0.2424795, 0.037911415]\n",
      "Iter 552, loss [-0.2261232, -0.29633412, 0.07021092]\n",
      "Iter 553, loss [-0.22480701, -0.2651033, 0.0402963]\n",
      "Iter 554, loss [-0.3068125, -0.31661594, 0.009803454]\n",
      "Iter 555, loss [-0.2172969, -0.25968894, 0.042392038]\n",
      "Iter 556, loss [-0.21510938, -0.2542828, 0.039173424]\n",
      "Iter 557, loss [-0.21660106, -0.2532917, 0.036690637]\n",
      "Iter 558, loss [-0.21031255, -0.24860144, 0.0382889]\n",
      "Iter 559, loss [-0.22350408, -0.26315698, 0.0396529]\n",
      "Iter 560, loss [-0.19887066, -0.23536417, 0.036493517]\n",
      "Iter 561, loss [-0.22103323, -0.26833063, 0.047297403]\n",
      "Iter 562, loss [-0.21016735, -0.24835332, 0.03818597]\n",
      "Iter 563, loss [-0.21166626, -0.25134787, 0.03968162]\n",
      "Iter 564, loss [-0.21010126, -0.24954902, 0.039447755]\n",
      "Iter 565, loss [-0.24009308, -0.27567327, 0.035580195]\n",
      "Iter 566, loss [-0.21565153, -0.2549808, 0.039329275]\n",
      "Iter 567, loss [-0.21603172, -0.25534636, 0.03931464]\n",
      "Iter 568, loss [-0.2136621, -0.2548047, 0.041142598]\n",
      "Iter 569, loss [-0.22318628, -0.26043352, 0.037247248]\n",
      "Iter 570, loss [-0.21046841, -0.24921204, 0.038743626]\n",
      "Iter 571, loss [-0.22533503, -0.26566082, 0.040325783]\n",
      "Iter 572, loss [-0.2104884, -0.24990876, 0.039420363]\n",
      "Iter 573, loss [-0.21402267, -0.25476593, 0.040743254]\n",
      "Iter 574, loss [-0.2164751, -0.2556009, 0.039125793]\n",
      "Iter 575, loss [-0.21775037, -0.2610489, 0.043298542]\n",
      "Iter 576, loss [-0.22105199, -0.25833192, 0.03727994]\n",
      "Iter 577, loss [-0.21234578, -0.24928154, 0.03693576]\n",
      "Iter 578, loss [-0.2197116, -0.29930165, 0.07959006]\n",
      "Iter 579, loss [-0.22112465, -0.26829356, 0.047168918]\n",
      "Iter 580, loss [-0.22117954, -0.26026407, 0.039084524]\n",
      "Iter 581, loss [-0.21407473, -0.25450578, 0.040431052]\n",
      "Iter 582, loss [-0.20598532, -0.24868755, 0.042702224]\n",
      "Iter 583, loss [-0.2271911, -0.2663787, 0.03918759]\n",
      "Iter 584, loss [-0.19860981, -0.28916985, 0.090560034]\n",
      "Iter 585, loss [-0.22503567, -0.266095, 0.041059338]\n",
      "Iter 586, loss [-0.20090812, -0.23457244, 0.03366431]\n",
      "Iter 587, loss [-0.18392701, -0.23762204, 0.053695023]\n",
      "Iter 588, loss [-0.23579961, -0.2703416, 0.034541987]\n",
      "Iter 589, loss [-0.19807577, -0.26646438, 0.06838861]\n",
      "Iter 590, loss [-0.2042012, -0.24190497, 0.037703767]\n",
      "Iter 591, loss [-0.20649976, -0.24561054, 0.039110787]\n",
      "Iter 592, loss [-0.20549701, -0.25218138, 0.04668437]\n",
      "Iter 593, loss [-0.2068771, -0.2565504, 0.049673304]\n",
      "Iter 594, loss [-0.20421219, -0.24624303, 0.04203084]\n",
      "Iter 595, loss [-0.22862776, -0.29648972, 0.06786196]\n",
      "Iter 596, loss [-0.2182249, -0.25670952, 0.038484614]\n",
      "Iter 597, loss [-0.21236491, -0.24883798, 0.036473062]\n",
      "Iter 598, loss [-0.21405128, -0.2515451, 0.03749382]\n",
      "Iter 599, loss [-0.2029302, -0.24443787, 0.041507676]\n",
      "Iter 600, loss [-0.2128609, -0.2511804, 0.038319513]\n",
      "Iter 601, loss [-0.21549574, -0.25721556, 0.041719817]\n",
      "Iter 602, loss [-0.21508758, -0.2542977, 0.039210126]\n",
      "Iter 603, loss [-0.20757371, -0.24796493, 0.040391225]\n",
      "Iter 604, loss [-0.21914372, -0.29991496, 0.08077123]\n",
      "Iter 605, loss [-0.239163, -0.3012889, 0.062125903]\n",
      "Iter 606, loss [-0.21206066, -0.2559809, 0.04392024]\n",
      "Iter 607, loss [-0.2427006, -0.2844248, 0.0417242]\n",
      "Iter 608, loss [-0.20346138, -0.243847, 0.04038561]\n",
      "Iter 609, loss [-0.1781902, -0.22560352, 0.047413327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610, loss [-0.22004583, -0.26289317, 0.042847328]\n",
      "Iter 611, loss [-0.21297401, -0.24944057, 0.036466554]\n",
      "Iter 612, loss [-0.20371999, -0.24670856, 0.042988565]\n",
      "Iter 613, loss [-0.20393807, -0.24572876, 0.0417907]\n",
      "Iter 614, loss [-0.19766103, -0.23748848, 0.039827447]\n",
      "Iter 615, loss [-0.20763867, -0.2550239, 0.047385227]\n",
      "Iter 616, loss [-0.20521131, -0.24582657, 0.040615268]\n",
      "Iter 617, loss [-0.17471528, -0.2268558, 0.052140515]\n",
      "Iter 618, loss [-0.20321442, -0.2416514, 0.038436983]\n",
      "Iter 619, loss [-0.20134792, -0.24062403, 0.03927611]\n",
      "Iter 620, loss [-0.21383595, -0.24804991, 0.034213968]\n",
      "Iter 621, loss [-0.2084891, -0.2421215, 0.033632398]\n",
      "Iter 622, loss [-0.20475513, -0.24172518, 0.03697005]\n",
      "Iter 623, loss [-0.21763714, -0.2778554, 0.060218256]\n",
      "Iter 624, loss [-0.21558085, -0.2575961, 0.04201525]\n",
      "Iter 625, loss [-0.215676, -0.25466457, 0.03898857]\n",
      "Iter 626, loss [-0.20602462, -0.24818213, 0.042157512]\n",
      "Iter 627, loss [-0.21605825, -0.25739273, 0.04133448]\n",
      "Iter 628, loss [-0.20770968, -0.24965106, 0.04194137]\n",
      "Iter 629, loss [-0.2079311, -0.24713519, 0.039204083]\n",
      "Iter 630, loss [-0.23031428, -0.30179557, 0.07148129]\n",
      "Iter 631, loss [-0.22662282, -0.26577812, 0.0391553]\n",
      "Iter 632, loss [-0.22362219, -0.26289663, 0.039274435]\n",
      "Iter 633, loss [-0.20235643, -0.23928846, 0.03693203]\n",
      "Iter 634, loss [-0.21518038, -0.29938015, 0.08419977]\n",
      "Iter 635, loss [-0.23091716, -0.3094436, 0.078526445]\n",
      "Iter 636, loss [-0.20511743, -0.24242797, 0.037310537]\n",
      "Iter 637, loss [-0.2028693, -0.24624647, 0.04337717]\n",
      "Iter 638, loss [-0.20781656, -0.25225878, 0.04444222]\n",
      "Iter 639, loss [-0.21440443, -0.25077173, 0.036367305]\n",
      "Iter 640, loss [-0.2080816, -0.24274111, 0.0346595]\n",
      "Iter 641, loss [-0.17368272, -0.24118184, 0.067499116]\n",
      "Iter 642, loss [-0.2091581, -0.24881557, 0.03965747]\n",
      "Iter 643, loss [-0.2084747, -0.24961896, 0.04114426]\n",
      "Iter 644, loss [-0.21001439, -0.2611141, 0.0510997]\n",
      "Iter 645, loss [-0.21792585, -0.2627219, 0.044796042]\n",
      "Iter 646, loss [-0.20494553, -0.25077504, 0.045829512]\n",
      "Iter 647, loss [-0.2194959, -0.26503402, 0.045538113]\n",
      "Iter 648, loss [-0.19719683, -0.28543425, 0.08823742]\n",
      "Iter 649, loss [-0.21229847, -0.25416818, 0.041869715]\n",
      "Iter 650, loss [-0.20436472, -0.24152343, 0.037158713]\n",
      "Iter 651, loss [-0.22515167, -0.26089126, 0.035739582]\n",
      "Iter 652, loss [-0.21809706, -0.3000755, 0.08197844]\n",
      "Iter 653, loss [-0.21271709, -0.25208876, 0.039371673]\n",
      "Iter 654, loss [-0.20769204, -0.24085233, 0.033160284]\n",
      "Iter 655, loss [-0.21510899, -0.2501876, 0.035078615]\n",
      "Iter 656, loss [-0.21398851, -0.25101152, 0.037023008]\n",
      "Iter 657, loss [-0.21511039, -0.2502056, 0.035095207]\n",
      "Iter 658, loss [-0.22743511, -0.26403728, 0.036602166]\n",
      "Iter 659, loss [-0.20485558, -0.24788614, 0.043030556]\n",
      "Iter 660, loss [-0.1980767, -0.24105659, 0.04297989]\n",
      "Iter 661, loss [-0.20815481, -0.25810802, 0.049953204]\n",
      "Iter 662, loss [-0.21917513, -0.29189038, 0.07271525]\n",
      "Iter 663, loss [-0.20935339, -0.2484248, 0.039071403]\n",
      "Iter 664, loss [-0.22355272, -0.26109922, 0.0375465]\n",
      "Iter 665, loss [-0.21359809, -0.25380975, 0.040211663]\n",
      "Iter 666, loss [-0.20159087, -0.23926331, 0.037672438]\n",
      "Iter 667, loss [-0.2055479, -0.25418428, 0.048636373]\n",
      "Iter 668, loss [-0.21488541, -0.25315756, 0.038272142]\n",
      "Iter 669, loss [-0.22378765, -0.26741138, 0.04362373]\n",
      "Iter 670, loss [-0.20776355, -0.2513906, 0.04362705]\n",
      "Iter 671, loss [-0.20628646, -0.24478376, 0.03849729]\n",
      "Iter 672, loss [-0.2131637, -0.25460625, 0.04144255]\n",
      "Iter 673, loss [-0.21703471, -0.25685164, 0.039816927]\n",
      "Iter 674, loss [-0.21895438, -0.2593405, 0.040386107]\n",
      "Iter 675, loss [-0.21696766, -0.26011613, 0.04314847]\n",
      "Iter 676, loss [-0.30666712, -0.3165084, 0.009841296]\n",
      "Iter 677, loss [-0.20901662, -0.24567203, 0.03665541]\n",
      "Iter 678, loss [-0.22547315, -0.26326948, 0.03779633]\n",
      "Iter 679, loss [-0.24606955, -0.28889662, 0.042827062]\n",
      "Iter 680, loss [-0.20990214, -0.24881499, 0.038912855]\n",
      "Iter 681, loss [-0.21212271, -0.24886493, 0.03674222]\n",
      "Iter 682, loss [-0.22474632, -0.26822883, 0.043482512]\n",
      "Iter 683, loss [-0.21590073, -0.25622565, 0.040324908]\n",
      "Iter 684, loss [-0.22271444, -0.2609397, 0.03822525]\n",
      "Iter 685, loss [-0.2042894, -0.24470447, 0.040415064]\n",
      "Iter 686, loss [-0.23657341, -0.31496683, 0.078393415]\n",
      "Iter 687, loss [-0.2025155, -0.24145912, 0.038943615]\n",
      "Iter 688, loss [-0.22789484, -0.26568225, 0.0377874]\n",
      "Iter 689, loss [-0.21504703, -0.25742346, 0.04237643]\n",
      "Iter 690, loss [-0.22496632, -0.26698774, 0.042021424]\n",
      "Iter 691, loss [-0.22382414, -0.2648671, 0.041042954]\n",
      "Iter 692, loss [-0.2125378, -0.24964103, 0.037103243]\n",
      "Iter 693, loss [-0.20906653, -0.24955142, 0.04048489]\n",
      "Iter 694, loss [-0.22726142, -0.26443878, 0.037177347]\n",
      "Iter 695, loss [-0.21498877, -0.25433686, 0.03934809]\n",
      "Iter 696, loss [-0.22348845, -0.2609188, 0.03743035]\n",
      "Iter 697, loss [-0.2088096, -0.2515206, 0.042711]\n",
      "Iter 698, loss [-0.2191889, -0.2595142, 0.04032532]\n",
      "Iter 699, loss [-0.2370902, -0.31130135, 0.07421115]\n",
      "Iter 700, loss [-0.21487406, -0.2548524, 0.03997835]\n",
      "Iter 701, loss [-0.2176007, -0.25696492, 0.039364226]\n",
      "Iter 702, loss [-0.23592459, -0.3062384, 0.070313826]\n",
      "Iter 703, loss [-0.21543798, -0.2576466, 0.042208605]\n",
      "Iter 704, loss [-0.22236873, -0.304516, 0.082147256]\n",
      "Iter 705, loss [-0.2419787, -0.3081381, 0.06615939]\n",
      "Iter 706, loss [-0.18029279, -0.2294767, 0.049183927]\n",
      "Iter 707, loss [-0.21929948, -0.25889316, 0.03959368]\n",
      "Iter 708, loss [-0.23714525, -0.31719917, 0.08005392]\n",
      "Iter 709, loss [-0.21247934, -0.24855036, 0.036071014]\n",
      "Iter 710, loss [-0.22810112, -0.26681927, 0.03871815]\n",
      "Iter 711, loss [-0.22316484, -0.280551, 0.057386145]\n",
      "Iter 712, loss [-0.21187064, -0.2509596, 0.039088957]\n",
      "Iter 713, loss [-0.22598991, -0.2645703, 0.038580384]\n",
      "Iter 714, loss [-0.21955013, -0.2591815, 0.03963136]\n",
      "Iter 715, loss [-0.21591651, -0.2586254, 0.042708866]\n",
      "Iter 716, loss [-0.2307397, -0.268956, 0.038216308]\n",
      "Iter 717, loss [-0.22546603, -0.26362574, 0.038159717]\n",
      "Iter 718, loss [-0.22081241, -0.258846, 0.038033597]\n",
      "Iter 719, loss [-0.21782464, -0.2554063, 0.03758166]\n",
      "Iter 720, loss [-0.2118179, -0.25024998, 0.03843208]\n",
      "Iter 721, loss [-0.21028814, -0.257736, 0.04744786]\n",
      "Iter 722, loss [-0.30678332, -0.3162431, 0.009459801]\n",
      "Iter 723, loss [-0.21370015, -0.25164545, 0.037945293]\n",
      "Iter 724, loss [-0.21928233, -0.2572654, 0.03798306]\n",
      "Iter 725, loss [-0.21586253, -0.2566427, 0.040780168]\n",
      "Iter 726, loss [-0.20178825, -0.24088463, 0.039096378]\n",
      "Iter 727, loss [-0.22847591, -0.29668897, 0.06821306]\n",
      "Iter 728, loss [-0.2077881, -0.24563195, 0.03784385]\n",
      "Iter 729, loss [-0.20643872, -0.24735443, 0.040915713]\n",
      "Iter 730, loss [-0.1974766, -0.24420458, 0.04672798]\n",
      "Iter 731, loss [-0.21770638, -0.2545197, 0.03681331]\n",
      "Iter 732, loss [-0.20143218, -0.24107917, 0.039646983]\n",
      "Iter 733, loss [-0.21070033, -0.24977301, 0.03907267]\n",
      "Iter 734, loss [-0.21830577, -0.25516832, 0.03686256]\n",
      "Iter 735, loss [-0.21475187, -0.25477427, 0.0400224]\n",
      "Iter 736, loss [-0.20852718, -0.2578357, 0.049308516]\n",
      "Iter 737, loss [-0.21734104, -0.25477245, 0.03743141]\n",
      "Iter 738, loss [-0.22666341, -0.27186894, 0.045205534]\n",
      "Iter 739, loss [-0.23970689, -0.31089935, 0.07119246]\n",
      "Iter 740, loss [-0.22807921, -0.27056158, 0.042482357]\n",
      "Iter 741, loss [-0.21787342, -0.25472918, 0.036855754]\n",
      "Iter 742, loss [-0.23999277, -0.27556682, 0.03557404]\n",
      "Iter 743, loss [-0.21653914, -0.2547058, 0.03816665]\n",
      "Iter 744, loss [-0.20426938, -0.24563077, 0.041361388]\n",
      "Iter 745, loss [-0.21944182, -0.25968078, 0.04023896]\n",
      "Iter 746, loss [-0.21733297, -0.25699115, 0.039658174]\n",
      "Iter 747, loss [-0.20667447, -0.24935497, 0.0426805]\n",
      "Iter 748, loss [-0.2191214, -0.25915384, 0.04003244]\n",
      "Iter 749, loss [-0.2077448, -0.24609815, 0.03835333]\n",
      "Iter 750, loss [-0.19702159, -0.24407008, 0.047048494]\n",
      "Iter 751, loss [-0.20233566, -0.24242663, 0.040090986]\n",
      "Iter 752, loss [-0.20216474, -0.2408891, 0.038724355]\n",
      "Iter 753, loss [-0.22627324, -0.2639915, 0.037718263]\n",
      "Iter 754, loss [-0.2050589, -0.24085477, 0.035795867]\n",
      "Iter 755, loss [-0.21754384, -0.25493145, 0.03738761]\n",
      "Iter 756, loss [-0.24025318, -0.27613312, 0.035879936]\n",
      "Iter 757, loss [-0.20905906, -0.25079748, 0.04173842]\n",
      "Iter 758, loss [-0.20659292, -0.24428962, 0.03769671]\n",
      "Iter 759, loss [-0.21023238, -0.25137314, 0.041140772]\n",
      "Iter 760, loss [-0.21368024, -0.2535838, 0.03990355]\n",
      "Iter 761, loss [-0.21146768, -0.25274813, 0.041280452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 762, loss [-0.20880164, -0.25116944, 0.042367797]\n",
      "Iter 763, loss [-0.21223065, -0.24751084, 0.03528019]\n",
      "Iter 764, loss [-0.21061957, -0.24869852, 0.038078956]\n",
      "Iter 765, loss [-0.21835345, -0.2572017, 0.03884826]\n",
      "Iter 766, loss [-0.21145967, -0.25468695, 0.043227285]\n",
      "Iter 767, loss [-0.22621618, -0.28733045, 0.061114263]\n",
      "Iter 768, loss [-0.21028146, -0.2581036, 0.047822148]\n",
      "Iter 769, loss [-0.21237522, -0.2523872, 0.04001197]\n",
      "Iter 770, loss [-0.21752796, -0.25745082, 0.039922867]\n",
      "Iter 771, loss [-0.20898956, -0.2493987, 0.04040914]\n",
      "Iter 772, loss [-0.20523974, -0.25475854, 0.0495188]\n",
      "Iter 773, loss [-0.22635551, -0.26522812, 0.03887261]\n",
      "Iter 774, loss [-0.2264297, -0.26472685, 0.038297143]\n",
      "Iter 775, loss [-0.20264313, -0.240754, 0.038110875]\n",
      "Iter 776, loss [-0.30723774, -0.31668803, 0.0094503]\n",
      "Iter 777, loss [-0.21786408, -0.2537218, 0.035857722]\n",
      "Iter 778, loss [-0.22526512, -0.2608948, 0.035629682]\n",
      "Iter 779, loss [-0.21834615, -0.2552025, 0.036856346]\n",
      "Iter 780, loss [-0.20467147, -0.24170837, 0.03703689]\n",
      "Iter 781, loss [-0.21070006, -0.24826577, 0.03756571]\n",
      "Iter 782, loss [-0.21030492, -0.25111693, 0.040812008]\n",
      "Iter 783, loss [-0.21410847, -0.2534995, 0.039391037]\n",
      "Iter 784, loss [-0.2117132, -0.25082007, 0.03910687]\n",
      "Iter 785, loss [-0.2213081, -0.25873396, 0.037425857]\n",
      "Iter 786, loss [-0.22380544, -0.2642702, 0.040464748]\n",
      "Iter 787, loss [-0.22532476, -0.2650608, 0.039736047]\n",
      "Iter 788, loss [-0.20969135, -0.24915004, 0.03945869]\n",
      "Iter 789, loss [-0.22421929, -0.2679857, 0.04376641]\n",
      "Iter 790, loss [-0.22360979, -0.2607985, 0.037188724]\n",
      "Iter 791, loss [-0.2183052, -0.25509754, 0.036792334]\n",
      "Iter 792, loss [-0.22503802, -0.2638365, 0.03879849]\n",
      "Iter 793, loss [-0.20547745, -0.2541166, 0.048639145]\n",
      "Iter 794, loss [-0.21774338, -0.25553846, 0.03779508]\n",
      "Iter 795, loss [-0.21895263, -0.2567732, 0.037820585]\n",
      "Iter 796, loss [-0.2110141, -0.250493, 0.039478883]\n",
      "Iter 797, loss [-0.22291562, -0.30312854, 0.08021292]\n",
      "Iter 798, loss [-0.21437371, -0.25396392, 0.039590202]\n",
      "Iter 799, loss [-0.2125807, -0.25451028, 0.041929588]\n",
      "Iter 800, loss [-0.21787342, -0.25636408, 0.03849066]\n",
      "Iter 801, loss [-0.2068382, -0.24799961, 0.041161403]\n",
      "Iter 802, loss [-0.24172577, -0.30725148, 0.06552571]\n",
      "Iter 803, loss [-0.1811189, -0.22937788, 0.04825897]\n",
      "Iter 804, loss [-0.21099994, -0.25494298, 0.043943048]\n",
      "Iter 805, loss [-0.21198243, -0.27115253, 0.059170105]\n",
      "Iter 806, loss [-0.20918126, -0.24744105, 0.03825979]\n",
      "Iter 807, loss [-0.21801461, -0.2546359, 0.036621287]\n",
      "Iter 808, loss [-0.2267585, -0.26489258, 0.038134083]\n",
      "Iter 809, loss [-0.2107009, -0.25044057, 0.039739665]\n",
      "Iter 810, loss [-0.22547169, -0.26403606, 0.038564365]\n",
      "Iter 811, loss [-0.2269017, -0.2672231, 0.04032139]\n",
      "Iter 812, loss [-0.20954885, -0.26021364, 0.050664794]\n",
      "Iter 813, loss [-0.20651782, -0.24845034, 0.041932516]\n",
      "Iter 814, loss [-0.21142596, -0.25544152, 0.044015553]\n",
      "Iter 815, loss [-0.22274402, -0.25995982, 0.037215807]\n",
      "Iter 816, loss [-0.20457721, -0.24046002, 0.035882812]\n",
      "Iter 817, loss [-0.21003067, -0.24791086, 0.03788019]\n",
      "Iter 818, loss [-0.21000123, -0.2467968, 0.03679557]\n",
      "Iter 819, loss [-0.22685161, -0.27050254, 0.043650925]\n",
      "Iter 820, loss [-0.22272274, -0.26166397, 0.03894123]\n",
      "Iter 821, loss [-0.21462189, -0.25672367, 0.042101786]\n",
      "Iter 822, loss [-0.22328688, -0.2626533, 0.03936641]\n",
      "Iter 823, loss [-0.22868752, -0.2687078, 0.04002029]\n",
      "Iter 824, loss [-0.21840152, -0.25552696, 0.03712544]\n",
      "Iter 825, loss [-0.20515369, -0.24353036, 0.038376674]\n",
      "Iter 826, loss [-0.22654708, -0.28824738, 0.061700296]\n",
      "Iter 827, loss [-0.20696327, -0.24202126, 0.03505799]\n",
      "Iter 828, loss [-0.2114465, -0.24792479, 0.0364783]\n",
      "Iter 829, loss [-0.21191642, -0.25132638, 0.03940996]\n",
      "Iter 830, loss [-0.22352576, -0.26083344, 0.03730768]\n",
      "Iter 831, loss [-0.2109416, -0.25058198, 0.039640382]\n",
      "Iter 832, loss [-0.228486, -0.26842865, 0.039942645]\n",
      "Iter 833, loss [-0.22517644, -0.2662638, 0.041087374]\n",
      "Iter 834, loss [-0.2169257, -0.25614694, 0.039221242]\n",
      "Iter 835, loss [-0.21020393, -0.2588624, 0.048658475]\n",
      "Iter 836, loss [-0.21629643, -0.25812238, 0.04182595]\n",
      "Iter 837, loss [-0.20778053, -0.24507533, 0.0372948]\n",
      "Iter 838, loss [-0.22420143, -0.26399758, 0.039796155]\n",
      "Iter 839, loss [-0.22318673, -0.25943777, 0.036251035]\n",
      "Iter 840, loss [-0.2023784, -0.24407248, 0.04169407]\n",
      "Iter 841, loss [-0.2204506, -0.25942606, 0.038975466]\n",
      "Iter 842, loss [-0.21609242, -0.25669044, 0.04059802]\n",
      "Iter 843, loss [-0.2279134, -0.2662131, 0.03829969]\n",
      "Iter 844, loss [-0.21451691, -0.25887594, 0.044359036]\n",
      "Iter 845, loss [-0.24061796, -0.27684754, 0.036229577]\n",
      "Iter 846, loss [-0.19928963, -0.23607592, 0.036786288]\n",
      "Iter 847, loss [-0.21724084, -0.25473204, 0.037491202]\n",
      "Iter 848, loss [-0.2089628, -0.25143152, 0.04246872]\n",
      "Iter 849, loss [-0.24328446, -0.30681807, 0.063533604]\n",
      "Iter 850, loss [-0.21628514, -0.25733033, 0.041045193]\n",
      "Iter 851, loss [-0.21781139, -0.25613686, 0.038325474]\n",
      "Iter 852, loss [-0.2183983, -0.25791445, 0.039516144]\n",
      "Iter 853, loss [-0.21869251, -0.25606704, 0.03737453]\n",
      "Iter 854, loss [-0.21462837, -0.27548537, 0.060856998]\n",
      "Iter 855, loss [-0.2181558, -0.25705856, 0.038902763]\n",
      "Iter 856, loss [-0.21231574, -0.25313756, 0.040821828]\n",
      "Iter 857, loss [-0.23096687, -0.2684558, 0.037488945]\n",
      "Iter 858, loss [-0.20833054, -0.24698341, 0.03865286]\n",
      "Iter 859, loss [-0.21069005, -0.24886762, 0.038177565]\n",
      "Iter 860, loss [-0.2234996, -0.2623007, 0.03880111]\n",
      "Iter 861, loss [-0.21240732, -0.2523455, 0.03993818]\n",
      "Iter 862, loss [-0.23606148, -0.29063848, 0.054576993]\n",
      "Iter 863, loss [-0.20966944, -0.24924175, 0.03957231]\n",
      "Iter 864, loss [-0.21035646, -0.24948798, 0.039131522]\n",
      "Iter 865, loss [-0.21807453, -0.25679383, 0.038719293]\n",
      "Iter 866, loss [-0.22089264, -0.2608206, 0.039927956]\n",
      "Iter 867, loss [-0.21094632, -0.25136825, 0.040421933]\n",
      "Iter 868, loss [-0.22131914, -0.2596835, 0.03836435]\n",
      "Iter 869, loss [-0.21293494, -0.2584085, 0.045473546]\n",
      "Iter 870, loss [-0.2152559, -0.25496557, 0.03970967]\n",
      "Iter 871, loss [-0.21056668, -0.25810724, 0.04754056]\n",
      "Iter 872, loss [-0.22906172, -0.26626766, 0.037205927]\n",
      "Iter 873, loss [-0.22614785, -0.2622499, 0.036102045]\n",
      "Iter 874, loss [-0.21104024, -0.24761349, 0.036573246]\n",
      "Iter 875, loss [-0.20687115, -0.24777044, 0.04089929]\n",
      "Iter 876, loss [-0.20786874, -0.24480638, 0.036937635]\n",
      "Iter 877, loss [-0.2081404, -0.24659331, 0.038452905]\n",
      "Iter 878, loss [-0.21711291, -0.26279396, 0.04568104]\n",
      "Iter 879, loss [-0.2186816, -0.25716868, 0.038487084]\n",
      "Iter 880, loss [-0.22381836, -0.26215348, 0.038335115]\n",
      "Iter 881, loss [-0.24056447, -0.2757931, 0.035228647]\n",
      "Iter 882, loss [-0.24052516, -0.31382665, 0.073301494]\n",
      "Iter 883, loss [-0.19930045, -0.23508504, 0.035784587]\n",
      "Iter 884, loss [-0.20697714, -0.2473256, 0.04034845]\n",
      "Iter 885, loss [-0.20723468, -0.24779016, 0.04055547]\n",
      "Iter 886, loss [-0.21338221, -0.2491033, 0.035721075]\n",
      "Iter 887, loss [-0.20674033, -0.24812284, 0.04138251]\n",
      "Iter 888, loss [-0.20338023, -0.29490268, 0.091522455]\n",
      "Iter 889, loss [-0.21356848, -0.24986207, 0.03629359]\n",
      "Iter 890, loss [-0.2153417, -0.2553153, 0.0399736]\n",
      "Iter 891, loss [-0.22586522, -0.26320976, 0.037344538]\n",
      "Iter 892, loss [-0.2110158, -0.25200537, 0.040989563]\n",
      "Iter 893, loss [-0.2036027, -0.2426363, 0.039033584]\n",
      "Iter 894, loss [-0.24036983, -0.305095, 0.06472515]\n",
      "Iter 895, loss [-0.21523382, -0.25418782, 0.03895401]\n",
      "Iter 896, loss [-0.2147023, -0.25554323, 0.040840935]\n",
      "Iter 897, loss [-0.20246367, -0.24134779, 0.03888412]\n",
      "Iter 898, loss [-0.2148394, -0.25489897, 0.04005956]\n",
      "Iter 899, loss [-0.22570735, -0.27133805, 0.0456307]\n",
      "Iter 900, loss [-0.20727997, -0.24684782, 0.03956786]\n",
      "Iter 901, loss [-0.21741134, -0.25706005, 0.03964872]\n",
      "Iter 902, loss [-0.21734749, -0.25801355, 0.04066606]\n",
      "Iter 903, loss [-0.20602936, -0.26571748, 0.05968813]\n",
      "Iter 904, loss [-0.2042382, -0.24447551, 0.040237315]\n",
      "Iter 905, loss [-0.21681266, -0.26166722, 0.044854563]\n",
      "Iter 906, loss [-0.22504985, -0.26278025, 0.037730396]\n",
      "Iter 907, loss [-0.20734718, -0.25874537, 0.051398188]\n",
      "Iter 908, loss [-0.21797478, -0.2801239, 0.062149107]\n",
      "Iter 909, loss [-0.21063879, -0.25467116, 0.04403236]\n",
      "Iter 910, loss [-0.20747533, -0.2689911, 0.06151577]\n",
      "Iter 911, loss [-0.22665931, -0.2647643, 0.038104992]\n",
      "Iter 912, loss [-0.22365955, -0.26499382, 0.041334275]\n",
      "Iter 913, loss [-0.21355611, -0.2532055, 0.039649405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 914, loss [-0.21022013, -0.25170255, 0.04148242]\n",
      "Iter 915, loss [-0.21561004, -0.25371075, 0.0381007]\n",
      "Iter 916, loss [-0.20574804, -0.24768496, 0.04193692]\n",
      "Iter 917, loss [-0.20603256, -0.24154156, 0.035509005]\n",
      "Iter 918, loss [-0.22868292, -0.289872, 0.061189067]\n",
      "Iter 919, loss [-0.17915183, -0.22979257, 0.050640732]\n",
      "Iter 920, loss [-0.21626712, -0.2570934, 0.04082628]\n",
      "Iter 921, loss [-0.20198542, -0.24330415, 0.041318722]\n",
      "Iter 922, loss [-0.20771524, -0.24747494, 0.0397597]\n",
      "Iter 923, loss [-0.2248382, -0.2645876, 0.03974942]\n",
      "Iter 924, loss [-0.21679258, -0.25407422, 0.03728163]\n",
      "Iter 925, loss [-0.21698967, -0.2559663, 0.038976647]\n",
      "Iter 926, loss [-0.20598231, -0.24109475, 0.035112437]\n",
      "Iter 927, loss [-0.21562238, -0.26009813, 0.044475745]\n",
      "Iter 928, loss [-0.21836604, -0.2567298, 0.038363766]\n",
      "Iter 929, loss [-0.21105954, -0.25139877, 0.04033923]\n",
      "Iter 930, loss [-0.22572523, -0.26593232, 0.040207084]\n",
      "Iter 931, loss [-0.20953825, -0.2580998, 0.048561536]\n",
      "Iter 932, loss [-0.21337503, -0.25309968, 0.03972464]\n",
      "Iter 933, loss [-0.23417825, -0.3106711, 0.07649285]\n",
      "Iter 934, loss [-0.2241745, -0.26358706, 0.039412558]\n",
      "Iter 935, loss [-0.21175215, -0.2527274, 0.040975235]\n",
      "Iter 936, loss [-0.22309242, -0.26632908, 0.043236658]\n",
      "Iter 937, loss [-0.22312735, -0.26620677, 0.04307942]\n",
      "Iter 938, loss [-0.21274588, -0.25186247, 0.0391166]\n",
      "Iter 939, loss [-0.21675298, -0.25374883, 0.03699586]\n",
      "Iter 940, loss [-0.24651316, -0.2899536, 0.043440428]\n",
      "Iter 941, loss [-0.21359986, -0.2530373, 0.039437436]\n",
      "Iter 942, loss [-0.2174282, -0.25596136, 0.038533147]\n",
      "Iter 943, loss [-0.22722939, -0.2969565, 0.06972712]\n",
      "Iter 944, loss [-0.22567955, -0.263168, 0.03748846]\n",
      "Iter 945, loss [-0.22663833, -0.27285606, 0.046217725]\n",
      "Iter 946, loss [-0.21683224, -0.25674617, 0.039913934]\n",
      "Iter 947, loss [-0.22357002, -0.2651318, 0.04156179]\n",
      "Iter 948, loss [-0.21542072, -0.25544134, 0.040020622]\n",
      "Iter 949, loss [-0.22826368, -0.2715431, 0.043279417]\n",
      "Iter 950, loss [-0.20700932, -0.24919762, 0.0421883]\n",
      "Iter 951, loss [-0.22358753, -0.26128906, 0.037701536]\n",
      "Iter 952, loss [-0.2467531, -0.29100767, 0.044254564]\n",
      "Iter 953, loss [-0.22613448, -0.26288167, 0.036747184]\n",
      "Iter 954, loss [-0.24734953, -0.29137242, 0.04402288]\n",
      "Iter 955, loss [-0.18113407, -0.2302878, 0.04915373]\n",
      "Iter 956, loss [-0.22037853, -0.25939992, 0.03902139]\n",
      "Iter 957, loss [-0.21249115, -0.2492528, 0.03676164]\n",
      "Iter 958, loss [-0.21410921, -0.2741781, 0.060068868]\n",
      "Iter 959, loss [-0.20378236, -0.24226473, 0.038482368]\n",
      "Iter 960, loss [-0.21818498, -0.25592425, 0.037739284]\n",
      "Iter 961, loss [-0.20699497, -0.2487367, 0.04174173]\n",
      "Iter 962, loss [-0.21302596, -0.25785273, 0.04482677]\n",
      "Iter 963, loss [-0.21181628, -0.25432855, 0.042512264]\n",
      "Iter 964, loss [-0.20806322, -0.24764349, 0.039580263]\n",
      "Iter 965, loss [-0.21494061, -0.27629575, 0.06135515]\n",
      "Iter 966, loss [-0.20469698, -0.2452143, 0.040517308]\n",
      "Iter 967, loss [-0.21641216, -0.25460014, 0.038187988]\n",
      "Iter 968, loss [-0.23864707, -0.31109917, 0.0724521]\n",
      "Iter 969, loss [-0.22086573, -0.2596586, 0.03879288]\n",
      "Iter 970, loss [-0.21775033, -0.260687, 0.042936664]\n",
      "Iter 971, loss [-0.21906061, -0.25982505, 0.040764432]\n",
      "Iter 972, loss [-0.2175229, -0.25634092, 0.038818017]\n",
      "Iter 973, loss [-0.21039286, -0.2586799, 0.04828704]\n",
      "Iter 974, loss [-0.22079909, -0.26735392, 0.046554834]\n",
      "Iter 975, loss [-0.20507266, -0.24215282, 0.03708017]\n",
      "Iter 976, loss [-0.21573913, -0.25571114, 0.039972015]\n",
      "Iter 977, loss [-0.22498634, -0.26288545, 0.037899114]\n",
      "Iter 978, loss [-0.23102774, -0.30561537, 0.07458763]\n",
      "Iter 979, loss [-0.1990327, -0.23608872, 0.03705602]\n",
      "Iter 980, loss [-0.22437957, -0.29732645, 0.07294688]\n",
      "Iter 981, loss [-0.20264769, -0.24413761, 0.04148992]\n",
      "Iter 982, loss [-0.20754252, -0.2467368, 0.039194275]\n",
      "Iter 983, loss [-0.21765879, -0.25877416, 0.041115373]\n",
      "Iter 984, loss [-0.22685665, -0.26471338, 0.03785672]\n",
      "Iter 985, loss [-0.22818764, -0.26500538, 0.03681774]\n",
      "Iter 986, loss [-0.20980611, -0.24562196, 0.035815854]\n",
      "Iter 987, loss [-0.21234125, -0.25334653, 0.04100529]\n",
      "Iter 988, loss [-0.21656854, -0.2984015, 0.08183296]\n",
      "Iter 989, loss [-0.23828402, -0.31368956, 0.07540553]\n",
      "Iter 990, loss [-0.21509948, -0.2559715, 0.04087201]\n",
      "Iter 991, loss [-0.2348643, -0.303209, 0.06834471]\n",
      "Iter 992, loss [-0.21357992, -0.25492543, 0.04134551]\n",
      "Iter 993, loss [-0.22578052, -0.26469237, 0.03891185]\n",
      "Iter 994, loss [-0.21653946, -0.25437328, 0.037833825]\n",
      "Iter 995, loss [-0.20994946, -0.24704254, 0.037093073]\n",
      "Iter 996, loss [-0.1983586, -0.23399898, 0.035640385]\n",
      "Iter 997, loss [-0.21659677, -0.25386438, 0.037267607]\n",
      "Iter 998, loss [-0.22506678, -0.26402774, 0.038960963]\n",
      "Iter 999, loss [-0.20862594, -0.25845313, 0.04982718]\n",
      "Iter 1000, loss [-0.3047549, -0.31483164, 0.010076741]\n",
      "Iter 1001, loss [-0.20649531, -0.24853274, 0.042037427]\n",
      "Iter 1002, loss [-0.19640037, -0.24340229, 0.047001906]\n",
      "Iter 1003, loss [-0.20666492, -0.24326456, 0.03659963]\n",
      "Iter 1004, loss [-0.22140561, -0.28151077, 0.06010516]\n",
      "Iter 1005, loss [-0.19757578, -0.24379966, 0.046223886]\n",
      "Iter 1006, loss [-0.22495773, -0.26386154, 0.038903795]\n",
      "Iter 1007, loss [-0.24209583, -0.30451265, 0.062416818]\n",
      "Iter 1008, loss [-0.23989889, -0.31236845, 0.072469555]\n",
      "Iter 1009, loss [-0.2175923, -0.2558963, 0.038304]\n",
      "Iter 1010, loss [-0.20844406, -0.24966893, 0.04122486]\n",
      "Iter 1011, loss [-0.19897455, -0.23649117, 0.037516616]\n",
      "Iter 1012, loss [-0.20901306, -0.25031736, 0.041304305]\n",
      "Iter 1013, loss [-0.20393124, -0.24537335, 0.04144212]\n",
      "Iter 1014, loss [-0.21800178, -0.25607756, 0.038075767]\n",
      "Iter 1015, loss [-0.19750644, -0.24399582, 0.046489373]\n",
      "Iter 1016, loss [-0.21523836, -0.2546995, 0.039461136]\n",
      "Iter 1017, loss [-0.2114011, -0.24908058, 0.037679486]\n",
      "Iter 1018, loss [-0.21734361, -0.25607422, 0.03873061]\n",
      "Iter 1019, loss [-0.2278159, -0.27085125, 0.04303536]\n",
      "Iter 1020, loss [-0.21521711, -0.25556496, 0.040347844]\n",
      "Iter 1021, loss [-0.30621284, -0.3163013, 0.010088441]\n",
      "Iter 1022, loss [-0.2188789, -0.26158392, 0.042705026]\n",
      "Iter 1023, loss [-0.21636105, -0.25624263, 0.03988158]\n",
      "Iter 1024, loss [-0.20601214, -0.24850623, 0.04249409]\n",
      "Iter 1025, loss [-0.21007085, -0.24942711, 0.039356254]\n",
      "Iter 1026, loss [-0.22058226, -0.25645274, 0.03587048]\n",
      "Iter 1027, loss [-0.2146547, -0.25322464, 0.038569942]\n",
      "Iter 1028, loss [-0.21960138, -0.257782, 0.038180634]\n",
      "Iter 1029, loss [-0.20891112, -0.25630692, 0.047395796]\n",
      "Iter 1030, loss [-0.21947387, -0.25906304, 0.039589174]\n",
      "Iter 1031, loss [-0.21627483, -0.25656876, 0.04029394]\n",
      "Iter 1032, loss [-0.22708648, -0.26459605, 0.037509553]\n",
      "Iter 1033, loss [-0.2020008, -0.24530123, 0.043300442]\n",
      "Iter 1034, loss [-0.22616334, -0.2717, 0.04553665]\n",
      "Iter 1035, loss [-0.2227825, -0.26526046, 0.04247796]\n",
      "Iter 1036, loss [-0.21122807, -0.25533617, 0.04410809]\n",
      "Iter 1037, loss [-0.2160219, -0.25139827, 0.035376377]\n",
      "Iter 1038, loss [-0.2237303, -0.28851554, 0.06478524]\n",
      "Iter 1039, loss [-0.22405922, -0.26116797, 0.03710874]\n",
      "Iter 1040, loss [-0.20994663, -0.24570242, 0.03575579]\n",
      "Iter 1041, loss [-0.21133813, -0.25124693, 0.039908804]\n",
      "Iter 1042, loss [-0.20831044, -0.24571593, 0.037405487]\n",
      "Iter 1043, loss [-0.22595201, -0.2623735, 0.03642149]\n",
      "Iter 1044, loss [-0.20532098, -0.24260795, 0.037286967]\n",
      "Iter 1045, loss [-0.20541461, -0.24321498, 0.037800368]\n",
      "Iter 1046, loss [-0.22596183, -0.2656395, 0.03967768]\n",
      "Iter 1047, loss [-0.21543479, -0.2568957, 0.041460894]\n",
      "Iter 1048, loss [-0.24057724, -0.27690375, 0.03632651]\n",
      "Iter 1049, loss [-0.22813183, -0.26774788, 0.039616056]\n",
      "Iter 1050, loss [-0.20484343, -0.24584216, 0.040998723]\n",
      "Iter 1051, loss [-0.2260296, -0.2647389, 0.03870928]\n",
      "Iter 1052, loss [-0.20510827, -0.25377348, 0.048665207]\n",
      "Iter 1053, loss [-0.20735809, -0.2482351, 0.040877018]\n",
      "Iter 1054, loss [-0.22002213, -0.2600291, 0.040006977]\n",
      "Iter 1055, loss [-0.22789271, -0.26446354, 0.03657083]\n",
      "Iter 1056, loss [-0.21837981, -0.254581, 0.03620119]\n",
      "Iter 1057, loss [-0.20708336, -0.24355546, 0.036472093]\n",
      "Iter 1058, loss [-0.22102985, -0.2602907, 0.039260864]\n",
      "Iter 1059, loss [-0.21525864, -0.25467238, 0.03941373]\n",
      "Iter 1060, loss [-0.20810093, -0.24527742, 0.03717649]\n",
      "Iter 1061, loss [-0.21100318, -0.24862275, 0.03761957]\n",
      "Iter 1062, loss [-0.21598212, -0.25518847, 0.03920634]\n",
      "Iter 1063, loss [-0.21305251, -0.25728434, 0.044231825]\n",
      "Iter 1064, loss [-0.21996708, -0.25931165, 0.039344564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1065, loss [-0.21256097, -0.25414658, 0.041585606]\n",
      "Iter 1066, loss [-0.21819542, -0.2551917, 0.03699629]\n",
      "Iter 1067, loss [-0.24050772, -0.27593583, 0.03542811]\n",
      "Iter 1068, loss [-0.2273155, -0.2659897, 0.038674187]\n",
      "Iter 1069, loss [-0.22529216, -0.26413184, 0.038839687]\n",
      "Iter 1070, loss [-0.21750924, -0.26274148, 0.045232244]\n",
      "Iter 1071, loss [-0.22648616, -0.26336738, 0.03688122]\n",
      "Iter 1072, loss [-0.22807494, -0.26523942, 0.03716448]\n",
      "Iter 1073, loss [-0.20367308, -0.24245454, 0.03878146]\n",
      "Iter 1074, loss [-0.22463264, -0.268541, 0.043908373]\n",
      "Iter 1075, loss [-0.22935495, -0.26843226, 0.039077308]\n",
      "Iter 1076, loss [-0.22435918, -0.265003, 0.04064382]\n",
      "Iter 1077, loss [-0.21018252, -0.24860515, 0.03842262]\n",
      "Iter 1078, loss [-0.21053857, -0.24992935, 0.039390787]\n",
      "Iter 1079, loss [-0.21061452, -0.25006437, 0.03944986]\n",
      "Iter 1080, loss [-0.2157071, -0.2578914, 0.042184293]\n",
      "Iter 1081, loss [-0.21108836, -0.24911323, 0.03802488]\n",
      "Iter 1082, loss [-0.20757551, -0.24854717, 0.04097165]\n",
      "Iter 1083, loss [-0.21863797, -0.25880927, 0.040171295]\n",
      "Iter 1084, loss [-0.21238841, -0.25224924, 0.03986083]\n",
      "Iter 1085, loss [-0.22254857, -0.30208543, 0.07953685]\n",
      "Iter 1086, loss [-0.21104181, -0.25184044, 0.04079863]\n",
      "Iter 1087, loss [-0.217385, -0.2561168, 0.038731817]\n",
      "Iter 1088, loss [-0.21018985, -0.2509926, 0.04080274]\n",
      "Iter 1089, loss [-0.22894457, -0.31416172, 0.08521714]\n",
      "Iter 1090, loss [-0.21748123, -0.25725603, 0.0397748]\n",
      "Iter 1091, loss [-0.1980628, -0.23308279, 0.035019975]\n",
      "Iter 1092, loss [-0.20052797, -0.24106443, 0.04053646]\n",
      "Iter 1093, loss [-0.20805329, -0.27108163, 0.063028336]\n",
      "Iter 1094, loss [-0.20931852, -0.25610727, 0.046788745]\n",
      "Iter 1095, loss [-0.22037852, -0.30227393, 0.0818954]\n",
      "Iter 1096, loss [-0.22622466, -0.2686041, 0.042379446]\n",
      "Iter 1097, loss [-0.22434214, -0.26833767, 0.043995522]\n",
      "Iter 1098, loss [-0.21269068, -0.2645818, 0.05189111]\n",
      "Iter 1099, loss [-0.22132885, -0.26266977, 0.041340914]\n",
      "Iter 1100, loss [-0.21952713, -0.2586141, 0.039086975]\n",
      "Iter 1101, loss [-0.22492835, -0.2686087, 0.043680333]\n",
      "Iter 1102, loss [-0.21119803, -0.24620207, 0.035004035]\n",
      "Iter 1103, loss [-0.20472838, -0.24374193, 0.039013546]\n",
      "Iter 1104, loss [-0.20462629, -0.24475108, 0.04012478]\n",
      "Iter 1105, loss [-0.22010571, -0.25566682, 0.03556111]\n",
      "Iter 1106, loss [-0.21484303, -0.2525246, 0.03768158]\n",
      "Iter 1107, loss [-0.22425926, -0.269766, 0.045506746]\n",
      "Iter 1108, loss [-0.20903206, -0.24749023, 0.03845816]\n",
      "Iter 1109, loss [-0.21804792, -0.25813928, 0.040091366]\n",
      "Iter 1110, loss [-0.21657604, -0.2569529, 0.04037688]\n",
      "Iter 1111, loss [-0.203727, -0.25324836, 0.049521357]\n",
      "Iter 1112, loss [-0.2107669, -0.24636815, 0.03560126]\n",
      "Iter 1113, loss [-0.22566566, -0.26960263, 0.043936964]\n",
      "Iter 1114, loss [-0.22066717, -0.29951227, 0.0788451]\n",
      "Iter 1115, loss [-0.20696029, -0.243331, 0.036370717]\n",
      "Iter 1116, loss [-0.2140409, -0.25224265, 0.038201742]\n",
      "Iter 1117, loss [-0.20910123, -0.2556972, 0.046595957]\n",
      "Iter 1118, loss [-0.22489476, -0.2615603, 0.036665525]\n",
      "Iter 1119, loss [-0.2026397, -0.28002393, 0.07738424]\n",
      "Iter 1120, loss [-0.22279474, -0.26052347, 0.03772872]\n",
      "Iter 1121, loss [-0.208233, -0.25541618, 0.047183193]\n",
      "Iter 1122, loss [-0.20935237, -0.25003082, 0.04067844]\n",
      "Iter 1123, loss [-0.21552059, -0.2571865, 0.04166591]\n",
      "Iter 1124, loss [-0.21033148, -0.25109637, 0.040764883]\n",
      "Iter 1125, loss [-0.22283272, -0.26549163, 0.042658906]\n",
      "Iter 1126, loss [-0.20221418, -0.24494332, 0.042729136]\n",
      "Iter 1127, loss [-0.22106332, -0.26004857, 0.03898526]\n",
      "Iter 1128, loss [-0.2387224, -0.27415758, 0.035435185]\n",
      "Iter 1129, loss [-0.21660614, -0.25528187, 0.038675733]\n",
      "Iter 1130, loss [-0.21700516, -0.25257516, 0.035569992]\n",
      "Iter 1131, loss [-0.20661326, -0.24627353, 0.03966027]\n",
      "Iter 1132, loss [-0.21508719, -0.3028501, 0.08776291]\n",
      "Iter 1133, loss [-0.20928547, -0.24689385, 0.037608393]\n",
      "Iter 1134, loss [-0.24302381, -0.28617847, 0.043154657]\n",
      "Iter 1135, loss [-0.19967726, -0.2363344, 0.03665714]\n",
      "Iter 1136, loss [-0.20821196, -0.2474881, 0.039276145]\n",
      "Iter 1137, loss [-0.22252971, -0.26233867, 0.03980895]\n",
      "Iter 1138, loss [-0.20561686, -0.24343465, 0.03781779]\n",
      "Iter 1139, loss [-0.21262464, -0.25191975, 0.0392951]\n",
      "Iter 1140, loss [-0.2243055, -0.267599, 0.043293487]\n",
      "Iter 1141, loss [-0.22882618, -0.2850375, 0.056211308]\n",
      "Iter 1142, loss [-0.20295659, -0.24253842, 0.039581843]\n",
      "Iter 1143, loss [-0.20589805, -0.25125536, 0.045357317]\n",
      "Iter 1144, loss [-0.21183205, -0.25431323, 0.042481177]\n",
      "Iter 1145, loss [-0.22188058, -0.26160842, 0.039727844]\n",
      "Iter 1146, loss [-0.22278625, -0.2625455, 0.039759256]\n",
      "Iter 1147, loss [-0.22410294, -0.26229703, 0.038194086]\n",
      "Iter 1148, loss [-0.22135875, -0.28787267, 0.066513926]\n",
      "Iter 1149, loss [-0.20523638, -0.24613075, 0.040894367]\n",
      "Iter 1150, loss [-0.22143406, -0.2797487, 0.058314648]\n",
      "Iter 1151, loss [-0.23362744, -0.28904426, 0.05541682]\n",
      "Iter 1152, loss [-0.21138233, -0.2475164, 0.036134057]\n",
      "Iter 1153, loss [-0.20951504, -0.2493413, 0.039826266]\n",
      "Iter 1154, loss [-0.2069844, -0.2457272, 0.038742796]\n",
      "Iter 1155, loss [-0.22582836, -0.26405585, 0.03822748]\n",
      "Iter 1156, loss [-0.22463416, -0.28693488, 0.062300727]\n",
      "Iter 1157, loss [-0.19680563, -0.24376711, 0.046961486]\n",
      "Iter 1158, loss [-0.21564986, -0.2521982, 0.03654833]\n",
      "Iter 1159, loss [-0.22071157, -0.2651675, 0.044455927]\n",
      "Iter 1160, loss [-0.22307181, -0.2601835, 0.037111707]\n",
      "Iter 1161, loss [-0.20614558, -0.24727298, 0.041127395]\n",
      "Iter 1162, loss [-0.20946947, -0.25758836, 0.048118886]\n",
      "Iter 1163, loss [-0.22326298, -0.26156884, 0.03830586]\n",
      "Iter 1164, loss [-0.20647879, -0.24771275, 0.041233957]\n",
      "Iter 1165, loss [-0.20415822, -0.24474485, 0.040586628]\n",
      "Iter 1166, loss [-0.22655334, -0.27197927, 0.045425937]\n",
      "Iter 1167, loss [-0.22335091, -0.26770812, 0.04435721]\n",
      "Iter 1168, loss [-0.20879516, -0.2492869, 0.040491752]\n",
      "Iter 1169, loss [-0.21767077, -0.25449783, 0.036827054]\n",
      "Iter 1170, loss [-0.21469977, -0.25161493, 0.036915146]\n",
      "Iter 1171, loss [-0.2109586, -0.25513777, 0.04417917]\n",
      "Iter 1172, loss [-0.22865231, -0.2712068, 0.04255448]\n",
      "Iter 1173, loss [-0.30686262, -0.31666282, 0.009800202]\n",
      "Iter 1174, loss [-0.22199586, -0.3017359, 0.07974004]\n",
      "Iter 1175, loss [-0.20187661, -0.24044482, 0.038568206]\n",
      "Iter 1176, loss [-0.21310848, -0.25177974, 0.038671263]\n",
      "Iter 1177, loss [-0.21645728, -0.25299972, 0.036542453]\n",
      "Iter 1178, loss [-0.23980352, -0.2755148, 0.03571128]\n",
      "Iter 1179, loss [-0.22955598, -0.26716277, 0.03760679]\n",
      "Iter 1180, loss [-0.20178522, -0.240984, 0.03919877]\n",
      "Iter 1181, loss [-0.2070149, -0.24468234, 0.03766744]\n",
      "Iter 1182, loss [-0.2099329, -0.24810846, 0.038175568]\n",
      "Iter 1183, loss [-0.20447329, -0.24564098, 0.04116769]\n",
      "Iter 1184, loss [-0.21103223, -0.2530193, 0.041987073]\n",
      "Iter 1185, loss [-0.20795311, -0.25071934, 0.042766225]\n",
      "Iter 1186, loss [-0.21681035, -0.25754255, 0.040732212]\n",
      "Iter 1187, loss [-0.22294521, -0.2598355, 0.036890298]\n",
      "Iter 1188, loss [-0.21745647, -0.25640896, 0.038952485]\n",
      "Iter 1189, loss [-0.21767338, -0.25597656, 0.03830318]\n",
      "Iter 1190, loss [-0.20384866, -0.24477108, 0.040922426]\n",
      "Iter 1191, loss [-0.2037099, -0.24523978, 0.041529886]\n",
      "Iter 1192, loss [-0.22628126, -0.26521412, 0.038932852]\n",
      "Iter 1193, loss [-0.21222374, -0.2555972, 0.043373458]\n",
      "Iter 1194, loss [-0.22283381, -0.2644742, 0.041640393]\n",
      "Iter 1195, loss [-0.2103058, -0.25040108, 0.040095285]\n",
      "Iter 1196, loss [-0.21005383, -0.24821416, 0.03816032]\n",
      "Iter 1197, loss [-0.22303078, -0.26629183, 0.043261047]\n",
      "Iter 1198, loss [-0.22341755, -0.26284096, 0.039423402]\n",
      "Iter 1199, loss [-0.20963812, -0.25561172, 0.0459736]\n",
      "Iter 1200, loss [-0.23061119, -0.26679808, 0.03618689]\n",
      "Iter 1201, loss [-0.21529144, -0.25482535, 0.039533913]\n",
      "Iter 1202, loss [-0.21988994, -0.25985393, 0.039963987]\n",
      "Iter 1203, loss [-0.21841471, -0.25820443, 0.03978972]\n",
      "Iter 1204, loss [-0.21032289, -0.24915677, 0.038833886]\n",
      "Iter 1205, loss [-0.21715117, -0.25672483, 0.039573673]\n",
      "Iter 1206, loss [-0.2238788, -0.26633644, 0.042457633]\n",
      "Iter 1207, loss [-0.20348239, -0.24182598, 0.038343593]\n",
      "Iter 1208, loss [-0.22705501, -0.2640758, 0.03702077]\n",
      "Iter 1209, loss [-0.21100423, -0.24780679, 0.036802556]\n",
      "Iter 1210, loss [-0.2074397, -0.24517524, 0.037735537]\n",
      "Iter 1211, loss [-0.21422651, -0.256019, 0.041792475]\n",
      "Iter 1212, loss [-0.22428319, -0.28535807, 0.061074883]\n",
      "Iter 1213, loss [-0.21480247, -0.25767252, 0.042870037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1214, loss [-0.22691572, -0.26561692, 0.038701214]\n",
      "Iter 1215, loss [-0.21904063, -0.26021683, 0.041176196]\n",
      "Iter 1216, loss [-0.22500038, -0.26340187, 0.038401484]\n",
      "Iter 1217, loss [-0.20626384, -0.24640287, 0.04013903]\n",
      "Iter 1218, loss [-0.2172084, -0.25453228, 0.037323877]\n",
      "Iter 1219, loss [-0.20433454, -0.24415748, 0.039822936]\n",
      "Iter 1220, loss [-0.2088935, -0.24489076, 0.035997268]\n",
      "Iter 1221, loss [-0.21095398, -0.24861607, 0.037662096]\n",
      "Iter 1222, loss [-0.21828498, -0.25847515, 0.04019017]\n",
      "Iter 1223, loss [-0.20960943, -0.24834378, 0.03873435]\n",
      "Iter 1224, loss [-0.22301549, -0.2633333, 0.040317796]\n",
      "Iter 1225, loss [-0.21797161, -0.25644314, 0.038471535]\n",
      "Iter 1226, loss [-0.24029909, -0.31367207, 0.073372975]\n",
      "Iter 1227, loss [-0.3061318, -0.31589437, 0.009762563]\n",
      "Iter 1228, loss [-0.22001742, -0.25878504, 0.038767617]\n",
      "Iter 1229, loss [-0.20680223, -0.24222042, 0.035418186]\n",
      "Iter 1230, loss [-0.20313096, -0.29316306, 0.0900321]\n",
      "Iter 1231, loss [-0.21769306, -0.25531566, 0.0376226]\n",
      "Iter 1232, loss [-0.23776598, -0.31539103, 0.07762505]\n",
      "Iter 1233, loss [-0.21723676, -0.25461796, 0.03738121]\n",
      "Iter 1234, loss [-0.22333738, -0.26174906, 0.038411677]\n",
      "Iter 1235, loss [-0.23012683, -0.2682401, 0.038113274]\n",
      "Iter 1236, loss [-0.2157623, -0.25649318, 0.04073088]\n",
      "Iter 1237, loss [-0.2195551, -0.26155886, 0.042003762]\n",
      "Iter 1238, loss [-0.20079541, -0.24238843, 0.04159301]\n",
      "Iter 1239, loss [-0.21782412, -0.3039117, 0.08608757]\n",
      "Iter 1240, loss [-0.22440499, -0.26589915, 0.04149417]\n",
      "Iter 1241, loss [-0.22529429, -0.2611995, 0.03590522]\n",
      "Iter 1242, loss [-0.21120423, -0.24612533, 0.034921095]\n",
      "Iter 1243, loss [-0.22219776, -0.25644895, 0.034251194]\n",
      "Iter 1244, loss [-0.20539682, -0.2454439, 0.040047076]\n",
      "Iter 1245, loss [-0.2172306, -0.25394705, 0.036716443]\n",
      "Iter 1246, loss [-0.20948976, -0.24758337, 0.03809362]\n",
      "Iter 1247, loss [-0.21173844, -0.25750604, 0.0457676]\n",
      "Iter 1248, loss [-0.21648191, -0.258364, 0.04188208]\n",
      "Iter 1249, loss [-0.20545226, -0.25113466, 0.0456824]\n",
      "Iter 1250, loss [-0.20940514, -0.25701317, 0.04760803]\n",
      "Iter 1251, loss [-0.22345613, -0.2661067, 0.04265056]\n",
      "Iter 1252, loss [-0.22454725, -0.2844713, 0.059924047]\n",
      "Iter 1253, loss [-0.20621999, -0.24822648, 0.04200649]\n",
      "Iter 1254, loss [-0.21937098, -0.25840026, 0.039029285]\n",
      "Iter 1255, loss [-0.22106631, -0.29530895, 0.07424264]\n",
      "Iter 1256, loss [-0.20909065, -0.24881329, 0.039722636]\n",
      "Iter 1257, loss [-0.20521833, -0.2486782, 0.043459874]\n",
      "Iter 1258, loss [-0.22743165, -0.30679134, 0.07935969]\n",
      "Iter 1259, loss [-0.24437654, -0.29126444, 0.04688791]\n",
      "Iter 1260, loss [-0.22119874, -0.26022124, 0.039022498]\n",
      "Iter 1261, loss [-0.30608365, -0.31617823, 0.010094593]\n",
      "Iter 1262, loss [-0.21618286, -0.25077593, 0.034593068]\n",
      "Iter 1263, loss [-0.22268677, -0.2581165, 0.035429753]\n",
      "Iter 1264, loss [-0.20644078, -0.24710952, 0.040668737]\n",
      "Iter 1265, loss [-0.21691614, -0.25462884, 0.037712693]\n",
      "Iter 1266, loss [-0.21755978, -0.2627223, 0.04516253]\n",
      "Iter 1267, loss [-0.21645172, -0.25465378, 0.038202062]\n",
      "Iter 1268, loss [-0.22335532, -0.26830837, 0.044953045]\n",
      "Iter 1269, loss [-0.20880875, -0.24803405, 0.039225303]\n",
      "Iter 1270, loss [-0.21006219, -0.25700384, 0.046941653]\n",
      "Iter 1271, loss [-0.20862797, -0.2584139, 0.049785934]\n",
      "Iter 1272, loss [-0.21684897, -0.2554724, 0.038623426]\n",
      "Iter 1273, loss [-0.20933188, -0.24687958, 0.037547696]\n",
      "Iter 1274, loss [-0.20101982, -0.2421267, 0.041106887]\n",
      "Iter 1275, loss [-0.21900758, -0.25660262, 0.037595026]\n",
      "Iter 1276, loss [-0.21513544, -0.2542292, 0.039093744]\n",
      "Iter 1277, loss [-0.21094668, -0.24903867, 0.038091984]\n",
      "Iter 1278, loss [-0.21797344, -0.25658238, 0.03860893]\n",
      "Iter 1279, loss [-0.21776444, -0.25798675, 0.040222317]\n",
      "Iter 1280, loss [-0.22651133, -0.27323154, 0.046720207]\n",
      "Iter 1281, loss [-0.20874205, -0.24703464, 0.038292583]\n",
      "Iter 1282, loss [-0.22379506, -0.2645885, 0.040793456]\n",
      "Iter 1283, loss [-0.2263659, -0.26381868, 0.037452795]\n",
      "Iter 1284, loss [-0.21755874, -0.25568983, 0.038131088]\n",
      "Iter 1285, loss [-0.22309685, -0.28408822, 0.060991377]\n",
      "Iter 1286, loss [-0.21171372, -0.25126708, 0.039553355]\n",
      "Iter 1287, loss [-0.21036085, -0.24823377, 0.03787291]\n",
      "Iter 1288, loss [-0.21114273, -0.25561792, 0.04447518]\n",
      "Iter 1289, loss [-0.21618728, -0.25447884, 0.03829156]\n",
      "Iter 1290, loss [-0.22678375, -0.27228418, 0.045500424]\n",
      "Iter 1291, loss [-0.22556546, -0.26506045, 0.039495]\n",
      "Iter 1292, loss [-0.22201239, -0.26117215, 0.039159756]\n",
      "Iter 1293, loss [-0.20095184, -0.24172403, 0.040772177]\n",
      "Iter 1294, loss [-0.22685587, -0.26464674, 0.03779086]\n",
      "Iter 1295, loss [-0.21746917, -0.25437808, 0.036908906]\n",
      "Iter 1296, loss [-0.21152027, -0.25499138, 0.043471113]\n",
      "Iter 1297, loss [-0.21669781, -0.2587848, 0.04208699]\n",
      "Iter 1298, loss [-0.20977986, -0.2682118, 0.05843196]\n",
      "Iter 1299, loss [-0.21573278, -0.25556928, 0.039836492]\n",
      "Iter 1300, loss [-0.22054675, -0.25851244, 0.037965693]\n",
      "Iter 1301, loss [-0.20594919, -0.24367987, 0.03773068]\n",
      "Iter 1302, loss [-0.21982008, -0.2677723, 0.0479522]\n",
      "Iter 1303, loss [-0.21779808, -0.25820005, 0.040401973]\n",
      "Iter 1304, loss [-0.20702592, -0.24624641, 0.039220493]\n",
      "Iter 1305, loss [-0.21907431, -0.25865996, 0.03958565]\n",
      "Iter 1306, loss [-0.20845443, -0.25722703, 0.048772603]\n",
      "Iter 1307, loss [-0.227768, -0.26647395, 0.038705945]\n",
      "Iter 1308, loss [-0.2145689, -0.29815224, 0.08358334]\n",
      "Iter 1309, loss [-0.20642786, -0.24626863, 0.039840773]\n",
      "Iter 1310, loss [-0.21163549, -0.25395274, 0.042317256]\n",
      "Iter 1311, loss [-0.20767435, -0.24492013, 0.037245784]\n",
      "Iter 1312, loss [-0.21423179, -0.25323746, 0.03900566]\n",
      "Iter 1313, loss [-0.21804881, -0.25568974, 0.03764093]\n",
      "Iter 1314, loss [-0.22891818, -0.2663821, 0.037463915]\n",
      "Iter 1315, loss [-0.21205273, -0.25762802, 0.0455753]\n",
      "Iter 1316, loss [-0.20741251, -0.24889319, 0.041480675]\n",
      "Iter 1317, loss [-0.20974645, -0.24841249, 0.03866604]\n",
      "Iter 1318, loss [-0.20092088, -0.24401973, 0.04309885]\n",
      "Iter 1319, loss [-0.20231807, -0.24077629, 0.038458213]\n",
      "Iter 1320, loss [-0.22434118, -0.2931988, 0.06885761]\n",
      "Iter 1321, loss [-0.21117634, -0.25293314, 0.041756816]\n",
      "Iter 1322, loss [-0.21117923, -0.2531866, 0.04200738]\n",
      "Iter 1323, loss [-0.21551797, -0.2571805, 0.04166254]\n",
      "Iter 1324, loss [-0.21989182, -0.2617867, 0.041894883]\n",
      "Iter 1325, loss [-0.17833066, -0.23035823, 0.05202756]\n",
      "Iter 1326, loss [-0.21503031, -0.26265568, 0.047625363]\n",
      "Iter 1327, loss [-0.21396323, -0.29721305, 0.08324982]\n",
      "Iter 1328, loss [-0.20874292, -0.24852717, 0.03978426]\n",
      "Iter 1329, loss [-0.19731124, -0.23250623, 0.03519499]\n",
      "Iter 1330, loss [-0.21099581, -0.24674438, 0.035748575]\n",
      "Iter 1331, loss [-0.21246995, -0.2529113, 0.04044135]\n",
      "Iter 1332, loss [-0.20546171, -0.24124801, 0.03578631]\n",
      "Iter 1333, loss [-0.20237412, -0.24983774, 0.047463626]\n",
      "Iter 1334, loss [-0.20027955, -0.23934871, 0.039069157]\n",
      "Iter 1335, loss [-0.2208785, -0.26619774, 0.045319244]\n",
      "Iter 1336, loss [-0.22287436, -0.26374108, 0.040866718]\n",
      "Iter 1337, loss [-0.22755837, -0.27080587, 0.04324749]\n",
      "Iter 1338, loss [-0.20121078, -0.24118401, 0.03997323]\n",
      "Iter 1339, loss [-0.30537587, -0.31537962, 0.010003748]\n",
      "Iter 1340, loss [-0.2132192, -0.25351104, 0.040291846]\n",
      "Iter 1341, loss [-0.21233526, -0.24725573, 0.034920476]\n",
      "Iter 1342, loss [-0.21767484, -0.25715813, 0.039483294]\n",
      "Iter 1343, loss [-0.22310348, -0.29380682, 0.07070334]\n",
      "Iter 1344, loss [-0.22985598, -0.26660502, 0.036749043]\n",
      "Iter 1345, loss [-0.2093148, -0.24821876, 0.038903963]\n",
      "Iter 1346, loss [-0.21863222, -0.25745675, 0.038824536]\n",
      "Iter 1347, loss [-0.2067776, -0.2492261, 0.042448483]\n",
      "Iter 1348, loss [-0.2273355, -0.29569918, 0.06836368]\n",
      "Iter 1349, loss [-0.21564984, -0.25536507, 0.039715227]\n",
      "Iter 1350, loss [-0.22729148, -0.2655217, 0.038230225]\n",
      "Iter 1351, loss [-0.23998028, -0.31402194, 0.074041665]\n",
      "Iter 1352, loss [-0.2150783, -0.25548857, 0.04041028]\n",
      "Iter 1353, loss [-0.22703905, -0.2723304, 0.045291346]\n",
      "Iter 1354, loss [-0.2240722, -0.28373924, 0.059667032]\n",
      "Iter 1355, loss [-0.20177118, -0.24106641, 0.039295226]\n",
      "Iter 1356, loss [-0.21999587, -0.2590999, 0.03910403]\n",
      "Iter 1357, loss [-0.20460016, -0.24217913, 0.03757897]\n",
      "Iter 1358, loss [-0.22368237, -0.2679371, 0.044254716]\n",
      "Iter 1359, loss [-0.21791688, -0.25847515, 0.04055827]\n",
      "Iter 1360, loss [-0.2354712, -0.3126761, 0.0772049]\n",
      "Iter 1361, loss [-0.21964315, -0.25926182, 0.039618663]\n",
      "Iter 1362, loss [-0.21787144, -0.25909418, 0.041222736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1363, loss [-0.21866447, -0.2596084, 0.04094392]\n",
      "Iter 1364, loss [-0.21626757, -0.25655577, 0.0402882]\n",
      "Iter 1365, loss [-0.23132613, -0.29975954, 0.068433404]\n",
      "Iter 1366, loss [-0.22659115, -0.26460853, 0.03801738]\n",
      "Iter 1367, loss [-0.2112568, -0.2542823, 0.04302549]\n",
      "Iter 1368, loss [-0.21682301, -0.25474718, 0.03792417]\n",
      "Iter 1369, loss [-0.21092668, -0.2447614, 0.03383472]\n",
      "Iter 1370, loss [-0.20783295, -0.25415415, 0.046321195]\n",
      "Iter 1371, loss [-0.21728921, -0.2536462, 0.036356986]\n",
      "Iter 1372, loss [-0.22019807, -0.28307894, 0.062880866]\n",
      "Iter 1373, loss [-0.2095981, -0.25087568, 0.041277587]\n",
      "Iter 1374, loss [-0.21277022, -0.25392482, 0.041154593]\n",
      "Iter 1375, loss [-0.21852492, -0.25996166, 0.041436747]\n",
      "Iter 1376, loss [-0.21753435, -0.25470173, 0.037167385]\n",
      "Iter 1377, loss [-0.21541324, -0.25718802, 0.041774772]\n",
      "Iter 1378, loss [-0.2150802, -0.25640428, 0.04132408]\n",
      "Iter 1379, loss [-0.21775085, -0.2985691, 0.08081826]\n",
      "Iter 1380, loss [-0.20363863, -0.2443686, 0.040729966]\n",
      "Iter 1381, loss [-0.21724772, -0.25484398, 0.037596248]\n",
      "Iter 1382, loss [-0.21823311, -0.26079434, 0.042561233]\n",
      "Iter 1383, loss [-0.20687439, -0.24555236, 0.038677976]\n",
      "Iter 1384, loss [-0.21235949, -0.25020173, 0.037842236]\n",
      "Iter 1385, loss [-0.20577247, -0.24897036, 0.043197885]\n",
      "Iter 1386, loss [-0.2100572, -0.25886413, 0.04880693]\n",
      "Iter 1387, loss [-0.20699988, -0.24308799, 0.03608811]\n",
      "Iter 1388, loss [-0.21067622, -0.24852034, 0.03784412]\n",
      "Iter 1389, loss [-0.22617796, -0.26221812, 0.036040165]\n",
      "Iter 1390, loss [-0.30754608, -0.316843, 0.009296916]\n",
      "Iter 1391, loss [-0.21774046, -0.25501007, 0.037269607]\n",
      "Iter 1392, loss [-0.21649022, -0.25226948, 0.035779253]\n",
      "Iter 1393, loss [-0.22667706, -0.27027872, 0.043601662]\n",
      "Iter 1394, loss [-0.20993327, -0.24894527, 0.039012]\n",
      "Iter 1395, loss [-0.2049391, -0.2542183, 0.049279213]\n",
      "Iter 1396, loss [-0.21159548, -0.256811, 0.045215514]\n",
      "Iter 1397, loss [-0.22370799, -0.2884872, 0.06477921]\n",
      "Iter 1398, loss [-0.22776607, -0.26675692, 0.038990855]\n",
      "Iter 1399, loss [-0.22298095, -0.2592356, 0.036254637]\n",
      "Iter 1400, loss [-0.21795325, -0.2522613, 0.03430806]\n",
      "Iter 1401, loss [-0.20425159, -0.23917632, 0.03492473]\n",
      "Iter 1402, loss [-0.21359287, -0.27317533, 0.059582457]\n",
      "Iter 1403, loss [-0.21137193, -0.25006855, 0.038696624]\n",
      "Iter 1404, loss [-0.21064113, -0.25130033, 0.040659204]\n",
      "Iter 1405, loss [-0.2458547, -0.2899672, 0.044112496]\n",
      "Iter 1406, loss [-0.20773692, -0.24700955, 0.039272625]\n",
      "Iter 1407, loss [-0.21006593, -0.25102496, 0.040959023]\n",
      "Iter 1408, loss [-0.21577004, -0.25922424, 0.0434542]\n",
      "Iter 1409, loss [-0.21757066, -0.26046482, 0.042894155]\n",
      "Iter 1410, loss [-0.21129405, -0.25511566, 0.04382161]\n",
      "Iter 1411, loss [-0.23339301, -0.28678805, 0.05339503]\n",
      "Iter 1412, loss [-0.2254902, -0.2639204, 0.038430195]\n",
      "Iter 1413, loss [-0.2131308, -0.25446877, 0.041337963]\n",
      "Iter 1414, loss [-0.21759063, -0.25587475, 0.038284123]\n",
      "Iter 1415, loss [-0.1990776, -0.23466288, 0.035585266]\n",
      "Iter 1416, loss [-0.20758414, -0.24525279, 0.037668638]\n",
      "Iter 1417, loss [-0.21975519, -0.2587648, 0.03900962]\n",
      "Iter 1418, loss [-0.2152431, -0.25773096, 0.042487867]\n",
      "Iter 1419, loss [-0.21129884, -0.25260982, 0.04131098]\n",
      "Iter 1420, loss [-0.22413108, -0.28577134, 0.06164026]\n",
      "Iter 1421, loss [-0.20921677, -0.24839899, 0.039182212]\n",
      "Iter 1422, loss [-0.22693536, -0.2638915, 0.03695613]\n",
      "Iter 1423, loss [-0.2163359, -0.25526267, 0.038926788]\n",
      "Iter 1424, loss [-0.21165499, -0.24839614, 0.03674116]\n",
      "Iter 1425, loss [-0.22859165, -0.29442897, 0.06583732]\n",
      "Iter 1426, loss [-0.2182666, -0.2566347, 0.038368102]\n",
      "Iter 1427, loss [-0.22778568, -0.28957343, 0.061787747]\n",
      "Iter 1428, loss [-0.21740445, -0.25531512, 0.037910677]\n",
      "Iter 1429, loss [-0.20901464, -0.26049742, 0.051482778]\n",
      "Iter 1430, loss [-0.2037896, -0.29765463, 0.09386502]\n",
      "Iter 1431, loss [-0.21736243, -0.26254922, 0.045186784]\n",
      "Iter 1432, loss [-0.22794762, -0.26522943, 0.03728182]\n",
      "Iter 1433, loss [-0.3068235, -0.31630456, 0.009481085]\n",
      "Iter 1434, loss [-0.21802852, -0.25611976, 0.038091242]\n",
      "Iter 1435, loss [-0.24102199, -0.29894617, 0.057924174]\n",
      "Iter 1436, loss [-0.21329619, -0.2522203, 0.038924113]\n",
      "Iter 1437, loss [-0.20410341, -0.29631323, 0.09220981]\n",
      "Iter 1438, loss [-0.22098444, -0.25936875, 0.038384303]\n",
      "Iter 1439, loss [-0.21002987, -0.25133094, 0.04130108]\n",
      "Iter 1440, loss [-0.2389408, -0.27703768, 0.038096868]\n",
      "Iter 1441, loss [-0.20372406, -0.24357738, 0.039853312]\n",
      "Iter 1442, loss [-0.21885478, -0.25894576, 0.04009097]\n",
      "Iter 1443, loss [-0.22258146, -0.2599845, 0.037403036]\n",
      "Iter 1444, loss [-0.2074377, -0.24393627, 0.036498584]\n",
      "Iter 1445, loss [-0.30766466, -0.31713971, 0.009475059]\n",
      "Iter 1446, loss [-0.22594863, -0.26196903, 0.03602039]\n",
      "Iter 1447, loss [-0.21443574, -0.25403953, 0.039603785]\n",
      "Iter 1448, loss [-0.21965384, -0.2572335, 0.03757965]\n",
      "Iter 1449, loss [-0.20632009, -0.24698123, 0.040661138]\n",
      "Iter 1450, loss [-0.23829356, -0.30440137, 0.0661078]\n",
      "Iter 1451, loss [-0.215426, -0.25643212, 0.041006118]\n",
      "Iter 1452, loss [-0.21142867, -0.2522475, 0.040818848]\n",
      "Iter 1453, loss [-0.21302974, -0.27558118, 0.06255143]\n",
      "Iter 1454, loss [-0.22404283, -0.262125, 0.038082145]\n",
      "Iter 1455, loss [-0.21998096, -0.256681, 0.03670004]\n",
      "Iter 1456, loss [-0.21721472, -0.25382397, 0.036609244]\n",
      "Iter 1457, loss [-0.21497953, -0.25648072, 0.041501194]\n",
      "Iter 1458, loss [-0.21828261, -0.25837636, 0.040093757]\n",
      "Iter 1459, loss [-0.21212685, -0.25437576, 0.042248912]\n",
      "Iter 1460, loss [-0.20486955, -0.25408643, 0.049216878]\n",
      "Iter 1461, loss [-0.20988609, -0.25113723, 0.041251138]\n",
      "Iter 1462, loss [-0.22760287, -0.26590666, 0.0383038]\n",
      "Iter 1463, loss [-0.22703998, -0.26577613, 0.03873615]\n",
      "Iter 1464, loss [-0.21800637, -0.25489688, 0.036890507]\n",
      "Iter 1465, loss [-0.23374161, -0.29401693, 0.060275313]\n",
      "Iter 1466, loss [-0.22690181, -0.27236095, 0.045459133]\n",
      "Iter 1467, loss [-0.23028962, -0.3077371, 0.07744749]\n",
      "Iter 1468, loss [-0.21502768, -0.2587716, 0.04374392]\n",
      "Iter 1469, loss [-0.19673488, -0.2458083, 0.04907342]\n",
      "Iter 1470, loss [-0.20603806, -0.2491458, 0.04310774]\n",
      "Iter 1471, loss [-0.20374383, -0.24562472, 0.041880887]\n",
      "Iter 1472, loss [-0.2046664, -0.2915585, 0.0868921]\n",
      "Iter 1473, loss [-0.218725, -0.25555685, 0.03683185]\n",
      "Iter 1474, loss [-0.3066745, -0.31628, 0.009605488]\n",
      "Iter 1475, loss [-0.20552783, -0.23990889, 0.03438106]\n",
      "Iter 1476, loss [-0.21595025, -0.2512036, 0.035253342]\n",
      "Iter 1477, loss [-0.21671748, -0.2509676, 0.034250107]\n",
      "Iter 1478, loss [-0.21982694, -0.25764546, 0.03781852]\n",
      "Iter 1479, loss [-0.20850936, -0.25215313, 0.04364378]\n",
      "Iter 1480, loss [-0.20162556, -0.24203032, 0.040404774]\n",
      "Iter 1481, loss [-0.2039231, -0.24238114, 0.038458034]\n",
      "Iter 1482, loss [-0.20333996, -0.24904017, 0.045700215]\n",
      "Iter 1483, loss [-0.20832452, -0.2503336, 0.042009093]\n",
      "Iter 1484, loss [-0.20562622, -0.2677466, 0.062120378]\n",
      "Iter 1485, loss [-0.20983045, -0.25392374, 0.044093296]\n",
      "Iter 1486, loss [-0.16788176, -0.24928963, 0.08140787]\n",
      "Iter 1487, loss [-0.20427035, -0.25031877, 0.046048418]\n",
      "Iter 1488, loss [-0.19863394, -0.25874192, 0.060107976]\n",
      "Iter 1489, loss [-0.22314773, -0.26929507, 0.046147328]\n",
      "Iter 1490, loss [-0.22216967, -0.2615206, 0.039350923]\n",
      "Iter 1491, loss [-0.2062594, -0.24535738, 0.039097976]\n",
      "Iter 1492, loss [-0.20533834, -0.24993216, 0.04459381]\n",
      "Iter 1493, loss [-0.21734549, -0.2791226, 0.0617771]\n",
      "Iter 1494, loss [-0.20401831, -0.24694291, 0.042924598]\n",
      "Iter 1495, loss [-0.23700553, -0.27216786, 0.035162337]\n",
      "Iter 1496, loss [-0.21152902, -0.24964514, 0.038116124]\n",
      "Iter 1497, loss [-0.3057363, -0.31610706, 0.010370762]\n",
      "Iter 1498, loss [-0.21299025, -0.2503937, 0.03740343]\n",
      "Iter 1499, loss [-0.20673949, -0.24768291, 0.040943425]\n",
      "Iter 1500, loss [-0.20521653, -0.24442928, 0.03921275]\n",
      "Iter 1501, loss [-0.20930631, -0.24700159, 0.037695274]\n",
      "Iter 1502, loss [-0.21861349, -0.25811565, 0.039502155]\n",
      "Iter 1503, loss [-0.21853691, -0.25834787, 0.039810963]\n",
      "Iter 1504, loss [-0.21693727, -0.2587017, 0.041764446]\n",
      "Iter 1505, loss [-0.20553398, -0.24484722, 0.03931325]\n",
      "Iter 1506, loss [-0.22469708, -0.2643684, 0.039671324]\n",
      "Iter 1507, loss [-0.21517047, -0.25625184, 0.041081365]\n",
      "Iter 1508, loss [-0.22242548, -0.26645836, 0.044032887]\n",
      "Iter 1509, loss [-0.20421466, -0.24145886, 0.03724421]\n",
      "Iter 1510, loss [-0.21565363, -0.25279737, 0.037143745]\n",
      "Iter 1511, loss [-0.22473279, -0.26404428, 0.03931149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1512, loss [-0.2116301, -0.25214344, 0.040513333]\n",
      "Iter 1513, loss [-0.21769553, -0.2577685, 0.040072978]\n",
      "Iter 1514, loss [-0.21153037, -0.2515084, 0.03997804]\n",
      "Iter 1515, loss [-0.19880798, -0.23533314, 0.036525153]\n",
      "Iter 1516, loss [-0.21611753, -0.25506756, 0.03895003]\n",
      "Iter 1517, loss [-0.22246243, -0.26156303, 0.0391006]\n",
      "Iter 1518, loss [-0.21756709, -0.2573982, 0.039831102]\n",
      "Iter 1519, loss [-0.21470875, -0.25554916, 0.04084041]\n",
      "Iter 1520, loss [-0.21474317, -0.2554429, 0.040699728]\n",
      "Iter 1521, loss [-0.22501849, -0.2632013, 0.03818281]\n",
      "Iter 1522, loss [-0.20900705, -0.24914965, 0.040142603]\n",
      "Iter 1523, loss [-0.22390282, -0.264287, 0.040384173]\n",
      "Iter 1524, loss [-0.21672988, -0.26100057, 0.0442707]\n",
      "Iter 1525, loss [-0.21839248, -0.25440443, 0.03601195]\n",
      "Iter 1526, loss [-0.20464194, -0.24448691, 0.039844975]\n",
      "Iter 1527, loss [-0.2126807, -0.25482106, 0.042140357]\n",
      "Iter 1528, loss [-0.22749162, -0.26650906, 0.039017446]\n",
      "Iter 1529, loss [-0.21559091, -0.25882939, 0.043238476]\n",
      "Iter 1530, loss [-0.21301986, -0.25407735, 0.041057486]\n",
      "Iter 1531, loss [-0.21560206, -0.2552631, 0.039661035]\n",
      "Iter 1532, loss [-0.22612762, -0.2884929, 0.06236527]\n",
      "Iter 1533, loss [-0.21023437, -0.24799553, 0.03776115]\n",
      "Iter 1534, loss [-0.21736176, -0.26108122, 0.043719452]\n",
      "Iter 1535, loss [-0.20506535, -0.25226352, 0.04719816]\n",
      "Iter 1536, loss [-0.1978686, -0.24379532, 0.04592672]\n",
      "Iter 1537, loss [-0.21571665, -0.25550947, 0.03979282]\n",
      "Iter 1538, loss [-0.21605444, -0.2563497, 0.04029528]\n",
      "Iter 1539, loss [-0.21839708, -0.25552022, 0.03712315]\n",
      "Iter 1540, loss [-0.20186357, -0.2422465, 0.04038292]\n",
      "Iter 1541, loss [-0.22851437, -0.2727155, 0.04420113]\n",
      "Iter 1542, loss [-0.22725652, -0.2670185, 0.03976197]\n",
      "Iter 1543, loss [-0.21252413, -0.27366912, 0.061144993]\n",
      "Iter 1544, loss [-0.20872928, -0.25228837, 0.043559086]\n",
      "Iter 1545, loss [-0.2104793, -0.2505304, 0.040051088]\n",
      "Iter 1546, loss [-0.2161389, -0.25772136, 0.04158246]\n",
      "Iter 1547, loss [-0.20727363, -0.24787539, 0.04060176]\n",
      "Iter 1548, loss [-0.2400888, -0.30327874, 0.06318994]\n",
      "Iter 1549, loss [-0.20693971, -0.24729322, 0.040353507]\n",
      "Iter 1550, loss [-0.21824485, -0.254812, 0.036567148]\n",
      "Iter 1551, loss [-0.2102337, -0.24833979, 0.03810608]\n",
      "Iter 1552, loss [-0.22058937, -0.26030985, 0.039720472]\n",
      "Iter 1553, loss [-0.22638759, -0.2887554, 0.062367797]\n",
      "Iter 1554, loss [-0.20188206, -0.24622118, 0.04433912]\n",
      "Iter 1555, loss [-0.22504455, -0.26820984, 0.043165293]\n",
      "Iter 1556, loss [-0.2175723, -0.26293454, 0.045362227]\n",
      "Iter 1557, loss [-0.30683908, -0.31638357, 0.009544501]\n",
      "Iter 1558, loss [-0.22036055, -0.25849006, 0.038129512]\n",
      "Iter 1559, loss [-0.2051428, -0.24108665, 0.035943855]\n",
      "Iter 1560, loss [-0.30706215, -0.31631273, 0.009250594]\n",
      "Iter 1561, loss [-0.20467281, -0.2404771, 0.035804287]\n",
      "Iter 1562, loss [-0.22837447, -0.26961786, 0.041243393]\n",
      "Iter 1563, loss [-0.2075353, -0.24341519, 0.035879903]\n",
      "Iter 1564, loss [-0.21861786, -0.25538546, 0.03676761]\n",
      "Iter 1565, loss [-0.21302807, -0.25864828, 0.045620196]\n",
      "Iter 1566, loss [-0.22331622, -0.26198515, 0.03866893]\n",
      "Iter 1567, loss [-0.22032124, -0.25999707, 0.039675824]\n",
      "Iter 1568, loss [-0.21560669, -0.2771654, 0.061558723]\n",
      "Iter 1569, loss [-0.22534297, -0.26544732, 0.04010434]\n",
      "Iter 1570, loss [-0.2170189, -0.25369766, 0.036678754]\n",
      "Iter 1571, loss [-0.23126903, -0.26821148, 0.036942452]\n",
      "Iter 1572, loss [-0.23974623, -0.3134669, 0.07372068]\n",
      "Iter 1573, loss [-0.20468913, -0.24268015, 0.037991017]\n",
      "Iter 1574, loss [-0.21606182, -0.2543833, 0.038321476]\n",
      "Iter 1575, loss [-0.228684, -0.29771703, 0.06903304]\n",
      "Iter 1576, loss [-0.20987204, -0.24728152, 0.037409484]\n",
      "Iter 1577, loss [-0.22081566, -0.2587099, 0.03789425]\n",
      "Iter 1578, loss [-0.21244499, -0.2520919, 0.039646927]\n",
      "Iter 1579, loss [-0.2161021, -0.25542578, 0.039323688]\n",
      "Iter 1580, loss [-0.21887656, -0.25602406, 0.037147507]\n",
      "Iter 1581, loss [-0.21117848, -0.25148657, 0.04030808]\n",
      "Iter 1582, loss [-0.20229349, -0.2942808, 0.09198731]\n",
      "Iter 1583, loss [-0.21947631, -0.26052588, 0.041049574]\n",
      "Iter 1584, loss [-0.22111662, -0.25996208, 0.03884546]\n",
      "Iter 1585, loss [-0.22564666, -0.265159, 0.03951235]\n",
      "Iter 1586, loss [-0.21690838, -0.255757, 0.038848624]\n",
      "Iter 1587, loss [-0.2156688, -0.25603536, 0.04036656]\n",
      "Iter 1588, loss [-0.21533637, -0.2554263, 0.04008992]\n",
      "Iter 1589, loss [-0.20888962, -0.24814911, 0.03925949]\n",
      "Iter 1590, loss [-0.21650809, -0.28374988, 0.06724178]\n",
      "Iter 1591, loss [-0.2153632, -0.2512743, 0.035911087]\n",
      "Iter 1592, loss [-0.21568403, -0.25431523, 0.038631193]\n",
      "Iter 1593, loss [-0.22627074, -0.26310048, 0.036829732]\n",
      "Iter 1594, loss [-0.20603234, -0.24442723, 0.038394906]\n",
      "Iter 1595, loss [-0.21859114, -0.26635107, 0.047759935]\n",
      "Iter 1596, loss [-0.20490536, -0.24804226, 0.043136895]\n",
      "Iter 1597, loss [-0.2129003, -0.2555449, 0.0426446]\n",
      "Iter 1598, loss [-0.2261167, -0.26658803, 0.04047133]\n",
      "Iter 1599, loss [-0.20675729, -0.2491637, 0.04240641]\n",
      "Iter 1600, loss [-0.21470726, -0.25654492, 0.041837655]\n",
      "Iter 1601, loss [-0.2119575, -0.2522206, 0.0402631]\n",
      "Iter 1602, loss [-0.2078174, -0.24552079, 0.037703384]\n",
      "Iter 1603, loss [-0.2125798, -0.2517216, 0.039141785]\n",
      "Iter 1604, loss [-0.21177475, -0.25502416, 0.04324941]\n",
      "Iter 1605, loss [-0.21416229, -0.25390097, 0.039738692]\n",
      "Iter 1606, loss [-0.21099797, -0.2506038, 0.039605826]\n",
      "Iter 1607, loss [-0.23954412, -0.276303, 0.036758877]\n",
      "Iter 1608, loss [-0.18619601, -0.2750865, 0.08889048]\n",
      "Iter 1609, loss [-0.20771892, -0.253257, 0.04553808]\n",
      "Iter 1610, loss [-0.21634233, -0.25842354, 0.0420812]\n",
      "Iter 1611, loss [-0.22513008, -0.26495197, 0.039821893]\n",
      "Iter 1612, loss [-0.22099063, -0.25984386, 0.038853228]\n",
      "Iter 1613, loss [-0.21863429, -0.25784627, 0.03921197]\n",
      "Iter 1614, loss [-0.16953993, -0.27227652, 0.10273659]\n",
      "Iter 1615, loss [-0.21223445, -0.24857752, 0.036343068]\n",
      "Iter 1616, loss [-0.22261105, -0.258185, 0.03557395]\n",
      "Iter 1617, loss [-0.22799824, -0.28756937, 0.05957113]\n",
      "Iter 1618, loss [-0.22297716, -0.26469284, 0.041715674]\n",
      "Iter 1619, loss [-0.2038479, -0.23977254, 0.03592464]\n",
      "Iter 1620, loss [-0.22538921, -0.26360062, 0.03821141]\n",
      "Iter 1621, loss [-0.21677867, -0.2548603, 0.03808164]\n",
      "Iter 1622, loss [-0.23451303, -0.28875697, 0.054243933]\n",
      "Iter 1623, loss [-0.20430705, -0.25204754, 0.04774049]\n",
      "Iter 1624, loss [-0.17869917, -0.2301801, 0.051480934]\n",
      "Iter 1625, loss [-0.21282735, -0.25565705, 0.042829685]\n",
      "Iter 1626, loss [-0.20103666, -0.24213444, 0.041097783]\n",
      "Iter 1627, loss [-0.2238363, -0.25882903, 0.03499272]\n",
      "Iter 1628, loss [-0.2200873, -0.2552361, 0.03514878]\n",
      "Iter 1629, loss [-0.21953751, -0.254977, 0.035439476]\n",
      "Iter 1630, loss [-0.20519629, -0.24446239, 0.03926609]\n",
      "Iter 1631, loss [-0.2011525, -0.23917547, 0.038022958]\n",
      "Iter 1632, loss [-0.21287638, -0.25451282, 0.041636445]\n",
      "Iter 1633, loss [-0.19255254, -0.28342643, 0.09087389]\n",
      "Iter 1634, loss [-0.20049429, -0.24312021, 0.04262591]\n",
      "Iter 1635, loss [-0.22610833, -0.27358434, 0.047476005]\n",
      "Iter 1636, loss [-0.22455125, -0.26652738, 0.041976135]\n",
      "Iter 1637, loss [-0.21648951, -0.25999385, 0.04350434]\n",
      "Iter 1638, loss [-0.2009835, -0.23919216, 0.038208663]\n",
      "Iter 1639, loss [-0.30653012, -0.31620824, 0.009678114]\n",
      "Iter 1640, loss [-0.21140926, -0.24678582, 0.035376564]\n",
      "Iter 1641, loss [-0.20965743, -0.25112194, 0.041464504]\n",
      "Iter 1642, loss [-0.20549412, -0.23944545, 0.033951327]\n",
      "Iter 1643, loss [-0.23902154, -0.30052704, 0.061505497]\n",
      "Iter 1644, loss [-0.23437345, -0.31298518, 0.07861173]\n",
      "Iter 1645, loss [-0.2068601, -0.24899098, 0.042130884]\n",
      "Iter 1646, loss [-0.20663895, -0.24845165, 0.0418127]\n",
      "Iter 1647, loss [-0.20917799, -0.25902343, 0.049845442]\n",
      "Iter 1648, loss [-0.21326053, -0.25663272, 0.04337219]\n",
      "Iter 1649, loss [-0.21093573, -0.2546607, 0.04372497]\n",
      "Iter 1650, loss [-0.19514768, -0.28623968, 0.091092005]\n",
      "Iter 1651, loss [-0.22067855, -0.30034173, 0.07966317]\n",
      "Iter 1652, loss [-0.22723532, -0.26338133, 0.03614601]\n",
      "Iter 1653, loss [-0.2128537, -0.25125706, 0.03840336]\n",
      "Iter 1654, loss [-0.1906784, -0.2803589, 0.08968051]\n",
      "Iter 1655, loss [-0.22615477, -0.2704395, 0.04428473]\n",
      "Iter 1656, loss [-0.21388109, -0.2499198, 0.036038715]\n",
      "Iter 1657, loss [-0.22345755, -0.26116174, 0.037704207]\n",
      "Iter 1658, loss [-0.20656492, -0.24360654, 0.03704162]\n",
      "Iter 1659, loss [-0.22259748, -0.26344228, 0.04084479]\n",
      "Iter 1660, loss [-0.20089686, -0.26033652, 0.05943966]\n",
      "Iter 1661, loss [-0.22188902, -0.26253957, 0.04065054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1662, loss [-0.21081981, -0.25100145, 0.040181633]\n",
      "Iter 1663, loss [-0.21431758, -0.27741683, 0.06309925]\n",
      "Iter 1664, loss [-0.20936747, -0.25616384, 0.046796363]\n",
      "Iter 1665, loss [-0.20670031, -0.24786586, 0.04116554]\n",
      "Iter 1666, loss [-0.20932302, -0.28864685, 0.079323836]\n",
      "Iter 1667, loss [-0.21251033, -0.2529057, 0.04039536]\n",
      "Iter 1668, loss [-0.20293155, -0.24078135, 0.037849795]\n",
      "Iter 1669, loss [-0.20889631, -0.25031725, 0.041420937]\n",
      "Iter 1670, loss [-0.21672831, -0.25893414, 0.042205825]\n",
      "Iter 1671, loss [-0.2099503, -0.24859841, 0.03864811]\n",
      "Iter 1672, loss [-0.21444164, -0.25742945, 0.04298781]\n",
      "Iter 1673, loss [-0.22306201, -0.26401913, 0.04095713]\n",
      "Iter 1674, loss [-0.20665753, -0.24433948, 0.03768195]\n",
      "Iter 1675, loss [-0.20193446, -0.24179193, 0.03985747]\n",
      "Iter 1676, loss [-0.1916981, -0.2881486, 0.0964505]\n",
      "Iter 1677, loss [-0.21753046, -0.30010286, 0.08257239]\n",
      "Iter 1678, loss [-0.22484791, -0.26818544, 0.043337524]\n",
      "Iter 1679, loss [-0.22326377, -0.26208115, 0.038817383]\n",
      "Iter 1680, loss [-0.21333954, -0.29455537, 0.081215836]\n",
      "Iter 1681, loss [-0.21016864, -0.24797268, 0.037804037]\n",
      "Iter 1682, loss [-0.21615359, -0.27993774, 0.06378415]\n",
      "Iter 1683, loss [-0.21825814, -0.2586003, 0.040342145]\n",
      "Iter 1684, loss [-0.21414179, -0.2535412, 0.039399423]\n",
      "Iter 1685, loss [-0.20095372, -0.2405365, 0.03958278]\n",
      "Iter 1686, loss [-0.216676, -0.257142, 0.040466018]\n",
      "Iter 1687, loss [-0.21931912, -0.2583981, 0.039078966]\n",
      "Iter 1688, loss [-0.21703352, -0.25772697, 0.04069345]\n",
      "Iter 1689, loss [-0.20645902, -0.24907055, 0.04261154]\n",
      "Iter 1690, loss [-0.21557535, -0.26205498, 0.046479624]\n",
      "Iter 1691, loss [-0.22647643, -0.2735961, 0.047119677]\n",
      "Iter 1692, loss [-0.21998408, -0.26018408, 0.040200002]\n",
      "Iter 1693, loss [-0.21684548, -0.2558749, 0.039029416]\n",
      "Iter 1694, loss [-0.23249903, -0.28729805, 0.054799013]\n",
      "Iter 1695, loss [-0.21944743, -0.2595863, 0.04013887]\n",
      "Iter 1696, loss [-0.22629999, -0.26587793, 0.039577946]\n",
      "Iter 1697, loss [-0.24434522, -0.30738884, 0.06304362]\n",
      "Iter 1698, loss [-0.21218625, -0.25433993, 0.042153694]\n",
      "Iter 1699, loss [-0.20172247, -0.24154873, 0.039826255]\n",
      "Iter 1700, loss [-0.23836552, -0.31808254, 0.079717025]\n",
      "Iter 1701, loss [-0.24612133, -0.30996704, 0.06384571]\n",
      "Iter 1702, loss [-0.22411728, -0.2683509, 0.04423362]\n",
      "Iter 1703, loss [-0.21164224, -0.25601548, 0.04437324]\n",
      "Iter 1704, loss [-0.22433212, -0.26804134, 0.04370921]\n",
      "Iter 1705, loss [-0.21156892, -0.24997379, 0.038404863]\n",
      "Iter 1706, loss [-0.22545728, -0.28649226, 0.061034974]\n",
      "Iter 1707, loss [-0.20512712, -0.24161984, 0.036492713]\n",
      "Iter 1708, loss [-0.19939232, -0.23566066, 0.03626834]\n",
      "Iter 1709, loss [-0.22358468, -0.2612817, 0.037697017]\n",
      "Iter 1710, loss [-0.22850896, -0.29824817, 0.06973921]\n",
      "Iter 1711, loss [-0.21769832, -0.2577566, 0.04005827]\n",
      "Iter 1712, loss [-0.22497085, -0.26789895, 0.042928107]\n",
      "Iter 1713, loss [-0.21239015, -0.25738397, 0.044993818]\n",
      "Iter 1714, loss [-0.23876852, -0.3178222, 0.07905366]\n",
      "Iter 1715, loss [-0.20674708, -0.24787939, 0.041132294]\n",
      "Iter 1716, loss [-0.21729764, -0.25511298, 0.037815325]\n",
      "Iter 1717, loss [-0.20503715, -0.25304827, 0.04801113]\n",
      "Iter 1718, loss [-0.20947868, -0.24753305, 0.038054377]\n",
      "Iter 1719, loss [-0.22601114, -0.2852724, 0.059261244]\n",
      "Iter 1720, loss [-0.21971035, -0.26000527, 0.040294923]\n",
      "Iter 1721, loss [-0.21017194, -0.24776636, 0.037594415]\n",
      "Iter 1722, loss [-0.22533779, -0.26498523, 0.03964744]\n",
      "Iter 1723, loss [-0.21293564, -0.24860255, 0.03566691]\n",
      "Iter 1724, loss [-0.22538224, -0.26753724, 0.042154994]\n",
      "Iter 1725, loss [-0.2184114, -0.2561416, 0.037730202]\n",
      "Iter 1726, loss [-0.20775038, -0.24466586, 0.03691549]\n",
      "Iter 1727, loss [-0.21224226, -0.25641906, 0.044176802]\n",
      "Iter 1728, loss [-0.2058638, -0.24362011, 0.0377563]\n",
      "Iter 1729, loss [-0.30682403, -0.3164208, 0.009596765]\n",
      "Iter 1730, loss [-0.21723598, -0.25396946, 0.03673348]\n",
      "Iter 1731, loss [-0.20462133, -0.243706, 0.039084673]\n",
      "Iter 1732, loss [-0.21011837, -0.25627214, 0.04615377]\n",
      "Iter 1733, loss [-0.22113423, -0.26571563, 0.044581395]\n",
      "Iter 1734, loss [-0.22320688, -0.30039814, 0.07719126]\n",
      "Iter 1735, loss [-0.21796653, -0.257, 0.039033473]\n",
      "Iter 1736, loss [-0.21226646, -0.24911965, 0.03685319]\n",
      "Iter 1737, loss [-0.2141445, -0.25509465, 0.040950157]\n",
      "Iter 1738, loss [-0.212078, -0.2516338, 0.039555795]\n",
      "Iter 1739, loss [-0.2270203, -0.2653065, 0.038286213]\n",
      "Iter 1740, loss [-0.21413311, -0.25402254, 0.03988942]\n",
      "Iter 1741, loss [-0.22112954, -0.2670263, 0.045896776]\n",
      "Iter 1742, loss [-0.2176621, -0.26061398, 0.04295188]\n",
      "Iter 1743, loss [-0.20181237, -0.2409432, 0.039130826]\n",
      "Iter 1744, loss [-0.22746497, -0.26588476, 0.03841979]\n",
      "Iter 1745, loss [-0.21254645, -0.25646728, 0.043920826]\n",
      "Iter 1746, loss [-0.20246397, -0.24461183, 0.042147856]\n",
      "Iter 1747, loss [-0.21538185, -0.25483012, 0.039448276]\n",
      "Iter 1748, loss [-0.21122192, -0.25283873, 0.04161681]\n",
      "Iter 1749, loss [-0.21599716, -0.25770223, 0.041705072]\n",
      "Iter 1750, loss [-0.20472418, -0.24432035, 0.03959617]\n",
      "Iter 1751, loss [-0.20927179, -0.25074232, 0.041470528]\n",
      "Iter 1752, loss [-0.21504557, -0.2565634, 0.041517824]\n",
      "Iter 1753, loss [-0.21634015, -0.26179317, 0.045453012]\n",
      "Iter 1754, loss [-0.21674736, -0.25678945, 0.040042087]\n",
      "Iter 1755, loss [-0.21055742, -0.27165273, 0.061095312]\n",
      "Iter 1756, loss [-0.22427256, -0.2614636, 0.037191045]\n",
      "Iter 1757, loss [-0.22547486, -0.26246157, 0.036986716]\n",
      "Iter 1758, loss [-0.21094461, -0.24995391, 0.0390093]\n",
      "Iter 1759, loss [-0.22322106, -0.29218888, 0.06896782]\n",
      "Iter 1760, loss [-0.21619247, -0.25854996, 0.042357486]\n",
      "Iter 1761, loss [-0.22545646, -0.29594263, 0.07048617]\n",
      "Iter 1762, loss [-0.20802343, -0.24730483, 0.03928139]\n",
      "Iter 1763, loss [-0.20186125, -0.24715827, 0.045297023]\n",
      "Iter 1764, loss [-0.2244857, -0.2639485, 0.039462812]\n",
      "Iter 1765, loss [-0.21612996, -0.2545954, 0.038465448]\n",
      "Iter 1766, loss [-0.21789524, -0.25462973, 0.036734488]\n",
      "Iter 1767, loss [-0.22480598, -0.2643631, 0.039557125]\n",
      "Iter 1768, loss [-0.20636362, -0.24707747, 0.040713847]\n",
      "Iter 1769, loss [-0.21310945, -0.25399005, 0.0408806]\n",
      "Iter 1770, loss [-0.21033035, -0.25017816, 0.039847802]\n",
      "Iter 1771, loss [-0.20288508, -0.24638137, 0.043496292]\n",
      "Iter 1772, loss [-0.21365431, -0.25876024, 0.045105927]\n",
      "Iter 1773, loss [-0.22112772, -0.26708832, 0.045960598]\n",
      "Iter 1774, loss [-0.18026277, -0.22898133, 0.048718557]\n",
      "Iter 1775, loss [-0.22000177, -0.2980653, 0.07806353]\n",
      "Iter 1776, loss [-0.22808856, -0.27099174, 0.042903185]\n",
      "Iter 1777, loss [-0.21132435, -0.256401, 0.045076653]\n",
      "Iter 1778, loss [-0.21633677, -0.26283312, 0.046496347]\n",
      "Iter 1779, loss [-0.21145612, -0.25644073, 0.044984616]\n",
      "Iter 1780, loss [-0.21669988, -0.25637302, 0.03967313]\n",
      "Iter 1781, loss [-0.21158184, -0.25039715, 0.038815305]\n",
      "Iter 1782, loss [-0.23970407, -0.2745644, 0.03486032]\n",
      "Iter 1783, loss [-0.20693545, -0.2472226, 0.040287152]\n",
      "Iter 1784, loss [-0.22164273, -0.26674467, 0.045101933]\n",
      "Iter 1785, loss [-0.22015402, -0.25802615, 0.037872136]\n",
      "Iter 1786, loss [-0.2026266, -0.2448533, 0.042226702]\n",
      "Iter 1787, loss [-0.21714005, -0.2543838, 0.037243757]\n",
      "Iter 1788, loss [-0.22208306, -0.26781115, 0.04572808]\n",
      "Iter 1789, loss [-0.20255336, -0.24166803, 0.039114665]\n",
      "Iter 1790, loss [-0.21780157, -0.25748, 0.039678432]\n",
      "Iter 1791, loss [-0.21741581, -0.26278386, 0.045368038]\n",
      "Iter 1792, loss [-0.22076017, -0.26047054, 0.039710365]\n",
      "Iter 1793, loss [-0.20751446, -0.24454455, 0.037030093]\n",
      "Iter 1794, loss [-0.2103637, -0.24963924, 0.039275546]\n",
      "Iter 1795, loss [-0.20889586, -0.2589334, 0.050037533]\n",
      "Iter 1796, loss [-0.30714196, -0.31674033, 0.009598389]\n",
      "Iter 1797, loss [-0.21782824, -0.2618034, 0.043975152]\n",
      "Iter 1798, loss [-0.21901506, -0.25861263, 0.03959758]\n",
      "Iter 1799, loss [-0.2228603, -0.30299872, 0.080138415]\n",
      "Iter 1800, loss [-0.22324127, -0.26039246, 0.037151195]\n",
      "Iter 1801, loss [-0.22817537, -0.26687995, 0.038704567]\n",
      "Iter 1802, loss [-0.220769, -0.26005006, 0.039281055]\n",
      "Iter 1803, loss [-0.2176952, -0.2567654, 0.039070193]\n",
      "Iter 1804, loss [-0.22590889, -0.26544365, 0.03953476]\n",
      "Iter 1805, loss [-0.21786512, -0.25844556, 0.040580433]\n",
      "Iter 1806, loss [-0.2052603, -0.24365225, 0.038391955]\n",
      "Iter 1807, loss [-0.22307533, -0.26163128, 0.038555946]\n",
      "Iter 1808, loss [-0.22326177, -0.26118407, 0.037922297]\n",
      "Iter 1809, loss [-0.20992403, -0.24752334, 0.037599314]\n",
      "Iter 1810, loss [-0.23071566, -0.26634136, 0.035625692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1811, loss [-0.23112367, -0.2668583, 0.035734635]\n",
      "Iter 1812, loss [-0.21606657, -0.25680354, 0.04073697]\n",
      "Iter 1813, loss [-0.21970545, -0.2590665, 0.039361045]\n",
      "Iter 1814, loss [-0.21245733, -0.25463808, 0.042180754]\n",
      "Iter 1815, loss [-0.21711116, -0.257434, 0.04032286]\n",
      "Iter 1816, loss [-0.2105295, -0.25145444, 0.040924937]\n",
      "Iter 1817, loss [-0.20803782, -0.24543235, 0.037394524]\n",
      "Iter 1818, loss [-0.22317874, -0.2621547, 0.038975947]\n",
      "Iter 1819, loss [-0.20488815, -0.24551183, 0.040623676]\n",
      "Iter 1820, loss [-0.22007363, -0.25853375, 0.038460117]\n",
      "Iter 1821, loss [-0.30721357, -0.31678802, 0.009574441]\n",
      "Iter 1822, loss [-0.19625455, -0.2841594, 0.08790484]\n",
      "Iter 1823, loss [-0.21518427, -0.25417164, 0.03898737]\n",
      "Iter 1824, loss [-0.22232194, -0.25969547, 0.037373528]\n",
      "Iter 1825, loss [-0.20298186, -0.29638883, 0.09340697]\n",
      "Iter 1826, loss [-0.22568923, -0.2640594, 0.038370162]\n",
      "Iter 1827, loss [-0.23869544, -0.3104258, 0.071730345]\n",
      "Iter 1828, loss [-0.22535825, -0.28436014, 0.059001893]\n",
      "Iter 1829, loss [-0.30808124, -0.317469, 0.009387775]\n",
      "Iter 1830, loss [-0.21469961, -0.27275315, 0.058053534]\n",
      "Iter 1831, loss [-0.22337753, -0.26578876, 0.042411245]\n",
      "Iter 1832, loss [-0.21569066, -0.25496823, 0.039277565]\n",
      "Iter 1833, loss [-0.22848481, -0.26572886, 0.037244055]\n",
      "Iter 1834, loss [-0.24307711, -0.30643308, 0.06335597]\n",
      "Iter 1835, loss [-0.2022127, -0.24688895, 0.04467624]\n",
      "Iter 1836, loss [-0.22356218, -0.26179823, 0.03823606]\n",
      "Iter 1837, loss [-0.20984979, -0.25193012, 0.042080324]\n",
      "Iter 1838, loss [-0.2137851, -0.25337097, 0.039585877]\n",
      "Iter 1839, loss [-0.21601377, -0.2565772, 0.04056342]\n",
      "Iter 1840, loss [-0.2085261, -0.2516539, 0.043127798]\n",
      "Iter 1841, loss [-0.21744347, -0.25633508, 0.03889161]\n",
      "Iter 1842, loss [-0.20754054, -0.24379587, 0.03625533]\n",
      "Iter 1843, loss [-0.22936387, -0.29841813, 0.06905426]\n",
      "Iter 1844, loss [-0.21783316, -0.25681087, 0.038977716]\n",
      "Iter 1845, loss [-0.24720606, -0.29038957, 0.043183498]\n",
      "Iter 1846, loss [-0.21085009, -0.25038266, 0.039532565]\n",
      "Iter 1847, loss [-0.21624693, -0.27830055, 0.06205362]\n",
      "Iter 1848, loss [-0.21651173, -0.25718313, 0.040671416]\n",
      "Iter 1849, loss [-0.24054335, -0.2758243, 0.035280954]\n",
      "Iter 1850, loss [-0.20752102, -0.24423759, 0.036716558]\n",
      "Iter 1851, loss [-0.21844357, -0.25741938, 0.038975798]\n",
      "Iter 1852, loss [-0.20857218, -0.24606471, 0.03749253]\n",
      "Iter 1853, loss [-0.22188611, -0.26805156, 0.046165448]\n",
      "Iter 1854, loss [-0.20710227, -0.24841008, 0.041307803]\n",
      "Iter 1855, loss [-0.22693436, -0.28769976, 0.060765397]\n",
      "Iter 1856, loss [-0.19776745, -0.24479698, 0.04702952]\n",
      "Iter 1857, loss [-0.22398053, -0.26168126, 0.037700724]\n",
      "Iter 1858, loss [-0.21636298, -0.2581508, 0.041787803]\n",
      "Iter 1859, loss [-0.21871994, -0.25844726, 0.03972731]\n",
      "Iter 1860, loss [-0.2072424, -0.24923342, 0.041991018]\n",
      "Iter 1861, loss [-0.21649346, -0.25875527, 0.04226181]\n",
      "Iter 1862, loss [-0.22612597, -0.2632737, 0.037147716]\n",
      "Iter 1863, loss [-0.20336983, -0.2467755, 0.04340566]\n",
      "Iter 1864, loss [-0.21665995, -0.25870082, 0.04204087]\n",
      "Iter 1865, loss [-0.22882782, -0.2994773, 0.07064949]\n",
      "Iter 1866, loss [-0.21692869, -0.25770822, 0.04077954]\n",
      "Iter 1867, loss [-0.24526815, -0.3058221, 0.060553953]\n",
      "Iter 1868, loss [-0.21844009, -0.25381804, 0.035377942]\n",
      "Iter 1869, loss [-0.22358263, -0.2606032, 0.037020564]\n",
      "Iter 1870, loss [-0.22847791, -0.29031545, 0.061837535]\n",
      "Iter 1871, loss [-0.21086952, -0.2484753, 0.03760577]\n",
      "Iter 1872, loss [-0.23683235, -0.29430255, 0.0574702]\n",
      "Iter 1873, loss [-0.24063186, -0.3206736, 0.08004175]\n",
      "Iter 1874, loss [-0.24244455, -0.3157994, 0.07335484]\n",
      "Iter 1875, loss [-0.21403345, -0.25269446, 0.03866101]\n",
      "Iter 1876, loss [-0.22918005, -0.27190855, 0.0427285]\n",
      "Iter 1877, loss [-0.21793303, -0.25617203, 0.03823901]\n",
      "Iter 1878, loss [-0.21685837, -0.25524604, 0.03838767]\n",
      "Iter 1879, loss [-0.21839446, -0.25717765, 0.03878319]\n",
      "Iter 1880, loss [-0.22366127, -0.26270667, 0.0390454]\n",
      "Iter 1881, loss [-0.21388452, -0.25605652, 0.042171996]\n",
      "Iter 1882, loss [-0.21228352, -0.2519253, 0.039641764]\n",
      "Iter 1883, loss [-0.20785686, -0.24541174, 0.037554882]\n",
      "Iter 1884, loss [-0.215348, -0.2556054, 0.04025739]\n",
      "Iter 1885, loss [-0.20213115, -0.24114138, 0.03901022]\n",
      "Iter 1886, loss [-0.21671385, -0.25637257, 0.039658718]\n",
      "Iter 1887, loss [-0.23020595, -0.29702944, 0.066823475]\n",
      "Iter 1888, loss [-0.21668124, -0.25657764, 0.039896403]\n",
      "Iter 1889, loss [-0.21899098, -0.2561743, 0.037183315]\n",
      "Iter 1890, loss [-0.21988425, -0.2611495, 0.041265246]\n",
      "Iter 1891, loss [-0.24426013, -0.3088065, 0.06454637]\n",
      "Iter 1892, loss [-0.21106717, -0.25084186, 0.03977469]\n",
      "Iter 1893, loss [-0.24778625, -0.2918091, 0.044022854]\n",
      "Iter 1894, loss [-0.21261787, -0.24920025, 0.036582388]\n",
      "Iter 1895, loss [-0.21112409, -0.24870327, 0.03757917]\n",
      "Iter 1896, loss [-0.22750968, -0.26529077, 0.03778109]\n",
      "Iter 1897, loss [-0.2168065, -0.2576344, 0.040827908]\n",
      "Iter 1898, loss [-0.22513577, -0.26322317, 0.0380874]\n",
      "Iter 1899, loss [-0.19788337, -0.24443032, 0.046546947]\n",
      "Iter 1900, loss [-0.22043711, -0.26099044, 0.04055334]\n",
      "Iter 1901, loss [-0.2072899, -0.24899589, 0.04170598]\n",
      "Iter 1902, loss [-0.20561844, -0.25439528, 0.04877683]\n",
      "Iter 1903, loss [-0.22161487, -0.2598205, 0.038205616]\n",
      "Iter 1904, loss [-0.22437087, -0.26223665, 0.037865788]\n",
      "Iter 1905, loss [-0.21229699, -0.25015745, 0.03786046]\n",
      "Iter 1906, loss [-0.21999572, -0.2605025, 0.04050677]\n",
      "Iter 1907, loss [-0.22894767, -0.2909297, 0.06198203]\n",
      "Iter 1908, loss [-0.22680315, -0.26546448, 0.038661323]\n",
      "Iter 1909, loss [-0.21365961, -0.25914887, 0.045489244]\n",
      "Iter 1910, loss [-0.22952247, -0.2675546, 0.038032137]\n",
      "Iter 1911, loss [-0.22370994, -0.26209036, 0.03838042]\n",
      "Iter 1912, loss [-0.24095547, -0.276039, 0.035083525]\n",
      "Iter 1913, loss [-0.2077819, -0.24459423, 0.03681233]\n",
      "Iter 1914, loss [-0.22701016, -0.26546067, 0.03845051]\n",
      "Iter 1915, loss [-0.22182989, -0.25877905, 0.036949165]\n",
      "Iter 1916, loss [-0.19970727, -0.23656869, 0.036861416]\n",
      "Iter 1917, loss [-0.22394423, -0.26313663, 0.039192397]\n",
      "Iter 1918, loss [-0.20967484, -0.24981359, 0.04013876]\n",
      "Iter 1919, loss [-0.20311986, -0.24231121, 0.039191347]\n",
      "Iter 1920, loss [-0.2242342, -0.26275578, 0.038521584]\n",
      "Iter 1921, loss [-0.22886986, -0.26838037, 0.039510526]\n",
      "Iter 1922, loss [-0.21088153, -0.24823402, 0.037352487]\n",
      "Iter 1923, loss [-0.20967153, -0.24971895, 0.04004743]\n",
      "Iter 1924, loss [-0.22947292, -0.29119122, 0.0617183]\n",
      "Iter 1925, loss [-0.21681625, -0.25530037, 0.038484126]\n",
      "Iter 1926, loss [-0.21073496, -0.25086525, 0.040130295]\n",
      "Iter 1927, loss [-0.24723229, -0.30941975, 0.062187456]\n",
      "Iter 1928, loss [-0.20380676, -0.24307552, 0.039268754]\n",
      "Iter 1929, loss [-0.22978088, -0.26772115, 0.037940264]\n",
      "Iter 1930, loss [-0.1995617, -0.23599403, 0.036432322]\n",
      "Iter 1931, loss [-0.30718997, -0.31689104, 0.009701076]\n",
      "Iter 1932, loss [-0.2175801, -0.26274058, 0.045160484]\n",
      "Iter 1933, loss [-0.22749221, -0.26614174, 0.038649525]\n",
      "Iter 1934, loss [-0.22537783, -0.26400107, 0.038623244]\n",
      "Iter 1935, loss [-0.22547136, -0.26570565, 0.04023428]\n",
      "Iter 1936, loss [-0.21509269, -0.25433096, 0.039238278]\n",
      "Iter 1937, loss [-0.20494837, -0.24501993, 0.04007157]\n",
      "Iter 1938, loss [-0.24110958, -0.31384864, 0.072739065]\n",
      "Iter 1939, loss [-0.2087358, -0.24630928, 0.03757348]\n",
      "Iter 1940, loss [-0.20830873, -0.24491043, 0.036601707]\n",
      "Iter 1941, loss [-0.22459656, -0.26504636, 0.040449798]\n",
      "Iter 1942, loss [-0.20571151, -0.2434732, 0.037761696]\n",
      "Iter 1943, loss [-0.1999054, -0.2362808, 0.036375407]\n",
      "Iter 1944, loss [-0.23475096, -0.28901538, 0.054264423]\n",
      "Iter 1945, loss [-0.20773053, -0.24421737, 0.036486827]\n",
      "Iter 1946, loss [-0.22015625, -0.26068982, 0.04053358]\n",
      "Iter 1947, loss [-0.20228837, -0.24288286, 0.040594492]\n",
      "Iter 1948, loss [-0.22595142, -0.28733775, 0.06138633]\n",
      "Iter 1949, loss [-0.21571144, -0.2580207, 0.04230925]\n",
      "Iter 1950, loss [-0.20883721, -0.24643591, 0.037598692]\n",
      "Iter 1951, loss [-0.22029652, -0.2588364, 0.03853987]\n",
      "Iter 1952, loss [-0.24122699, -0.31887007, 0.07764308]\n",
      "Iter 1953, loss [-0.22200322, -0.26874223, 0.04673902]\n",
      "Iter 1954, loss [-0.20509335, -0.2461964, 0.041103043]\n",
      "Iter 1955, loss [-0.21521962, -0.25532684, 0.040107213]\n",
      "Iter 1956, loss [-0.20902206, -0.25235945, 0.043337386]\n",
      "Iter 1957, loss [-0.2164529, -0.2567493, 0.040296413]\n",
      "Iter 1958, loss [-0.20527339, -0.24196573, 0.036692336]\n",
      "Iter 1959, loss [-0.22677529, -0.26529878, 0.038523503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1960, loss [-0.20581892, -0.25414863, 0.048329707]\n",
      "Iter 1961, loss [-0.2125935, -0.24926426, 0.036670767]\n",
      "Iter 1962, loss [-0.21557854, -0.2555371, 0.03995855]\n",
      "Iter 1963, loss [-0.24471891, -0.30779734, 0.06307843]\n",
      "Iter 1964, loss [-0.22173162, -0.2589437, 0.037212085]\n",
      "Iter 1965, loss [-0.22417793, -0.26143444, 0.0372565]\n",
      "Iter 1966, loss [-0.24069068, -0.27542004, 0.034729365]\n",
      "Iter 1967, loss [-0.21615985, -0.25567868, 0.03951884]\n",
      "Iter 1968, loss [-0.20761415, -0.24624363, 0.038629472]\n",
      "Iter 1969, loss [-0.2179143, -0.25548515, 0.037570845]\n",
      "Iter 1970, loss [-0.22896026, -0.30094558, 0.07198532]\n",
      "Iter 1971, loss [-0.21596348, -0.25675532, 0.040791847]\n",
      "Iter 1972, loss [-0.21999013, -0.26028553, 0.04029539]\n",
      "Iter 1973, loss [-0.210348, -0.25805387, 0.04770587]\n",
      "Iter 1974, loss [-0.21494985, -0.2526335, 0.037683662]\n",
      "Iter 1975, loss [-0.23836061, -0.2967576, 0.058396995]\n",
      "Iter 1976, loss [-0.20202161, -0.24057308, 0.038551465]\n",
      "Iter 1977, loss [-0.21081269, -0.24939013, 0.038577445]\n",
      "Iter 1978, loss [-0.21577796, -0.25594398, 0.040166028]\n",
      "Iter 1979, loss [-0.20908287, -0.2516904, 0.042607516]\n",
      "Iter 1980, loss [-0.20707394, -0.24873807, 0.04166412]\n",
      "Iter 1981, loss [-0.2259888, -0.266542, 0.04055319]\n",
      "Iter 1982, loss [-0.2155573, -0.25656208, 0.041004784]\n",
      "Iter 1983, loss [-0.21598548, -0.26123968, 0.04525421]\n",
      "Iter 1984, loss [-0.20461753, -0.25084245, 0.04622492]\n",
      "Iter 1985, loss [-0.21720892, -0.25090346, 0.033694528]\n",
      "Iter 1986, loss [-0.1983767, -0.23226754, 0.033890847]\n",
      "Iter 1987, loss [-0.2238333, -0.26339084, 0.039557554]\n",
      "Iter 1988, loss [-0.20318285, -0.2410339, 0.03785105]\n",
      "Iter 1989, loss [-0.21677312, -0.25202134, 0.035248224]\n",
      "Iter 1990, loss [-0.20120132, -0.24241911, 0.04121778]\n",
      "Iter 1991, loss [-0.21169095, -0.25397032, 0.042279374]\n",
      "Iter 1992, loss [-0.2107732, -0.25100753, 0.040234324]\n",
      "Iter 1993, loss [-0.2236598, -0.26144746, 0.03778766]\n",
      "Iter 1994, loss [-0.2115431, -0.25535515, 0.04381205]\n",
      "Iter 1995, loss [-0.21354538, -0.25365666, 0.040111266]\n",
      "Iter 1996, loss [-0.21830696, -0.2553998, 0.037092835]\n",
      "Iter 1997, loss [-0.21979538, -0.2584721, 0.038676735]\n",
      "Iter 1998, loss [-0.21723023, -0.2617344, 0.044504166]\n",
      "Iter 1999, loss [-0.21282078, -0.25490433, 0.042083547]\n",
      "Iter 2000, loss [-0.22722645, -0.2668684, 0.03964196]\n",
      "Iter 2001, loss [-0.23557477, -0.31032598, 0.07475121]\n",
      "Iter 2002, loss [-0.22491129, -0.2643583, 0.03944702]\n",
      "Iter 2003, loss [-0.21527103, -0.2553427, 0.040071674]\n",
      "Iter 2004, loss [-0.22380632, -0.26359284, 0.039786525]\n",
      "Iter 2005, loss [-0.21407305, -0.2544361, 0.040363062]\n",
      "Iter 2006, loss [-0.22045165, -0.26014107, 0.039689414]\n",
      "Iter 2007, loss [-0.21702847, -0.26121476, 0.044186294]\n",
      "Iter 2008, loss [-0.21491887, -0.2563118, 0.041392934]\n",
      "Iter 2009, loss [-0.18024284, -0.23050192, 0.050259084]\n",
      "Iter 2010, loss [-0.20170161, -0.24153748, 0.039835867]\n",
      "Iter 2011, loss [-0.22752655, -0.26656365, 0.03903711]\n",
      "Iter 2012, loss [-0.21004958, -0.24910942, 0.03905983]\n",
      "Iter 2013, loss [-0.20517136, -0.24176738, 0.03659601]\n",
      "Iter 2014, loss [-0.22298917, -0.2981908, 0.07520162]\n",
      "Iter 2015, loss [-0.21177256, -0.25029105, 0.03851848]\n",
      "Iter 2016, loss [-0.20558026, -0.2489436, 0.043363333]\n",
      "Iter 2017, loss [-0.2261924, -0.27319032, 0.04699792]\n",
      "Iter 2018, loss [-0.20952448, -0.25151986, 0.041995376]\n",
      "Iter 2019, loss [-0.21240464, -0.27870622, 0.066301584]\n",
      "Iter 2020, loss [-0.2153105, -0.25693464, 0.041624144]\n",
      "Iter 2021, loss [-0.23388231, -0.28796634, 0.05408403]\n",
      "Iter 2022, loss [-0.20971437, -0.24756382, 0.037849456]\n",
      "Iter 2023, loss [-0.21567245, -0.25495237, 0.03927992]\n",
      "Iter 2024, loss [-0.2026349, -0.23589076, 0.03325586]\n",
      "Iter 2025, loss [-0.2164639, -0.25120464, 0.034740742]\n",
      "Iter 2026, loss [-0.2218746, -0.25929722, 0.037422623]\n",
      "Iter 2027, loss [-0.20366058, -0.24347204, 0.039811462]\n",
      "Iter 2028, loss [-0.23476015, -0.30031294, 0.065552786]\n",
      "Iter 2029, loss [-0.22700979, -0.2727848, 0.045775007]\n",
      "Iter 2030, loss [-0.24613905, -0.29265186, 0.046512805]\n",
      "Iter 2031, loss [-0.22495224, -0.2654813, 0.040529054]\n",
      "Iter 2032, loss [-0.2406117, -0.30576628, 0.06515458]\n",
      "Iter 2033, loss [-0.22268844, -0.26646549, 0.043777045]\n",
      "Iter 2034, loss [-0.2455456, -0.2871157, 0.041570105]\n",
      "Iter 2035, loss [-0.20311004, -0.29251325, 0.08940321]\n",
      "Iter 2036, loss [-0.2160692, -0.25621045, 0.040141236]\n",
      "Iter 2037, loss [-0.22656722, -0.2643327, 0.037765484]\n",
      "Iter 2038, loss [-0.21185818, -0.25077066, 0.038912468]\n",
      "Iter 2039, loss [-0.22934785, -0.26691416, 0.037566297]\n",
      "Iter 2040, loss [-0.20597228, -0.24886581, 0.04289352]\n",
      "Iter 2041, loss [-0.20644172, -0.24866505, 0.042223334]\n",
      "Iter 2042, loss [-0.21264419, -0.24816254, 0.035518356]\n",
      "Iter 2043, loss [-0.30605137, -0.31586942, 0.00981805]\n",
      "Iter 2044, loss [-0.20113175, -0.24018128, 0.039049536]\n",
      "Iter 2045, loss [-0.21003751, -0.25021538, 0.040177867]\n",
      "Iter 2046, loss [-0.2149071, -0.25322548, 0.038318384]\n",
      "Iter 2047, loss [-0.21703526, -0.25615978, 0.03912452]\n",
      "Iter 2048, loss [-0.21749252, -0.25473964, 0.03724712]\n",
      "Iter 2049, loss [-0.21542662, -0.25520217, 0.039775543]\n",
      "Iter 2050, loss [-0.21692847, -0.2577521, 0.04082362]\n",
      "Iter 2051, loss [-0.2263214, -0.2655018, 0.03918039]\n",
      "Iter 2052, loss [-0.2277124, -0.2716415, 0.043929107]\n",
      "Iter 2053, loss [-0.21583414, -0.25667045, 0.040836297]\n",
      "Iter 2054, loss [-0.2119541, -0.250166, 0.038211897]\n",
      "Iter 2055, loss [-0.21139616, -0.25651917, 0.045123007]\n",
      "Iter 2056, loss [-0.23625416, -0.29733503, 0.061080873]\n",
      "Iter 2057, loss [-0.22634159, -0.264164, 0.037822407]\n",
      "Iter 2058, loss [-0.21914008, -0.25831157, 0.039171487]\n",
      "Iter 2059, loss [-0.22510806, -0.27021784, 0.045109775]\n",
      "Iter 2060, loss [-0.22542003, -0.26294893, 0.03752891]\n",
      "Iter 2061, loss [-0.21404867, -0.3009064, 0.08685772]\n",
      "Iter 2062, loss [-0.22667956, -0.2717532, 0.045073636]\n",
      "Iter 2063, loss [-0.22683033, -0.26831877, 0.04148843]\n",
      "Iter 2064, loss [-0.24485353, -0.28705692, 0.04220339]\n",
      "Iter 2065, loss [-0.21407235, -0.25255004, 0.03847768]\n",
      "Iter 2066, loss [-0.2040326, -0.25171095, 0.04767836]\n",
      "Iter 2067, loss [-0.22335646, -0.25925362, 0.035897173]\n",
      "Iter 2068, loss [-0.21300685, -0.254029, 0.04102216]\n",
      "Iter 2069, loss [-0.22204366, -0.2604453, 0.038401634]\n",
      "Iter 2070, loss [-0.21741334, -0.25541636, 0.03800302]\n",
      "Iter 2071, loss [-0.2096003, -0.2512419, 0.0416416]\n",
      "Iter 2072, loss [-0.21718425, -0.2582104, 0.041026153]\n",
      "Iter 2073, loss [-0.30595326, -0.31576392, 0.00981066]\n",
      "Iter 2074, loss [-0.22409637, -0.2660151, 0.041918736]\n",
      "Iter 2075, loss [-0.30688754, -0.3162213, 0.009333756]\n",
      "Iter 2076, loss [-0.2088936, -0.24558501, 0.036691405]\n",
      "Iter 2077, loss [-0.22700533, -0.2648287, 0.03782337]\n",
      "Iter 2078, loss [-0.21946281, -0.25414065, 0.034677833]\n",
      "Iter 2079, loss [-0.21395083, -0.25402856, 0.04007773]\n",
      "Iter 2080, loss [-0.21770099, -0.2571696, 0.039468624]\n",
      "Iter 2081, loss [-0.21256447, -0.2518627, 0.039298244]\n",
      "Iter 2082, loss [-0.20461014, -0.24322332, 0.03861318]\n",
      "Iter 2083, loss [-0.20693628, -0.25035727, 0.04342098]\n",
      "Iter 2084, loss [-0.21807176, -0.25852847, 0.040456716]\n",
      "Iter 2085, loss [-0.23235825, -0.29404426, 0.06168601]\n",
      "Iter 2086, loss [-0.22235419, -0.29032147, 0.06796728]\n",
      "Iter 2087, loss [-0.2140514, -0.25912502, 0.045073636]\n",
      "Iter 2088, loss [-0.21501009, -0.2558895, 0.040879413]\n",
      "Iter 2089, loss [-0.22063325, -0.2944825, 0.073849246]\n",
      "Iter 2090, loss [-0.22137758, -0.2668047, 0.04542711]\n",
      "Iter 2091, loss [-0.2287601, -0.26532173, 0.03656163]\n",
      "Iter 2092, loss [-0.2055108, -0.24702668, 0.041515887]\n",
      "Iter 2093, loss [-0.21351331, -0.25126445, 0.037751146]\n",
      "Iter 2094, loss [-0.22026654, -0.26466334, 0.044396803]\n",
      "Iter 2095, loss [-0.21667612, -0.25475147, 0.038075365]\n",
      "Iter 2096, loss [-0.21606351, -0.25321206, 0.037148546]\n",
      "Iter 2097, loss [-0.21651933, -0.25548294, 0.038963616]\n",
      "Iter 2098, loss [-0.21741843, -0.25816673, 0.04074829]\n",
      "Iter 2099, loss [-0.19957799, -0.24100725, 0.04142927]\n",
      "Iter 2100, loss [-0.20417596, -0.24366805, 0.03949209]\n",
      "Iter 2101, loss [-0.21186829, -0.24993089, 0.038062595]\n",
      "Iter 2102, loss [-0.20545399, -0.24389237, 0.038438372]\n",
      "Iter 2103, loss [-0.20855042, -0.24622717, 0.03767675]\n",
      "Iter 2104, loss [-0.20665802, -0.24448621, 0.03782819]\n",
      "Iter 2105, loss [-0.21508798, -0.25293532, 0.03784734]\n",
      "Iter 2106, loss [-0.20265546, -0.24056327, 0.037907805]\n",
      "Iter 2107, loss [-0.2170867, -0.25552237, 0.03843566]\n",
      "Iter 2108, loss [-0.22823541, -0.2685542, 0.0403188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2109, loss [-0.20910853, -0.24973148, 0.04062295]\n",
      "Iter 2110, loss [-0.22049753, -0.26190457, 0.041407038]\n",
      "Iter 2111, loss [-0.206563, -0.25019082, 0.04362782]\n",
      "Iter 2112, loss [-0.21059534, -0.25155804, 0.04096269]\n",
      "Iter 2113, loss [-0.21794158, -0.2561527, 0.038211107]\n",
      "Iter 2114, loss [-0.21836069, -0.2574242, 0.039063513]\n",
      "Iter 2115, loss [-0.2118315, -0.25036854, 0.038537037]\n",
      "Iter 2116, loss [-0.2240262, -0.2605054, 0.0364792]\n",
      "Iter 2117, loss [-0.2057642, -0.24298674, 0.03722253]\n",
      "Iter 2118, loss [-0.21604243, -0.25602722, 0.039984792]\n",
      "Iter 2119, loss [-0.22820029, -0.29912403, 0.07092375]\n",
      "Iter 2120, loss [-0.30676144, -0.3165137, 0.009752257]\n",
      "Iter 2121, loss [-0.21534473, -0.2583514, 0.04300665]\n",
      "Iter 2122, loss [-0.2206795, -0.25970647, 0.03902696]\n",
      "Iter 2123, loss [-0.21268699, -0.2526397, 0.039952733]\n",
      "Iter 2124, loss [-0.30802473, -0.3172264, 0.009201679]\n",
      "Iter 2125, loss [-0.21282287, -0.24731523, 0.03449236]\n",
      "Iter 2126, loss [-0.18047675, -0.22741498, 0.046938233]\n",
      "Iter 2127, loss [-0.2183133, -0.2556435, 0.037330173]\n",
      "Iter 2128, loss [-0.20198257, -0.24000485, 0.03802228]\n",
      "Iter 2129, loss [-0.21636972, -0.2563, 0.039930284]\n",
      "Iter 2130, loss [-0.21623284, -0.2584679, 0.04223507]\n",
      "Iter 2131, loss [-0.21642047, -0.25713518, 0.040714704]\n",
      "Iter 2132, loss [-0.21810856, -0.25555113, 0.037442558]\n",
      "Iter 2133, loss [-0.2025449, -0.24559815, 0.043053247]\n",
      "Iter 2134, loss [-0.21381712, -0.2528837, 0.039066575]\n",
      "Iter 2135, loss [-0.20555179, -0.24253944, 0.036987644]\n",
      "Iter 2136, loss [-0.21106465, -0.24934372, 0.038279068]\n",
      "Iter 2137, loss [-0.23906833, -0.31278098, 0.07371264]\n",
      "Iter 2138, loss [-0.20723206, -0.24879164, 0.04155957]\n",
      "Iter 2139, loss [-0.20590857, -0.24351105, 0.037602477]\n",
      "Iter 2140, loss [-0.22169212, -0.2586617, 0.036969565]\n",
      "Iter 2141, loss [-0.22240245, -0.30073294, 0.078330494]\n",
      "Iter 2142, loss [-0.20274073, -0.24219556, 0.039454833]\n",
      "Iter 2143, loss [-0.20660266, -0.24821953, 0.04161688]\n",
      "Iter 2144, loss [-0.22056147, -0.2607282, 0.04016673]\n",
      "Iter 2145, loss [-0.20747632, -0.24572879, 0.038252465]\n",
      "Iter 2146, loss [-0.21893273, -0.26111436, 0.042181626]\n",
      "Iter 2147, loss [-0.21749112, -0.26145896, 0.04396784]\n",
      "Iter 2148, loss [-0.21771096, -0.2556825, 0.037971545]\n",
      "Iter 2149, loss [-0.22265348, -0.2594658, 0.036812328]\n",
      "Iter 2150, loss [-0.20459354, -0.26752427, 0.062930726]\n",
      "Iter 2151, loss [-0.21721485, -0.2546165, 0.037401654]\n",
      "Iter 2152, loss [-0.21450615, -0.25361842, 0.039112262]\n",
      "Iter 2153, loss [-0.21882011, -0.25887284, 0.040052727]\n",
      "Iter 2154, loss [-0.20997435, -0.24909557, 0.039121218]\n",
      "Iter 2155, loss [-0.20735443, -0.24491958, 0.03756515]\n",
      "Iter 2156, loss [-0.20956755, -0.24906199, 0.039494433]\n",
      "Iter 2157, loss [-0.20024969, -0.2598418, 0.059592113]\n",
      "Iter 2158, loss [-0.2156881, -0.25678787, 0.041099768]\n",
      "Iter 2159, loss [-0.20608675, -0.24366245, 0.037575684]\n",
      "Iter 2160, loss [-0.2165185, -0.25755444, 0.041035935]\n",
      "Iter 2161, loss [-0.23004265, -0.26839763, 0.038354974]\n",
      "Iter 2162, loss [-0.21289364, -0.25267518, 0.039781548]\n",
      "Iter 2163, loss [-0.19847634, -0.23604833, 0.037571978]\n",
      "Iter 2164, loss [-0.21611609, -0.25581434, 0.039698258]\n",
      "Iter 2165, loss [-0.20692138, -0.24909094, 0.042169552]\n",
      "Iter 2166, loss [-0.2191517, -0.25712225, 0.037970535]\n",
      "Iter 2167, loss [-0.2262775, -0.2644808, 0.038203306]\n",
      "Iter 2168, loss [-0.21241967, -0.25443286, 0.04201318]\n",
      "Iter 2169, loss [-0.22647333, -0.26449832, 0.038024984]\n",
      "Iter 2170, loss [-0.22781783, -0.2652322, 0.037414376]\n",
      "Iter 2171, loss [-0.21669316, -0.25492418, 0.038231015]\n",
      "Iter 2172, loss [-0.21799205, -0.2554371, 0.037445053]\n",
      "Iter 2173, loss [-0.22160874, -0.30579078, 0.08418204]\n",
      "Iter 2174, loss [-0.21287483, -0.25472265, 0.041847833]\n",
      "Iter 2175, loss [-0.24351019, -0.3066398, 0.0631296]\n",
      "Iter 2176, loss [-0.23891006, -0.3102426, 0.07133253]\n",
      "Iter 2177, loss [-0.2181434, -0.25777167, 0.039628267]\n",
      "Iter 2178, loss [-0.21774566, -0.25810596, 0.04036031]\n",
      "Iter 2179, loss [-0.22893488, -0.29894736, 0.07001249]\n",
      "Iter 2180, loss [-0.22904125, -0.26752385, 0.038482606]\n",
      "Iter 2181, loss [-0.19723427, -0.24435596, 0.04712169]\n",
      "Iter 2182, loss [-0.22174977, -0.29925236, 0.07750259]\n",
      "Iter 2183, loss [-0.24010102, -0.27602687, 0.03592585]\n",
      "Iter 2184, loss [-0.20600593, -0.24835959, 0.042353656]\n",
      "Iter 2185, loss [-0.20952596, -0.24897434, 0.039448384]\n",
      "Iter 2186, loss [-0.20746282, -0.24684995, 0.03938713]\n",
      "Iter 2187, loss [-0.21030965, -0.24993674, 0.03962709]\n",
      "Iter 2188, loss [-0.24628243, -0.29090786, 0.04462544]\n",
      "Iter 2189, loss [-0.20501947, -0.27035782, 0.065338336]\n",
      "Iter 2190, loss [-0.20035586, -0.29531446, 0.0949586]\n",
      "Iter 2191, loss [-0.23260802, -0.30786365, 0.07525564]\n",
      "Iter 2192, loss [-0.2203234, -0.2627117, 0.0423883]\n",
      "Iter 2193, loss [-0.20764822, -0.24631985, 0.038671635]\n",
      "Iter 2194, loss [-0.22375426, -0.26221943, 0.038465165]\n",
      "Iter 2195, loss [-0.21144417, -0.25255132, 0.041107155]\n",
      "Iter 2196, loss [-0.21456996, -0.2551558, 0.04058584]\n",
      "Iter 2197, loss [-0.21342802, -0.2533336, 0.03990557]\n",
      "Iter 2198, loss [-0.22055903, -0.3038395, 0.083280474]\n",
      "Iter 2199, loss [-0.21912594, -0.26685977, 0.04773383]\n",
      "Iter 2200, loss [-0.21567214, -0.25484934, 0.0391772]\n",
      "Iter 2201, loss [-0.20846191, -0.24964778, 0.041185867]\n",
      "Iter 2202, loss [-0.19668658, -0.2425902, 0.04590362]\n",
      "Iter 2203, loss [-0.2301164, -0.31022468, 0.080108285]\n",
      "Iter 2204, loss [-0.23547235, -0.28985375, 0.054381393]\n",
      "Iter 2205, loss [-0.21233076, -0.24924362, 0.036912862]\n",
      "Iter 2206, loss [-0.22473112, -0.2688296, 0.044098496]\n",
      "Iter 2207, loss [-0.20555669, -0.24364504, 0.038088348]\n",
      "Iter 2208, loss [-0.20769534, -0.24844277, 0.040747426]\n",
      "Iter 2209, loss [-0.24208857, -0.2865499, 0.044461325]\n",
      "Iter 2210, loss [-0.20932546, -0.24518616, 0.0358607]\n",
      "Iter 2211, loss [-0.21506828, -0.25134188, 0.036273606]\n",
      "Iter 2212, loss [-0.20998004, -0.25540772, 0.04542768]\n",
      "Iter 2213, loss [-0.22493339, -0.26416, 0.03922662]\n",
      "Iter 2214, loss [-0.21539508, -0.2613437, 0.04594861]\n",
      "Iter 2215, loss [-0.22738945, -0.26606497, 0.038675517]\n",
      "Iter 2216, loss [-0.21352088, -0.25416958, 0.040648695]\n",
      "Iter 2217, loss [-0.20716451, -0.24530329, 0.038138773]\n",
      "Iter 2218, loss [-0.30491054, -0.31487155, 0.009961018]\n",
      "Iter 2219, loss [-0.20800164, -0.25692454, 0.048922904]\n",
      "Iter 2220, loss [-0.21171421, -0.24835429, 0.03664007]\n",
      "Iter 2221, loss [-0.2073149, -0.24311215, 0.03579725]\n",
      "Iter 2222, loss [-0.21669917, -0.25489697, 0.038197804]\n",
      "Iter 2223, loss [-0.23390415, -0.2872467, 0.053342547]\n",
      "Iter 2224, loss [-0.3055203, -0.31494126, 0.009420954]\n",
      "Iter 2225, loss [-0.23073101, -0.26744315, 0.036712136]\n",
      "Iter 2226, loss [-0.23482314, -0.29157597, 0.056752827]\n",
      "Iter 2227, loss [-0.22663957, -0.26597252, 0.039332952]\n",
      "Iter 2228, loss [-0.22060198, -0.2661541, 0.045552135]\n",
      "Iter 2229, loss [-0.21235132, -0.24835005, 0.035998724]\n",
      "Iter 2230, loss [-0.2363115, -0.2924797, 0.0561682]\n",
      "Iter 2231, loss [-0.20829992, -0.25095972, 0.0426598]\n",
      "Iter 2232, loss [-0.22411083, -0.26427233, 0.040161505]\n",
      "Iter 2233, loss [-0.21171755, -0.2512346, 0.03951704]\n",
      "Iter 2234, loss [-0.21772009, -0.26050803, 0.04278794]\n",
      "Iter 2235, loss [-0.30774382, -0.31716818, 0.009424368]\n",
      "Iter 2236, loss [-0.20411056, -0.2437338, 0.03962324]\n",
      "Iter 2237, loss [-0.22442362, -0.28478178, 0.06035816]\n",
      "Iter 2238, loss [-0.21028873, -0.24679372, 0.036504976]\n",
      "Iter 2239, loss [-0.30740607, -0.3166515, 0.009245411]\n",
      "Iter 2240, loss [-0.21616136, -0.25566515, 0.039503798]\n",
      "Iter 2241, loss [-0.21772155, -0.2538069, 0.036085337]\n",
      "Iter 2242, loss [-0.2108558, -0.24910463, 0.038248837]\n",
      "Iter 2243, loss [-0.21554817, -0.257504, 0.04195581]\n",
      "Iter 2244, loss [-0.20835917, -0.2572707, 0.048911527]\n",
      "Iter 2245, loss [-0.19932395, -0.23551467, 0.03619072]\n",
      "Iter 2246, loss [-0.17932257, -0.22857553, 0.049252965]\n",
      "Iter 2247, loss [-0.23105343, -0.2672657, 0.03621228]\n",
      "Iter 2248, loss [-0.21794562, -0.26076072, 0.0428151]\n",
      "Iter 2249, loss [-0.21730244, -0.25449458, 0.03719213]\n",
      "Iter 2250, loss [-0.20353897, -0.24230088, 0.038761918]\n",
      "Iter 2251, loss [-0.19730297, -0.24394397, 0.046641015]\n",
      "Iter 2252, loss [-0.21276382, -0.25485045, 0.042086627]\n",
      "Iter 2253, loss [-0.23723805, -0.29328284, 0.056044795]\n",
      "Iter 2254, loss [-0.21611372, -0.25627947, 0.040165745]\n",
      "Iter 2255, loss [-0.21027946, -0.25844803, 0.04816857]\n",
      "Iter 2256, loss [-0.23857978, -0.2942381, 0.055658307]\n",
      "Iter 2257, loss [-0.20931557, -0.2514515, 0.042135924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2258, loss [-0.2147837, -0.25388423, 0.03910052]\n",
      "Iter 2259, loss [-0.21434057, -0.2527263, 0.03838572]\n",
      "Iter 2260, loss [-0.2159645, -0.2552975, 0.03933301]\n",
      "Iter 2261, loss [-0.2260947, -0.2858862, 0.059791505]\n",
      "Iter 2262, loss [-0.21195315, -0.25086975, 0.0389166]\n",
      "Iter 2263, loss [-0.21760547, -0.25576806, 0.03816259]\n",
      "Iter 2264, loss [-0.21584943, -0.25501677, 0.039167345]\n",
      "Iter 2265, loss [-0.2408995, -0.27578092, 0.03488141]\n",
      "Iter 2266, loss [-0.21562119, -0.25727198, 0.04165079]\n",
      "Iter 2267, loss [-0.21603926, -0.257986, 0.04194675]\n",
      "Iter 2268, loss [-0.23164614, -0.26899648, 0.037350345]\n",
      "Iter 2269, loss [-0.21829204, -0.25995043, 0.04165839]\n",
      "Iter 2270, loss [-0.21073446, -0.25045228, 0.03971783]\n",
      "Iter 2271, loss [-0.22761309, -0.2668306, 0.03921751]\n",
      "Iter 2272, loss [-0.21075189, -0.2594691, 0.04871721]\n",
      "Iter 2273, loss [-0.21830481, -0.2614556, 0.043150775]\n",
      "Iter 2274, loss [-0.23061141, -0.29812613, 0.06751471]\n",
      "Iter 2275, loss [-0.19808704, -0.24430385, 0.046216823]\n",
      "Iter 2276, loss [-0.22931568, -0.26673892, 0.03742324]\n",
      "Iter 2277, loss [-0.21061432, -0.25898027, 0.048365958]\n",
      "Iter 2278, loss [-0.22039293, -0.26007625, 0.039683327]\n",
      "Iter 2279, loss [-0.22021127, -0.26011378, 0.039902516]\n",
      "Iter 2280, loss [-0.21025763, -0.2584989, 0.04824127]\n",
      "Iter 2281, loss [-0.2026045, -0.24557212, 0.042967618]\n",
      "Iter 2282, loss [-0.21096429, -0.24867687, 0.037712567]\n",
      "Iter 2283, loss [-0.22712429, -0.26463267, 0.037508383]\n",
      "Iter 2284, loss [-0.22746131, -0.26372734, 0.03626603]\n",
      "Iter 2285, loss [-0.21767373, -0.2617902, 0.04411645]\n",
      "Iter 2286, loss [-0.21686864, -0.25650093, 0.03963229]\n",
      "Iter 2287, loss [-0.22183849, -0.25997725, 0.038138762]\n",
      "Iter 2288, loss [-0.2233493, -0.3051565, 0.081807196]\n",
      "Iter 2289, loss [-0.21307278, -0.25874683, 0.045674052]\n",
      "Iter 2290, loss [-0.22888665, -0.2724647, 0.04357804]\n",
      "Iter 2291, loss [-0.22904867, -0.2722953, 0.04324662]\n",
      "Iter 2292, loss [-0.2112042, -0.25502354, 0.04381933]\n",
      "Iter 2293, loss [-0.22469847, -0.26664802, 0.041949555]\n",
      "Iter 2294, loss [-0.21195891, -0.25002772, 0.038068794]\n",
      "Iter 2295, loss [-0.21041474, -0.24690172, 0.036486976]\n",
      "Iter 2296, loss [-0.20217134, -0.24056028, 0.038388934]\n",
      "Iter 2297, loss [-0.22009507, -0.25935188, 0.03925681]\n",
      "Iter 2298, loss [-0.2183521, -0.25625995, 0.037907854]\n",
      "Iter 2299, loss [-0.21863705, -0.2600571, 0.041420043]\n",
      "Iter 2300, loss [-0.22004026, -0.26165137, 0.041611113]\n",
      "Iter 2301, loss [-0.20904233, -0.2528055, 0.043763176]\n",
      "Iter 2302, loss [-0.21306023, -0.25759026, 0.044530034]\n",
      "Iter 2303, loss [-0.21363606, -0.2751574, 0.061521336]\n",
      "Iter 2304, loss [-0.21091677, -0.25009176, 0.039174985]\n",
      "Iter 2305, loss [-0.21056765, -0.24995747, 0.039389826]\n",
      "Iter 2306, loss [-0.21065496, -0.24744706, 0.036792103]\n",
      "Iter 2307, loss [-0.20733118, -0.24788086, 0.04054968]\n",
      "Iter 2308, loss [-0.21492723, -0.254442, 0.039514787]\n",
      "Iter 2309, loss [-0.2169592, -0.26205257, 0.04509337]\n",
      "Iter 2310, loss [-0.22023593, -0.26042354, 0.040187612]\n",
      "Iter 2311, loss [-0.20563783, -0.24320446, 0.037566632]\n",
      "Iter 2312, loss [-0.2112911, -0.25214404, 0.04085294]\n",
      "Iter 2313, loss [-0.2023718, -0.2433207, 0.040948894]\n",
      "Iter 2314, loss [-0.22806263, -0.29055923, 0.06249661]\n",
      "Iter 2315, loss [-0.21767247, -0.25479788, 0.037125405]\n",
      "Iter 2316, loss [-0.24559735, -0.30800527, 0.062407922]\n",
      "Iter 2317, loss [-0.22497556, -0.26658177, 0.041606218]\n",
      "Iter 2318, loss [-0.2292358, -0.27200073, 0.04276493]\n",
      "Iter 2319, loss [-0.21639599, -0.25797868, 0.04158269]\n",
      "Iter 2320, loss [-0.23909363, -0.31950003, 0.0804064]\n",
      "Iter 2321, loss [-0.21793349, -0.26334244, 0.045408946]\n",
      "Iter 2322, loss [-0.21996003, -0.26146308, 0.04150304]\n",
      "Iter 2323, loss [-0.21492967, -0.25551018, 0.040580504]\n",
      "Iter 2324, loss [-0.22017352, -0.25904816, 0.03887464]\n",
      "Iter 2325, loss [-0.2187779, -0.2552753, 0.036497407]\n",
      "Iter 2326, loss [-0.24594156, -0.28793395, 0.041992377]\n",
      "Iter 2327, loss [-0.22869624, -0.27084884, 0.0421526]\n",
      "Iter 2328, loss [-0.21955223, -0.2583813, 0.038829073]\n",
      "Iter 2329, loss [-0.21693614, -0.2546309, 0.037694745]\n",
      "Iter 2330, loss [-0.21893552, -0.25741494, 0.038479418]\n",
      "Iter 2331, loss [-0.20720513, -0.24573642, 0.03853129]\n",
      "Iter 2332, loss [-0.20997828, -0.24923316, 0.03925487]\n",
      "Iter 2333, loss [-0.20739123, -0.24714515, 0.03975392]\n",
      "Iter 2334, loss [-0.2038154, -0.24292706, 0.039111666]\n",
      "Iter 2335, loss [-0.21015279, -0.257025, 0.04687221]\n",
      "Iter 2336, loss [-0.20429057, -0.24283193, 0.038541354]\n",
      "Iter 2337, loss [-0.23693055, -0.30594832, 0.06901777]\n",
      "Iter 2338, loss [-0.21762647, -0.26173338, 0.044106916]\n",
      "Iter 2339, loss [-0.2274208, -0.26708353, 0.03966271]\n",
      "Iter 2340, loss [-0.20983884, -0.24903248, 0.039193653]\n",
      "Iter 2341, loss [-0.22087921, -0.25940675, 0.038527537]\n",
      "Iter 2342, loss [-0.2178398, -0.25660625, 0.03876645]\n",
      "Iter 2343, loss [-0.21665701, -0.2568484, 0.040191382]\n",
      "Iter 2344, loss [-0.22461143, -0.26629543, 0.04168401]\n",
      "Iter 2345, loss [-0.21813083, -0.25508514, 0.036954317]\n",
      "Iter 2346, loss [-0.23400412, -0.30014524, 0.06614111]\n",
      "Iter 2347, loss [-0.21598205, -0.25244728, 0.036465224]\n",
      "Iter 2348, loss [-0.22040853, -0.2638812, 0.04347267]\n",
      "Iter 2349, loss [-0.19601823, -0.28180337, 0.085785136]\n",
      "Iter 2350, loss [-0.21065849, -0.2544126, 0.043754093]\n",
      "Iter 2351, loss [-0.21726125, -0.26372233, 0.04646107]\n",
      "Iter 2352, loss [-0.20768674, -0.2508093, 0.043122575]\n",
      "Iter 2353, loss [-0.22162423, -0.2620853, 0.040461056]\n",
      "Iter 2354, loss [-0.21675178, -0.25631925, 0.03956747]\n",
      "Iter 2355, loss [-0.20644173, -0.24359065, 0.037148923]\n",
      "Iter 2356, loss [-0.21583022, -0.2801049, 0.06427468]\n",
      "Iter 2357, loss [-0.21775927, -0.2528992, 0.035139933]\n",
      "Iter 2358, loss [-0.22314914, -0.26491734, 0.04176821]\n",
      "Iter 2359, loss [-0.22495905, -0.26091367, 0.035954617]\n",
      "Iter 2360, loss [-0.21018034, -0.24643055, 0.036250196]\n",
      "Iter 2361, loss [-0.22554612, -0.2619197, 0.036373578]\n",
      "Iter 2362, loss [-0.21763423, -0.25523606, 0.03760182]\n",
      "Iter 2363, loss [-0.20575121, -0.24885117, 0.043099955]\n",
      "Iter 2364, loss [-0.21974072, -0.29166496, 0.07192425]\n",
      "Iter 2365, loss [-0.21774265, -0.25863096, 0.04088831]\n",
      "Iter 2366, loss [-0.2084373, -0.25339097, 0.044953674]\n",
      "Iter 2367, loss [-0.21724582, -0.2556132, 0.038367383]\n",
      "Iter 2368, loss [-0.22859356, -0.26574054, 0.037146993]\n",
      "Iter 2369, loss [-0.20286159, -0.250797, 0.047935408]\n",
      "Iter 2370, loss [-0.21903814, -0.25641915, 0.03738101]\n",
      "Iter 2371, loss [-0.19985569, -0.23632592, 0.036470227]\n",
      "Iter 2372, loss [-0.2066195, -0.24332488, 0.03670538]\n",
      "Iter 2373, loss [-0.20948416, -0.25748828, 0.04800412]\n",
      "Iter 2374, loss [-0.21577722, -0.255413, 0.039635774]\n",
      "Iter 2375, loss [-0.21773013, -0.26030412, 0.04257399]\n",
      "Iter 2376, loss [-0.20187202, -0.24719667, 0.045324653]\n",
      "Iter 2377, loss [-0.3058421, -0.316076, 0.010233897]\n",
      "Iter 2378, loss [-0.22724827, -0.26448888, 0.037240606]\n",
      "Iter 2379, loss [-0.20948234, -0.24729587, 0.037813537]\n",
      "Iter 2380, loss [-0.20972545, -0.24711534, 0.03738989]\n",
      "Iter 2381, loss [-0.21171041, -0.25133285, 0.03962244]\n",
      "Iter 2382, loss [-0.21763904, -0.25511828, 0.037479233]\n",
      "Iter 2383, loss [-0.19969815, -0.29514563, 0.09544747]\n",
      "Iter 2384, loss [-0.2376081, -0.2917364, 0.05412829]\n",
      "Iter 2385, loss [-0.21246718, -0.24819213, 0.035724957]\n",
      "Iter 2386, loss [-0.20895678, -0.24646857, 0.037511796]\n",
      "Iter 2387, loss [-0.21296498, -0.24964814, 0.03668316]\n",
      "Iter 2388, loss [-0.30794, -0.3176589, 0.009718898]\n",
      "Iter 2389, loss [-0.21795431, -0.2540878, 0.036133498]\n",
      "Iter 2390, loss [-0.21733935, -0.2555919, 0.038252544]\n",
      "Iter 2391, loss [-0.23954302, -0.2756216, 0.03607858]\n",
      "Iter 2392, loss [-0.21751238, -0.25809962, 0.040587228]\n",
      "Iter 2393, loss [-0.21042573, -0.24935961, 0.038933877]\n",
      "Iter 2394, loss [-0.21725959, -0.25674698, 0.0394874]\n",
      "Iter 2395, loss [-0.20296244, -0.24325494, 0.040292498]\n",
      "Iter 2396, loss [-0.2151568, -0.2556149, 0.040458113]\n",
      "Iter 2397, loss [-0.20706928, -0.24407235, 0.037003078]\n",
      "Iter 2398, loss [-0.22461939, -0.26342124, 0.038801856]\n",
      "Iter 2399, loss [-0.22009403, -0.25684753, 0.036753505]\n",
      "Iter 2400, loss [-0.2134358, -0.2545167, 0.0410809]\n",
      "Iter 2401, loss [-0.22926427, -0.2885572, 0.059292924]\n",
      "Iter 2402, loss [-0.2127102, -0.2583359, 0.045625687]\n",
      "Iter 2403, loss [-0.20290308, -0.24353594, 0.040632863]\n",
      "Iter 2404, loss [-0.21509387, -0.25582358, 0.04072972]\n",
      "Iter 2405, loss [-0.20349647, -0.25439543, 0.05089895]\n",
      "Iter 2406, loss [-0.2066778, -0.24945405, 0.04277625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2407, loss [-0.2169809, -0.26341334, 0.046432428]\n",
      "Iter 2408, loss [-0.20661023, -0.24762903, 0.04101879]\n",
      "Iter 2409, loss [-0.23061019, -0.2665596, 0.0359494]\n",
      "Iter 2410, loss [-0.1800035, -0.22632265, 0.046319157]\n",
      "Iter 2411, loss [-0.20467077, -0.23898226, 0.03431149]\n",
      "Iter 2412, loss [-0.2245276, -0.26147848, 0.03695088]\n",
      "Iter 2413, loss [-0.20669325, -0.24754325, 0.04085]\n",
      "Iter 2414, loss [-0.19902053, -0.23561247, 0.036591925]\n",
      "Iter 2415, loss [-0.21413788, -0.25470474, 0.040566854]\n",
      "Iter 2416, loss [-0.22036022, -0.29687268, 0.07651246]\n",
      "Iter 2417, loss [-0.2045956, -0.24556647, 0.04097087]\n",
      "Iter 2418, loss [-0.21805437, -0.26070452, 0.04265015]\n",
      "Iter 2419, loss [-0.21829951, -0.2531542, 0.034854677]\n",
      "Iter 2420, loss [-0.21745476, -0.25529706, 0.03784231]\n",
      "Iter 2421, loss [-0.2120535, -0.24648078, 0.034427285]\n",
      "Iter 2422, loss [-0.23949483, -0.27254358, 0.03304875]\n",
      "Iter 2423, loss [-0.21720603, -0.25568765, 0.03848163]\n",
      "Iter 2424, loss [-0.30734178, -0.3169019, 0.009560096]\n",
      "Iter 2425, loss [-0.2153511, -0.25597033, 0.040619224]\n",
      "Iter 2426, loss [-0.20954064, -0.2581317, 0.048591085]\n",
      "Iter 2427, loss [-0.22680365, -0.26656926, 0.03976561]\n",
      "Iter 2428, loss [-0.2099778, -0.25905797, 0.04908017]\n",
      "Iter 2429, loss [-0.22318473, -0.2621576, 0.038972847]\n",
      "Iter 2430, loss [-0.19904095, -0.2345128, 0.03547185]\n",
      "Iter 2431, loss [-0.18065971, -0.22813292, 0.047473207]\n",
      "Iter 2432, loss [-0.19760662, -0.2426972, 0.045090564]\n",
      "Iter 2433, loss [-0.20772065, -0.24311563, 0.035394978]\n",
      "Iter 2434, loss [-0.2126638, -0.2482328, 0.03556899]\n",
      "Iter 2435, loss [-0.22696804, -0.2649339, 0.037965883]\n",
      "Iter 2436, loss [-0.3076067, -0.3172984, 0.009691721]\n",
      "Iter 2437, loss [-0.21836218, -0.25723204, 0.03886986]\n",
      "Iter 2438, loss [-0.22702932, -0.26687363, 0.03984431]\n",
      "Iter 2439, loss [-0.21101494, -0.25695997, 0.04594503]\n",
      "Iter 2440, loss [-0.22788313, -0.26649004, 0.038606912]\n",
      "Iter 2441, loss [-0.19783233, -0.244714, 0.046881672]\n",
      "Iter 2442, loss [-0.23803002, -0.29741922, 0.059389204]\n",
      "Iter 2443, loss [-0.21082684, -0.24850242, 0.037675574]\n",
      "Iter 2444, loss [-0.20487879, -0.24052304, 0.035644244]\n",
      "Iter 2445, loss [-0.23517871, -0.2931716, 0.057992898]\n",
      "Iter 2446, loss [-0.22140516, -0.25886303, 0.037457865]\n",
      "Iter 2447, loss [-0.21585353, -0.25556755, 0.03971402]\n",
      "Iter 2448, loss [-0.21861154, -0.2555386, 0.036927074]\n",
      "Iter 2449, loss [-0.2095839, -0.24947283, 0.039888937]\n",
      "Iter 2450, loss [-0.20996106, -0.24996516, 0.040004097]\n",
      "Iter 2451, loss [-0.3075055, -0.3173072, 0.009801712]\n",
      "Iter 2452, loss [-0.21534237, -0.2571444, 0.041802026]\n",
      "Iter 2453, loss [-0.21173482, -0.25532395, 0.043589126]\n",
      "Iter 2454, loss [-0.22867477, -0.26534316, 0.036668397]\n",
      "Iter 2455, loss [-0.22315536, -0.2593299, 0.03617452]\n",
      "Iter 2456, loss [-0.21075624, -0.25767785, 0.04692161]\n",
      "Iter 2457, loss [-0.21871068, -0.2585082, 0.039797526]\n",
      "Iter 2458, loss [-0.22792618, -0.2650492, 0.03712301]\n",
      "Iter 2459, loss [-0.22631383, -0.2632552, 0.03694138]\n",
      "Iter 2460, loss [-0.20775267, -0.24965778, 0.041905098]\n",
      "Iter 2461, loss [-0.22382908, -0.26217332, 0.03834425]\n",
      "Iter 2462, loss [-0.21102199, -0.25147757, 0.040455587]\n",
      "Iter 2463, loss [-0.21833399, -0.2569664, 0.03863243]\n",
      "Iter 2464, loss [-0.21891527, -0.25910205, 0.040186778]\n",
      "Iter 2465, loss [-0.21889207, -0.25907835, 0.040186293]\n",
      "Iter 2466, loss [-0.21867883, -0.2550513, 0.03637249]\n",
      "Iter 2467, loss [-0.2177507, -0.25496358, 0.03721287]\n",
      "Iter 2468, loss [-0.21681064, -0.2565556, 0.039744936]\n",
      "Iter 2469, loss [-0.21933079, -0.25587162, 0.036540844]\n",
      "Iter 2470, loss [-0.22181918, -0.25883502, 0.037015837]\n",
      "Iter 2471, loss [-0.2296936, -0.26786453, 0.03817092]\n",
      "Iter 2472, loss [-0.21845743, -0.2589682, 0.040510774]\n",
      "Iter 2473, loss [-0.2117073, -0.25213444, 0.04042714]\n",
      "Iter 2474, loss [-0.22989306, -0.2686703, 0.038777236]\n",
      "Iter 2475, loss [-0.21525076, -0.25548095, 0.040230192]\n",
      "Iter 2476, loss [-0.21062289, -0.2493967, 0.038773805]\n",
      "Iter 2477, loss [-0.21437499, -0.25358194, 0.03920696]\n",
      "Iter 2478, loss [-0.21256949, -0.24917635, 0.036606863]\n",
      "Iter 2479, loss [-0.20274675, -0.2415211, 0.038774364]\n",
      "Iter 2480, loss [-0.21115375, -0.24807096, 0.036917213]\n",
      "Iter 2481, loss [-0.21826215, -0.26317677, 0.044914618]\n",
      "Iter 2482, loss [-0.20775262, -0.2441937, 0.036441095]\n",
      "Iter 2483, loss [-0.22008097, -0.2606913, 0.040610313]\n",
      "Iter 2484, loss [-0.21216926, -0.2574533, 0.045284033]\n",
      "Iter 2485, loss [-0.19827843, -0.24606274, 0.04778431]\n",
      "Iter 2486, loss [-0.20608988, -0.24313837, 0.03704848]\n",
      "Iter 2487, loss [-0.20619847, -0.24316408, 0.036965605]\n",
      "Iter 2488, loss [-0.21587247, -0.2565122, 0.04063972]\n",
      "Iter 2489, loss [-0.224412, -0.265664, 0.041252013]\n",
      "Iter 2490, loss [-0.21588963, -0.2552724, 0.03938276]\n",
      "Iter 2491, loss [-0.20625037, -0.24201275, 0.03576238]\n",
      "Iter 2492, loss [-0.23043758, -0.29915372, 0.06871614]\n",
      "Iter 2493, loss [-0.22827144, -0.26481593, 0.036544483]\n",
      "Iter 2494, loss [-0.23160401, -0.26803726, 0.03643325]\n",
      "Iter 2495, loss [-0.21098329, -0.24903207, 0.038048774]\n",
      "Iter 2496, loss [-0.21233867, -0.25666285, 0.04432417]\n",
      "Iter 2497, loss [-0.21650782, -0.2564037, 0.039895892]\n",
      "Iter 2498, loss [-0.21842086, -0.26405796, 0.0456371]\n",
      "Iter 2499, loss [-0.21825814, -0.25601378, 0.037755635]\n",
      "Iter 2500, loss [-0.2240609, -0.26266503, 0.038604133]\n",
      "Iter 2501, loss [-0.2191972, -0.25743756, 0.03824036]\n",
      "Iter 2502, loss [-0.20389071, -0.2434238, 0.039533086]\n",
      "Iter 2503, loss [-0.21077672, -0.24897033, 0.038193613]\n",
      "Iter 2504, loss [-0.21936184, -0.25943792, 0.040076073]\n",
      "Iter 2505, loss [-0.22219984, -0.26793933, 0.045739483]\n",
      "Iter 2506, loss [-0.22783922, -0.2659422, 0.03810297]\n",
      "Iter 2507, loss [-0.2069632, -0.247557, 0.0405938]\n",
      "Iter 2508, loss [-0.21223056, -0.25136566, 0.039135095]\n",
      "Iter 2509, loss [-0.20297873, -0.2909217, 0.08794296]\n",
      "Iter 2510, loss [-0.21956022, -0.25893855, 0.03937833]\n",
      "Iter 2511, loss [-0.20232181, -0.24589407, 0.04357226]\n",
      "Iter 2512, loss [-0.21222582, -0.25530037, 0.043074545]\n",
      "Iter 2513, loss [-0.22602493, -0.26649168, 0.040466763]\n",
      "Iter 2514, loss [-0.21926849, -0.26115984, 0.041891348]\n",
      "Iter 2515, loss [-0.21708089, -0.25769243, 0.040611535]\n",
      "Iter 2516, loss [-0.215743, -0.254407, 0.038663976]\n",
      "Iter 2517, loss [-0.21638672, -0.25432238, 0.03793566]\n",
      "Iter 2518, loss [-0.21601501, -0.25666237, 0.040647358]\n",
      "Iter 2519, loss [-0.21019101, -0.24805029, 0.037859276]\n",
      "Iter 2520, loss [-0.20303468, -0.24200995, 0.038975272]\n",
      "Iter 2521, loss [-0.20689577, -0.24244519, 0.035549425]\n",
      "Iter 2522, loss [-0.21074834, -0.24802811, 0.037279766]\n",
      "Iter 2523, loss [-0.22746886, -0.26610363, 0.038634762]\n",
      "Iter 2524, loss [-0.21786657, -0.2570755, 0.039208915]\n",
      "Iter 2525, loss [-0.21049805, -0.25341105, 0.042913]\n",
      "Iter 2526, loss [-0.22775069, -0.26602575, 0.03827507]\n",
      "Iter 2527, loss [-0.21837486, -0.25945476, 0.041079894]\n",
      "Iter 2528, loss [-0.21019165, -0.25093544, 0.04074378]\n",
      "Iter 2529, loss [-0.21417764, -0.25403878, 0.03986114]\n",
      "Iter 2530, loss [-0.2188037, -0.25826487, 0.039461166]\n",
      "Iter 2531, loss [-0.21699259, -0.25212207, 0.035129495]\n",
      "Iter 2532, loss [-0.22340442, -0.25943258, 0.03602816]\n",
      "Iter 2533, loss [-0.21097244, -0.24760062, 0.03662817]\n",
      "Iter 2534, loss [-0.22092924, -0.2603787, 0.03944945]\n",
      "Iter 2535, loss [-0.22302157, -0.26251057, 0.039488994]\n",
      "Iter 2536, loss [-0.20910287, -0.24911666, 0.04001379]\n",
      "Iter 2537, loss [-0.22065713, -0.26981634, 0.049159214]\n",
      "Iter 2538, loss [-0.19734338, -0.24625751, 0.04891413]\n",
      "Iter 2539, loss [-0.2466959, -0.2895422, 0.0428463]\n",
      "Iter 2540, loss [-0.2280683, -0.26603362, 0.03796531]\n",
      "Iter 2541, loss [-0.2115323, -0.2513048, 0.039772503]\n",
      "Iter 2542, loss [-0.2409932, -0.30520436, 0.06421116]\n",
      "Iter 2543, loss [-0.21036068, -0.24650557, 0.036144897]\n",
      "Iter 2544, loss [-0.22220613, -0.26811472, 0.04590858]\n",
      "Iter 2545, loss [-0.22323233, -0.2618013, 0.03856897]\n",
      "Iter 2546, loss [-0.22857815, -0.26749104, 0.038912892]\n",
      "Iter 2547, loss [-0.21814649, -0.25782582, 0.039679334]\n",
      "Iter 2548, loss [-0.20358089, -0.24412614, 0.040545247]\n",
      "Iter 2549, loss [-0.22670668, -0.27247033, 0.04576364]\n",
      "Iter 2550, loss [-0.21791984, -0.25457817, 0.03665833]\n",
      "Iter 2551, loss [-0.22723478, -0.27233508, 0.045100298]\n",
      "Iter 2552, loss [-0.24563959, -0.29138178, 0.045742176]\n",
      "Iter 2553, loss [-0.21847528, -0.25453308, 0.036057796]\n",
      "Iter 2554, loss [-0.21696939, -0.25323576, 0.03626637]\n",
      "Iter 2555, loss [-0.2118081, -0.2490081, 0.037200004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2556, loss [-0.23527287, -0.3067636, 0.07149072]\n",
      "Iter 2557, loss [-0.21048558, -0.24937738, 0.038891803]\n",
      "Iter 2558, loss [-0.22057115, -0.26736167, 0.04679052]\n",
      "Iter 2559, loss [-0.24594443, -0.31174672, 0.06580229]\n",
      "Iter 2560, loss [-0.21432647, -0.25426954, 0.039943065]\n",
      "Iter 2561, loss [-0.2151711, -0.25527602, 0.04010492]\n",
      "Iter 2562, loss [-0.22281761, -0.26163858, 0.038820967]\n",
      "Iter 2563, loss [-0.20869662, -0.25680956, 0.048112944]\n",
      "Iter 2564, loss [-0.2277551, -0.26450694, 0.036751833]\n",
      "Iter 2565, loss [-0.21416116, -0.2738187, 0.059657536]\n",
      "Iter 2566, loss [-0.3075705, -0.31700233, 0.009431839]\n",
      "Iter 2567, loss [-0.22423838, -0.26297557, 0.038737193]\n",
      "Iter 2568, loss [-0.21812312, -0.25724488, 0.039121766]\n",
      "Iter 2569, loss [-0.22433296, -0.2675321, 0.043199148]\n",
      "Iter 2570, loss [-0.24033763, -0.27546623, 0.035128605]\n",
      "Iter 2571, loss [-0.22882281, -0.29598534, 0.06716253]\n",
      "Iter 2572, loss [-0.20990571, -0.26023477, 0.050329052]\n",
      "Iter 2573, loss [-0.2234029, -0.263531, 0.0401281]\n",
      "Iter 2574, loss [-0.24332249, -0.3073213, 0.06399882]\n",
      "Iter 2575, loss [-0.21580057, -0.2570651, 0.04126452]\n",
      "Iter 2576, loss [-0.22592229, -0.26321232, 0.03729003]\n",
      "Iter 2577, loss [-0.2175664, -0.25922963, 0.041663237]\n",
      "Iter 2578, loss [-0.21878377, -0.2578658, 0.039082017]\n",
      "Iter 2579, loss [-0.24518847, -0.30507144, 0.05988296]\n",
      "Iter 2580, loss [-0.21100307, -0.2482433, 0.037240233]\n",
      "Iter 2581, loss [-0.2183203, -0.25956404, 0.041243743]\n",
      "Iter 2582, loss [-0.22811368, -0.26724732, 0.039133646]\n",
      "Iter 2583, loss [-0.2068094, -0.24543652, 0.03862711]\n",
      "Iter 2584, loss [-0.21735969, -0.2636637, 0.04630401]\n",
      "Iter 2585, loss [-0.20881009, -0.25268167, 0.043871578]\n",
      "Iter 2586, loss [-0.22771308, -0.26641315, 0.038700067]\n",
      "Iter 2587, loss [-0.2088999, -0.25131592, 0.042416018]\n",
      "Iter 2588, loss [-0.2046974, -0.24435547, 0.039658077]\n",
      "Iter 2589, loss [-0.21557966, -0.25379908, 0.038219415]\n",
      "Iter 2590, loss [-0.19969755, -0.23504056, 0.035343014]\n",
      "Iter 2591, loss [-0.22790268, -0.2646593, 0.036756612]\n",
      "Iter 2592, loss [-0.23130964, -0.2683426, 0.03703298]\n",
      "Iter 2593, loss [-0.2055022, -0.24246491, 0.036962718]\n",
      "Iter 2594, loss [-0.22783452, -0.2671127, 0.039278187]\n",
      "Iter 2595, loss [-0.22036493, -0.2591325, 0.038767576]\n",
      "Iter 2596, loss [-0.20592558, -0.24339071, 0.037465125]\n",
      "Iter 2597, loss [-0.2025945, -0.24220224, 0.039607733]\n",
      "Iter 2598, loss [-0.20535569, -0.25368056, 0.048324864]\n",
      "Iter 2599, loss [-0.22566931, -0.26502132, 0.039352015]\n",
      "Iter 2600, loss [-0.21697958, -0.2555154, 0.038535815]\n",
      "Iter 2601, loss [-0.22898974, -0.26778713, 0.038797393]\n",
      "Iter 2602, loss [-0.21400252, -0.25887668, 0.044874154]\n",
      "Iter 2603, loss [-0.21575281, -0.25520936, 0.039456543]\n",
      "Iter 2604, loss [-0.20521656, -0.24635068, 0.04113412]\n",
      "Iter 2605, loss [-0.20390901, -0.24412417, 0.040215164]\n",
      "Iter 2606, loss [-0.21551538, -0.25814703, 0.042631656]\n",
      "Iter 2607, loss [-0.20790306, -0.24692132, 0.039018266]\n",
      "Iter 2608, loss [-0.21095209, -0.25004858, 0.03909649]\n",
      "Iter 2609, loss [-0.23793738, -0.31779337, 0.07985599]\n",
      "Iter 2610, loss [-0.20791413, -0.24617071, 0.03825659]\n",
      "Iter 2611, loss [-0.21472459, -0.25500816, 0.040283576]\n",
      "Iter 2612, loss [-0.20557371, -0.2534842, 0.04791049]\n",
      "Iter 2613, loss [-0.22324851, -0.2606537, 0.037405185]\n",
      "Iter 2614, loss [-0.18001607, -0.22928298, 0.049266897]\n",
      "Iter 2615, loss [-0.20533913, -0.24348406, 0.038144935]\n",
      "Iter 2616, loss [-0.30761117, -0.31707546, 0.009464305]\n",
      "Iter 2617, loss [-0.20202924, -0.2416323, 0.039603055]\n",
      "Iter 2618, loss [-0.21085197, -0.25014335, 0.039291386]\n",
      "Iter 2619, loss [-0.20718169, -0.2482414, 0.041059695]\n",
      "Iter 2620, loss [-0.22090562, -0.2594319, 0.03852628]\n",
      "Iter 2621, loss [-0.21227196, -0.25049976, 0.0382278]\n",
      "Iter 2622, loss [-0.20251316, -0.24589346, 0.043380305]\n",
      "Iter 2623, loss [-0.20997612, -0.2586288, 0.04865266]\n",
      "Iter 2624, loss [-0.19780686, -0.245222, 0.047415137]\n",
      "Iter 2625, loss [-0.22542502, -0.2640081, 0.03858308]\n",
      "Iter 2626, loss [-0.23130193, -0.26760048, 0.036298543]\n",
      "Iter 2627, loss [-0.21809444, -0.25660154, 0.03850711]\n",
      "Iter 2628, loss [-0.22359732, -0.26088795, 0.037290625]\n",
      "Iter 2629, loss [-0.22392751, -0.26094285, 0.037015334]\n",
      "Iter 2630, loss [-0.20779589, -0.24417299, 0.036377102]\n",
      "Iter 2631, loss [-0.23167256, -0.2685987, 0.03692615]\n",
      "Iter 2632, loss [-0.21921504, -0.2601458, 0.040930778]\n",
      "Iter 2633, loss [-0.20895804, -0.24775629, 0.038798247]\n",
      "Iter 2634, loss [-0.21602109, -0.2587304, 0.042709313]\n",
      "Iter 2635, loss [-0.227606, -0.27332366, 0.04571765]\n",
      "Iter 2636, loss [-0.212621, -0.2506855, 0.038064502]\n",
      "Iter 2637, loss [-0.22386831, -0.26111895, 0.037250638]\n",
      "Iter 2638, loss [-0.24032909, -0.30112803, 0.060798943]\n",
      "Iter 2639, loss [-0.21603976, -0.25776127, 0.041721508]\n",
      "Iter 2640, loss [-0.21322438, -0.25891146, 0.045687072]\n",
      "Iter 2641, loss [-0.19979982, -0.23718342, 0.0373836]\n",
      "Iter 2642, loss [-0.22004357, -0.26026616, 0.040222585]\n",
      "Iter 2643, loss [-0.21792117, -0.25888738, 0.040966213]\n",
      "Iter 2644, loss [-0.20753203, -0.25033107, 0.042799037]\n",
      "Iter 2645, loss [-0.21253216, -0.25315696, 0.040624805]\n",
      "Iter 2646, loss [-0.2058171, -0.24230866, 0.036491558]\n",
      "Iter 2647, loss [-0.22744346, -0.27219495, 0.044751488]\n",
      "Iter 2648, loss [-0.21792461, -0.25681642, 0.038891807]\n",
      "Iter 2649, loss [-0.20308404, -0.2457342, 0.042650163]\n",
      "Iter 2650, loss [-0.2140922, -0.25266007, 0.038567863]\n",
      "Iter 2651, loss [-0.30728087, -0.31690136, 0.009620493]\n",
      "Iter 2652, loss [-0.22412176, -0.26123258, 0.03711082]\n",
      "Iter 2653, loss [-0.24091083, -0.27549306, 0.034582224]\n",
      "Iter 2654, loss [-0.21563554, -0.25489497, 0.03925943]\n",
      "Iter 2655, loss [-0.21154314, -0.25152513, 0.039981987]\n",
      "Iter 2656, loss [-0.2144371, -0.2764437, 0.062006593]\n",
      "Iter 2657, loss [-0.21541202, -0.27764484, 0.062232815]\n",
      "Iter 2658, loss [-0.21875408, -0.256252, 0.037497915]\n",
      "Iter 2659, loss [-0.20601979, -0.24403262, 0.03801283]\n",
      "Iter 2660, loss [-0.22347558, -0.2622772, 0.03880161]\n",
      "Iter 2661, loss [-0.21879056, -0.2552411, 0.036450535]\n",
      "Iter 2662, loss [-0.21311042, -0.2485927, 0.035482287]\n",
      "Iter 2663, loss [-0.21430677, -0.25852916, 0.044222385]\n",
      "Iter 2664, loss [-0.20980775, -0.24999475, 0.040187]\n",
      "Iter 2665, loss [-0.2239398, -0.26510724, 0.04116744]\n",
      "Iter 2666, loss [-0.21070337, -0.25066188, 0.039958514]\n",
      "Iter 2667, loss [-0.20945641, -0.24861068, 0.03915427]\n",
      "Iter 2668, loss [-0.21806446, -0.25791472, 0.039850265]\n",
      "Iter 2669, loss [-0.21672413, -0.25853747, 0.04181334]\n",
      "Iter 2670, loss [-0.2091392, -0.25170162, 0.042562433]\n",
      "Iter 2671, loss [-0.21019675, -0.24861404, 0.03841729]\n",
      "Iter 2672, loss [-0.24100623, -0.27585837, 0.034852143]\n",
      "Iter 2673, loss [-0.22066486, -0.25946978, 0.03880491]\n",
      "Iter 2674, loss [-0.18115896, -0.2304622, 0.049303226]\n",
      "Iter 2675, loss [-0.21794611, -0.25624266, 0.03829655]\n",
      "Iter 2676, loss [-0.2130648, -0.2551301, 0.042065304]\n",
      "Iter 2677, loss [-0.2129237, -0.249595, 0.03667129]\n",
      "Iter 2678, loss [-0.22790161, -0.272713, 0.044811398]\n",
      "Iter 2679, loss [-0.24362354, -0.3075969, 0.06397335]\n",
      "Iter 2680, loss [-0.21913467, -0.25517377, 0.036039095]\n",
      "Iter 2681, loss [-0.30748987, -0.3167567, 0.0092668375]\n",
      "Iter 2682, loss [-0.21068537, -0.24811223, 0.037426855]\n",
      "Iter 2683, loss [-0.20653212, -0.2983482, 0.09181606]\n",
      "Iter 2684, loss [-0.21108755, -0.24938503, 0.03829748]\n",
      "Iter 2685, loss [-0.22785436, -0.29012784, 0.062273484]\n",
      "Iter 2686, loss [-0.20465137, -0.24454525, 0.03989388]\n",
      "Iter 2687, loss [-0.21529762, -0.2775507, 0.06225307]\n",
      "Iter 2688, loss [-0.22520262, -0.2673112, 0.042108558]\n",
      "Iter 2689, loss [-0.21041395, -0.24954507, 0.039131116]\n",
      "Iter 2690, loss [-0.21857403, -0.25833255, 0.03975852]\n",
      "Iter 2691, loss [-0.21872711, -0.25881937, 0.04009226]\n",
      "Iter 2692, loss [-0.22339019, -0.26103377, 0.037643574]\n",
      "Iter 2693, loss [-0.20893896, -0.25161776, 0.04267881]\n",
      "Iter 2694, loss [-0.2222626, -0.2826767, 0.060414087]\n",
      "Iter 2695, loss [-0.2129403, -0.24975923, 0.036818914]\n",
      "Iter 2696, loss [-0.21236023, -0.24894404, 0.036583807]\n",
      "Iter 2697, loss [-0.22726741, -0.28909758, 0.061830156]\n",
      "Iter 2698, loss [-0.20829006, -0.24618894, 0.037898887]\n",
      "Iter 2699, loss [-0.21553285, -0.25586843, 0.04033558]\n",
      "Iter 2700, loss [-0.22399543, -0.26169217, 0.03769673]\n",
      "Iter 2701, loss [-0.21865873, -0.25867078, 0.040012043]\n",
      "Iter 2702, loss [-0.21756098, -0.25589034, 0.03832937]\n",
      "Iter 2703, loss [-0.22630236, -0.2639135, 0.037611157]\n",
      "Iter 2704, loss [-0.22063851, -0.26008663, 0.039448112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2705, loss [-0.21884023, -0.25948486, 0.04064463]\n",
      "Iter 2706, loss [-0.20735455, -0.2489711, 0.041616555]\n",
      "Iter 2707, loss [-0.2202617, -0.26115587, 0.04089418]\n",
      "Iter 2708, loss [-0.20414491, -0.24336353, 0.039218616]\n",
      "Iter 2709, loss [-0.21638846, -0.25584674, 0.039458275]\n",
      "Iter 2710, loss [-0.22446443, -0.26875278, 0.04428835]\n",
      "Iter 2711, loss [-0.22855045, -0.26546425, 0.036913797]\n",
      "Iter 2712, loss [-0.22316572, -0.30518717, 0.082021445]\n",
      "Iter 2713, loss [-0.22532675, -0.26456195, 0.039235197]\n",
      "Iter 2714, loss [-0.20519182, -0.2525185, 0.04732668]\n",
      "Iter 2715, loss [-0.21840906, -0.2576665, 0.039257437]\n",
      "Iter 2716, loss [-0.22116446, -0.25722668, 0.036062207]\n",
      "Iter 2717, loss [-0.20305431, -0.24545746, 0.04240314]\n",
      "Iter 2718, loss [-0.22527662, -0.26752162, 0.042245008]\n",
      "Iter 2719, loss [-0.24103437, -0.27654627, 0.035511896]\n",
      "Iter 2720, loss [-0.19776732, -0.2457064, 0.047939073]\n",
      "Iter 2721, loss [-0.21067539, -0.25033665, 0.039661255]\n",
      "Iter 2722, loss [-0.22422817, -0.26317137, 0.0389432]\n",
      "Iter 2723, loss [-0.21685717, -0.25793958, 0.04108241]\n",
      "Iter 2724, loss [-0.21446592, -0.25956678, 0.045100868]\n",
      "Iter 2725, loss [-0.20611945, -0.25396818, 0.04784874]\n",
      "Iter 2726, loss [-0.22504957, -0.26817986, 0.04313029]\n",
      "Iter 2727, loss [-0.21879986, -0.25794953, 0.039149668]\n",
      "Iter 2728, loss [-0.19976619, -0.23561014, 0.03584396]\n",
      "Iter 2729, loss [-0.20281851, -0.24157974, 0.038761236]\n",
      "Iter 2730, loss [-0.22851829, -0.26639265, 0.037874352]\n",
      "Iter 2731, loss [-0.23981875, -0.30235988, 0.06254113]\n",
      "Iter 2732, loss [-0.21932735, -0.29993212, 0.08060478]\n",
      "Iter 2733, loss [-0.23442361, -0.29380566, 0.059382048]\n",
      "Iter 2734, loss [-0.20165375, -0.2423887, 0.040734954]\n",
      "Iter 2735, loss [-0.20480001, -0.25634837, 0.051548354]\n",
      "Iter 2736, loss [-0.20196797, -0.24036232, 0.038394347]\n",
      "Iter 2737, loss [-0.2234157, -0.26368445, 0.04026874]\n",
      "Iter 2738, loss [-0.20910993, -0.29248655, 0.083376616]\n",
      "Iter 2739, loss [-0.23604345, -0.30768955, 0.071646094]\n",
      "Iter 2740, loss [-0.22196288, -0.2591141, 0.037151203]\n",
      "Iter 2741, loss [-0.2251193, -0.26342294, 0.03830365]\n",
      "Iter 2742, loss [-0.21442461, -0.25920138, 0.044776767]\n",
      "Iter 2743, loss [-0.21479481, -0.25208968, 0.037294872]\n",
      "Iter 2744, loss [-0.20963071, -0.25536567, 0.045734957]\n",
      "Iter 2745, loss [-0.20561844, -0.2780794, 0.07246094]\n",
      "Iter 2746, loss [-0.20547432, -0.24852692, 0.0430526]\n",
      "Iter 2747, loss [-0.22568412, -0.29849052, 0.0728064]\n",
      "Iter 2748, loss [-0.21054353, -0.25114006, 0.04059653]\n",
      "Iter 2749, loss [-0.2131456, -0.25100777, 0.037862163]\n",
      "Iter 2750, loss [-0.19840035, -0.2385866, 0.040186256]\n",
      "Iter 2751, loss [-0.20693548, -0.24892332, 0.041987836]\n",
      "Iter 2752, loss [-0.20615134, -0.25056237, 0.044411026]\n",
      "Iter 2753, loss [-0.2028561, -0.2417614, 0.038905308]\n",
      "Iter 2754, loss [-0.21450745, -0.25585476, 0.041347306]\n",
      "Iter 2755, loss [-0.22201222, -0.26053026, 0.038518034]\n",
      "Iter 2756, loss [-0.21100801, -0.25396723, 0.04295921]\n",
      "Iter 2757, loss [-0.19960944, -0.23913506, 0.039525613]\n",
      "Iter 2758, loss [-0.2121501, -0.25147423, 0.03932413]\n",
      "Iter 2759, loss [-0.21903796, -0.25563633, 0.036598366]\n",
      "Iter 2760, loss [-0.20635405, -0.2440595, 0.037705444]\n",
      "Iter 2761, loss [-0.20514014, -0.24678944, 0.041649293]\n",
      "Iter 2762, loss [-0.21762551, -0.2543076, 0.036682084]\n",
      "Iter 2763, loss [-0.21138984, -0.24897598, 0.03758613]\n",
      "Iter 2764, loss [-0.2161465, -0.25319394, 0.03704744]\n",
      "Iter 2765, loss [-0.21754792, -0.2599061, 0.04235819]\n",
      "Iter 2766, loss [-0.22644676, -0.2651359, 0.03868915]\n",
      "Iter 2767, loss [-0.21016304, -0.25393844, 0.04377539]\n",
      "Iter 2768, loss [-0.2310489, -0.30420387, 0.07315497]\n",
      "Iter 2769, loss [-0.21686956, -0.25548965, 0.038620085]\n",
      "Iter 2770, loss [-0.30665496, -0.3160348, 0.009379823]\n",
      "Iter 2771, loss [-0.21700147, -0.25775567, 0.04075419]\n",
      "Iter 2772, loss [-0.20025645, -0.2397339, 0.039477453]\n",
      "Iter 2773, loss [-0.20076023, -0.23749177, 0.036731545]\n",
      "Iter 2774, loss [-0.18750626, -0.273162, 0.08565575]\n",
      "Iter 2775, loss [-0.21460006, -0.254099, 0.039498955]\n",
      "Iter 2776, loss [-0.20386487, -0.24370615, 0.03984128]\n",
      "Iter 2777, loss [-0.20854118, -0.25401607, 0.045474894]\n",
      "Iter 2778, loss [-0.21304156, -0.25704563, 0.044004064]\n",
      "Iter 2779, loss [-0.21546425, -0.30597076, 0.09050651]\n",
      "Iter 2780, loss [-0.19894052, -0.23635463, 0.03741411]\n",
      "Iter 2781, loss [-0.21579069, -0.25309518, 0.037304483]\n",
      "Iter 2782, loss [-0.22461013, -0.25966567, 0.035055533]\n",
      "Iter 2783, loss [-0.20548889, -0.2675835, 0.06209459]\n",
      "Iter 2784, loss [-0.20989491, -0.24412899, 0.03423408]\n",
      "Iter 2785, loss [-0.2068782, -0.25383672, 0.04695852]\n",
      "Iter 2786, loss [-0.21651985, -0.25766882, 0.04114898]\n",
      "Iter 2787, loss [-0.20883839, -0.25184825, 0.04300986]\n",
      "Iter 2788, loss [-0.19528078, -0.24832022, 0.053039443]\n",
      "Iter 2789, loss [-0.21044524, -0.25751865, 0.04707341]\n",
      "Iter 2790, loss [-0.21169595, -0.2543596, 0.04266365]\n",
      "Iter 2791, loss [-0.21233924, -0.25343385, 0.041094616]\n",
      "Iter 2792, loss [-0.20386261, -0.23919818, 0.035335567]\n",
      "Iter 2793, loss [-0.20526388, -0.25289255, 0.04762868]\n",
      "Iter 2794, loss [-0.19716942, -0.28727436, 0.09010494]\n",
      "Iter 2795, loss [-0.21870205, -0.2559631, 0.03726103]\n",
      "Iter 2796, loss [-0.22033346, -0.26501817, 0.044684716]\n",
      "Iter 2797, loss [-0.22162996, -0.30179507, 0.0801651]\n",
      "Iter 2798, loss [-0.2027444, -0.243154, 0.040409613]\n",
      "Iter 2799, loss [-0.2351012, -0.31557465, 0.08047345]\n",
      "Iter 2800, loss [-0.22615838, -0.26431793, 0.038159557]\n",
      "Iter 2801, loss [-0.20306931, -0.24150938, 0.038440064]\n",
      "Iter 2802, loss [-0.23126927, -0.28862628, 0.05735701]\n",
      "Iter 2803, loss [-0.21542303, -0.2501693, 0.03474627]\n",
      "Iter 2804, loss [-0.21130043, -0.2506214, 0.039320976]\n",
      "Iter 2805, loss [-0.2237072, -0.26654366, 0.042836454]\n",
      "Iter 2806, loss [-0.21212447, -0.25370353, 0.041579068]\n",
      "Iter 2807, loss [-0.1966891, -0.2445875, 0.04789839]\n",
      "Iter 2808, loss [-0.21549092, -0.25516513, 0.039674208]\n",
      "Iter 2809, loss [-0.19923615, -0.23708649, 0.037850343]\n",
      "Iter 2810, loss [-0.22343723, -0.26185042, 0.038413182]\n",
      "Iter 2811, loss [-0.20680584, -0.24906166, 0.04225582]\n",
      "Iter 2812, loss [-0.2279123, -0.26604548, 0.03813318]\n",
      "Iter 2813, loss [-0.22063854, -0.25973648, 0.039097942]\n",
      "Iter 2814, loss [-0.20981628, -0.24837045, 0.03855417]\n",
      "Iter 2815, loss [-0.22494029, -0.2670795, 0.042139217]\n",
      "Iter 2816, loss [-0.21052796, -0.25064257, 0.04011461]\n",
      "Iter 2817, loss [-0.22716515, -0.27277988, 0.04561473]\n",
      "Iter 2818, loss [-0.2260773, -0.2921293, 0.066052005]\n",
      "Iter 2819, loss [-0.20284493, -0.24181947, 0.03897454]\n",
      "Iter 2820, loss [-0.21363111, -0.2554524, 0.041821282]\n",
      "Iter 2821, loss [-0.22742891, -0.26758838, 0.040159464]\n",
      "Iter 2822, loss [-0.2236242, -0.26884174, 0.045217544]\n",
      "Iter 2823, loss [-0.24570043, -0.29075724, 0.045056805]\n",
      "Iter 2824, loss [-0.20894244, -0.24939866, 0.040456213]\n",
      "Iter 2825, loss [-0.21487564, -0.25448677, 0.03961114]\n",
      "Iter 2826, loss [-0.20334888, -0.29702297, 0.09367409]\n",
      "Iter 2827, loss [-0.21461122, -0.252634, 0.03802277]\n",
      "Iter 2828, loss [-0.22340268, -0.260756, 0.0373533]\n",
      "Iter 2829, loss [-0.19959188, -0.23859599, 0.03900411]\n",
      "Iter 2830, loss [-0.22165358, -0.2589319, 0.03727833]\n",
      "Iter 2831, loss [-0.24094887, -0.30432916, 0.063380286]\n",
      "Iter 2832, loss [-0.2188598, -0.25838688, 0.039527074]\n",
      "Iter 2833, loss [-0.21649453, -0.2587852, 0.04229065]\n",
      "Iter 2834, loss [-0.1973106, -0.24604858, 0.048737984]\n",
      "Iter 2835, loss [-0.19895738, -0.2372052, 0.03824783]\n",
      "Iter 2836, loss [-0.20865363, -0.24850929, 0.03985566]\n",
      "Iter 2837, loss [-0.21520175, -0.2559914, 0.04078965]\n",
      "Iter 2838, loss [-0.218135, -0.2583364, 0.040201396]\n",
      "Iter 2839, loss [-0.21433303, -0.2532951, 0.038962074]\n",
      "Iter 2840, loss [-0.22532293, -0.264662, 0.03933907]\n",
      "Iter 2841, loss [-0.22088858, -0.26680893, 0.045920342]\n",
      "Iter 2842, loss [-0.21604346, -0.25795662, 0.041913163]\n",
      "Iter 2843, loss [-0.22522943, -0.26616982, 0.040940385]\n",
      "Iter 2844, loss [-0.20758806, -0.24605578, 0.03846772]\n",
      "Iter 2845, loss [-0.226843, -0.26692322, 0.040080227]\n",
      "Iter 2846, loss [-0.2219364, -0.26806068, 0.04612428]\n",
      "Iter 2847, loss [-0.24050897, -0.30417085, 0.06366187]\n",
      "Iter 2848, loss [-0.2103104, -0.24864747, 0.03833707]\n",
      "Iter 2849, loss [-0.2227494, -0.30249378, 0.07974438]\n",
      "Iter 2850, loss [-0.21683837, -0.2558175, 0.038979128]\n",
      "Iter 2851, loss [-0.21001239, -0.24956197, 0.039549574]\n",
      "Iter 2852, loss [-0.22057517, -0.25880024, 0.03822507]\n",
      "Iter 2853, loss [-0.2097598, -0.24992818, 0.04016838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2854, loss [-0.2220477, -0.26075616, 0.038708467]\n",
      "Iter 2855, loss [-0.19746183, -0.24489997, 0.047438145]\n",
      "Iter 2856, loss [-0.17999205, -0.22923562, 0.049243577]\n",
      "Iter 2857, loss [-0.30607536, -0.315831, 0.009755643]\n",
      "Iter 2858, loss [-0.21800132, -0.2579987, 0.03999738]\n",
      "Iter 2859, loss [-0.21108407, -0.254804, 0.043719914]\n",
      "Iter 2860, loss [-0.20989285, -0.24739031, 0.03749746]\n",
      "Iter 2861, loss [-0.21826284, -0.25425294, 0.035990104]\n",
      "Iter 2862, loss [-0.20697957, -0.24739641, 0.04041683]\n",
      "Iter 2863, loss [-0.21195142, -0.2556789, 0.04372747]\n",
      "Iter 2864, loss [-0.20945671, -0.25805494, 0.048598237]\n",
      "Iter 2865, loss [-0.20526385, -0.24281271, 0.037548862]\n",
      "Iter 2866, loss [-0.22810364, -0.2709444, 0.04284075]\n",
      "Iter 2867, loss [-0.2094109, -0.2495535, 0.040142603]\n",
      "Iter 2868, loss [-0.23084456, -0.26769394, 0.036849376]\n",
      "Iter 2869, loss [-0.2164245, -0.25801158, 0.041587085]\n",
      "Iter 2870, loss [-0.30681905, -0.31625435, 0.00943531]\n",
      "Iter 2871, loss [-0.22263847, -0.2862361, 0.063597634]\n",
      "Iter 2872, loss [-0.2104285, -0.24782021, 0.037391704]\n",
      "Iter 2873, loss [-0.21044314, -0.24657845, 0.03613531]\n",
      "Iter 2874, loss [-0.22585687, -0.26323727, 0.03738039]\n",
      "Iter 2875, loss [-0.21284993, -0.25115386, 0.038303927]\n",
      "Iter 2876, loss [-0.22346912, -0.26070723, 0.037238106]\n",
      "Iter 2877, loss [-0.21040751, -0.24993277, 0.03952525]\n",
      "Iter 2878, loss [-0.20806016, -0.24618432, 0.03812416]\n",
      "Iter 2879, loss [-0.22701316, -0.26464218, 0.03762902]\n",
      "Iter 2880, loss [-0.22457378, -0.26710296, 0.04252918]\n",
      "Iter 2881, loss [-0.20994537, -0.2584469, 0.048501536]\n",
      "Iter 2882, loss [-0.20837079, -0.26804426, 0.059673473]\n",
      "Iter 2883, loss [-0.2190457, -0.25635308, 0.037307374]\n",
      "Iter 2884, loss [-0.21054609, -0.2603026, 0.049756512]\n",
      "Iter 2885, loss [-0.21643299, -0.25865823, 0.042225238]\n",
      "Iter 2886, loss [-0.20768216, -0.24458942, 0.036907256]\n",
      "Iter 2887, loss [-0.20994775, -0.2479651, 0.038017344]\n",
      "Iter 2888, loss [-0.2140323, -0.25349396, 0.039461657]\n",
      "Iter 2889, loss [-0.21017392, -0.25011182, 0.039937895]\n",
      "Iter 2890, loss [-0.21752945, -0.25707182, 0.039542377]\n",
      "Iter 2891, loss [-0.21732369, -0.25566578, 0.03834208]\n",
      "Iter 2892, loss [-0.21854067, -0.25547966, 0.036938988]\n",
      "Iter 2893, loss [-0.21028969, -0.24742573, 0.03713604]\n",
      "Iter 2894, loss [-0.22595048, -0.26375768, 0.037807193]\n",
      "Iter 2895, loss [-0.22424646, -0.26434365, 0.040097192]\n",
      "Iter 2896, loss [-0.22105764, -0.25772065, 0.036663007]\n",
      "Iter 2897, loss [-0.22372982, -0.26189438, 0.03816455]\n",
      "Iter 2898, loss [-0.23992996, -0.2750377, 0.035107743]\n",
      "Iter 2899, loss [-0.21035358, -0.2580925, 0.04773891]\n",
      "Iter 2900, loss [-0.21473372, -0.2611119, 0.046378158]\n",
      "Iter 2901, loss [-0.2092019, -0.24860266, 0.03940075]\n",
      "Iter 2902, loss [-0.22475863, -0.26947334, 0.044714727]\n",
      "Iter 2903, loss [-0.21079907, -0.24903506, 0.038235985]\n",
      "Iter 2904, loss [-0.21908541, -0.25520176, 0.036116347]\n",
      "Iter 2905, loss [-0.1983297, -0.24404144, 0.04571174]\n",
      "Iter 2906, loss [-0.21280402, -0.24871765, 0.035913624]\n",
      "Iter 2907, loss [-0.21778417, -0.25467014, 0.036885977]\n",
      "Iter 2908, loss [-0.21296142, -0.2493182, 0.036356777]\n",
      "Iter 2909, loss [-0.2187789, -0.2552091, 0.03643019]\n",
      "Iter 2910, loss [-0.22001654, -0.26076484, 0.040748306]\n",
      "Iter 2911, loss [-0.20807508, -0.24634612, 0.03827104]\n",
      "Iter 2912, loss [-0.22686967, -0.2962361, 0.069366425]\n",
      "Iter 2913, loss [-0.21834962, -0.25812444, 0.03977482]\n",
      "Iter 2914, loss [-0.21298467, -0.2554076, 0.04242293]\n",
      "Iter 2915, loss [-0.21066521, -0.24876422, 0.038099006]\n",
      "Iter 2916, loss [-0.30661076, -0.3162751, 0.0096643185]\n",
      "Iter 2917, loss [-0.22565153, -0.2655297, 0.039878152]\n",
      "Iter 2918, loss [-0.22254388, -0.3020054, 0.07946153]\n",
      "Iter 2919, loss [-0.22673175, -0.2653192, 0.038587447]\n",
      "Iter 2920, loss [-0.22692013, -0.26606748, 0.039147347]\n",
      "Iter 2921, loss [-0.2054807, -0.24386619, 0.038385503]\n",
      "Iter 2922, loss [-0.21018922, -0.25918666, 0.04899743]\n",
      "Iter 2923, loss [-0.22511932, -0.26443097, 0.039311655]\n",
      "Iter 2924, loss [-0.22006963, -0.259786, 0.039716378]\n",
      "Iter 2925, loss [-0.20750289, -0.24793506, 0.040432166]\n",
      "Iter 2926, loss [-0.21367839, -0.25753185, 0.043853454]\n",
      "Iter 2927, loss [-0.2169277, -0.2571442, 0.040216513]\n",
      "Iter 2928, loss [-0.22555554, -0.26634428, 0.040788732]\n",
      "Iter 2929, loss [-0.21908599, -0.2583433, 0.03925731]\n",
      "Iter 2930, loss [-0.21589318, -0.25521937, 0.0393262]\n",
      "Iter 2931, loss [-0.22379148, -0.26175123, 0.037959762]\n",
      "Iter 2932, loss [-0.2078313, -0.24911396, 0.04128266]\n",
      "Iter 2933, loss [-0.220687, -0.26024467, 0.03955766]\n",
      "Iter 2934, loss [-0.21736382, -0.2589533, 0.041589484]\n",
      "Iter 2935, loss [-0.20847465, -0.2453183, 0.036843643]\n",
      "Iter 2936, loss [-0.211638, -0.25040194, 0.03876394]\n",
      "Iter 2937, loss [-0.22062957, -0.2586464, 0.038016833]\n",
      "Iter 2938, loss [-0.22590292, -0.2653349, 0.039431993]\n",
      "Iter 2939, loss [-0.22516593, -0.26904333, 0.043877386]\n",
      "Iter 2940, loss [-0.2109411, -0.26008725, 0.04914614]\n",
      "Iter 2941, loss [-0.22541109, -0.26908532, 0.043674223]\n",
      "Iter 2942, loss [-0.22040752, -0.2603937, 0.03998619]\n",
      "Iter 2943, loss [-0.20865227, -0.24505049, 0.03639822]\n",
      "Iter 2944, loss [-0.20526671, -0.2452067, 0.039939977]\n",
      "Iter 2945, loss [-0.22620241, -0.2627388, 0.03653638]\n",
      "Iter 2946, loss [-0.21333535, -0.27600646, 0.06267111]\n",
      "Iter 2947, loss [-0.21137121, -0.24984656, 0.03847535]\n",
      "Iter 2948, loss [-0.24085885, -0.27622423, 0.035365365]\n",
      "Iter 2949, loss [-0.21319672, -0.24927983, 0.036083095]\n",
      "Iter 2950, loss [-0.20529312, -0.24573797, 0.040444847]\n",
      "Iter 2951, loss [-0.21834192, -0.25667205, 0.038330134]\n",
      "Iter 2952, loss [-0.24113163, -0.27667853, 0.0355469]\n",
      "Iter 2953, loss [-0.2298317, -0.30822644, 0.07839474]\n",
      "Iter 2954, loss [-0.24296543, -0.3081131, 0.06514767]\n",
      "Iter 2955, loss [-0.21063074, -0.25152484, 0.04089409]\n",
      "Iter 2956, loss [-0.21819648, -0.26175657, 0.043560084]\n",
      "Iter 2957, loss [-0.20739448, -0.24686348, 0.03946901]\n",
      "Iter 2958, loss [-0.2273625, -0.27202454, 0.04466204]\n",
      "Iter 2959, loss [-0.2278254, -0.2682518, 0.040426396]\n",
      "Iter 2960, loss [-0.18497731, -0.28418404, 0.09920673]\n",
      "Iter 2961, loss [-0.1798863, -0.22702923, 0.047142934]\n",
      "Iter 2962, loss [-0.20701984, -0.24198854, 0.0349687]\n",
      "Iter 2963, loss [-0.2093566, -0.24789956, 0.038542964]\n",
      "Iter 2964, loss [-0.20497923, -0.24049985, 0.035520628]\n",
      "Iter 2965, loss [-0.20843937, -0.25375432, 0.045314953]\n",
      "Iter 2966, loss [-0.20459995, -0.24700554, 0.042405598]\n",
      "Iter 2967, loss [-0.30542395, -0.31621766, 0.010793714]\n",
      "Iter 2968, loss [-0.2186509, -0.26351556, 0.044864647]\n",
      "Iter 2969, loss [-0.19683963, -0.26700187, 0.07016223]\n",
      "Iter 2970, loss [-0.21321875, -0.25306368, 0.03984493]\n",
      "Iter 2971, loss [-0.23771726, -0.2744843, 0.036767054]\n",
      "Iter 2972, loss [-0.20397256, -0.24907948, 0.045106918]\n",
      "Iter 2973, loss [-0.19477259, -0.24292086, 0.048148274]\n",
      "Iter 2974, loss [-0.3051627, -0.3148699, 0.009707208]\n",
      "Iter 2975, loss [-0.20494449, -0.24953538, 0.04459089]\n",
      "Iter 2976, loss [-0.21033174, -0.2525323, 0.04220056]\n",
      "Iter 2977, loss [-0.22609797, -0.26446688, 0.038368907]\n",
      "Iter 2978, loss [-0.20507923, -0.24134529, 0.036266055]\n",
      "Iter 2979, loss [-0.2234464, -0.26534903, 0.04190263]\n",
      "Iter 2980, loss [-0.2253145, -0.2702502, 0.044935703]\n",
      "Iter 2981, loss [-0.20790902, -0.24490489, 0.03699587]\n",
      "Iter 2982, loss [-0.20850946, -0.25621268, 0.047703218]\n",
      "Iter 2983, loss [-0.21702795, -0.2558406, 0.03881265]\n",
      "Iter 2984, loss [-0.30647585, -0.31609282, 0.009616969]\n",
      "Iter 2985, loss [-0.20891911, -0.24745011, 0.038530998]\n",
      "Iter 2986, loss [-0.20758443, -0.24724397, 0.039659545]\n",
      "Iter 2987, loss [-0.2259247, -0.2627354, 0.03681069]\n",
      "Iter 2988, loss [-0.21746938, -0.25521886, 0.037749484]\n",
      "Iter 2989, loss [-0.2049823, -0.2414735, 0.0364912]\n",
      "Iter 2990, loss [-0.23669448, -0.30503088, 0.0683364]\n",
      "Iter 2991, loss [-0.21774381, -0.25787222, 0.040128406]\n",
      "Iter 2992, loss [-0.21096382, -0.25177795, 0.040814128]\n",
      "Iter 2993, loss [-0.23422998, -0.30807567, 0.073845685]\n",
      "Iter 2994, loss [-0.21895574, -0.2594332, 0.040477466]\n",
      "Iter 2995, loss [-0.22737855, -0.2646239, 0.037245363]\n",
      "Iter 2996, loss [-0.21615322, -0.25689384, 0.04074062]\n",
      "Iter 2997, loss [-0.2246683, -0.26635754, 0.041689243]\n",
      "Iter 2998, loss [-0.2110849, -0.25154343, 0.040458526]\n",
      "Iter 2999, loss [-0.20710734, -0.24456754, 0.0374602]\n",
      "Iter 3000, loss [-0.21460286, -0.25644615, 0.041843288]\n",
      "Iter 3001, loss [-0.20778985, -0.27096868, 0.06317882]\n",
      "Iter 3002, loss [-0.21060562, -0.24870652, 0.0381009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3003, loss [-0.20800935, -0.25114122, 0.043131873]\n",
      "Iter 3004, loss [-0.21724956, -0.25705197, 0.039802413]\n",
      "Iter 3005, loss [-0.2122637, -0.25761136, 0.045347653]\n",
      "Iter 3006, loss [-0.22809821, -0.26681945, 0.038721226]\n",
      "Iter 3007, loss [-0.21344806, -0.25481197, 0.041363906]\n",
      "Iter 3008, loss [-0.22056817, -0.26541588, 0.044847712]\n",
      "Iter 3009, loss [-0.21980765, -0.25798106, 0.038173415]\n",
      "Iter 3010, loss [-0.22265314, -0.25990182, 0.037248686]\n",
      "Iter 3011, loss [-0.22458443, -0.2668158, 0.042231373]\n",
      "Iter 3012, loss [-0.21545503, -0.25580972, 0.0403547]\n",
      "Iter 3013, loss [-0.21301755, -0.25321466, 0.040197104]\n",
      "Iter 3014, loss [-0.22007763, -0.26059997, 0.040522337]\n",
      "Iter 3015, loss [-0.23793449, -0.3101826, 0.072248116]\n",
      "Iter 3016, loss [-0.21006836, -0.24698797, 0.036919605]\n",
      "Iter 3017, loss [-0.20479713, -0.24287081, 0.03807367]\n",
      "Iter 3018, loss [-0.20803241, -0.24513052, 0.03709811]\n",
      "Iter 3019, loss [-0.2432025, -0.30568805, 0.06248556]\n",
      "Iter 3020, loss [-0.21787645, -0.25755438, 0.03967793]\n",
      "Iter 3021, loss [-0.22039826, -0.26040167, 0.040003404]\n",
      "Iter 3022, loss [-0.21716231, -0.2613115, 0.044149183]\n",
      "Iter 3023, loss [-0.2076127, -0.24481648, 0.03720379]\n",
      "Iter 3024, loss [-0.2161963, -0.2564236, 0.04022729]\n",
      "Iter 3025, loss [-0.19953708, -0.23543471, 0.035897624]\n",
      "Iter 3026, loss [-0.21873815, -0.2587284, 0.039990257]\n",
      "Iter 3027, loss [-0.21879855, -0.25895184, 0.0401533]\n",
      "Iter 3028, loss [-0.20812233, -0.24498291, 0.036860585]\n",
      "Iter 3029, loss [-0.20214988, -0.24186115, 0.039711267]\n",
      "Iter 3030, loss [-0.20977074, -0.24979913, 0.040028393]\n",
      "Iter 3031, loss [-0.20836057, -0.24673282, 0.038372252]\n",
      "Iter 3032, loss [-0.20256126, -0.24234116, 0.039779894]\n",
      "Iter 3033, loss [-0.22040853, -0.26032442, 0.03991589]\n",
      "Iter 3034, loss [-0.3075302, -0.3170291, 0.009498898]\n",
      "Iter 3035, loss [-0.21325049, -0.25475144, 0.04150096]\n",
      "Iter 3036, loss [-0.20711976, -0.2473199, 0.040200137]\n",
      "Iter 3037, loss [-0.21220805, -0.27301157, 0.060803518]\n",
      "Iter 3038, loss [-0.20250252, -0.24116302, 0.038660504]\n",
      "Iter 3039, loss [-0.30811998, -0.31719172, 0.009071743]\n",
      "Iter 3040, loss [-0.2271249, -0.26417193, 0.03704702]\n",
      "Iter 3041, loss [-0.20783661, -0.24396904, 0.036132425]\n",
      "Iter 3042, loss [-0.20946719, -0.24741057, 0.037943378]\n",
      "Iter 3043, loss [-0.21559897, -0.25723282, 0.04163385]\n",
      "Iter 3044, loss [-0.22557794, -0.26560673, 0.040028792]\n",
      "Iter 3045, loss [-0.2164607, -0.25481698, 0.038356267]\n",
      "Iter 3046, loss [-0.21086958, -0.25117123, 0.04030166]\n",
      "Iter 3047, loss [-0.3079496, -0.31709972, 0.009150118]\n",
      "Iter 3048, loss [-0.2120172, -0.24980018, 0.03778298]\n",
      "Iter 3049, loss [-0.24269152, -0.3058598, 0.063168295]\n",
      "Iter 3050, loss [-0.2176338, -0.26018378, 0.04254998]\n",
      "Iter 3051, loss [-0.21783766, -0.2553292, 0.03749153]\n",
      "Iter 3052, loss [-0.22710495, -0.28902707, 0.061922118]\n",
      "Iter 3053, loss [-0.21547945, -0.25585344, 0.040373992]\n",
      "Iter 3054, loss [-0.20811817, -0.24643503, 0.038316865]\n",
      "Iter 3055, loss [-0.20802134, -0.24496883, 0.036947493]\n",
      "Iter 3056, loss [-0.21871586, -0.25824043, 0.03952457]\n",
      "Iter 3057, loss [-0.21329139, -0.24995391, 0.03666252]\n",
      "Iter 3058, loss [-0.21160516, -0.25163433, 0.040029176]\n",
      "Iter 3059, loss [-0.21002248, -0.24826537, 0.038242884]\n",
      "Iter 3060, loss [-0.21484408, -0.2752733, 0.060429223]\n",
      "Iter 3061, loss [-0.21073985, -0.24962929, 0.038889434]\n",
      "Iter 3062, loss [-0.20856512, -0.2516281, 0.043062985]\n",
      "Iter 3063, loss [-0.2046349, -0.24284312, 0.03820821]\n",
      "Iter 3064, loss [-0.22177586, -0.26861778, 0.046841927]\n",
      "Iter 3065, loss [-0.24010774, -0.27531403, 0.035206288]\n",
      "Iter 3066, loss [-0.21220389, -0.25020084, 0.03799694]\n",
      "Iter 3067, loss [-0.24049066, -0.30471808, 0.06422742]\n",
      "Iter 3068, loss [-0.20621431, -0.24716535, 0.040951036]\n",
      "Iter 3069, loss [-0.21243311, -0.2539386, 0.04150547]\n",
      "Iter 3070, loss [-0.21330342, -0.2544147, 0.041111283]\n",
      "Iter 3071, loss [-0.3073974, -0.31710362, 0.009706235]\n",
      "Iter 3072, loss [-0.2175197, -0.2589348, 0.04141509]\n",
      "Iter 3073, loss [-0.21216747, -0.25753546, 0.04536798]\n",
      "Iter 3074, loss [-0.21666396, -0.25508446, 0.038420506]\n",
      "Iter 3075, loss [-0.2245698, -0.26257536, 0.03800556]\n",
      "Iter 3076, loss [-0.21023126, -0.2487813, 0.038550034]\n",
      "Iter 3077, loss [-0.21072683, -0.24762906, 0.036902227]\n",
      "Iter 3078, loss [-0.20363031, -0.24298137, 0.03935106]\n",
      "Iter 3079, loss [-0.22033831, -0.25806034, 0.037722014]\n",
      "Iter 3080, loss [-0.18042257, -0.23024482, 0.049822234]\n",
      "Iter 3081, loss [-0.21176393, -0.25374693, 0.04198299]\n",
      "Iter 3082, loss [-0.2184343, -0.25941414, 0.040979825]\n",
      "Iter 3083, loss [-0.22109503, -0.26063094, 0.039535906]\n",
      "Iter 3084, loss [-0.21923484, -0.25619364, 0.036958795]\n",
      "Iter 3085, loss [-0.24107152, -0.27590725, 0.03483572]\n",
      "Iter 3086, loss [-0.2257764, -0.26542577, 0.039649375]\n",
      "Iter 3087, loss [-0.21252437, -0.25067583, 0.03815146]\n",
      "Iter 3088, loss [-0.20774412, -0.24838305, 0.04063893]\n",
      "Iter 3089, loss [-0.22573951, -0.26786608, 0.042126574]\n",
      "Iter 3090, loss [-0.24292442, -0.30503735, 0.062112927]\n",
      "Iter 3091, loss [-0.22373663, -0.26243412, 0.038697496]\n",
      "Iter 3092, loss [-0.21924418, -0.2569893, 0.03774511]\n",
      "Iter 3093, loss [-0.22764668, -0.2994722, 0.071825534]\n",
      "Iter 3094, loss [-0.21801585, -0.25690308, 0.03888724]\n",
      "Iter 3095, loss [-0.22367463, -0.26173636, 0.038061745]\n",
      "Iter 3096, loss [-0.21090403, -0.24735796, 0.03645394]\n",
      "Iter 3097, loss [-0.20578273, -0.24141295, 0.035630226]\n",
      "Iter 3098, loss [-0.2238157, -0.26072508, 0.036909383]\n",
      "Iter 3099, loss [-0.20764735, -0.24785806, 0.0402107]\n",
      "Iter 3100, loss [-0.21202898, -0.2554247, 0.04339572]\n",
      "Iter 3101, loss [-0.20256886, -0.24058774, 0.038018886]\n",
      "Iter 3102, loss [-0.2355254, -0.31311464, 0.07758925]\n",
      "Iter 3103, loss [-0.20875806, -0.2536289, 0.04487085]\n",
      "Iter 3104, loss [-0.17997661, -0.23187527, 0.05189865]\n",
      "Iter 3105, loss [-0.21271074, -0.25698277, 0.04427203]\n",
      "Iter 3106, loss [-0.21254922, -0.25944895, 0.04689972]\n",
      "Iter 3107, loss [-0.20552856, -0.2428897, 0.037361138]\n",
      "Iter 3108, loss [-0.21609417, -0.26123163, 0.045137472]\n",
      "Iter 3109, loss [-0.21339127, -0.2530283, 0.03963702]\n",
      "Iter 3110, loss [-0.22778311, -0.2633471, 0.035563983]\n",
      "Iter 3111, loss [-0.2144917, -0.25213814, 0.03764644]\n",
      "Iter 3112, loss [-0.20378082, -0.2420939, 0.03831309]\n",
      "Iter 3113, loss [-0.207778, -0.24471298, 0.03693498]\n",
      "Iter 3114, loss [-0.22775912, -0.26631722, 0.038558092]\n",
      "Iter 3115, loss [-0.21579781, -0.2574222, 0.04162439]\n",
      "Iter 3116, loss [-0.20787555, -0.24977735, 0.041901797]\n",
      "Iter 3117, loss [-0.22809008, -0.26746598, 0.03937591]\n",
      "Iter 3118, loss [-0.24510433, -0.28962594, 0.044521615]\n",
      "Iter 3119, loss [-0.21030337, -0.24824566, 0.037942298]\n",
      "Iter 3120, loss [-0.21794441, -0.25390527, 0.035960846]\n",
      "Iter 3121, loss [-0.20720258, -0.24707144, 0.039868858]\n",
      "Iter 3122, loss [-0.24696977, -0.2903326, 0.043362807]\n",
      "Iter 3123, loss [-0.21081015, -0.24989925, 0.0390891]\n",
      "Iter 3124, loss [-0.22309434, -0.2617164, 0.038622044]\n",
      "Iter 3125, loss [-0.2213837, -0.26864573, 0.047262024]\n",
      "Iter 3126, loss [-0.21381456, -0.25551975, 0.041705187]\n",
      "Iter 3127, loss [-0.21870172, -0.25935686, 0.040655132]\n",
      "Iter 3128, loss [-0.22313239, -0.26204857, 0.038916185]\n",
      "Iter 3129, loss [-0.21086687, -0.24854948, 0.03768261]\n",
      "Iter 3130, loss [-0.21625835, -0.25832453, 0.042066187]\n",
      "Iter 3131, loss [-0.22863925, -0.27170047, 0.04306122]\n",
      "Iter 3132, loss [-0.21668732, -0.25470522, 0.038017895]\n",
      "Iter 3133, loss [-0.21786004, -0.2574238, 0.039563753]\n",
      "Iter 3134, loss [-0.22382243, -0.26098937, 0.03716694]\n",
      "Iter 3135, loss [-0.2204602, -0.26006, 0.0395998]\n",
      "Iter 3136, loss [-0.20786925, -0.2466112, 0.038741942]\n",
      "Iter 3137, loss [-0.22667925, -0.26575515, 0.039075896]\n",
      "Iter 3138, loss [-0.20199528, -0.24268763, 0.040692344]\n",
      "Iter 3139, loss [-0.20811835, -0.24686514, 0.03874679]\n",
      "Iter 3140, loss [-0.21134222, -0.25137016, 0.040027946]\n",
      "Iter 3141, loss [-0.2114696, -0.24913873, 0.03766912]\n",
      "Iter 3142, loss [-0.21434595, -0.25876093, 0.044414982]\n",
      "Iter 3143, loss [-0.20214467, -0.24148574, 0.039341073]\n",
      "Iter 3144, loss [-0.2278161, -0.26634857, 0.03853246]\n",
      "Iter 3145, loss [-0.2121728, -0.25318888, 0.041016065]\n",
      "Iter 3146, loss [-0.22076783, -0.2598908, 0.039122965]\n",
      "Iter 3147, loss [-0.2244634, -0.2654998, 0.041036393]\n",
      "Iter 3148, loss [-0.2208376, -0.25979042, 0.038952824]\n",
      "Iter 3149, loss [-0.22543022, -0.2693692, 0.043938994]\n",
      "Iter 3150, loss [-0.21194552, -0.25167412, 0.039728597]\n",
      "Iter 3151, loss [-0.2059446, -0.24299148, 0.037046876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3152, loss [-0.2059557, -0.25323182, 0.04727612]\n",
      "Iter 3153, loss [-0.22613087, -0.26541674, 0.03928586]\n",
      "Iter 3154, loss [-0.21180123, -0.24856976, 0.03676852]\n",
      "Iter 3155, loss [-0.20998663, -0.25261456, 0.04262793]\n",
      "Iter 3156, loss [-0.21617518, -0.25601256, 0.039837375]\n",
      "Iter 3157, loss [-0.22960299, -0.27287647, 0.04327347]\n",
      "Iter 3158, loss [-0.21089317, -0.25884855, 0.047955375]\n",
      "Iter 3159, loss [-0.20789477, -0.2497396, 0.041844822]\n",
      "Iter 3160, loss [-0.21129657, -0.24933931, 0.038042735]\n",
      "Iter 3161, loss [-0.227339, -0.26565436, 0.03831535]\n",
      "Iter 3162, loss [-0.22639243, -0.2635252, 0.03713275]\n",
      "Iter 3163, loss [-0.20609924, -0.2435563, 0.037457056]\n",
      "Iter 3164, loss [-0.22502834, -0.26556394, 0.0405356]\n",
      "Iter 3165, loss [-0.20350803, -0.2948583, 0.09135027]\n",
      "Iter 3166, loss [-0.21896182, -0.2580441, 0.039082274]\n",
      "Iter 3167, loss [-0.20884553, -0.2523844, 0.043538865]\n",
      "Iter 3168, loss [-0.30745438, -0.31703034, 0.009575977]\n",
      "Iter 3169, loss [-0.20785436, -0.24469756, 0.036843203]\n",
      "Iter 3170, loss [-0.21055815, -0.25080097, 0.04024283]\n",
      "Iter 3171, loss [-0.21055064, -0.24880052, 0.03824988]\n",
      "Iter 3172, loss [-0.24657555, -0.2897256, 0.04315005]\n",
      "Iter 3173, loss [-0.21578018, -0.25522682, 0.039446637]\n",
      "Iter 3174, loss [-0.21625826, -0.2572172, 0.04095894]\n",
      "Iter 3175, loss [-0.21889518, -0.25864536, 0.039750174]\n",
      "Iter 3176, loss [-0.21602239, -0.25505206, 0.039029676]\n",
      "Iter 3177, loss [-0.19967362, -0.23623262, 0.036558997]\n",
      "Iter 3178, loss [-0.22828293, -0.27259004, 0.04430712]\n",
      "Iter 3179, loss [-0.21760616, -0.26233107, 0.044724904]\n",
      "Iter 3180, loss [-0.2164944, -0.26278442, 0.04629002]\n",
      "Iter 3181, loss [-0.23797667, -0.30451962, 0.06654296]\n",
      "Iter 3182, loss [-0.21734792, -0.25574937, 0.038401447]\n",
      "Iter 3183, loss [-0.22804661, -0.29551372, 0.06746711]\n",
      "Iter 3184, loss [-0.21961996, -0.25690797, 0.037288018]\n",
      "Iter 3185, loss [-0.21862482, -0.25769538, 0.03907056]\n",
      "Iter 3186, loss [-0.19930065, -0.23545925, 0.036158614]\n",
      "Iter 3187, loss [-0.21590063, -0.2581729, 0.042272277]\n",
      "Iter 3188, loss [-0.20495607, -0.24356627, 0.038610205]\n",
      "Iter 3189, loss [-0.22885816, -0.2739615, 0.045103353]\n",
      "Iter 3190, loss [-0.22007275, -0.3012635, 0.08119076]\n",
      "Iter 3191, loss [-0.2100738, -0.24994826, 0.03987446]\n",
      "Iter 3192, loss [-0.20948553, -0.25856328, 0.04907774]\n",
      "Iter 3193, loss [-0.21123895, -0.2515055, 0.04026655]\n",
      "Iter 3194, loss [-0.20781755, -0.257375, 0.049557444]\n",
      "Iter 3195, loss [-0.21562225, -0.25331348, 0.037691243]\n",
      "Iter 3196, loss [-0.2272754, -0.26435348, 0.03707809]\n",
      "Iter 3197, loss [-0.21930534, -0.2590663, 0.039760984]\n",
      "Iter 3198, loss [-0.22169977, -0.2792642, 0.057564437]\n",
      "Iter 3199, loss [-0.2098411, -0.24681762, 0.036976524]\n",
      "Iter 3200, loss [-0.21781316, -0.25470862, 0.03689545]\n",
      "Iter 3201, loss [-0.20778885, -0.2456217, 0.037832834]\n",
      "Iter 3202, loss [-0.20669006, -0.24901879, 0.042328727]\n",
      "Iter 3203, loss [-0.22395313, -0.26603186, 0.042078726]\n",
      "Iter 3204, loss [-0.2131916, -0.2762429, 0.063051306]\n",
      "Iter 3205, loss [-0.21172303, -0.25281677, 0.04109374]\n",
      "Iter 3206, loss [-0.22613883, -0.26480696, 0.038668126]\n",
      "Iter 3207, loss [-0.22716963, -0.26518843, 0.038018785]\n",
      "Iter 3208, loss [-0.21262474, -0.25362837, 0.041003626]\n",
      "Iter 3209, loss [-0.22319545, -0.26139835, 0.038202893]\n",
      "Iter 3210, loss [-0.22395802, -0.26443496, 0.04047694]\n",
      "Iter 3211, loss [-0.20712033, -0.24424139, 0.03712105]\n",
      "Iter 3212, loss [-0.2131716, -0.2557552, 0.042583577]\n",
      "Iter 3213, loss [-0.21674807, -0.25638995, 0.03964187]\n",
      "Iter 3214, loss [-0.30745012, -0.31725666, 0.009806543]\n",
      "Iter 3215, loss [-0.22777197, -0.26633278, 0.038560804]\n",
      "Iter 3216, loss [-0.22548573, -0.26534358, 0.03985785]\n",
      "Iter 3217, loss [-0.22011536, -0.25973532, 0.039619956]\n",
      "Iter 3218, loss [-0.22435701, -0.2633603, 0.03900328]\n",
      "Iter 3219, loss [-0.1812113, -0.22853148, 0.047320183]\n",
      "Iter 3220, loss [-0.30775863, -0.31679466, 0.009036028]\n",
      "Iter 3221, loss [-0.21367791, -0.25178236, 0.038104452]\n",
      "Iter 3222, loss [-0.21166363, -0.25169283, 0.04002919]\n",
      "Iter 3223, loss [-0.21810618, -0.26076654, 0.042660348]\n",
      "Iter 3224, loss [-0.21680444, -0.25800106, 0.041196607]\n",
      "Iter 3225, loss [-0.21694735, -0.2533758, 0.03642846]\n",
      "Iter 3226, loss [-0.19961318, -0.2977343, 0.09812111]\n",
      "Iter 3227, loss [-0.22770143, -0.26297614, 0.03527472]\n",
      "Iter 3228, loss [-0.2272673, -0.2624886, 0.03522131]\n",
      "Iter 3229, loss [-0.19901338, -0.23372963, 0.03471624]\n",
      "Iter 3230, loss [-0.21674559, -0.25903225, 0.04228666]\n",
      "Iter 3231, loss [-0.21037135, -0.24803814, 0.037666798]\n",
      "Iter 3232, loss [-0.22528958, -0.26360682, 0.038317226]\n",
      "Iter 3233, loss [-0.20501286, -0.24320105, 0.038188197]\n",
      "Iter 3234, loss [-0.20972796, -0.25877395, 0.04904599]\n",
      "Iter 3235, loss [-0.2079413, -0.26543215, 0.057490855]\n",
      "Iter 3236, loss [-0.21127912, -0.25061452, 0.0393354]\n",
      "Iter 3237, loss [-0.19927233, -0.23608191, 0.03680958]\n",
      "Iter 3238, loss [-0.21742816, -0.25972784, 0.04229967]\n",
      "Iter 3239, loss [-0.19907452, -0.23648486, 0.037410334]\n",
      "Iter 3240, loss [-0.206592, -0.2493976, 0.04280562]\n",
      "Iter 3241, loss [-0.2189277, -0.26175362, 0.04282592]\n",
      "Iter 3242, loss [-0.22409707, -0.26545238, 0.04135531]\n",
      "Iter 3243, loss [-0.20721316, -0.2433124, 0.036099236]\n",
      "Iter 3244, loss [-0.22386372, -0.26834017, 0.044476442]\n",
      "Iter 3245, loss [-0.217078, -0.2557113, 0.03863329]\n",
      "Iter 3246, loss [-0.22424626, -0.26457003, 0.040323764]\n",
      "Iter 3247, loss [-0.2105727, -0.24875203, 0.038179323]\n",
      "Iter 3248, loss [-0.23043846, -0.26705754, 0.036619082]\n",
      "Iter 3249, loss [-0.2157253, -0.26035124, 0.044625938]\n",
      "Iter 3250, loss [-0.2115177, -0.25552988, 0.04401217]\n",
      "Iter 3251, loss [-0.21676391, -0.25727177, 0.040507846]\n",
      "Iter 3252, loss [-0.22396089, -0.26200566, 0.038044762]\n",
      "Iter 3253, loss [-0.21703139, -0.2569761, 0.039944716]\n",
      "Iter 3254, loss [-0.23992065, -0.2749928, 0.03507214]\n",
      "Iter 3255, loss [-0.21884026, -0.25528648, 0.03644623]\n",
      "Iter 3256, loss [-0.2047529, -0.24508382, 0.040330917]\n",
      "Iter 3257, loss [-0.22348285, -0.26243556, 0.0389527]\n",
      "Iter 3258, loss [-0.24727343, -0.29292092, 0.045647487]\n",
      "Iter 3259, loss [-0.21076298, -0.25903872, 0.04827573]\n",
      "Iter 3260, loss [-0.21952875, -0.26053882, 0.041010067]\n",
      "Iter 3261, loss [-0.21024993, -0.24871823, 0.038468298]\n",
      "Iter 3262, loss [-0.21204899, -0.25263402, 0.04058503]\n",
      "Iter 3263, loss [-0.20684989, -0.24762115, 0.04077126]\n",
      "Iter 3264, loss [-0.21185668, -0.25443068, 0.042574]\n",
      "Iter 3265, loss [-0.30840784, -0.31764135, 0.009233492]\n",
      "Iter 3266, loss [-0.20792237, -0.24309775, 0.035175376]\n",
      "Iter 3267, loss [-0.22732268, -0.26399636, 0.036673676]\n",
      "Iter 3268, loss [-0.21663989, -0.25455827, 0.037918374]\n",
      "Iter 3269, loss [-0.23393601, -0.3120534, 0.0781174]\n",
      "Iter 3270, loss [-0.21237695, -0.27442312, 0.062046178]\n",
      "Iter 3271, loss [-0.21217671, -0.25395936, 0.041782655]\n",
      "Iter 3272, loss [-0.21013227, -0.2764004, 0.066268116]\n",
      "Iter 3273, loss [-0.20762971, -0.24722654, 0.039596826]\n",
      "Iter 3274, loss [-0.2310916, -0.26793447, 0.036842868]\n",
      "Iter 3275, loss [-0.22236189, -0.28335118, 0.060989283]\n",
      "Iter 3276, loss [-0.21492007, -0.25455675, 0.03963667]\n",
      "Iter 3277, loss [-0.21165696, -0.2533198, 0.04166285]\n",
      "Iter 3278, loss [-0.30835086, -0.31729975, 0.008948896]\n",
      "Iter 3279, loss [-0.20990217, -0.25424814, 0.044345967]\n",
      "Iter 3280, loss [-0.21700178, -0.2525811, 0.035579305]\n",
      "Iter 3281, loss [-0.20732316, -0.2421662, 0.03484305]\n",
      "Iter 3282, loss [-0.2112737, -0.24582918, 0.03455548]\n",
      "Iter 3283, loss [-0.21756983, -0.2617084, 0.04413858]\n",
      "Iter 3284, loss [-0.21390323, -0.25608924, 0.042186003]\n",
      "Iter 3285, loss [-0.22686663, -0.26653358, 0.039666947]\n",
      "Iter 3286, loss [-0.2463119, -0.2924576, 0.046145715]\n",
      "Iter 3287, loss [-0.21798679, -0.25661066, 0.038623877]\n",
      "Iter 3288, loss [-0.20854042, -0.25190702, 0.043366592]\n",
      "Iter 3289, loss [-0.20915753, -0.24803832, 0.038880788]\n",
      "Iter 3290, loss [-0.21600994, -0.2538799, 0.037869968]\n",
      "Iter 3291, loss [-0.22458842, -0.26287872, 0.0382903]\n",
      "Iter 3292, loss [-0.21813598, -0.25490808, 0.0367721]\n",
      "Iter 3293, loss [-0.21822478, -0.25762087, 0.03939609]\n",
      "Iter 3294, loss [-0.21895082, -0.26034167, 0.041390847]\n",
      "Iter 3295, loss [-0.21265273, -0.25055182, 0.037899088]\n",
      "Iter 3296, loss [-0.2081282, -0.24607535, 0.037947144]\n",
      "Iter 3297, loss [-0.20597553, -0.24328923, 0.0373137]\n",
      "Iter 3298, loss [-0.22563872, -0.26766518, 0.042026453]\n",
      "Iter 3299, loss [-0.22042096, -0.26025602, 0.039835073]\n",
      "Iter 3300, loss [-0.21078983, -0.257156, 0.046366177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3301, loss [-0.2249967, -0.26454842, 0.039551716]\n",
      "Iter 3302, loss [-0.22568575, -0.26513276, 0.039447002]\n",
      "Iter 3303, loss [-0.20603883, -0.24367571, 0.03763687]\n",
      "Iter 3304, loss [-0.22834201, -0.26591918, 0.037577163]\n",
      "Iter 3305, loss [-0.20753822, -0.24911425, 0.041576028]\n",
      "Iter 3306, loss [-0.20650181, -0.24336682, 0.036865003]\n",
      "Iter 3307, loss [-0.22622198, -0.26658148, 0.04035949]\n",
      "Iter 3308, loss [-0.21379405, -0.24982905, 0.036035]\n",
      "Iter 3309, loss [-0.22436804, -0.26232746, 0.037959434]\n",
      "Iter 3310, loss [-0.242054, -0.3047736, 0.0627196]\n",
      "Iter 3311, loss [-0.23731637, -0.30952394, 0.07220757]\n",
      "Iter 3312, loss [-0.21430263, -0.27524182, 0.060939193]\n",
      "Iter 3313, loss [-0.2100381, -0.24995801, 0.039919913]\n",
      "Iter 3314, loss [-0.24383096, -0.290229, 0.046398025]\n",
      "Iter 3315, loss [-0.21686754, -0.25907773, 0.042210184]\n",
      "Iter 3316, loss [-0.21690294, -0.25722152, 0.040318586]\n",
      "Iter 3317, loss [-0.20386489, -0.2523864, 0.048521504]\n",
      "Iter 3318, loss [-0.20731711, -0.2500573, 0.04274019]\n",
      "Iter 3319, loss [-0.21520409, -0.25480133, 0.03959724]\n",
      "Iter 3320, loss [-0.21926165, -0.25917065, 0.039908998]\n",
      "Iter 3321, loss [-0.2119983, -0.24770239, 0.03570409]\n",
      "Iter 3322, loss [-0.19375022, -0.26307482, 0.0693246]\n",
      "Iter 3323, loss [-0.2170042, -0.255577, 0.038572803]\n",
      "Iter 3324, loss [-0.22541766, -0.26418376, 0.0387661]\n",
      "Iter 3325, loss [-0.21770331, -0.2556956, 0.037992306]\n",
      "Iter 3326, loss [-0.2078039, -0.2514552, 0.043651275]\n",
      "Iter 3327, loss [-0.2240578, -0.26306066, 0.03900286]\n",
      "Iter 3328, loss [-0.21016145, -0.24931234, 0.039150894]\n",
      "Iter 3329, loss [-0.21465203, -0.25637275, 0.04172072]\n",
      "Iter 3330, loss [-0.21774784, -0.25508934, 0.037341505]\n",
      "Iter 3331, loss [-0.21272562, -0.24839078, 0.035665154]\n",
      "Iter 3332, loss [-0.21645136, -0.2543298, 0.037878443]\n",
      "Iter 3333, loss [-0.22361171, -0.2613263, 0.0377146]\n",
      "Iter 3334, loss [-0.22551565, -0.26369256, 0.03817691]\n",
      "Iter 3335, loss [-0.21205516, -0.25231093, 0.04025577]\n",
      "Iter 3336, loss [-0.21031518, -0.2503741, 0.040058922]\n",
      "Iter 3337, loss [-0.20221059, -0.24242105, 0.040210456]\n",
      "Iter 3338, loss [-0.2108451, -0.2511404, 0.040295284]\n",
      "Iter 3339, loss [-0.22782281, -0.26623622, 0.0384134]\n",
      "Iter 3340, loss [-0.21387261, -0.25198945, 0.038116843]\n",
      "Iter 3341, loss [-0.22026868, -0.25993648, 0.0396678]\n",
      "Iter 3342, loss [-0.2186986, -0.256443, 0.03774439]\n",
      "Iter 3343, loss [-0.2241728, -0.26164362, 0.03747081]\n",
      "Iter 3344, loss [-0.20598158, -0.25403988, 0.0480583]\n",
      "Iter 3345, loss [-0.2214055, -0.2579559, 0.0365504]\n",
      "Iter 3346, loss [-0.21326934, -0.25458065, 0.04131131]\n",
      "Iter 3347, loss [-0.21329, -0.25471076, 0.041420758]\n",
      "Iter 3348, loss [-0.21878839, -0.25840998, 0.039621588]\n",
      "Iter 3349, loss [-0.22705525, -0.2656977, 0.038642436]\n",
      "Iter 3350, loss [-0.22503886, -0.2694008, 0.04436194]\n",
      "Iter 3351, loss [-0.21758828, -0.25612062, 0.038532346]\n",
      "Iter 3352, loss [-0.21110407, -0.25914222, 0.048038155]\n",
      "Iter 3353, loss [-0.2387606, -0.311087, 0.07232641]\n",
      "Iter 3354, loss [-0.21848927, -0.25711533, 0.038626064]\n",
      "Iter 3355, loss [-0.20409498, -0.24242963, 0.038334645]\n",
      "Iter 3356, loss [-0.22962588, -0.26712993, 0.03750404]\n",
      "Iter 3357, loss [-0.22071007, -0.26008877, 0.03937871]\n",
      "Iter 3358, loss [-0.2108421, -0.26031008, 0.04946798]\n",
      "Iter 3359, loss [-0.21235447, -0.25717977, 0.044825297]\n",
      "Iter 3360, loss [-0.21250135, -0.2573169, 0.044815548]\n",
      "Iter 3361, loss [-0.21755691, -0.25606734, 0.038510423]\n",
      "Iter 3362, loss [-0.20317626, -0.29379502, 0.09061876]\n",
      "Iter 3363, loss [-0.225833, -0.26766768, 0.041834675]\n",
      "Iter 3364, loss [-0.2234468, -0.28444263, 0.06099583]\n",
      "Iter 3365, loss [-0.22553067, -0.2646382, 0.039107513]\n",
      "Iter 3366, loss [-0.2106833, -0.24838188, 0.03769858]\n",
      "Iter 3367, loss [-0.21818803, -0.25637734, 0.038189307]\n",
      "Iter 3368, loss [-0.21368316, -0.25479662, 0.04111346]\n",
      "Iter 3369, loss [-0.21859443, -0.25684005, 0.03824561]\n",
      "Iter 3370, loss [-0.22462721, -0.2658118, 0.04118459]\n",
      "Iter 3371, loss [-0.2212078, -0.3047117, 0.0835039]\n",
      "Iter 3372, loss [-0.21362315, -0.25625488, 0.04263173]\n",
      "Iter 3373, loss [-0.20341462, -0.29352784, 0.09011322]\n",
      "Iter 3374, loss [-0.21553135, -0.25488222, 0.039350875]\n",
      "Iter 3375, loss [-0.21361718, -0.25889808, 0.045280896]\n",
      "Iter 3376, loss [-0.21123363, -0.24889861, 0.03766498]\n",
      "Iter 3377, loss [-0.22644012, -0.26521504, 0.038774922]\n",
      "Iter 3378, loss [-0.22424832, -0.26505727, 0.04080894]\n",
      "Iter 3379, loss [-0.21505624, -0.25713554, 0.042079292]\n",
      "Iter 3380, loss [-0.21889764, -0.2560295, 0.037131853]\n",
      "Iter 3381, loss [-0.21088558, -0.25127903, 0.040393442]\n",
      "Iter 3382, loss [-0.22196504, -0.26814815, 0.046183117]\n",
      "Iter 3383, loss [-0.20919889, -0.24848224, 0.03928335]\n",
      "Iter 3384, loss [-0.20965143, -0.2520021, 0.042350665]\n",
      "Iter 3385, loss [-0.22085905, -0.25971758, 0.038858525]\n",
      "Iter 3386, loss [-0.22580105, -0.26795948, 0.04215842]\n",
      "Iter 3387, loss [-0.20286134, -0.24608502, 0.04322367]\n",
      "Iter 3388, loss [-0.22594106, -0.26597118, 0.04003013]\n",
      "Iter 3389, loss [-0.20244151, -0.24250881, 0.0400673]\n",
      "Iter 3390, loss [-0.2121647, -0.2529858, 0.040821105]\n",
      "Iter 3391, loss [-0.22092396, -0.25991717, 0.03899321]\n",
      "Iter 3392, loss [-0.22502705, -0.2656384, 0.04061135]\n",
      "Iter 3393, loss [-0.22392039, -0.26121408, 0.037293684]\n",
      "Iter 3394, loss [-0.18121807, -0.22967893, 0.048460852]\n",
      "Iter 3395, loss [-0.30747882, -0.31687993, 0.009401111]\n",
      "Iter 3396, loss [-0.22030126, -0.26011825, 0.03981699]\n",
      "Iter 3397, loss [-0.22630681, -0.28828952, 0.061982706]\n",
      "Iter 3398, loss [-0.21375188, -0.2489459, 0.035194032]\n",
      "Iter 3399, loss [-0.228628, -0.2651349, 0.036506902]\n",
      "Iter 3400, loss [-0.2189648, -0.25725394, 0.038289145]\n",
      "Iter 3401, loss [-0.20332956, -0.2459603, 0.042630725]\n",
      "Iter 3402, loss [-0.21912062, -0.25551388, 0.036393255]\n",
      "Iter 3403, loss [-0.2295627, -0.27225426, 0.04269156]\n",
      "Iter 3404, loss [-0.23646325, -0.31542903, 0.07896578]\n",
      "Iter 3405, loss [-0.21414559, -0.25574374, 0.041598156]\n",
      "Iter 3406, loss [-0.21529123, -0.25640747, 0.041116245]\n",
      "Iter 3407, loss [-0.20833302, -0.24712837, 0.038795345]\n",
      "Iter 3408, loss [-0.22506206, -0.30737108, 0.08230902]\n",
      "Iter 3409, loss [-0.21208715, -0.25678578, 0.04469862]\n",
      "Iter 3410, loss [-0.21206148, -0.2577048, 0.045643315]\n",
      "Iter 3411, loss [-0.21796021, -0.25643694, 0.038476728]\n",
      "Iter 3412, loss [-0.21221402, -0.25506914, 0.042855114]\n",
      "Iter 3413, loss [-0.22001757, -0.25913334, 0.03911577]\n",
      "Iter 3414, loss [-0.21853298, -0.25745565, 0.03892266]\n",
      "Iter 3415, loss [-0.20795539, -0.24424388, 0.036288492]\n",
      "Iter 3416, loss [-0.21878433, -0.25527197, 0.03648763]\n",
      "Iter 3417, loss [-0.22804019, -0.26558748, 0.037547298]\n",
      "Iter 3418, loss [-0.20975041, -0.2534567, 0.04370629]\n",
      "Iter 3419, loss [-0.21373427, -0.256266, 0.04253172]\n",
      "Iter 3420, loss [-0.22492725, -0.2694069, 0.044479664]\n",
      "Iter 3421, loss [-0.21202606, -0.2514502, 0.039424147]\n",
      "Iter 3422, loss [-0.21444106, -0.25436944, 0.03992837]\n",
      "Iter 3423, loss [-0.22184789, -0.25883892, 0.036991037]\n",
      "Iter 3424, loss [-0.22198367, -0.2588881, 0.036904417]\n",
      "Iter 3425, loss [-0.21795343, -0.26191095, 0.043957517]\n",
      "Iter 3426, loss [-0.2164549, -0.25814137, 0.041686483]\n",
      "Iter 3427, loss [-0.22974095, -0.27261326, 0.042872302]\n",
      "Iter 3428, loss [-0.21630682, -0.25648925, 0.040182423]\n",
      "Iter 3429, loss [-0.22856866, -0.26638332, 0.03781466]\n",
      "Iter 3430, loss [-0.2121794, -0.2537414, 0.04156203]\n",
      "Iter 3431, loss [-0.210921, -0.25036076, 0.03943975]\n",
      "Iter 3432, loss [-0.2189779, -0.2627581, 0.043780204]\n",
      "Iter 3433, loss [-0.2444072, -0.3069381, 0.062530905]\n",
      "Iter 3434, loss [-0.21316338, -0.24957463, 0.03641125]\n",
      "Iter 3435, loss [-0.2164495, -0.2578189, 0.041369416]\n",
      "Iter 3436, loss [-0.22970706, -0.26731604, 0.03760898]\n",
      "Iter 3437, loss [-0.21876153, -0.25802436, 0.039262824]\n",
      "Iter 3438, loss [-0.2307944, -0.30018163, 0.06938723]\n",
      "Iter 3439, loss [-0.21704112, -0.2575185, 0.04047738]\n",
      "Iter 3440, loss [-0.22723101, -0.2657002, 0.03846918]\n",
      "Iter 3441, loss [-0.21794346, -0.25628582, 0.038342353]\n",
      "Iter 3442, loss [-0.22930878, -0.26847127, 0.03916248]\n",
      "Iter 3443, loss [-0.22569168, -0.2642453, 0.03855362]\n",
      "Iter 3444, loss [-0.20629191, -0.25448054, 0.04818862]\n",
      "Iter 3445, loss [-0.20869654, -0.24686614, 0.03816959]\n",
      "Iter 3446, loss [-0.21155527, -0.25049144, 0.038936168]\n",
      "Iter 3447, loss [-0.22626442, -0.26365876, 0.03739434]\n",
      "Iter 3448, loss [-0.21448009, -0.25940126, 0.044921175]\n",
      "Iter 3449, loss [-0.20877919, -0.24538876, 0.036609575]\n",
      "Iter 3450, loss [-0.21139315, -0.24956241, 0.038169257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3451, loss [-0.30792782, -0.31732696, 0.009399156]\n",
      "Iter 3452, loss [-0.22444844, -0.26143828, 0.03698984]\n",
      "Iter 3453, loss [-0.21639475, -0.25768462, 0.04128987]\n",
      "Iter 3454, loss [-0.22013827, -0.26032045, 0.04018219]\n",
      "Iter 3455, loss [-0.20322996, -0.24224703, 0.039017074]\n",
      "Iter 3456, loss [-0.22988099, -0.26831648, 0.038435493]\n",
      "Iter 3457, loss [-0.21914276, -0.25774676, 0.038603988]\n",
      "Iter 3458, loss [-0.22519945, -0.3055248, 0.08032535]\n",
      "Iter 3459, loss [-0.21202984, -0.25344568, 0.041415833]\n",
      "Iter 3460, loss [-0.21659312, -0.2564133, 0.03982019]\n",
      "Iter 3461, loss [-0.19976953, -0.23614734, 0.03637781]\n",
      "Iter 3462, loss [-0.21203534, -0.25263822, 0.040602878]\n",
      "Iter 3463, loss [-0.22048406, -0.25895357, 0.038469505]\n",
      "Iter 3464, loss [-0.22036976, -0.26076594, 0.040396176]\n",
      "Iter 3465, loss [-0.21787642, -0.2565115, 0.038635086]\n",
      "Iter 3466, loss [-0.2084654, -0.24488646, 0.036421068]\n",
      "Iter 3467, loss [-0.22398634, -0.28501445, 0.061028108]\n",
      "Iter 3468, loss [-0.21788602, -0.25847545, 0.040589433]\n",
      "Iter 3469, loss [-0.22743972, -0.2660873, 0.038647577]\n",
      "Iter 3470, loss [-0.23684332, -0.29186755, 0.05502423]\n",
      "Iter 3471, loss [-0.18123993, -0.2300553, 0.048815362]\n",
      "Iter 3472, loss [-0.21814403, -0.25680712, 0.038663086]\n",
      "Iter 3473, loss [-0.22797216, -0.26592582, 0.037953664]\n",
      "Iter 3474, loss [-0.22049156, -0.260393, 0.039901428]\n",
      "Iter 3475, loss [-0.20614731, -0.2434278, 0.037280492]\n",
      "Iter 3476, loss [-0.21128708, -0.2507104, 0.03942331]\n",
      "Iter 3477, loss [-0.21681146, -0.2574724, 0.04066093]\n",
      "Iter 3478, loss [-0.21865949, -0.2579312, 0.039271712]\n",
      "Iter 3479, loss [-0.21373153, -0.25541922, 0.04168769]\n",
      "Iter 3480, loss [-0.22852495, -0.26592973, 0.03740477]\n",
      "Iter 3481, loss [-0.2110566, -0.24786802, 0.036811408]\n",
      "Iter 3482, loss [-0.229965, -0.26764122, 0.037676215]\n",
      "Iter 3483, loss [-0.21133885, -0.25076142, 0.039422564]\n",
      "Iter 3484, loss [-0.22965804, -0.27343303, 0.043774985]\n",
      "Iter 3485, loss [-0.21162704, -0.24973734, 0.03811031]\n",
      "Iter 3486, loss [-0.21644399, -0.25954145, 0.043097466]\n",
      "Iter 3487, loss [-0.21886946, -0.25888318, 0.040013712]\n",
      "Iter 3488, loss [-0.21924031, -0.25717193, 0.03793162]\n",
      "Iter 3489, loss [-0.22547528, -0.28438568, 0.0589104]\n",
      "Iter 3490, loss [-0.22737488, -0.30653214, 0.079157256]\n",
      "Iter 3491, loss [-0.21691181, -0.2584792, 0.0415674]\n",
      "Iter 3492, loss [-0.218561, -0.2548292, 0.036268212]\n",
      "Iter 3493, loss [-0.21604937, -0.25682038, 0.040771008]\n",
      "Iter 3494, loss [-0.20853733, -0.24729069, 0.03875336]\n",
      "Iter 3495, loss [-0.21435012, -0.25948864, 0.045138523]\n",
      "Iter 3496, loss [-0.21454373, -0.2596125, 0.045068763]\n",
      "Iter 3497, loss [-0.22108541, -0.26060614, 0.039520726]\n",
      "Iter 3498, loss [-0.20344181, -0.24626303, 0.04282121]\n",
      "Iter 3499, loss [-0.2285922, -0.26579988, 0.037207678]\n",
      "Iter 3500, loss [-0.21655634, -0.25949094, 0.04293459]\n",
      "Iter 3501, loss [-0.24396984, -0.30866477, 0.064694926]\n",
      "Iter 3502, loss [-0.21896298, -0.25758424, 0.038621258]\n",
      "Iter 3503, loss [-0.22546053, -0.26330796, 0.03784743]\n",
      "Iter 3504, loss [-0.20719612, -0.24726033, 0.04006422]\n",
      "Iter 3505, loss [-0.21044952, -0.25753504, 0.04708552]\n",
      "Iter 3506, loss [-0.22512025, -0.28467909, 0.059558835]\n",
      "Iter 3507, loss [-0.21782628, -0.2635395, 0.045713216]\n",
      "Iter 3508, loss [-0.2086294, -0.248443, 0.03981359]\n",
      "Iter 3509, loss [-0.20945899, -0.2541278, 0.04466881]\n",
      "Iter 3510, loss [-0.21867748, -0.25992554, 0.04124807]\n",
      "Iter 3511, loss [-0.21871737, -0.25888264, 0.040165268]\n",
      "Iter 3512, loss [-0.22826159, -0.2980191, 0.06975752]\n",
      "Iter 3513, loss [-0.2286526, -0.2655725, 0.03691989]\n",
      "Iter 3514, loss [-0.21020353, -0.25139284, 0.04118932]\n",
      "Iter 3515, loss [-0.22837573, -0.26493183, 0.0365561]\n",
      "Iter 3516, loss [-0.218571, -0.26054248, 0.04197147]\n",
      "Iter 3517, loss [-0.21799967, -0.25573313, 0.03773346]\n",
      "Iter 3518, loss [-0.2097719, -0.25219762, 0.04242573]\n",
      "Iter 3519, loss [-0.20019856, -0.2371158, 0.03691724]\n",
      "Iter 3520, loss [-0.21145295, -0.24997161, 0.038518667]\n",
      "Iter 3521, loss [-0.22696242, -0.26653054, 0.039568134]\n",
      "Iter 3522, loss [-0.20615515, -0.25534874, 0.049193583]\n",
      "Iter 3523, loss [-0.22846475, -0.2667115, 0.03824676]\n",
      "Iter 3524, loss [-0.21249351, -0.2512764, 0.038782895]\n",
      "Iter 3525, loss [-0.21083911, -0.24879445, 0.037955344]\n",
      "Iter 3526, loss [-0.22436062, -0.2621198, 0.037759185]\n",
      "Iter 3527, loss [-0.21905364, -0.25776404, 0.038710397]\n",
      "Iter 3528, loss [-0.21678086, -0.25711247, 0.040331617]\n",
      "Iter 3529, loss [-0.21872178, -0.25810328, 0.03938151]\n",
      "Iter 3530, loss [-0.2179406, -0.25624502, 0.038304426]\n",
      "Iter 3531, loss [-0.20790493, -0.24948297, 0.04157804]\n",
      "Iter 3532, loss [-0.21060775, -0.25029135, 0.039683595]\n",
      "Iter 3533, loss [-0.21673405, -0.2585393, 0.041805234]\n",
      "Iter 3534, loss [-0.20881444, -0.24523987, 0.036425423]\n",
      "Iter 3535, loss [-0.21436016, -0.2529201, 0.03855993]\n",
      "Iter 3536, loss [-0.2134765, -0.254751, 0.041274503]\n",
      "Iter 3537, loss [-0.21779117, -0.25419962, 0.03640846]\n",
      "Iter 3538, loss [-0.22123027, -0.29973325, 0.07850298]\n",
      "Iter 3539, loss [-0.20610681, -0.24859409, 0.04248728]\n",
      "Iter 3540, loss [-0.17900205, -0.22976127, 0.050759234]\n",
      "Iter 3541, loss [-0.20121393, -0.2470714, 0.04585747]\n",
      "Iter 3542, loss [-0.21759307, -0.26064497, 0.043051906]\n",
      "Iter 3543, loss [-0.21035162, -0.24949646, 0.039144836]\n",
      "Iter 3544, loss [-0.21492419, -0.2575729, 0.04264871]\n",
      "Iter 3545, loss [-0.22056359, -0.257771, 0.03720739]\n",
      "Iter 3546, loss [-0.23956978, -0.2731877, 0.033617914]\n",
      "Iter 3547, loss [-0.21595033, -0.25187343, 0.03592311]\n",
      "Iter 3548, loss [-0.22436568, -0.26237786, 0.03801217]\n",
      "Iter 3549, loss [-0.20159185, -0.2784266, 0.07683474]\n",
      "Iter 3550, loss [-0.210031, -0.24843597, 0.038404968]\n",
      "Iter 3551, loss [-0.21539897, -0.2512164, 0.035817437]\n",
      "Iter 3552, loss [-0.23094428, -0.29224184, 0.061297566]\n",
      "Iter 3553, loss [-0.21556462, -0.25458124, 0.03901662]\n",
      "Iter 3554, loss [-0.20625307, -0.24290079, 0.036647722]\n",
      "Iter 3555, loss [-0.2331649, -0.3167375, 0.0835726]\n",
      "Iter 3556, loss [-0.23680362, -0.3145124, 0.07770877]\n",
      "Iter 3557, loss [-0.2119079, -0.2531754, 0.041267507]\n",
      "Iter 3558, loss [-0.21337454, -0.25569943, 0.042324882]\n",
      "Iter 3559, loss [-0.21411642, -0.25651547, 0.042399045]\n",
      "Iter 3560, loss [-0.21448645, -0.2524121, 0.037925657]\n",
      "Iter 3561, loss [-0.2020776, -0.24571112, 0.043633517]\n",
      "Iter 3562, loss [-0.22992402, -0.303096, 0.07317197]\n",
      "Iter 3563, loss [-0.17998123, -0.22734126, 0.04736004]\n",
      "Iter 3564, loss [-0.21235837, -0.25246605, 0.040107682]\n",
      "Iter 3565, loss [-0.20252487, -0.23942989, 0.03690502]\n",
      "Iter 3566, loss [-0.21702841, -0.25795743, 0.04092902]\n",
      "Iter 3567, loss [-0.20992525, -0.2496026, 0.03967735]\n",
      "Iter 3568, loss [-0.20556417, -0.24734223, 0.041778065]\n",
      "Iter 3569, loss [-0.21327455, -0.28171033, 0.06843577]\n",
      "Iter 3570, loss [-0.21641196, -0.25757766, 0.04116569]\n",
      "Iter 3571, loss [-0.21767974, -0.25512773, 0.03744798]\n",
      "Iter 3572, loss [-0.2067881, -0.25776684, 0.050978743]\n",
      "Iter 3573, loss [-0.22722694, -0.2668177, 0.03959074]\n",
      "Iter 3574, loss [-0.2259461, -0.26494372, 0.03899762]\n",
      "Iter 3575, loss [-0.20085186, -0.2400351, 0.039183244]\n",
      "Iter 3576, loss [-0.20601803, -0.24717933, 0.0411613]\n",
      "Iter 3577, loss [-0.20974009, -0.2476038, 0.03786372]\n",
      "Iter 3578, loss [-0.22300985, -0.26486892, 0.041859053]\n",
      "Iter 3579, loss [-0.24261527, -0.30756974, 0.064954475]\n",
      "Iter 3580, loss [-0.225495, -0.2630663, 0.037571292]\n",
      "Iter 3581, loss [-0.22307134, -0.26026416, 0.03719283]\n",
      "Iter 3582, loss [-0.3071522, -0.31699714, 0.009844927]\n",
      "Iter 3583, loss [-0.21123771, -0.25203618, 0.040798467]\n",
      "Iter 3584, loss [-0.20903714, -0.24481903, 0.03578189]\n",
      "Iter 3585, loss [-0.21015728, -0.25656804, 0.046410777]\n",
      "Iter 3586, loss [-0.20937252, -0.25539112, 0.0460186]\n",
      "Iter 3587, loss [-0.21225744, -0.24675965, 0.034502205]\n",
      "Iter 3588, loss [-0.21598987, -0.25555456, 0.039564688]\n",
      "Iter 3589, loss [-0.1801329, -0.22979827, 0.04966537]\n",
      "Iter 3590, loss [-0.21576303, -0.2560901, 0.040327076]\n",
      "Iter 3591, loss [-0.24418709, -0.29223388, 0.048046794]\n",
      "Iter 3592, loss [-0.21144553, -0.25132373, 0.03987821]\n",
      "Iter 3593, loss [-0.22492325, -0.2620996, 0.037176333]\n",
      "Iter 3594, loss [-0.22615412, -0.2644504, 0.038296286]\n",
      "Iter 3595, loss [-0.22439599, -0.3043334, 0.079937406]\n",
      "Iter 3596, loss [-0.2242195, -0.26329777, 0.03907826]\n",
      "Iter 3597, loss [-0.23977077, -0.2734409, 0.033670127]\n",
      "Iter 3598, loss [-0.23686509, -0.2921062, 0.05524112]\n",
      "Iter 3599, loss [-0.2175878, -0.25431827, 0.03673046]\n",
      "Iter 3600, loss [-0.202451, -0.24626312, 0.043812107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3601, loss [-0.2232337, -0.26292908, 0.03969539]\n",
      "Iter 3602, loss [-0.21894309, -0.26078045, 0.041837372]\n",
      "Iter 3603, loss [-0.2067746, -0.24971671, 0.042942107]\n",
      "Iter 3604, loss [-0.218176, -0.25506774, 0.03689173]\n",
      "Iter 3605, loss [-0.20942324, -0.25328866, 0.043865405]\n",
      "Iter 3606, loss [-0.21077648, -0.25067854, 0.03990207]\n",
      "Iter 3607, loss [-0.2111828, -0.24801926, 0.036836468]\n",
      "Iter 3608, loss [-0.20761736, -0.24330446, 0.035687108]\n",
      "Iter 3609, loss [-0.2208484, -0.2597411, 0.0388927]\n",
      "Iter 3610, loss [-0.20508002, -0.25447816, 0.049398135]\n",
      "Iter 3611, loss [-0.24731988, -0.31122297, 0.06390309]\n",
      "Iter 3612, loss [-0.20213816, -0.24207763, 0.039939474]\n",
      "Iter 3613, loss [-0.18099916, -0.23092875, 0.04992958]\n",
      "Iter 3614, loss [-0.21875584, -0.25490248, 0.036146645]\n",
      "Iter 3615, loss [-0.21622622, -0.25526193, 0.039035715]\n",
      "Iter 3616, loss [-0.20730537, -0.24715097, 0.0398456]\n",
      "Iter 3617, loss [-0.22673798, -0.26442438, 0.0376864]\n",
      "Iter 3618, loss [-0.21692464, -0.25744602, 0.040521376]\n",
      "Iter 3619, loss [-0.23156056, -0.26883343, 0.037272878]\n",
      "Iter 3620, loss [-0.210971, -0.24939783, 0.038426835]\n",
      "Iter 3621, loss [-0.22015005, -0.25994936, 0.039799303]\n",
      "Iter 3622, loss [-0.20232707, -0.24364966, 0.04132259]\n",
      "Iter 3623, loss [-0.20672804, -0.24940276, 0.042674717]\n",
      "Iter 3624, loss [-0.22026634, -0.2610847, 0.04081836]\n",
      "Iter 3625, loss [-0.2471478, -0.2889229, 0.041775115]\n",
      "Iter 3626, loss [-0.22323655, -0.2601091, 0.03687255]\n",
      "Iter 3627, loss [-0.306164, -0.31559968, 0.00943568]\n",
      "Iter 3628, loss [-0.21043207, -0.26944023, 0.059008166]\n",
      "Iter 3629, loss [-0.21806253, -0.25875124, 0.040688705]\n",
      "Iter 3630, loss [-0.21688443, -0.256209, 0.03932455]\n",
      "Iter 3631, loss [-0.19937588, -0.24008799, 0.0407121]\n",
      "Iter 3632, loss [-0.2096143, -0.24919218, 0.03957788]\n",
      "Iter 3633, loss [-0.21232152, -0.25376582, 0.041444294]\n",
      "Iter 3634, loss [-0.20606491, -0.24415489, 0.038089976]\n",
      "Iter 3635, loss [-0.21220881, -0.25688025, 0.044671446]\n",
      "Iter 3636, loss [-0.22933398, -0.28618014, 0.056846153]\n",
      "Iter 3637, loss [-0.21197583, -0.2557887, 0.043812882]\n",
      "Iter 3638, loss [-0.21630016, -0.2535366, 0.037236445]\n",
      "Iter 3639, loss [-0.21425356, -0.2530567, 0.03880315]\n",
      "Iter 3640, loss [-0.19858885, -0.23484321, 0.036254358]\n",
      "Iter 3641, loss [-0.21482882, -0.2568817, 0.042052902]\n",
      "Iter 3642, loss [-0.30695868, -0.31664175, 0.009683058]\n",
      "Iter 3643, loss [-0.20785789, -0.24690327, 0.039045382]\n",
      "Iter 3644, loss [-0.21735992, -0.25744063, 0.04008071]\n",
      "Iter 3645, loss [-0.22534461, -0.26268393, 0.037339315]\n",
      "Iter 3646, loss [-0.2390302, -0.30351815, 0.06448795]\n",
      "Iter 3647, loss [-0.20782271, -0.24560282, 0.03778011]\n",
      "Iter 3648, loss [-0.21460518, -0.25531557, 0.040710382]\n",
      "Iter 3649, loss [-0.21012247, -0.25417387, 0.044051416]\n",
      "Iter 3650, loss [-0.21039127, -0.25079152, 0.04040025]\n",
      "Iter 3651, loss [-0.20979862, -0.2504983, 0.040699676]\n",
      "Iter 3652, loss [-0.21909419, -0.26085192, 0.04175774]\n",
      "Iter 3653, loss [-0.21052349, -0.25041237, 0.03988889]\n",
      "Iter 3654, loss [-0.21808302, -0.25829884, 0.040215828]\n",
      "Iter 3655, loss [-0.20617154, -0.24688895, 0.040717408]\n",
      "Iter 3656, loss [-0.21223465, -0.25344265, 0.04120799]\n",
      "Iter 3657, loss [-0.21078688, -0.24748948, 0.036702596]\n",
      "Iter 3658, loss [-0.21014763, -0.25705802, 0.046910387]\n",
      "Iter 3659, loss [-0.21800983, -0.25576395, 0.03775412]\n",
      "Iter 3660, loss [-0.21707812, -0.2543396, 0.037261494]\n",
      "Iter 3661, loss [-0.21252581, -0.25010294, 0.03757713]\n",
      "Iter 3662, loss [-0.21728408, -0.2568512, 0.039567105]\n",
      "Iter 3663, loss [-0.21296853, -0.2583217, 0.04535318]\n",
      "Iter 3664, loss [-0.20660162, -0.24950932, 0.042907696]\n",
      "Iter 3665, loss [-0.2289646, -0.2682503, 0.03928569]\n",
      "Iter 3666, loss [-0.30722886, -0.31682006, 0.009591198]\n",
      "Iter 3667, loss [-0.21641307, -0.25728717, 0.040874105]\n",
      "Iter 3668, loss [-0.21835107, -0.25542635, 0.03707528]\n",
      "Iter 3669, loss [-0.20761737, -0.24304873, 0.035431363]\n",
      "Iter 3670, loss [-0.24750322, -0.28920248, 0.041699253]\n",
      "Iter 3671, loss [-0.22774981, -0.26386085, 0.036111042]\n",
      "Iter 3672, loss [-0.225487, -0.26524782, 0.03976082]\n",
      "Iter 3673, loss [-0.22489451, -0.2641539, 0.039259385]\n",
      "Iter 3674, loss [-0.23603687, -0.31757873, 0.081541866]\n",
      "Iter 3675, loss [-0.21055742, -0.25056428, 0.040006857]\n",
      "Iter 3676, loss [-0.21523346, -0.25267628, 0.037442822]\n",
      "Iter 3677, loss [-0.24705572, -0.30961847, 0.06256275]\n",
      "Iter 3678, loss [-0.23726395, -0.2918559, 0.05459195]\n",
      "Iter 3679, loss [-0.20814785, -0.24838625, 0.040238388]\n",
      "Iter 3680, loss [-0.2117675, -0.25294384, 0.041176356]\n",
      "Iter 3681, loss [-0.21603197, -0.2569433, 0.040911313]\n",
      "Iter 3682, loss [-0.20032132, -0.24077208, 0.04045076]\n",
      "Iter 3683, loss [-0.21659958, -0.25572103, 0.039121453]\n",
      "Iter 3684, loss [-0.22942275, -0.29919595, 0.06977319]\n",
      "Iter 3685, loss [-0.21841002, -0.25916848, 0.04075847]\n",
      "Iter 3686, loss [-0.22602767, -0.26453072, 0.038503055]\n",
      "Iter 3687, loss [-0.30635425, -0.31566772, 0.009313457]\n",
      "Iter 3688, loss [-0.22877797, -0.26535064, 0.036572658]\n",
      "Iter 3689, loss [-0.22270349, -0.25925615, 0.036552668]\n",
      "Iter 3690, loss [-0.20375392, -0.29564613, 0.09189221]\n",
      "Iter 3691, loss [-0.24665321, -0.30824152, 0.061588302]\n",
      "Iter 3692, loss [-0.21791674, -0.2576777, 0.039760962]\n",
      "Iter 3693, loss [-0.21538574, -0.25573108, 0.04034534]\n",
      "Iter 3694, loss [-0.21064168, -0.25603336, 0.04539168]\n",
      "Iter 3695, loss [-0.21292795, -0.25432917, 0.041401222]\n",
      "Iter 3696, loss [-0.2177188, -0.2586721, 0.040953293]\n",
      "Iter 3697, loss [-0.21730946, -0.26136798, 0.044058513]\n",
      "Iter 3698, loss [-0.22209935, -0.2909971, 0.06889774]\n",
      "Iter 3699, loss [-0.2092613, -0.257771, 0.04850968]\n",
      "Iter 3700, loss [-0.217201, -0.26008245, 0.04288145]\n",
      "Iter 3701, loss [-0.20982002, -0.25670204, 0.046882015]\n",
      "Iter 3702, loss [-0.21566655, -0.2563872, 0.040720653]\n",
      "Iter 3703, loss [-0.21597965, -0.2526978, 0.03671814]\n",
      "Iter 3704, loss [-0.20978323, -0.2495051, 0.039721884]\n",
      "Iter 3705, loss [-0.21488333, -0.25431713, 0.0394338]\n",
      "Iter 3706, loss [-0.21798545, -0.25579697, 0.03781151]\n",
      "Iter 3707, loss [-0.20232722, -0.24752851, 0.04520128]\n",
      "Iter 3708, loss [-0.21078323, -0.2521964, 0.041413173]\n",
      "Iter 3709, loss [-0.20895049, -0.24969333, 0.04074284]\n",
      "Iter 3710, loss [-0.21264793, -0.24951504, 0.03686711]\n",
      "Iter 3711, loss [-0.22115938, -0.25809765, 0.03693826]\n",
      "Iter 3712, loss [-0.20501053, -0.24161291, 0.036602385]\n",
      "Iter 3713, loss [-0.17971689, -0.2272, 0.047483113]\n",
      "Iter 3714, loss [-0.21005464, -0.2472177, 0.037163064]\n",
      "Iter 3715, loss [-0.23299122, -0.28993198, 0.056940757]\n",
      "Iter 3716, loss [-0.20792954, -0.24573591, 0.037806377]\n",
      "Iter 3717, loss [-0.20357099, -0.29867136, 0.095100366]\n",
      "Iter 3718, loss [-0.21720776, -0.25582045, 0.0386127]\n",
      "Iter 3719, loss [-0.22609258, -0.27158403, 0.045491453]\n",
      "Iter 3720, loss [-0.22682625, -0.26412162, 0.03729538]\n",
      "Iter 3721, loss [-0.21618073, -0.25267977, 0.03649904]\n",
      "Iter 3722, loss [-0.17976049, -0.2296502, 0.049889706]\n",
      "Iter 3723, loss [-0.2285819, -0.26584175, 0.037259847]\n",
      "Iter 3724, loss [-0.21589889, -0.25683022, 0.040931325]\n",
      "Iter 3725, loss [-0.21649547, -0.254568, 0.038072538]\n",
      "Iter 3726, loss [-0.21696606, -0.25559402, 0.03862796]\n",
      "Iter 3727, loss [-0.20734349, -0.24497662, 0.03763313]\n",
      "Iter 3728, loss [-0.21013182, -0.25110635, 0.04097453]\n",
      "Iter 3729, loss [-0.22085059, -0.28307876, 0.062228166]\n",
      "Iter 3730, loss [-0.21544388, -0.25726303, 0.041819155]\n",
      "Iter 3731, loss [-0.21561447, -0.25781733, 0.04220286]\n",
      "Iter 3732, loss [-0.20860477, -0.24838306, 0.039778292]\n",
      "Iter 3733, loss [-0.2271718, -0.2648169, 0.037645113]\n",
      "Iter 3734, loss [-0.2361744, -0.31536353, 0.079189114]\n",
      "Iter 3735, loss [-0.20565179, -0.24205035, 0.036398567]\n",
      "Iter 3736, loss [-0.20486382, -0.24158968, 0.03672586]\n",
      "Iter 3737, loss [-0.2242672, -0.26459724, 0.040330034]\n",
      "Iter 3738, loss [-0.21805584, -0.2568354, 0.038779564]\n",
      "Iter 3739, loss [-0.24539739, -0.2885798, 0.0431824]\n",
      "Iter 3740, loss [-0.20307398, -0.24291566, 0.03984168]\n",
      "Iter 3741, loss [-0.20775084, -0.24720019, 0.03944935]\n",
      "Iter 3742, loss [-0.22681451, -0.26645792, 0.039643407]\n",
      "Iter 3743, loss [-0.20540264, -0.26489988, 0.05949723]\n",
      "Iter 3744, loss [-0.2066938, -0.25009343, 0.04339963]\n",
      "Iter 3745, loss [-0.20630896, -0.24614905, 0.039840087]\n",
      "Iter 3746, loss [-0.20608443, -0.24503243, 0.038947992]\n",
      "Iter 3747, loss [-0.21436797, -0.25541103, 0.041043058]\n",
      "Iter 3748, loss [-0.22556907, -0.27071103, 0.045141965]\n",
      "Iter 3749, loss [-0.20574366, -0.24177247, 0.036028814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3750, loss [-0.30656347, -0.3158689, 0.00930544]\n",
      "Iter 3751, loss [-0.22474536, -0.2630024, 0.038257025]\n",
      "Iter 3752, loss [-0.19662353, -0.24118929, 0.044565745]\n",
      "Iter 3753, loss [-0.18026242, -0.22716025, 0.046897825]\n",
      "Iter 3754, loss [-0.20931956, -0.24469598, 0.035376407]\n",
      "Iter 3755, loss [-0.2235086, -0.28403166, 0.06052306]\n",
      "Iter 3756, loss [-0.21548846, -0.2545439, 0.039055444]\n",
      "Iter 3757, loss [-0.24411294, -0.30824298, 0.06413004]\n",
      "Iter 3758, loss [-0.21507154, -0.25489354, 0.039821994]\n",
      "Iter 3759, loss [-0.20710371, -0.245166, 0.03806229]\n",
      "Iter 3760, loss [-0.21785754, -0.2566175, 0.03875994]\n",
      "Iter 3761, loss [-0.24232644, -0.30456835, 0.06224191]\n",
      "Iter 3762, loss [-0.21024714, -0.25034687, 0.040099725]\n",
      "Iter 3763, loss [-0.23747544, -0.3165814, 0.07910596]\n",
      "Iter 3764, loss [-0.21644132, -0.2578175, 0.04137619]\n",
      "Iter 3765, loss [-0.20412655, -0.24794395, 0.0438174]\n",
      "Iter 3766, loss [-0.20599979, -0.2485681, 0.042568304]\n",
      "Iter 3767, loss [-0.21147954, -0.2540177, 0.04253816]\n",
      "Iter 3768, loss [-0.21450977, -0.2941162, 0.07960643]\n",
      "Iter 3769, loss [-0.22633898, -0.2685429, 0.0422039]\n",
      "Iter 3770, loss [-0.19800982, -0.23376258, 0.035752766]\n",
      "Iter 3771, loss [-0.30709794, -0.31736428, 0.010266329]\n",
      "Iter 3772, loss [-0.19832203, -0.23461229, 0.03629026]\n",
      "Iter 3773, loss [-0.2119861, -0.24822119, 0.0362351]\n",
      "Iter 3774, loss [-0.20563841, -0.24533996, 0.039701547]\n",
      "Iter 3775, loss [-0.22019316, -0.25729597, 0.0371028]\n",
      "Iter 3776, loss [-0.2143896, -0.25612372, 0.041734114]\n",
      "Iter 3777, loss [-0.19659606, -0.25878873, 0.06219268]\n",
      "Iter 3778, loss [-0.21933803, -0.26396132, 0.044623293]\n",
      "Iter 3779, loss [-0.2155374, -0.2555269, 0.03998951]\n",
      "Iter 3780, loss [-0.20453915, -0.26901272, 0.06447356]\n",
      "Iter 3781, loss [-0.20132495, -0.24264853, 0.04132357]\n",
      "Iter 3782, loss [-0.20511013, -0.24722436, 0.042114235]\n",
      "Iter 3783, loss [-0.2064766, -0.24582365, 0.03934706]\n",
      "Iter 3784, loss [-0.2235851, -0.30173016, 0.078145064]\n",
      "Iter 3785, loss [-0.22511229, -0.2676583, 0.042546004]\n",
      "Iter 3786, loss [-0.21817409, -0.26483193, 0.04665784]\n",
      "Iter 3787, loss [-0.21605977, -0.2569233, 0.040863514]\n",
      "Iter 3788, loss [-0.22523905, -0.26601356, 0.04077451]\n",
      "Iter 3789, loss [-0.18465665, -0.28663614, 0.101979494]\n",
      "Iter 3790, loss [-0.21970873, -0.25858256, 0.038873836]\n",
      "Iter 3791, loss [-0.21022701, -0.2508393, 0.040612273]\n",
      "Iter 3792, loss [-0.20855984, -0.24888268, 0.04032284]\n",
      "Iter 3793, loss [-0.20262598, -0.23661678, 0.033990804]\n",
      "Iter 3794, loss [-0.19657749, -0.2535167, 0.05693921]\n",
      "Iter 3795, loss [-0.21331728, -0.2517928, 0.038475506]\n",
      "Iter 3796, loss [-0.21628551, -0.25667742, 0.04039191]\n",
      "Iter 3797, loss [-0.21823886, -0.28292492, 0.06468607]\n",
      "Iter 3798, loss [-0.21451807, -0.25582334, 0.041305274]\n",
      "Iter 3799, loss [-0.20805669, -0.27479756, 0.06674087]\n",
      "Iter 3800, loss [-0.21888016, -0.2578511, 0.03897093]\n",
      "Iter 3801, loss [-0.2078179, -0.24804546, 0.040227562]\n",
      "Iter 3802, loss [-0.2456995, -0.28887975, 0.04318025]\n",
      "Iter 3803, loss [-0.20876063, -0.25523663, 0.046475988]\n",
      "Iter 3804, loss [-0.21959463, -0.26358995, 0.043995313]\n",
      "Iter 3805, loss [-0.21660808, -0.2574129, 0.04080483]\n",
      "Iter 3806, loss [-0.21119326, -0.24777454, 0.036581278]\n",
      "Iter 3807, loss [-0.21766514, -0.25653633, 0.03887119]\n",
      "Iter 3808, loss [-0.22428791, -0.26347256, 0.039184645]\n",
      "Iter 3809, loss [-0.22788233, -0.2667974, 0.038915068]\n",
      "Iter 3810, loss [-0.20961604, -0.25127172, 0.041655682]\n",
      "Iter 3811, loss [-0.22350705, -0.2695183, 0.046011236]\n",
      "Iter 3812, loss [-0.21385302, -0.25526243, 0.041409414]\n",
      "Iter 3813, loss [-0.20178737, -0.24715224, 0.04536487]\n",
      "Iter 3814, loss [-0.2179524, -0.25579068, 0.037838288]\n",
      "Iter 3815, loss [-0.21452945, -0.25436538, 0.03983593]\n",
      "Iter 3816, loss [-0.22726071, -0.26468688, 0.03742618]\n",
      "Iter 3817, loss [-0.2071919, -0.24784894, 0.04065704]\n",
      "Iter 3818, loss [-0.21673459, -0.25435787, 0.03762328]\n",
      "Iter 3819, loss [-0.20791882, -0.24555701, 0.037638184]\n",
      "Iter 3820, loss [-0.21803822, -0.2560776, 0.03803937]\n",
      "Iter 3821, loss [-0.20142053, -0.24163091, 0.04021038]\n",
      "Iter 3822, loss [-0.24019074, -0.27616775, 0.035977002]\n",
      "Iter 3823, loss [-0.20780961, -0.24541837, 0.037608758]\n",
      "Iter 3824, loss [-0.2477322, -0.29207873, 0.044346523]\n",
      "Iter 3825, loss [-0.20285806, -0.24253376, 0.039675698]\n",
      "Iter 3826, loss [-0.22576529, -0.26605785, 0.04029257]\n",
      "Iter 3827, loss [-0.22898334, -0.27163553, 0.042652182]\n",
      "Iter 3828, loss [-0.20727979, -0.24817538, 0.040895596]\n",
      "Iter 3829, loss [-0.22923854, -0.2717695, 0.042530954]\n",
      "Iter 3830, loss [-0.22723281, -0.2657725, 0.038539678]\n",
      "Iter 3831, loss [-0.21303633, -0.250042, 0.037005667]\n",
      "Iter 3832, loss [-0.21126309, -0.25110957, 0.039846487]\n",
      "Iter 3833, loss [-0.22704646, -0.26594508, 0.03889861]\n",
      "Iter 3834, loss [-0.20773676, -0.25054505, 0.042808294]\n",
      "Iter 3835, loss [-0.22394288, -0.2624988, 0.038555913]\n",
      "Iter 3836, loss [-0.21596824, -0.25523126, 0.039263025]\n",
      "Iter 3837, loss [-0.18166137, -0.23038498, 0.048723616]\n",
      "Iter 3838, loss [-0.21119526, -0.25893557, 0.047740303]\n",
      "Iter 3839, loss [-0.20781654, -0.24952129, 0.041704737]\n",
      "Iter 3840, loss [-0.22074288, -0.2592983, 0.03855542]\n",
      "Iter 3841, loss [-0.20417616, -0.24323541, 0.03905926]\n",
      "Iter 3842, loss [-0.2118366, -0.25117588, 0.039339267]\n",
      "Iter 3843, loss [-0.21228474, -0.2516174, 0.039332654]\n",
      "Iter 3844, loss [-0.23663464, -0.29135394, 0.0547193]\n",
      "Iter 3845, loss [-0.20582944, -0.25479048, 0.048961043]\n",
      "Iter 3846, loss [-0.21995966, -0.26022765, 0.040267993]\n",
      "Iter 3847, loss [-0.22495034, -0.27008367, 0.04513333]\n",
      "Iter 3848, loss [-0.22045368, -0.26158795, 0.04113427]\n",
      "Iter 3849, loss [-0.23804206, -0.29359043, 0.055548362]\n",
      "Iter 3850, loss [-0.21073198, -0.24875356, 0.03802158]\n",
      "Iter 3851, loss [-0.21640903, -0.2551357, 0.038726665]\n",
      "Iter 3852, loss [-0.2262501, -0.26219437, 0.035944264]\n",
      "Iter 3853, loss [-0.22061574, -0.26054674, 0.039931007]\n",
      "Iter 3854, loss [-0.22420934, -0.26153105, 0.03732171]\n",
      "Iter 3855, loss [-0.21596839, -0.25548524, 0.03951685]\n",
      "Iter 3856, loss [-0.30779788, -0.31739232, 0.00959443]\n",
      "Iter 3857, loss [-0.2143771, -0.2535546, 0.039177507]\n",
      "Iter 3858, loss [-0.21792714, -0.26330763, 0.045380484]\n",
      "Iter 3859, loss [-0.22236472, -0.268595, 0.046230294]\n",
      "Iter 3860, loss [-0.20405021, -0.2428755, 0.038825296]\n",
      "Iter 3861, loss [-0.2248973, -0.2646164, 0.03971911]\n",
      "Iter 3862, loss [-0.24564397, -0.30680996, 0.06116599]\n",
      "Iter 3863, loss [-0.21202067, -0.25553465, 0.043513983]\n",
      "Iter 3864, loss [-0.2059805, -0.24406478, 0.038084287]\n",
      "Iter 3865, loss [-0.20721167, -0.24920854, 0.041996866]\n",
      "Iter 3866, loss [-0.20349024, -0.24386753, 0.040377285]\n",
      "Iter 3867, loss [-0.21837653, -0.26282862, 0.044452082]\n",
      "Iter 3868, loss [-0.21317476, -0.24947904, 0.036304273]\n",
      "Iter 3869, loss [-0.2143316, -0.25488764, 0.040556043]\n",
      "Iter 3870, loss [-0.19804703, -0.24378386, 0.04573683]\n",
      "Iter 3871, loss [-0.21131895, -0.24969856, 0.038379606]\n",
      "Iter 3872, loss [-0.20856693, -0.24579987, 0.037232935]\n",
      "Iter 3873, loss [-0.21785244, -0.25493792, 0.037085474]\n",
      "Iter 3874, loss [-0.21682556, -0.2569556, 0.040130034]\n",
      "Iter 3875, loss [-0.21874367, -0.25819573, 0.03945206]\n",
      "Iter 3876, loss [-0.2473, -0.31135663, 0.06405664]\n",
      "Iter 3877, loss [-0.21151699, -0.24971455, 0.03819756]\n",
      "Iter 3878, loss [-0.22001296, -0.26108146, 0.0410685]\n",
      "Iter 3879, loss [-0.24902517, -0.3115252, 0.06250002]\n",
      "Iter 3880, loss [-0.21144082, -0.25062802, 0.03918721]\n",
      "Iter 3881, loss [-0.21923664, -0.26071927, 0.04148263]\n",
      "Iter 3882, loss [-0.2029222, -0.24296091, 0.04003872]\n",
      "Iter 3883, loss [-0.24124558, -0.27726564, 0.036020055]\n",
      "Iter 3884, loss [-0.22839376, -0.26664388, 0.03825012]\n",
      "Iter 3885, loss [-0.2298763, -0.27339244, 0.043516144]\n",
      "Iter 3886, loss [-0.21239425, -0.2567407, 0.044346433]\n",
      "Iter 3887, loss [-0.202759, -0.24201871, 0.039259713]\n",
      "Iter 3888, loss [-0.2078558, -0.24479732, 0.03694151]\n",
      "Iter 3889, loss [-0.20790006, -0.24998452, 0.042084455]\n",
      "Iter 3890, loss [-0.3079468, -0.31725556, 0.00930875]\n",
      "Iter 3891, loss [-0.2083771, -0.24457677, 0.03619967]\n",
      "Iter 3892, loss [-0.3087188, -0.31788984, 0.009171043]\n",
      "Iter 3893, loss [-0.21999177, -0.2594873, 0.039495524]\n",
      "Iter 3894, loss [-0.22232775, -0.26746815, 0.045140397]\n",
      "Iter 3895, loss [-0.21059659, -0.24812451, 0.037527923]\n",
      "Iter 3896, loss [-0.20607033, -0.24385189, 0.03778156]\n",
      "Iter 3897, loss [-0.22837439, -0.26670194, 0.038327552]\n",
      "Iter 3898, loss [-0.18119061, -0.23134726, 0.050156645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3899, loss [-0.22427925, -0.26493436, 0.040655106]\n",
      "Iter 3900, loss [-0.23137498, -0.26780164, 0.03642666]\n",
      "Iter 3901, loss [-0.2072956, -0.24794255, 0.040646948]\n",
      "Iter 3902, loss [-0.20311987, -0.24120367, 0.03808379]\n",
      "Iter 3903, loss [-0.21733692, -0.25405905, 0.03672212]\n",
      "Iter 3904, loss [-0.21874508, -0.25541028, 0.036665194]\n",
      "Iter 3905, loss [-0.21897972, -0.25544363, 0.036463913]\n",
      "Iter 3906, loss [-0.21024549, -0.2478211, 0.037575595]\n",
      "Iter 3907, loss [-0.21654314, -0.2571957, 0.04065257]\n",
      "Iter 3908, loss [-0.22556922, -0.2685573, 0.04298809]\n",
      "Iter 3909, loss [-0.24029046, -0.31331983, 0.07302937]\n",
      "Iter 3910, loss [-0.21224502, -0.25630218, 0.044057157]\n",
      "Iter 3911, loss [-0.21886927, -0.25665832, 0.037789047]\n",
      "Iter 3912, loss [-0.22041838, -0.25885627, 0.038437888]\n",
      "Iter 3913, loss [-0.21611822, -0.25531307, 0.03919486]\n",
      "Iter 3914, loss [-0.2202784, -0.2604744, 0.040196016]\n",
      "Iter 3915, loss [-0.22448176, -0.30337244, 0.078890674]\n",
      "Iter 3916, loss [-0.21534128, -0.25550127, 0.040159985]\n",
      "Iter 3917, loss [-0.21823369, -0.25637648, 0.03814278]\n",
      "Iter 3918, loss [-0.22029765, -0.26191267, 0.041615024]\n",
      "Iter 3919, loss [-0.2071119, -0.25006574, 0.042953856]\n",
      "Iter 3920, loss [-0.23313059, -0.2935103, 0.0603797]\n",
      "Iter 3921, loss [-0.21419969, -0.2535677, 0.03936801]\n",
      "Iter 3922, loss [-0.20974162, -0.25674745, 0.04700584]\n",
      "Iter 3923, loss [-0.21231747, -0.24831042, 0.03599295]\n",
      "Iter 3924, loss [-0.21209669, -0.25124404, 0.03914735]\n",
      "Iter 3925, loss [-0.2131907, -0.2704572, 0.057266504]\n",
      "Iter 3926, loss [-0.3077956, -0.3170552, 0.009259569]\n",
      "Iter 3927, loss [-0.21741268, -0.26280752, 0.04539483]\n",
      "Iter 3928, loss [-0.21610531, -0.2589789, 0.04287359]\n",
      "Iter 3929, loss [-0.24674997, -0.29280823, 0.04605826]\n",
      "Iter 3930, loss [-0.2100695, -0.25031534, 0.04024583]\n",
      "Iter 3931, loss [-0.20812958, -0.2457619, 0.037632316]\n",
      "Iter 3932, loss [-0.24237171, -0.30796432, 0.06559262]\n",
      "Iter 3933, loss [-0.21479523, -0.25471047, 0.039915234]\n",
      "Iter 3934, loss [-0.2158391, -0.25552362, 0.03968452]\n",
      "Iter 3935, loss [-0.21504837, -0.2526728, 0.03762442]\n",
      "Iter 3936, loss [-0.21955061, -0.25719738, 0.037646763]\n",
      "Iter 3937, loss [-0.21388379, -0.2588397, 0.044955917]\n",
      "Iter 3938, loss [-0.24675275, -0.28840584, 0.04165308]\n",
      "Iter 3939, loss [-0.21347724, -0.2560131, 0.042535853]\n",
      "Iter 3940, loss [-0.2173113, -0.25596407, 0.038652774]\n",
      "Iter 3941, loss [-0.21538344, -0.25598225, 0.040598817]\n",
      "Iter 3942, loss [-0.24002239, -0.31216094, 0.07213855]\n",
      "Iter 3943, loss [-0.22753164, -0.2888637, 0.06133204]\n",
      "Iter 3944, loss [-0.24057084, -0.27633423, 0.035763383]\n",
      "Iter 3945, loss [-0.19744012, -0.24487127, 0.047431163]\n",
      "Iter 3946, loss [-0.20661274, -0.24808627, 0.041473538]\n",
      "Iter 3947, loss [-0.20220207, -0.24065061, 0.038448542]\n",
      "Iter 3948, loss [-0.20393306, -0.24333288, 0.039399818]\n",
      "Iter 3949, loss [-0.22443783, -0.28831416, 0.06387632]\n",
      "Iter 3950, loss [-0.203287, -0.24253705, 0.039250042]\n",
      "Iter 3951, loss [-0.21688975, -0.2584264, 0.041536644]\n",
      "Iter 3952, loss [-0.22689442, -0.27261075, 0.04571633]\n",
      "Iter 3953, loss [-0.22197703, -0.268229, 0.046251982]\n",
      "Iter 3954, loss [-0.21897125, -0.25915194, 0.04018068]\n",
      "Iter 3955, loss [-0.2234494, -0.30312747, 0.07967807]\n",
      "Iter 3956, loss [-0.20984586, -0.25316, 0.043314144]\n",
      "Iter 3957, loss [-0.20760372, -0.249502, 0.04189828]\n",
      "Iter 3958, loss [-0.20454231, -0.24571894, 0.041176632]\n",
      "Iter 3959, loss [-0.24082659, -0.27704743, 0.036220834]\n",
      "Iter 3960, loss [-0.21698037, -0.25871015, 0.041729786]\n",
      "Iter 3961, loss [-0.2162176, -0.25600308, 0.039785475]\n",
      "Iter 3962, loss [-0.21532781, -0.25758082, 0.042253003]\n",
      "Iter 3963, loss [-0.20883615, -0.25124013, 0.04240398]\n",
      "Iter 3964, loss [-0.20823225, -0.24371111, 0.035478856]\n",
      "Iter 3965, loss [-0.21589434, -0.25453147, 0.038637124]\n",
      "Iter 3966, loss [-0.22842756, -0.2645603, 0.036132745]\n",
      "Iter 3967, loss [-0.21849525, -0.25806516, 0.03956992]\n",
      "Iter 3968, loss [-0.21589407, -0.2560446, 0.04015053]\n",
      "Iter 3969, loss [-0.21920358, -0.2604661, 0.04126252]\n",
      "Iter 3970, loss [-0.2238219, -0.2624343, 0.03861241]\n",
      "Iter 3971, loss [-0.20880102, -0.25149336, 0.04269235]\n",
      "Iter 3972, loss [-0.2127336, -0.25436822, 0.04163461]\n",
      "Iter 3973, loss [-0.22261392, -0.26788276, 0.045268845]\n",
      "Iter 3974, loss [-0.22260295, -0.26706824, 0.044465285]\n",
      "Iter 3975, loss [-0.22445604, -0.2613384, 0.03688238]\n",
      "Iter 3976, loss [-0.20881891, -0.24673975, 0.037920825]\n",
      "Iter 3977, loss [-0.22778404, -0.2655258, 0.037741754]\n",
      "Iter 3978, loss [-0.21659474, -0.25829756, 0.041702818]\n",
      "Iter 3979, loss [-0.2083145, -0.24740177, 0.03908728]\n",
      "Iter 3980, loss [-0.21820395, -0.25680566, 0.03860171]\n",
      "Iter 3981, loss [-0.2279593, -0.26764616, 0.039686866]\n",
      "Iter 3982, loss [-0.21064574, -0.25192714, 0.04128141]\n",
      "Iter 3983, loss [-0.22377104, -0.26339495, 0.039623916]\n",
      "Iter 3984, loss [-0.21482687, -0.25383753, 0.03901066]\n",
      "Iter 3985, loss [-0.1819827, -0.23069076, 0.048708063]\n",
      "Iter 3986, loss [-0.21745989, -0.25376305, 0.036303155]\n",
      "Iter 3987, loss [-0.2056278, -0.2412961, 0.035668306]\n",
      "Iter 3988, loss [-0.24115677, -0.27508095, 0.033924177]\n",
      "Iter 3989, loss [-0.22753564, -0.29002005, 0.062484406]\n",
      "Iter 3990, loss [-0.20448025, -0.24346793, 0.038987678]\n",
      "Iter 3991, loss [-0.23845902, -0.2951854, 0.056726363]\n",
      "Iter 3992, loss [-0.22719122, -0.26654965, 0.039358422]\n",
      "Iter 3993, loss [-0.2103205, -0.25404188, 0.04372137]\n",
      "Iter 3994, loss [-0.21842153, -0.26418453, 0.045762997]\n",
      "Iter 3995, loss [-0.21069197, -0.24937686, 0.038684893]\n",
      "Iter 3996, loss [-0.22867036, -0.26528287, 0.036612514]\n",
      "Iter 3997, loss [-0.20519955, -0.2448722, 0.03967264]\n",
      "Iter 3998, loss [-0.21048471, -0.2500368, 0.039552096]\n",
      "Iter 3999, loss [-0.21844584, -0.25544712, 0.037001282]\n",
      "Iter 4000, loss [-0.21910837, -0.26242453, 0.043316152]\n",
      "Iter 4001, loss [-0.22812873, -0.26662856, 0.03849984]\n",
      "Iter 4002, loss [-0.24081692, -0.31776738, 0.07695046]\n",
      "Iter 4003, loss [-0.21685773, -0.25883064, 0.041972898]\n",
      "Iter 4004, loss [-0.21974906, -0.26083153, 0.04108248]\n",
      "Iter 4005, loss [-0.20751554, -0.24937041, 0.04185487]\n",
      "Iter 4006, loss [-0.20018926, -0.23715897, 0.036969703]\n",
      "Iter 4007, loss [-0.20828818, -0.24531732, 0.037029147]\n",
      "Iter 4008, loss [-0.22528364, -0.2695682, 0.044284567]\n",
      "Iter 4009, loss [-0.21442786, -0.25546938, 0.04104152]\n",
      "Iter 4010, loss [-0.2112337, -0.25868878, 0.04745507]\n",
      "Iter 4011, loss [-0.22810699, -0.27270737, 0.044600382]\n",
      "Iter 4012, loss [-0.22129965, -0.2595682, 0.038268562]\n",
      "Iter 4013, loss [-0.24111928, -0.27553096, 0.034411684]\n",
      "Iter 4014, loss [-0.22909823, -0.26741067, 0.038312428]\n",
      "Iter 4015, loss [-0.20796758, -0.24874489, 0.04077732]\n",
      "Iter 4016, loss [-0.24163684, -0.2771976, 0.035560764]\n",
      "Iter 4017, loss [-0.21188319, -0.25667486, 0.04479166]\n",
      "Iter 4018, loss [-0.23009351, -0.26906422, 0.03897071]\n",
      "Iter 4019, loss [-0.21897334, -0.25836882, 0.03939549]\n",
      "Iter 4020, loss [-0.21947256, -0.25726563, 0.037793078]\n",
      "Iter 4021, loss [-0.2190564, -0.25773084, 0.038674437]\n",
      "Iter 4022, loss [-0.30744857, -0.31674945, 0.009300878]\n",
      "Iter 4023, loss [-0.21687834, -0.25792038, 0.041042045]\n",
      "Iter 4024, loss [-0.2161793, -0.25442234, 0.038243037]\n",
      "Iter 4025, loss [-0.20286798, -0.24463068, 0.04176269]\n",
      "Iter 4026, loss [-0.20989148, -0.2514327, 0.0415412]\n",
      "Iter 4027, loss [-0.24390027, -0.30684265, 0.062942386]\n",
      "Iter 4028, loss [-0.21657051, -0.2779868, 0.06141628]\n",
      "Iter 4029, loss [-0.22676373, -0.26498365, 0.03821993]\n",
      "Iter 4030, loss [-0.2190695, -0.2557992, 0.03672971]\n",
      "Iter 4031, loss [-0.22273682, -0.2684502, 0.04571338]\n",
      "Iter 4032, loss [-0.21211326, -0.25546244, 0.043349177]\n",
      "Iter 4033, loss [-0.21134436, -0.24986394, 0.03851957]\n",
      "Iter 4034, loss [-0.24441986, -0.30612344, 0.061703578]\n",
      "Iter 4035, loss [-0.22859994, -0.26622662, 0.037626684]\n",
      "Iter 4036, loss [-0.21810146, -0.26303545, 0.044933986]\n",
      "Iter 4037, loss [-0.20981455, -0.2517939, 0.04197934]\n",
      "Iter 4038, loss [-0.21692269, -0.25653365, 0.039610967]\n",
      "Iter 4039, loss [-0.2111434, -0.2509232, 0.039779782]\n",
      "Iter 4040, loss [-0.23094854, -0.26811272, 0.037164178]\n",
      "Iter 4041, loss [-0.21945576, -0.25959677, 0.040140998]\n",
      "Iter 4042, loss [-0.24132425, -0.2764704, 0.035146143]\n",
      "Iter 4043, loss [-0.22774385, -0.26619884, 0.038454995]\n",
      "Iter 4044, loss [-0.241419, -0.27678555, 0.03536655]\n",
      "Iter 4045, loss [-0.20431207, -0.24369256, 0.039380487]\n",
      "Iter 4046, loss [-0.23051223, -0.31463924, 0.08412701]\n",
      "Iter 4047, loss [-0.21555242, -0.2541473, 0.038594864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4048, loss [-0.21743752, -0.2593578, 0.04192029]\n",
      "Iter 4049, loss [-0.21541053, -0.25189057, 0.036480047]\n",
      "Iter 4050, loss [-0.22521375, -0.2689324, 0.043718647]\n",
      "Iter 4051, loss [-0.20276058, -0.2491175, 0.046356916]\n",
      "Iter 4052, loss [-0.21649115, -0.2540305, 0.037539344]\n",
      "Iter 4053, loss [-0.23052448, -0.26749912, 0.036974635]\n",
      "Iter 4054, loss [-0.20485246, -0.24741802, 0.04256556]\n",
      "Iter 4055, loss [-0.20805463, -0.25079083, 0.0427362]\n",
      "Iter 4056, loss [-0.21290039, -0.2573315, 0.0444311]\n",
      "Iter 4057, loss [-0.21492928, -0.27717918, 0.062249906]\n",
      "Iter 4058, loss [-0.2190294, -0.2609881, 0.04195869]\n",
      "Iter 4059, loss [-0.23396939, -0.2953719, 0.061402492]\n",
      "Iter 4060, loss [-0.2129219, -0.25130528, 0.038383376]\n",
      "Iter 4061, loss [-0.20707723, -0.24862042, 0.041543182]\n",
      "Iter 4062, loss [-0.20336339, -0.24597237, 0.042608973]\n",
      "Iter 4063, loss [-0.1936413, -0.24118108, 0.04753977]\n",
      "Iter 4064, loss [-0.20376453, -0.24579182, 0.042027302]\n",
      "Iter 4065, loss [-0.2092289, -0.2513014, 0.042072512]\n",
      "Iter 4066, loss [-0.20104085, -0.23997068, 0.038929835]\n",
      "Iter 4067, loss [-0.21496338, -0.2529284, 0.037965037]\n",
      "Iter 4068, loss [-0.21562472, -0.25104517, 0.035420448]\n",
      "Iter 4069, loss [-0.20314421, -0.24120165, 0.038057446]\n",
      "Iter 4070, loss [-0.22571208, -0.2624104, 0.036698323]\n",
      "Iter 4071, loss [-0.21917833, -0.2598991, 0.040720776]\n",
      "Iter 4072, loss [-0.21591742, -0.25377297, 0.037855547]\n",
      "Iter 4073, loss [-0.21062306, -0.2544365, 0.04381343]\n",
      "Iter 4074, loss [-0.21676642, -0.26092163, 0.044155203]\n",
      "Iter 4075, loss [-0.21852621, -0.30549818, 0.08697196]\n",
      "Iter 4076, loss [-0.2220383, -0.25978348, 0.037745185]\n",
      "Iter 4077, loss [-0.21599562, -0.25413242, 0.038136795]\n",
      "Iter 4078, loss [-0.21025357, -0.2499043, 0.03965074]\n",
      "Iter 4079, loss [-0.21939802, -0.2593554, 0.039957367]\n",
      "Iter 4080, loss [-0.20135675, -0.23697178, 0.035615023]\n",
      "Iter 4081, loss [-0.22314285, -0.2588615, 0.035718665]\n",
      "Iter 4082, loss [-0.21133846, -0.26909932, 0.057760872]\n",
      "Iter 4083, loss [-0.21439835, -0.2569938, 0.04259544]\n",
      "Iter 4084, loss [-0.2144836, -0.25524887, 0.04076527]\n",
      "Iter 4085, loss [-0.22623, -0.2657375, 0.039507505]\n",
      "Iter 4086, loss [-0.20746233, -0.25060916, 0.04314683]\n",
      "Iter 4087, loss [-0.22581662, -0.3090815, 0.08326487]\n",
      "Iter 4088, loss [-0.20591643, -0.2580735, 0.05215708]\n",
      "Iter 4089, loss [-0.23223686, -0.3056498, 0.073412925]\n",
      "Iter 4090, loss [-0.22302651, -0.26340613, 0.040379614]\n",
      "Iter 4091, loss [-0.2138019, -0.25561693, 0.041815028]\n",
      "Iter 4092, loss [-0.20568351, -0.24291503, 0.037231516]\n",
      "Iter 4093, loss [-0.20710306, -0.24490102, 0.037797954]\n",
      "Iter 4094, loss [-0.214301, -0.28526726, 0.07096626]\n",
      "Iter 4095, loss [-0.23230283, -0.31252658, 0.080223754]\n",
      "Iter 4096, loss [-0.21676874, -0.25808385, 0.041315105]\n",
      "Iter 4097, loss [-0.21271726, -0.251507, 0.038789745]\n",
      "Iter 4098, loss [-0.21706167, -0.25820333, 0.041141666]\n",
      "Iter 4099, loss [-0.20683065, -0.24506149, 0.038230844]\n",
      "Iter 4100, loss [-0.19951722, -0.24011329, 0.040596068]\n",
      "Iter 4101, loss [-0.20669821, -0.24332076, 0.036622554]\n",
      "Iter 4102, loss [-0.21531329, -0.25333858, 0.038025286]\n",
      "Iter 4103, loss [-0.17730771, -0.25356165, 0.076253936]\n",
      "Iter 4104, loss [-0.17909163, -0.22830802, 0.049216386]\n",
      "Iter 4105, loss [-0.20430923, -0.24145912, 0.037149884]\n",
      "Iter 4106, loss [-0.20804986, -0.2510576, 0.043007724]\n",
      "Iter 4107, loss [-0.2129474, -0.25788483, 0.044937428]\n",
      "Iter 4108, loss [-0.18831192, -0.28740826, 0.09909634]\n",
      "Iter 4109, loss [-0.20632894, -0.248076, 0.04174706]\n",
      "Iter 4110, loss [-0.2248412, -0.26900584, 0.044164635]\n",
      "Iter 4111, loss [-0.20904487, -0.25408077, 0.04503589]\n",
      "Iter 4112, loss [-0.22112954, -0.25878462, 0.037655078]\n",
      "Iter 4113, loss [-0.20546061, -0.24078023, 0.035319634]\n",
      "Iter 4114, loss [-0.2238122, -0.2597786, 0.035966404]\n",
      "Iter 4115, loss [-0.21762836, -0.25816554, 0.04053717]\n",
      "Iter 4116, loss [-0.21860892, -0.26551303, 0.046904117]\n",
      "Iter 4117, loss [-0.21638896, -0.25605363, 0.03966467]\n",
      "Iter 4118, loss [-0.21703097, -0.25574157, 0.0387106]\n",
      "Iter 4119, loss [-0.20899065, -0.24938247, 0.040391814]\n",
      "Iter 4120, loss [-0.24051006, -0.30531177, 0.06480171]\n",
      "Iter 4121, loss [-0.20566207, -0.25446066, 0.04879859]\n",
      "Iter 4122, loss [-0.23686674, -0.31065607, 0.07378933]\n",
      "Iter 4123, loss [-0.20424658, -0.24142073, 0.037174154]\n",
      "Iter 4124, loss [-0.21415606, -0.25258404, 0.03842797]\n",
      "Iter 4125, loss [-0.22310808, -0.263232, 0.04012391]\n",
      "Iter 4126, loss [-0.1981636, -0.23472169, 0.03655809]\n",
      "Iter 4127, loss [-0.24169084, -0.30713588, 0.06544503]\n",
      "Iter 4128, loss [-0.20880814, -0.24989834, 0.0410902]\n",
      "Iter 4129, loss [-0.21009937, -0.24675019, 0.036650814]\n",
      "Iter 4130, loss [-0.24342628, -0.30702385, 0.063597575]\n",
      "Iter 4131, loss [-0.22886032, -0.27231452, 0.043454196]\n",
      "Iter 4132, loss [-0.21483241, -0.27561358, 0.060781166]\n",
      "Iter 4133, loss [-0.2103804, -0.2541444, 0.043763995]\n",
      "Iter 4134, loss [-0.20654963, -0.24945514, 0.04290551]\n",
      "Iter 4135, loss [-0.22507876, -0.26693192, 0.041853152]\n",
      "Iter 4136, loss [-0.2015301, -0.24257055, 0.04104045]\n",
      "Iter 4137, loss [-0.22892256, -0.2728906, 0.043968037]\n",
      "Iter 4138, loss [-0.21756725, -0.2560083, 0.038441043]\n",
      "Iter 4139, loss [-0.22587416, -0.26615053, 0.04027638]\n",
      "Iter 4140, loss [-0.20080206, -0.29341438, 0.092612326]\n",
      "Iter 4141, loss [-0.22579834, -0.2615608, 0.035762466]\n",
      "Iter 4142, loss [-0.21472481, -0.2543162, 0.039591406]\n",
      "Iter 4143, loss [-0.21697551, -0.25489756, 0.037922055]\n",
      "Iter 4144, loss [-0.21048433, -0.2495939, 0.03910958]\n",
      "Iter 4145, loss [-0.23004304, -0.26785815, 0.03781511]\n",
      "Iter 4146, loss [-0.22814666, -0.2678493, 0.039702635]\n",
      "Iter 4147, loss [-0.22753844, -0.27238244, 0.04484401]\n",
      "Iter 4148, loss [-0.21674299, -0.25414303, 0.03740003]\n",
      "Iter 4149, loss [-0.21774134, -0.25629228, 0.038550943]\n",
      "Iter 4150, loss [-0.22307052, -0.26688913, 0.043818604]\n",
      "Iter 4151, loss [-0.23475426, -0.3090358, 0.074281536]\n",
      "Iter 4152, loss [-0.21465255, -0.2567919, 0.042139336]\n",
      "Iter 4153, loss [-0.21183391, -0.2575591, 0.045725178]\n",
      "Iter 4154, loss [-0.21435517, -0.25665215, 0.04229697]\n",
      "Iter 4155, loss [-0.22633217, -0.2711508, 0.04481862]\n",
      "Iter 4156, loss [-0.20448607, -0.2407686, 0.03628252]\n",
      "Iter 4157, loss [-0.20689556, -0.24715994, 0.040264383]\n",
      "Iter 4158, loss [-0.22262745, -0.30309147, 0.08046402]\n",
      "Iter 4159, loss [-0.20517331, -0.24220325, 0.037029937]\n",
      "Iter 4160, loss [-0.2127135, -0.2552071, 0.042493597]\n",
      "Iter 4161, loss [-0.24049708, -0.2763785, 0.035881422]\n",
      "Iter 4162, loss [-0.21964547, -0.26093063, 0.041285157]\n",
      "Iter 4163, loss [-0.21819544, -0.25510705, 0.036911607]\n",
      "Iter 4164, loss [-0.2451598, -0.29054782, 0.045388013]\n",
      "Iter 4165, loss [-0.20517689, -0.2533587, 0.048181795]\n",
      "Iter 4166, loss [-0.22600958, -0.26450709, 0.0384975]\n",
      "Iter 4167, loss [-0.21837378, -0.2533466, 0.034972813]\n",
      "Iter 4168, loss [-0.20769289, -0.24679668, 0.039103784]\n",
      "Iter 4169, loss [-0.22007222, -0.25844184, 0.038369607]\n",
      "Iter 4170, loss [-0.20818216, -0.24485917, 0.03667701]\n",
      "Iter 4171, loss [-0.21047574, -0.2589935, 0.04851776]\n",
      "Iter 4172, loss [-0.2411434, -0.27690673, 0.03576332]\n",
      "Iter 4173, loss [-0.22040167, -0.26012108, 0.03971941]\n",
      "Iter 4174, loss [-0.24749163, -0.29153907, 0.044047453]\n",
      "Iter 4175, loss [-0.21230285, -0.25279275, 0.040489893]\n",
      "Iter 4176, loss [-0.20925184, -0.2524214, 0.043169573]\n",
      "Iter 4177, loss [-0.21835828, -0.25524607, 0.036887802]\n",
      "Iter 4178, loss [-0.21884108, -0.25544196, 0.036600895]\n",
      "Iter 4179, loss [-0.20176664, -0.23981805, 0.03805142]\n",
      "Iter 4180, loss [-0.23143052, -0.26758897, 0.036158454]\n",
      "Iter 4181, loss [-0.24103355, -0.3128562, 0.07182264]\n",
      "Iter 4182, loss [-0.19973536, -0.23664291, 0.03690755]\n",
      "Iter 4183, loss [-0.21042754, -0.2605718, 0.050144266]\n",
      "Iter 4184, loss [-0.21112455, -0.2515539, 0.04042934]\n",
      "Iter 4185, loss [-0.21005279, -0.25402132, 0.04396853]\n",
      "Iter 4186, loss [-0.20330143, -0.24329187, 0.039990447]\n",
      "Iter 4187, loss [-0.2078812, -0.24954036, 0.041659158]\n",
      "Iter 4188, loss [-0.213446, -0.25540248, 0.041956466]\n",
      "Iter 4189, loss [-0.30643135, -0.3159781, 0.00954676]\n",
      "Iter 4190, loss [-0.21784346, -0.2541951, 0.036351636]\n",
      "Iter 4191, loss [-0.2174765, -0.25523788, 0.03776137]\n",
      "Iter 4192, loss [-0.21897459, -0.25402164, 0.03504706]\n",
      "Iter 4193, loss [-0.2201272, -0.2583965, 0.038269315]\n",
      "Iter 4194, loss [-0.20605929, -0.2966091, 0.09054981]\n",
      "Iter 4195, loss [-0.22988173, -0.3009313, 0.07104956]\n",
      "Iter 4196, loss [-0.24824473, -0.29280123, 0.044556506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4197, loss [-0.24581298, -0.31086054, 0.065047555]\n",
      "Iter 4198, loss [-0.22515056, -0.26348418, 0.038333632]\n",
      "Iter 4199, loss [-0.22512947, -0.2626446, 0.037515115]\n",
      "Iter 4200, loss [-0.219017, -0.2559453, 0.036928296]\n",
      "Iter 4201, loss [-0.2026515, -0.24489982, 0.042248316]\n",
      "Iter 4202, loss [-0.21191478, -0.25067177, 0.038756993]\n",
      "Iter 4203, loss [-0.20978162, -0.25787774, 0.04809612]\n",
      "Iter 4204, loss [-0.2057598, -0.25492436, 0.049164563]\n",
      "Iter 4205, loss [-0.21585989, -0.2580076, 0.04214769]\n",
      "Iter 4206, loss [-0.19999191, -0.23749939, 0.03750747]\n",
      "Iter 4207, loss [-0.2150478, -0.25536883, 0.04032102]\n",
      "Iter 4208, loss [-0.21635243, -0.25700516, 0.040652722]\n",
      "Iter 4209, loss [-0.22529185, -0.2638255, 0.038533665]\n",
      "Iter 4210, loss [-0.21425267, -0.25497368, 0.040721014]\n",
      "Iter 4211, loss [-0.21026967, -0.24767803, 0.037408352]\n",
      "Iter 4212, loss [-0.21123701, -0.25055456, 0.039317556]\n",
      "Iter 4213, loss [-0.21368533, -0.25578332, 0.042097986]\n",
      "Iter 4214, loss [-0.2265972, -0.2647281, 0.038130894]\n",
      "Iter 4215, loss [-0.22766906, -0.2732064, 0.04553735]\n",
      "Iter 4216, loss [-0.24123631, -0.27616802, 0.034931704]\n",
      "Iter 4217, loss [-0.21836956, -0.25488082, 0.036511257]\n",
      "Iter 4218, loss [-0.2080816, -0.26726347, 0.059181865]\n",
      "Iter 4219, loss [-0.22785917, -0.26548254, 0.037623372]\n",
      "Iter 4220, loss [-0.2197887, -0.25973326, 0.03994456]\n",
      "Iter 4221, loss [-0.20861536, -0.25070792, 0.04209256]\n",
      "Iter 4222, loss [-0.22137812, -0.26014745, 0.038769327]\n",
      "Iter 4223, loss [-0.20199615, -0.24702239, 0.045026235]\n",
      "Iter 4224, loss [-0.20507367, -0.24262662, 0.037552956]\n",
      "Iter 4225, loss [-0.21131246, -0.24982604, 0.038513586]\n",
      "Iter 4226, loss [-0.21351111, -0.25765508, 0.044143975]\n",
      "Iter 4227, loss [-0.240679, -0.3038339, 0.063154906]\n",
      "Iter 4228, loss [-0.21133158, -0.25053263, 0.03920106]\n",
      "Iter 4229, loss [-0.22475918, -0.2852636, 0.060504418]\n",
      "Iter 4230, loss [-0.22412282, -0.2652925, 0.04116968]\n",
      "Iter 4231, loss [-0.2242061, -0.26442435, 0.040218245]\n",
      "Iter 4232, loss [-0.21856064, -0.2568008, 0.038240165]\n",
      "Iter 4233, loss [-0.20475546, -0.2430722, 0.038316734]\n",
      "Iter 4234, loss [-0.21338892, -0.25481716, 0.041428234]\n",
      "Iter 4235, loss [-0.21019644, -0.250216, 0.040019568]\n",
      "Iter 4236, loss [-0.21876085, -0.257861, 0.039100137]\n",
      "Iter 4237, loss [-0.21935602, -0.25960174, 0.040245723]\n",
      "Iter 4238, loss [-0.23279634, -0.30843532, 0.07563897]\n",
      "Iter 4239, loss [-0.21004453, -0.24963863, 0.03959409]\n",
      "Iter 4240, loss [-0.22472185, -0.26556516, 0.040843304]\n",
      "Iter 4241, loss [-0.20144126, -0.24764776, 0.046206504]\n",
      "Iter 4242, loss [-0.2084659, -0.25783703, 0.049371116]\n",
      "Iter 4243, loss [-0.21792328, -0.2546501, 0.036726795]\n",
      "Iter 4244, loss [-0.2143728, -0.25937366, 0.045000862]\n",
      "Iter 4245, loss [-0.22064492, -0.2574762, 0.036831286]\n",
      "Iter 4246, loss [-0.21619439, -0.2542535, 0.03805911]\n",
      "Iter 4247, loss [-0.21195847, -0.2514046, 0.039446138]\n",
      "Iter 4248, loss [-0.21461591, -0.2528669, 0.03825099]\n",
      "Iter 4249, loss [-0.22671464, -0.26450917, 0.037794538]\n",
      "Iter 4250, loss [-0.2177951, -0.2572344, 0.039439283]\n",
      "Iter 4251, loss [-0.21582203, -0.2857021, 0.06988008]\n",
      "Iter 4252, loss [-0.3063149, -0.3163071, 0.009992208]\n",
      "Iter 4253, loss [-0.20410646, -0.25110623, 0.046999767]\n",
      "Iter 4254, loss [-0.2096403, -0.24510217, 0.035461865]\n",
      "Iter 4255, loss [-0.2264627, -0.26128593, 0.03482322]\n",
      "Iter 4256, loss [-0.21204615, -0.24985975, 0.037813604]\n",
      "Iter 4257, loss [-0.22711366, -0.2649329, 0.03781923]\n",
      "Iter 4258, loss [-0.22347936, -0.29258153, 0.06910216]\n",
      "Iter 4259, loss [-0.21591482, -0.25557518, 0.03966037]\n",
      "Iter 4260, loss [-0.20517385, -0.24892369, 0.04374984]\n",
      "Iter 4261, loss [-0.2181218, -0.2625603, 0.044438504]\n",
      "Iter 4262, loss [-0.20459059, -0.2446699, 0.04007931]\n",
      "Iter 4263, loss [-0.22816622, -0.2737038, 0.0455376]\n",
      "Iter 4264, loss [-0.21682805, -0.25760546, 0.04077741]\n",
      "Iter 4265, loss [-0.20382859, -0.2454072, 0.041578606]\n",
      "Iter 4266, loss [-0.22065523, -0.2588282, 0.038172957]\n",
      "Iter 4267, loss [-0.21884325, -0.2541712, 0.035327937]\n",
      "Iter 4268, loss [-0.21871093, -0.2537921, 0.03508117]\n",
      "Iter 4269, loss [-0.21299832, -0.24768357, 0.034685258]\n",
      "Iter 4270, loss [-0.20616, -0.24210463, 0.03594464]\n",
      "Iter 4271, loss [-0.2152734, -0.25582162, 0.04054822]\n",
      "Iter 4272, loss [-0.2373924, -0.31872272, 0.08133033]\n",
      "Iter 4273, loss [-0.3047195, -0.31479087, 0.010071379]\n",
      "Iter 4274, loss [-0.22272038, -0.26164755, 0.038927175]\n",
      "Iter 4275, loss [-0.21182883, -0.2731056, 0.061276764]\n",
      "Iter 4276, loss [-0.21954945, -0.26038864, 0.04083919]\n",
      "Iter 4277, loss [-0.21171346, -0.25410712, 0.042393647]\n",
      "Iter 4278, loss [-0.21896602, -0.26557654, 0.04661052]\n",
      "Iter 4279, loss [-0.20894322, -0.24648254, 0.037539322]\n",
      "Iter 4280, loss [-0.21011284, -0.24755023, 0.0374374]\n",
      "Iter 4281, loss [-0.20466378, -0.24251178, 0.037848003]\n",
      "Iter 4282, loss [-0.20881768, -0.24862504, 0.039807364]\n",
      "Iter 4283, loss [-0.21260205, -0.25126374, 0.03866168]\n",
      "Iter 4284, loss [-0.21727827, -0.25866085, 0.04138258]\n",
      "Iter 4285, loss [-0.21401948, -0.2524873, 0.038467824]\n",
      "Iter 4286, loss [-0.21284461, -0.25475898, 0.04191438]\n",
      "Iter 4287, loss [-0.22455496, -0.26332554, 0.03877058]\n",
      "Iter 4288, loss [-0.20445439, -0.24515833, 0.040703937]\n",
      "Iter 4289, loss [-0.22589098, -0.26306638, 0.037175402]\n",
      "Iter 4290, loss [-0.22875035, -0.26667047, 0.037920117]\n",
      "Iter 4291, loss [-0.20633432, -0.24419388, 0.03785956]\n",
      "Iter 4292, loss [-0.2053013, -0.25470868, 0.049407374]\n",
      "Iter 4293, loss [-0.22833173, -0.26680398, 0.038472246]\n",
      "Iter 4294, loss [-0.20289531, -0.24211459, 0.03921928]\n",
      "Iter 4295, loss [-0.21313348, -0.25413162, 0.040998124]\n",
      "Iter 4296, loss [-0.24741702, -0.290165, 0.042747986]\n",
      "Iter 4297, loss [-0.22124396, -0.25821063, 0.03696667]\n",
      "Iter 4298, loss [-0.22886863, -0.27173617, 0.042867538]\n",
      "Iter 4299, loss [-0.20465514, -0.24508809, 0.040432952]\n",
      "Iter 4300, loss [-0.22213164, -0.26856914, 0.046437502]\n",
      "Iter 4301, loss [-0.20341685, -0.24721938, 0.04380253]\n",
      "Iter 4302, loss [-0.23602778, -0.3157059, 0.07967812]\n",
      "Iter 4303, loss [-0.22570774, -0.28783432, 0.06212657]\n",
      "Iter 4304, loss [-0.22519551, -0.2656715, 0.04047598]\n",
      "Iter 4305, loss [-0.22513728, -0.26487207, 0.039734796]\n",
      "Iter 4306, loss [-0.18028976, -0.22789916, 0.0476094]\n",
      "Iter 4307, loss [-0.21948859, -0.2599404, 0.040451795]\n",
      "Iter 4308, loss [-0.1991591, -0.23478416, 0.03562505]\n",
      "Iter 4309, loss [-0.2220425, -0.26021788, 0.03817537]\n",
      "Iter 4310, loss [-0.21477169, -0.25537324, 0.040601548]\n",
      "Iter 4311, loss [-0.22887926, -0.27207443, 0.043195173]\n",
      "Iter 4312, loss [-0.20723088, -0.24581426, 0.038583383]\n",
      "Iter 4313, loss [-0.22779794, -0.26736277, 0.039564837]\n",
      "Iter 4314, loss [-0.21305753, -0.24990676, 0.03684923]\n",
      "Iter 4315, loss [-0.21816704, -0.28062746, 0.062460423]\n",
      "Iter 4316, loss [-0.22590074, -0.26273558, 0.03683483]\n",
      "Iter 4317, loss [-0.2130613, -0.2542669, 0.041205592]\n",
      "Iter 4318, loss [-0.20502123, -0.24149545, 0.036474213]\n",
      "Iter 4319, loss [-0.21187481, -0.25279498, 0.04092017]\n",
      "Iter 4320, loss [-0.22238438, -0.26066992, 0.038285535]\n",
      "Iter 4321, loss [-0.21570086, -0.25283638, 0.03713551]\n",
      "Iter 4322, loss [-0.21827811, -0.2616535, 0.043375395]\n",
      "Iter 4323, loss [-0.20467839, -0.24546552, 0.040787138]\n",
      "Iter 4324, loss [-0.22243197, -0.2608128, 0.038380817]\n",
      "Iter 4325, loss [-0.21200262, -0.25709027, 0.04508765]\n",
      "Iter 4326, loss [-0.22356297, -0.26251587, 0.038952906]\n",
      "Iter 4327, loss [-0.30526203, -0.31500083, 0.009738793]\n",
      "Iter 4328, loss [-0.22657934, -0.2736358, 0.04705646]\n",
      "Iter 4329, loss [-0.19692534, -0.28523785, 0.08831251]\n",
      "Iter 4330, loss [-0.21732914, -0.26285508, 0.04552593]\n",
      "Iter 4331, loss [-0.21812476, -0.25703213, 0.038907364]\n",
      "Iter 4332, loss [-0.22737068, -0.2649296, 0.037558913]\n",
      "Iter 4333, loss [-0.20954359, -0.25415707, 0.044613473]\n",
      "Iter 4334, loss [-0.21148317, -0.24861728, 0.03713411]\n",
      "Iter 4335, loss [-0.22959955, -0.29863444, 0.06903489]\n",
      "Iter 4336, loss [-0.30671945, -0.3162017, 0.009482227]\n",
      "Iter 4337, loss [-0.2101711, -0.24576803, 0.03559693]\n",
      "Iter 4338, loss [-0.21063569, -0.2459586, 0.035322897]\n",
      "Iter 4339, loss [-0.21062434, -0.24662916, 0.03600482]\n",
      "Iter 4340, loss [-0.21674806, -0.28427833, 0.067530274]\n",
      "Iter 4341, loss [-0.20000976, -0.23715693, 0.037147164]\n",
      "Iter 4342, loss [-0.21641302, -0.2629576, 0.04654458]\n",
      "Iter 4343, loss [-0.22344723, -0.26438823, 0.040940996]\n",
      "Iter 4344, loss [-0.23838615, -0.28988582, 0.051499665]\n",
      "Iter 4345, loss [-0.21040812, -0.2602765, 0.049868375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4346, loss [-0.21617784, -0.26068115, 0.044503313]\n",
      "Iter 4347, loss [-0.20918074, -0.25227162, 0.04309088]\n",
      "Iter 4348, loss [-0.22611919, -0.26593173, 0.039812528]\n",
      "Iter 4349, loss [-0.20750013, -0.24517496, 0.037674837]\n",
      "Iter 4350, loss [-0.21719028, -0.25327522, 0.036084935]\n",
      "Iter 4351, loss [-0.20202324, -0.23919335, 0.037170116]\n",
      "Iter 4352, loss [-0.23956366, -0.27290407, 0.03334041]\n",
      "Iter 4353, loss [-0.21538627, -0.253918, 0.038531728]\n",
      "Iter 4354, loss [-0.22811177, -0.27205023, 0.043938465]\n",
      "Iter 4355, loss [-0.22279237, -0.2691509, 0.04635854]\n",
      "Iter 4356, loss [-0.21798423, -0.25689977, 0.038915552]\n",
      "Iter 4357, loss [-0.22283536, -0.26229838, 0.039463013]\n",
      "Iter 4358, loss [-0.21837232, -0.2571118, 0.038739473]\n",
      "Iter 4359, loss [-0.22023556, -0.2611393, 0.040903755]\n",
      "Iter 4360, loss [-0.21526904, -0.25891584, 0.043646798]\n",
      "Iter 4361, loss [-0.22881384, -0.26506662, 0.036252778]\n",
      "Iter 4362, loss [-0.21834959, -0.2570015, 0.038651895]\n",
      "Iter 4363, loss [-0.21000886, -0.25705594, 0.04704708]\n",
      "Iter 4364, loss [-0.2187086, -0.25744325, 0.038734652]\n",
      "Iter 4365, loss [-0.19764262, -0.2439338, 0.046291173]\n",
      "Iter 4366, loss [-0.22102274, -0.26141354, 0.0403908]\n",
      "Iter 4367, loss [-0.2077683, -0.24507156, 0.037303254]\n",
      "Iter 4368, loss [-0.21821824, -0.25614858, 0.037930347]\n",
      "Iter 4369, loss [-0.21918999, -0.25734136, 0.03815137]\n",
      "Iter 4370, loss [-0.20524012, -0.24678354, 0.04154342]\n",
      "Iter 4371, loss [-0.21246931, -0.25081402, 0.038344707]\n",
      "Iter 4372, loss [-0.2120206, -0.25714034, 0.045119733]\n",
      "Iter 4373, loss [-0.22822991, -0.26571202, 0.03748212]\n",
      "Iter 4374, loss [-0.22788113, -0.28991184, 0.062030703]\n",
      "Iter 4375, loss [-0.21119754, -0.2492538, 0.038056254]\n",
      "Iter 4376, loss [-0.21980277, -0.2574196, 0.03761682]\n",
      "Iter 4377, loss [-0.18135443, -0.2282785, 0.046924062]\n",
      "Iter 4378, loss [-0.20553981, -0.24072497, 0.035185155]\n",
      "Iter 4379, loss [-0.24175173, -0.31457165, 0.07281991]\n",
      "Iter 4380, loss [-0.22841944, -0.26681772, 0.03839828]\n",
      "Iter 4381, loss [-0.21963827, -0.25741547, 0.037777197]\n",
      "Iter 4382, loss [-0.21590033, -0.27957863, 0.06367829]\n",
      "Iter 4383, loss [-0.21110077, -0.25225413, 0.041153356]\n",
      "Iter 4384, loss [-0.22072333, -0.26050952, 0.039786186]\n",
      "Iter 4385, loss [-0.2108806, -0.25063735, 0.039756753]\n",
      "Iter 4386, loss [-0.2202377, -0.25869524, 0.038457546]\n",
      "Iter 4387, loss [-0.22037937, -0.2582991, 0.03791974]\n",
      "Iter 4388, loss [-0.24775511, -0.2903089, 0.04255378]\n",
      "Iter 4389, loss [-0.2260544, -0.2652401, 0.0391857]\n",
      "Iter 4390, loss [-0.24120305, -0.27625492, 0.035051864]\n",
      "Iter 4391, loss [-0.21088205, -0.24952604, 0.038643986]\n",
      "Iter 4392, loss [-0.22415057, -0.2622758, 0.038125217]\n",
      "Iter 4393, loss [-0.2209998, -0.2615739, 0.040574096]\n",
      "Iter 4394, loss [-0.2276271, -0.2743854, 0.046758294]\n",
      "Iter 4395, loss [-0.21625967, -0.2601828, 0.04392312]\n",
      "Iter 4396, loss [-0.21898744, -0.25834948, 0.03936204]\n",
      "Iter 4397, loss [-0.21668944, -0.25917488, 0.042485453]\n",
      "Iter 4398, loss [-0.20740105, -0.24817538, 0.04077433]\n",
      "Iter 4399, loss [-0.21038032, -0.24906771, 0.038687397]\n",
      "Iter 4400, loss [-0.21896973, -0.26070756, 0.04173782]\n",
      "Iter 4401, loss [-0.22639927, -0.28602198, 0.0596227]\n",
      "Iter 4402, loss [-0.21625148, -0.2543823, 0.038130835]\n",
      "Iter 4403, loss [-0.20026179, -0.23640864, 0.036146846]\n",
      "Iter 4404, loss [-0.30762178, -0.31715977, 0.009538009]\n",
      "Iter 4405, loss [-0.2059834, -0.25529188, 0.04930847]\n",
      "Iter 4406, loss [-0.20995077, -0.2538664, 0.04391563]\n",
      "Iter 4407, loss [-0.2029987, -0.2442108, 0.0412121]\n",
      "Iter 4408, loss [-0.22091812, -0.26088974, 0.039971624]\n",
      "Iter 4409, loss [-0.22593282, -0.28686073, 0.06092791]\n",
      "Iter 4410, loss [-0.22998506, -0.27135506, 0.04137001]\n",
      "Iter 4411, loss [-0.24865736, -0.29073763, 0.04208027]\n",
      "Iter 4412, loss [-0.2284862, -0.26531312, 0.036826923]\n",
      "Iter 4413, loss [-0.20800355, -0.24342088, 0.035417326]\n",
      "Iter 4414, loss [-0.22282332, -0.2684822, 0.045658894]\n",
      "Iter 4415, loss [-0.2263901, -0.2669865, 0.040596392]\n",
      "Iter 4416, loss [-0.22547741, -0.26880452, 0.043327104]\n",
      "Iter 4417, loss [-0.20553264, -0.24773069, 0.042198054]\n",
      "Iter 4418, loss [-0.21474418, -0.25701168, 0.042267494]\n",
      "Iter 4419, loss [-0.22744262, -0.26644602, 0.03900341]\n",
      "Iter 4420, loss [-0.20847353, -0.24555075, 0.037077215]\n",
      "Iter 4421, loss [-0.20893478, -0.30002713, 0.09109234]\n",
      "Iter 4422, loss [-0.22160429, -0.26035842, 0.038754128]\n",
      "Iter 4423, loss [-0.22702037, -0.26414156, 0.037121188]\n",
      "Iter 4424, loss [-0.22561195, -0.3046037, 0.07899175]\n",
      "Iter 4425, loss [-0.22729851, -0.30777508, 0.08047657]\n",
      "Iter 4426, loss [-0.24883997, -0.29313338, 0.0442934]\n",
      "Iter 4427, loss [-0.24858528, -0.29339546, 0.044810176]\n",
      "Iter 4428, loss [-0.22829068, -0.2680267, 0.03973604]\n",
      "Iter 4429, loss [-0.21084863, -0.25939828, 0.048549645]\n",
      "Iter 4430, loss [-0.20414491, -0.24325171, 0.0391068]\n",
      "Iter 4431, loss [-0.21682402, -0.2558698, 0.039045773]\n",
      "Iter 4432, loss [-0.21669066, -0.25474474, 0.038054075]\n",
      "Iter 4433, loss [-0.20592733, -0.24134818, 0.03542085]\n",
      "Iter 4434, loss [-0.24134882, -0.2758235, 0.03447469]\n",
      "Iter 4435, loss [-0.2191027, -0.25681877, 0.037716076]\n",
      "Iter 4436, loss [-0.23007347, -0.2687011, 0.03862764]\n",
      "Iter 4437, loss [-0.24800543, -0.2931122, 0.045106754]\n",
      "Iter 4438, loss [-0.22496974, -0.2702197, 0.045249976]\n",
      "Iter 4439, loss [-0.22587739, -0.2651736, 0.039296225]\n",
      "Iter 4440, loss [-0.22503713, -0.26558775, 0.04055062]\n",
      "Iter 4441, loss [-0.22505797, -0.28450492, 0.059446946]\n",
      "Iter 4442, loss [-0.2316878, -0.2675409, 0.035853103]\n",
      "Iter 4443, loss [-0.18160819, -0.2291382, 0.047530007]\n",
      "Iter 4444, loss [-0.22274113, -0.26765493, 0.044913806]\n",
      "Iter 4445, loss [-0.21690437, -0.25747812, 0.040573753]\n",
      "Iter 4446, loss [-0.21842141, -0.25643486, 0.03801344]\n",
      "Iter 4447, loss [-0.21759692, -0.25611168, 0.038514756]\n",
      "Iter 4448, loss [-0.22579387, -0.26660883, 0.04081496]\n",
      "Iter 4449, loss [-0.21649353, -0.25780326, 0.04130973]\n",
      "Iter 4450, loss [-0.21187826, -0.25288737, 0.041009113]\n",
      "Iter 4451, loss [-0.2182492, -0.25805113, 0.039801933]\n",
      "Iter 4452, loss [-0.2271279, -0.28704792, 0.059920024]\n",
      "Iter 4453, loss [-0.21943274, -0.2592834, 0.039850652]\n",
      "Iter 4454, loss [-0.21877475, -0.2569181, 0.038143348]\n",
      "Iter 4455, loss [-0.22666344, -0.26304093, 0.03637749]\n",
      "Iter 4456, loss [-0.2163218, -0.25584632, 0.039524533]\n",
      "Iter 4457, loss [-0.22037503, -0.2607424, 0.04036736]\n",
      "Iter 4458, loss [-0.2076928, -0.24915847, 0.041465677]\n",
      "Iter 4459, loss [-0.21113044, -0.2588561, 0.047725648]\n",
      "Iter 4460, loss [-0.2084357, -0.24622051, 0.037784815]\n",
      "Iter 4461, loss [-0.22676626, -0.30693817, 0.080171905]\n",
      "Iter 4462, loss [-0.21855837, -0.25845045, 0.039892077]\n",
      "Iter 4463, loss [-0.23136157, -0.3007857, 0.069424115]\n",
      "Iter 4464, loss [-0.21824282, -0.26264825, 0.04440543]\n",
      "Iter 4465, loss [-0.20224224, -0.24202354, 0.039781302]\n",
      "Iter 4466, loss [-0.22755924, -0.30679077, 0.07923153]\n",
      "Iter 4467, loss [-0.21120968, -0.24920423, 0.037994552]\n",
      "Iter 4468, loss [-0.2114434, -0.24932688, 0.037883483]\n",
      "Iter 4469, loss [-0.20835006, -0.24562609, 0.037276022]\n",
      "Iter 4470, loss [-0.20816894, -0.2462841, 0.038115162]\n",
      "Iter 4471, loss [-0.2268238, -0.26523766, 0.038413845]\n",
      "Iter 4472, loss [-0.22380506, -0.2621403, 0.03833525]\n",
      "Iter 4473, loss [-0.20431003, -0.24319063, 0.0388806]\n",
      "Iter 4474, loss [-0.2124851, -0.25591904, 0.04343393]\n",
      "Iter 4475, loss [-0.23192477, -0.2681831, 0.036258347]\n",
      "Iter 4476, loss [-0.22046709, -0.25893962, 0.038472526]\n",
      "Iter 4477, loss [-0.21904834, -0.26196796, 0.04291962]\n",
      "Iter 4478, loss [-0.21266983, -0.25609308, 0.043423247]\n",
      "Iter 4479, loss [-0.21188536, -0.2505522, 0.03866685]\n",
      "Iter 4480, loss [-0.21151742, -0.25049275, 0.038975332]\n",
      "Iter 4481, loss [-0.20645037, -0.24402595, 0.03757557]\n",
      "Iter 4482, loss [-0.22065909, -0.2613354, 0.04067631]\n",
      "Iter 4483, loss [-0.18205035, -0.23041175, 0.048361406]\n",
      "Iter 4484, loss [-0.21710193, -0.2570383, 0.039936364]\n",
      "Iter 4485, loss [-0.22433451, -0.2621737, 0.037839197]\n",
      "Iter 4486, loss [-0.21272919, -0.2512209, 0.03849173]\n",
      "Iter 4487, loss [-0.2123028, -0.2529629, 0.040660083]\n",
      "Iter 4488, loss [-0.20750283, -0.2487861, 0.041283283]\n",
      "Iter 4489, loss [-0.21934533, -0.2590605, 0.03971518]\n",
      "Iter 4490, loss [-0.22062004, -0.2597232, 0.03910315]\n",
      "Iter 4491, loss [-0.23627287, -0.29320797, 0.056935098]\n",
      "Iter 4492, loss [-0.21957178, -0.25643045, 0.036858663]\n",
      "Iter 4493, loss [-0.2086676, -0.24539356, 0.03672596]\n",
      "Iter 4494, loss [-0.22578451, -0.26786304, 0.042078525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4495, loss [-0.20614344, -0.24253027, 0.036386825]\n",
      "Iter 4496, loss [-0.20856994, -0.24522002, 0.03665007]\n",
      "Iter 4497, loss [-0.2227659, -0.26849827, 0.045732386]\n",
      "Iter 4498, loss [-0.20766097, -0.2493009, 0.04163992]\n",
      "Iter 4499, loss [-0.20874158, -0.24546856, 0.036726985]\n",
      "Iter 4500, loss [-0.20974904, -0.30075288, 0.09100383]\n",
      "Iter 4501, loss [-0.30733818, -0.3167781, 0.009439912]\n",
      "Iter 4502, loss [-0.2245461, -0.2622127, 0.03766659]\n",
      "Iter 4503, loss [-0.2161591, -0.25636587, 0.040206764]\n",
      "Iter 4504, loss [-0.20563495, -0.2550155, 0.04938054]\n",
      "Iter 4505, loss [-0.21345198, -0.25545225, 0.042000264]\n",
      "Iter 4506, loss [-0.21798372, -0.26293144, 0.044947706]\n",
      "Iter 4507, loss [-0.21924178, -0.25558776, 0.036345974]\n",
      "Iter 4508, loss [-0.23178473, -0.26807633, 0.036291607]\n",
      "Iter 4509, loss [-0.2170749, -0.2570271, 0.03995218]\n",
      "Iter 4510, loss [-0.24149126, -0.27617615, 0.03468489]\n",
      "Iter 4511, loss [-0.30814117, -0.31748644, 0.00934527]\n",
      "Iter 4512, loss [-0.20750932, -0.24775706, 0.04024774]\n",
      "Iter 4513, loss [-0.22853301, -0.2670688, 0.038535785]\n",
      "Iter 4514, loss [-0.21920931, -0.25883487, 0.039625563]\n",
      "Iter 4515, loss [-0.21892197, -0.26181924, 0.042897265]\n",
      "Iter 4516, loss [-0.22145653, -0.26030734, 0.038850814]\n",
      "Iter 4517, loss [-0.19808948, -0.24512589, 0.047036402]\n",
      "Iter 4518, loss [-0.23746012, -0.29319066, 0.055730533]\n",
      "Iter 4519, loss [-0.20588401, -0.24278109, 0.03689707]\n",
      "Iter 4520, loss [-0.20817965, -0.24890849, 0.040728837]\n",
      "Iter 4521, loss [-0.22627315, -0.26595333, 0.039680183]\n",
      "Iter 4522, loss [-0.21907918, -0.26171672, 0.04263754]\n",
      "Iter 4523, loss [-0.22411911, -0.26078027, 0.03666116]\n",
      "Iter 4524, loss [-0.2111272, -0.2485759, 0.037448686]\n",
      "Iter 4525, loss [-0.22556548, -0.26323688, 0.0376714]\n",
      "Iter 4526, loss [-0.22481862, -0.2660221, 0.041203465]\n",
      "Iter 4527, loss [-0.21612631, -0.25701335, 0.040887043]\n",
      "Iter 4528, loss [-0.24735588, -0.29185683, 0.044500947]\n",
      "Iter 4529, loss [-0.20296496, -0.24325223, 0.040287275]\n",
      "Iter 4530, loss [-0.19982886, -0.2370971, 0.03726823]\n",
      "Iter 4531, loss [-0.21830902, -0.25507236, 0.036763348]\n",
      "Iter 4532, loss [-0.20214549, -0.24163692, 0.039491437]\n",
      "Iter 4533, loss [-0.21007052, -0.24962983, 0.039559305]\n",
      "Iter 4534, loss [-0.20345414, -0.2457963, 0.042342156]\n",
      "Iter 4535, loss [-0.22057025, -0.26083228, 0.040262025]\n",
      "Iter 4536, loss [-0.19852431, -0.24554701, 0.047022697]\n",
      "Iter 4537, loss [-0.22866416, -0.26628384, 0.037619673]\n",
      "Iter 4538, loss [-0.20936722, -0.24670991, 0.037342694]\n",
      "Iter 4539, loss [-0.21169503, -0.24917388, 0.03747885]\n",
      "Iter 4540, loss [-0.20037112, -0.23690909, 0.036537968]\n",
      "Iter 4541, loss [-0.21169251, -0.2521065, 0.040413976]\n",
      "Iter 4542, loss [-0.21618907, -0.25647748, 0.040288404]\n",
      "Iter 4543, loss [-0.21950606, -0.2632385, 0.043732427]\n",
      "Iter 4544, loss [-0.218588, -0.25602868, 0.037440687]\n",
      "Iter 4545, loss [-0.22642937, -0.26631233, 0.03988295]\n",
      "Iter 4546, loss [-0.20825097, -0.24440572, 0.036154743]\n",
      "Iter 4547, loss [-0.21963471, -0.25943017, 0.03979546]\n",
      "Iter 4548, loss [-0.20665836, -0.24282005, 0.0361617]\n",
      "Iter 4549, loss [-0.21183714, -0.2511302, 0.03929305]\n",
      "Iter 4550, loss [-0.23015547, -0.26803753, 0.037882052]\n",
      "Iter 4551, loss [-0.21253699, -0.25244823, 0.039911248]\n",
      "Iter 4552, loss [-0.21111585, -0.26023793, 0.04912208]\n",
      "Iter 4553, loss [-0.24910069, -0.2929997, 0.043899022]\n",
      "Iter 4554, loss [-0.21877736, -0.25570318, 0.03692583]\n",
      "Iter 4555, loss [-0.21405119, -0.25583097, 0.041779794]\n",
      "Iter 4556, loss [-0.2084523, -0.24918006, 0.040727768]\n",
      "Iter 4557, loss [-0.24086317, -0.31800827, 0.07714509]\n",
      "Iter 4558, loss [-0.21506688, -0.25409347, 0.039026596]\n",
      "Iter 4559, loss [-0.21936387, -0.25670165, 0.037337784]\n",
      "Iter 4560, loss [-0.22759072, -0.26685038, 0.039259657]\n",
      "Iter 4561, loss [-0.22082111, -0.26234555, 0.04152444]\n",
      "Iter 4562, loss [-0.22157466, -0.26027662, 0.038701948]\n",
      "Iter 4563, loss [-0.22406226, -0.26271474, 0.03865248]\n",
      "Iter 4564, loss [-0.20059541, -0.23725918, 0.03666377]\n",
      "Iter 4565, loss [-0.22163789, -0.26046157, 0.03882368]\n",
      "Iter 4566, loss [-0.24875152, -0.2924309, 0.043679386]\n",
      "Iter 4567, loss [-0.21935037, -0.30479434, 0.085443966]\n",
      "Iter 4568, loss [-0.20625861, -0.24298652, 0.0367279]\n",
      "Iter 4569, loss [-0.21205036, -0.2550427, 0.04299234]\n",
      "Iter 4570, loss [-0.22389902, -0.26354766, 0.039648633]\n",
      "Iter 4571, loss [-0.21954499, -0.2587252, 0.039180204]\n",
      "Iter 4572, loss [-0.22169279, -0.26429594, 0.04260315]\n",
      "Iter 4573, loss [-0.20172915, -0.24416523, 0.042436086]\n",
      "Iter 4574, loss [-0.21937038, -0.2598305, 0.04046012]\n",
      "Iter 4575, loss [-0.19206703, -0.26813486, 0.07606784]\n",
      "Iter 4576, loss [-0.2114059, -0.2546855, 0.043279596]\n",
      "Iter 4577, loss [-0.20316818, -0.298349, 0.09518081]\n",
      "Iter 4578, loss [-0.21323133, -0.25582144, 0.042590104]\n",
      "Iter 4579, loss [-0.20011222, -0.2421561, 0.042043872]\n",
      "Iter 4580, loss [-0.20098038, -0.24348648, 0.042506095]\n",
      "Iter 4581, loss [-0.20674628, -0.24747393, 0.040727653]\n",
      "Iter 4582, loss [-0.2103588, -0.29251423, 0.082155444]\n",
      "Iter 4583, loss [-0.21496272, -0.2538173, 0.03885457]\n",
      "Iter 4584, loss [-0.21178924, -0.2506085, 0.03881927]\n",
      "Iter 4585, loss [-0.21789712, -0.28326055, 0.06536344]\n",
      "Iter 4586, loss [-0.22374079, -0.26282617, 0.03908538]\n",
      "Iter 4587, loss [-0.21538585, -0.25447175, 0.039085887]\n",
      "Iter 4588, loss [-0.21012995, -0.25293228, 0.042802326]\n",
      "Iter 4589, loss [-0.22638912, -0.26691502, 0.0405259]\n",
      "Iter 4590, loss [-0.2174536, -0.25992122, 0.042467624]\n",
      "Iter 4591, loss [-0.20747669, -0.2502214, 0.042744707]\n",
      "Iter 4592, loss [-0.21571809, -0.2548593, 0.039141215]\n",
      "Iter 4593, loss [-0.21819948, -0.25733998, 0.03914051]\n",
      "Iter 4594, loss [-0.20612706, -0.2466209, 0.040493827]\n",
      "Iter 4595, loss [-0.2255291, -0.29426685, 0.06873774]\n",
      "Iter 4596, loss [-0.23918195, -0.30043957, 0.061257616]\n",
      "Iter 4597, loss [-0.21890604, -0.25639254, 0.0374865]\n",
      "Iter 4598, loss [-0.22620238, -0.269841, 0.0436386]\n",
      "Iter 4599, loss [-0.22588657, -0.26307923, 0.037192654]\n",
      "Iter 4600, loss [-0.2333255, -0.29168707, 0.058361575]\n",
      "Iter 4601, loss [-0.2172547, -0.25845715, 0.041202456]\n",
      "Iter 4602, loss [-0.22268718, -0.26158935, 0.038902167]\n",
      "Iter 4603, loss [-0.21979761, -0.26058543, 0.04078781]\n",
      "Iter 4604, loss [-0.21203503, -0.24779767, 0.03576263]\n",
      "Iter 4605, loss [-0.21301642, -0.25470787, 0.041691452]\n",
      "Iter 4606, loss [-0.22292185, -0.25990862, 0.036986765]\n",
      "Iter 4607, loss [-0.22505742, -0.26430073, 0.039243307]\n",
      "Iter 4608, loss [-0.24445263, -0.30745828, 0.06300566]\n",
      "Iter 4609, loss [-0.21795937, -0.256267, 0.038307633]\n",
      "Iter 4610, loss [-0.20323357, -0.24300863, 0.03977505]\n",
      "Iter 4611, loss [-0.20711195, -0.2500404, 0.04292845]\n",
      "Iter 4612, loss [-0.21804538, -0.25892442, 0.040879034]\n",
      "Iter 4613, loss [-0.21735483, -0.26399764, 0.046642803]\n",
      "Iter 4614, loss [-0.22486353, -0.2859026, 0.06103906]\n",
      "Iter 4615, loss [-0.22040956, -0.2605107, 0.040101152]\n",
      "Iter 4616, loss [-0.20600297, -0.24217007, 0.036167096]\n",
      "Iter 4617, loss [-0.20608267, -0.24221186, 0.0361292]\n",
      "Iter 4618, loss [-0.20936579, -0.24700561, 0.03763982]\n",
      "Iter 4619, loss [-0.22008683, -0.25975984, 0.03967301]\n",
      "Iter 4620, loss [-0.21938056, -0.2604114, 0.041030847]\n",
      "Iter 4621, loss [-0.21932715, -0.2577485, 0.038421363]\n",
      "Iter 4622, loss [-0.22966956, -0.2692768, 0.039607245]\n",
      "Iter 4623, loss [-0.22803114, -0.29106972, 0.06303857]\n",
      "Iter 4624, loss [-0.22112092, -0.26411757, 0.04299664]\n",
      "Iter 4625, loss [-0.21426848, -0.26106676, 0.04679828]\n",
      "Iter 4626, loss [-0.2053663, -0.24712408, 0.041757774]\n",
      "Iter 4627, loss [-0.24842252, -0.2910732, 0.04265068]\n",
      "Iter 4628, loss [-0.21303077, -0.24924132, 0.03621055]\n",
      "Iter 4629, loss [-0.21570382, -0.27717704, 0.061473213]\n",
      "Iter 4630, loss [-0.2301301, -0.2676463, 0.037516203]\n",
      "Iter 4631, loss [-0.2131646, -0.25317273, 0.040008124]\n",
      "Iter 4632, loss [-0.20566933, -0.24648818, 0.040818855]\n",
      "Iter 4633, loss [-0.22062463, -0.26013404, 0.039509423]\n",
      "Iter 4634, loss [-0.22887155, -0.26692018, 0.038048618]\n",
      "Iter 4635, loss [-0.21736106, -0.2631491, 0.045788057]\n",
      "Iter 4636, loss [-0.21120436, -0.25162584, 0.040421475]\n",
      "Iter 4637, loss [-0.21175686, -0.25165987, 0.039903022]\n",
      "Iter 4638, loss [-0.22886267, -0.26575598, 0.0368933]\n",
      "Iter 4639, loss [-0.21483022, -0.25341824, 0.038588017]\n",
      "Iter 4640, loss [-0.22420855, -0.26118216, 0.036973607]\n",
      "Iter 4641, loss [-0.22163764, -0.2615971, 0.039959457]\n",
      "Iter 4642, loss [-0.20776778, -0.24912614, 0.041358344]\n",
      "Iter 4643, loss [-0.21086203, -0.26059303, 0.049730998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4644, loss [-0.20641679, -0.24500054, 0.038583748]\n",
      "Iter 4645, loss [-0.21899956, -0.25910512, 0.040105544]\n",
      "Iter 4646, loss [-0.22524202, -0.27006075, 0.04481872]\n",
      "Iter 4647, loss [-0.22110209, -0.26025927, 0.039157182]\n",
      "Iter 4648, loss [-0.22098833, -0.26029426, 0.039305925]\n",
      "Iter 4649, loss [-0.2220982, -0.25789472, 0.03579652]\n",
      "Iter 4650, loss [-0.2210386, -0.26072276, 0.03968416]\n",
      "Iter 4651, loss [-0.21254326, -0.25581643, 0.043273166]\n",
      "Iter 4652, loss [-0.2115685, -0.27117267, 0.05960416]\n",
      "Iter 4653, loss [-0.22434077, -0.26284695, 0.03850618]\n",
      "Iter 4654, loss [-0.20609869, -0.25573465, 0.04963596]\n",
      "Iter 4655, loss [-0.21385625, -0.2553405, 0.04148423]\n",
      "Iter 4656, loss [-0.2082631, -0.24588487, 0.037621774]\n",
      "Iter 4657, loss [-0.21474288, -0.29944426, 0.084701374]\n",
      "Iter 4658, loss [-0.21824804, -0.25756943, 0.03932139]\n",
      "Iter 4659, loss [-0.21470912, -0.25155297, 0.03684385]\n",
      "Iter 4660, loss [-0.2189693, -0.25735062, 0.038381323]\n",
      "Iter 4661, loss [-0.19849192, -0.23382533, 0.03533341]\n",
      "Iter 4662, loss [-0.2040663, -0.2403198, 0.036253504]\n",
      "Iter 4663, loss [-0.21039142, -0.25211656, 0.04172514]\n",
      "Iter 4664, loss [-0.20937163, -0.28499144, 0.07561981]\n",
      "Iter 4665, loss [-0.20941398, -0.2495039, 0.04008992]\n",
      "Iter 4666, loss [-0.21951902, -0.26233572, 0.04281669]\n",
      "Iter 4667, loss [-0.21769288, -0.25740454, 0.039711647]\n",
      "Iter 4668, loss [-0.2165133, -0.26167345, 0.04516014]\n",
      "Iter 4669, loss [-0.22336754, -0.26421627, 0.04084873]\n",
      "Iter 4670, loss [-0.20659095, -0.2513055, 0.04471454]\n",
      "Iter 4671, loss [-0.22168508, -0.25969127, 0.03800619]\n",
      "Iter 4672, loss [-0.22452146, -0.26261914, 0.038097676]\n",
      "Iter 4673, loss [-0.21539234, -0.25458676, 0.039194416]\n",
      "Iter 4674, loss [-0.2094158, -0.25632924, 0.046913445]\n",
      "Iter 4675, loss [-0.22161064, -0.25826478, 0.036654152]\n",
      "Iter 4676, loss [-0.20355621, -0.2433896, 0.0398334]\n",
      "Iter 4677, loss [-0.22442874, -0.26264974, 0.038221]\n",
      "Iter 4678, loss [-0.22917733, -0.30666438, 0.077487044]\n",
      "Iter 4679, loss [-0.20848702, -0.29472187, 0.08623485]\n",
      "Iter 4680, loss [-0.2095333, -0.24597564, 0.03644234]\n",
      "Iter 4681, loss [-0.22528127, -0.26666722, 0.041385945]\n",
      "Iter 4682, loss [-0.210153, -0.24694158, 0.03678858]\n",
      "Iter 4683, loss [-0.2140665, -0.25372615, 0.039659657]\n",
      "Iter 4684, loss [-0.20658655, -0.2500547, 0.043468133]\n",
      "Iter 4685, loss [-0.20650925, -0.24625449, 0.039745245]\n",
      "Iter 4686, loss [-0.21639174, -0.25803936, 0.04164762]\n",
      "Iter 4687, loss [-0.20450044, -0.2430065, 0.038506065]\n",
      "Iter 4688, loss [-0.22054017, -0.2680308, 0.04749062]\n",
      "Iter 4689, loss [-0.23083767, -0.29413632, 0.063298635]\n",
      "Iter 4690, loss [-0.22317809, -0.2612712, 0.03809312]\n",
      "Iter 4691, loss [-0.21751767, -0.25698456, 0.039466895]\n",
      "Iter 4692, loss [-0.19997829, -0.2400563, 0.040078014]\n",
      "Iter 4693, loss [-0.2075593, -0.24833556, 0.040776253]\n",
      "Iter 4694, loss [-0.22407785, -0.2620971, 0.03801924]\n",
      "Iter 4695, loss [-0.2246486, -0.2662916, 0.041642986]\n",
      "Iter 4696, loss [-0.20080599, -0.24113207, 0.04032608]\n",
      "Iter 4697, loss [-0.2170386, -0.25872502, 0.041686416]\n",
      "Iter 4698, loss [-0.20755923, -0.2451821, 0.03762287]\n",
      "Iter 4699, loss [-0.21001518, -0.24856474, 0.038549554]\n",
      "Iter 4700, loss [-0.22883613, -0.27222487, 0.043388736]\n",
      "Iter 4701, loss [-0.2159096, -0.25746194, 0.041552335]\n",
      "Iter 4702, loss [-0.21237163, -0.24900165, 0.036630016]\n",
      "Iter 4703, loss [-0.21776837, -0.2561608, 0.038392417]\n",
      "Iter 4704, loss [-0.20368078, -0.2433581, 0.03967733]\n",
      "Iter 4705, loss [-0.2140014, -0.25551918, 0.041517783]\n",
      "Iter 4706, loss [-0.20644787, -0.24374406, 0.0372962]\n",
      "Iter 4707, loss [-0.20196593, -0.24359106, 0.041625127]\n",
      "Iter 4708, loss [-0.22905101, -0.26791, 0.038858995]\n",
      "Iter 4709, loss [-0.22454298, -0.26285306, 0.03831008]\n",
      "Iter 4710, loss [-0.20827714, -0.2453468, 0.037069663]\n",
      "Iter 4711, loss [-0.21732211, -0.26164538, 0.044323266]\n",
      "Iter 4712, loss [-0.22069153, -0.26030195, 0.039610416]\n",
      "Iter 4713, loss [-0.21595831, -0.2547155, 0.03875719]\n",
      "Iter 4714, loss [-0.22059602, -0.26067135, 0.04007533]\n",
      "Iter 4715, loss [-0.18123563, -0.23149489, 0.050259262]\n",
      "Iter 4716, loss [-0.21654509, -0.2591632, 0.042618107]\n",
      "Iter 4717, loss [-0.21586356, -0.25552115, 0.039657585]\n",
      "Iter 4718, loss [-0.22205105, -0.2586484, 0.036597334]\n",
      "Iter 4719, loss [-0.21059547, -0.2484391, 0.037843626]\n",
      "Iter 4720, loss [-0.2111088, -0.25015163, 0.03904283]\n",
      "Iter 4721, loss [-0.24613439, -0.31055886, 0.06442447]\n",
      "Iter 4722, loss [-0.2040212, -0.2438946, 0.039873406]\n",
      "Iter 4723, loss [-0.20653497, -0.24440368, 0.03786871]\n",
      "Iter 4724, loss [-0.21438658, -0.27682993, 0.06244334]\n",
      "Iter 4725, loss [-0.24028233, -0.31331038, 0.07302806]\n",
      "Iter 4726, loss [-0.2207672, -0.2588102, 0.038042985]\n",
      "Iter 4727, loss [-0.22509974, -0.26226288, 0.037163135]\n",
      "Iter 4728, loss [-0.21083464, -0.24781267, 0.036978036]\n",
      "Iter 4729, loss [-0.2116011, -0.25002587, 0.038424775]\n",
      "Iter 4730, loss [-0.20383427, -0.24258521, 0.038750943]\n",
      "Iter 4731, loss [-0.22058563, -0.26123887, 0.040653244]\n",
      "Iter 4732, loss [-0.20697588, -0.24836673, 0.04139086]\n",
      "Iter 4733, loss [-0.20977734, -0.24993442, 0.040157083]\n",
      "Iter 4734, loss [-0.2161661, -0.25567102, 0.039504927]\n",
      "Iter 4735, loss [-0.22632022, -0.26647612, 0.0401559]\n",
      "Iter 4736, loss [-0.21898383, -0.25914246, 0.040158637]\n",
      "Iter 4737, loss [-0.24538642, -0.29015276, 0.044766344]\n",
      "Iter 4738, loss [-0.21341357, -0.24907963, 0.03566607]\n",
      "Iter 4739, loss [-0.22095153, -0.25960952, 0.038657993]\n",
      "Iter 4740, loss [-0.18185955, -0.23060113, 0.04874158]\n",
      "Iter 4741, loss [-0.21837619, -0.2572574, 0.03888122]\n",
      "Iter 4742, loss [-0.22661571, -0.26504245, 0.03842674]\n",
      "Iter 4743, loss [-0.22837481, -0.26622918, 0.037854373]\n",
      "Iter 4744, loss [-0.22534849, -0.26915422, 0.04380573]\n",
      "Iter 4745, loss [-0.220888, -0.260972, 0.040083993]\n",
      "Iter 4746, loss [-0.22177884, -0.25841814, 0.036639296]\n",
      "Iter 4747, loss [-0.30768993, -0.31711194, 0.009421997]\n",
      "Iter 4748, loss [-0.23168474, -0.26775444, 0.03606969]\n",
      "Iter 4749, loss [-0.22797613, -0.28904685, 0.06107072]\n",
      "Iter 4750, loss [-0.20293128, -0.24184766, 0.038916383]\n",
      "Iter 4751, loss [-0.20918272, -0.24653782, 0.037355095]\n",
      "Iter 4752, loss [-0.20980553, -0.2529764, 0.04317085]\n",
      "Iter 4753, loss [-0.2309181, -0.30061013, 0.06969203]\n",
      "Iter 4754, loss [-0.21858071, -0.2641513, 0.045570593]\n",
      "Iter 4755, loss [-0.21691158, -0.2575634, 0.04065183]\n",
      "Iter 4756, loss [-0.21774894, -0.25607997, 0.03833103]\n",
      "Iter 4757, loss [-0.21109086, -0.2496528, 0.038561936]\n",
      "Iter 4758, loss [-0.22690293, -0.26379213, 0.036889188]\n",
      "Iter 4759, loss [-0.21792342, -0.25609425, 0.03817083]\n",
      "Iter 4760, loss [-0.21894515, -0.2578925, 0.03894734]\n",
      "Iter 4761, loss [-0.23185395, -0.26859537, 0.03674142]\n",
      "Iter 4762, loss [-0.21403757, -0.2560145, 0.041976925]\n",
      "Iter 4763, loss [-0.21976255, -0.2601492, 0.04038666]\n",
      "Iter 4764, loss [-0.213496, -0.25017926, 0.036683258]\n",
      "Iter 4765, loss [-0.21989784, -0.260059, 0.040161163]\n",
      "Iter 4766, loss [-0.22152728, -0.26187387, 0.0403466]\n",
      "Iter 4767, loss [-0.22863889, -0.2659716, 0.03733272]\n",
      "Iter 4768, loss [-0.21091153, -0.24915665, 0.038245127]\n",
      "Iter 4769, loss [-0.249143, -0.2922781, 0.043135107]\n",
      "Iter 4770, loss [-0.21968901, -0.25665054, 0.036961533]\n",
      "Iter 4771, loss [-0.3071779, -0.3167386, 0.009560702]\n",
      "Iter 4772, loss [-0.22680822, -0.26665354, 0.039845318]\n",
      "Iter 4773, loss [-0.21295562, -0.25330442, 0.0403488]\n",
      "Iter 4774, loss [-0.21318345, -0.25333494, 0.04015149]\n",
      "Iter 4775, loss [-0.21812035, -0.25496495, 0.036844593]\n",
      "Iter 4776, loss [-0.21153094, -0.25883165, 0.047300708]\n",
      "Iter 4777, loss [-0.22144035, -0.26146325, 0.04002291]\n",
      "Iter 4778, loss [-0.21285857, -0.2532716, 0.040413037]\n",
      "Iter 4779, loss [-0.22527522, -0.26659074, 0.041315526]\n",
      "Iter 4780, loss [-0.2112579, -0.25025555, 0.038997646]\n",
      "Iter 4781, loss [-0.21746844, -0.25548035, 0.038011905]\n",
      "Iter 4782, loss [-0.21580468, -0.25575534, 0.03995065]\n",
      "Iter 4783, loss [-0.22692725, -0.26657918, 0.039651927]\n",
      "Iter 4784, loss [-0.22700185, -0.26360294, 0.036601093]\n",
      "Iter 4785, loss [-0.21869066, -0.2583482, 0.03965754]\n",
      "Iter 4786, loss [-0.22169676, -0.2622246, 0.04052785]\n",
      "Iter 4787, loss [-0.22602725, -0.26818994, 0.042162687]\n",
      "Iter 4788, loss [-0.24271466, -0.31506056, 0.0723459]\n",
      "Iter 4789, loss [-0.2188656, -0.2595918, 0.040726192]\n",
      "Iter 4790, loss [-0.20891558, -0.24572332, 0.036807746]\n",
      "Iter 4791, loss [-0.2094652, -0.24726619, 0.037800983]\n",
      "Iter 4792, loss [-0.20462301, -0.24427839, 0.03965537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4793, loss [-0.22861826, -0.28985515, 0.06123689]\n",
      "Iter 4794, loss [-0.21363294, -0.2535925, 0.039959557]\n",
      "Iter 4795, loss [-0.24398658, -0.31625897, 0.07227239]\n",
      "Iter 4796, loss [-0.21471551, -0.2563758, 0.04166028]\n",
      "Iter 4797, loss [-0.21341944, -0.2500962, 0.036676772]\n",
      "Iter 4798, loss [-0.20395723, -0.24327965, 0.039322414]\n",
      "Iter 4799, loss [-0.23124683, -0.3014352, 0.07018837]\n",
      "Iter 4800, loss [-0.24907693, -0.29232362, 0.04324668]\n",
      "Iter 4801, loss [-0.24347408, -0.3146209, 0.07114683]\n",
      "Iter 4802, loss [-0.22111556, -0.25989214, 0.038776573]\n",
      "Iter 4803, loss [-0.19872707, -0.24549931, 0.04677225]\n",
      "Iter 4804, loss [-0.22823265, -0.27343404, 0.0452014]\n",
      "Iter 4805, loss [-0.23648264, -0.2913378, 0.054855153]\n",
      "Iter 4806, loss [-0.22817427, -0.27305594, 0.04488167]\n",
      "Iter 4807, loss [-0.22061843, -0.25969204, 0.039073624]\n",
      "Iter 4808, loss [-0.21685377, -0.2570865, 0.040232725]\n",
      "Iter 4809, loss [-0.2229776, -0.2692088, 0.04623119]\n",
      "Iter 4810, loss [-0.2113952, -0.2497121, 0.038316898]\n",
      "Iter 4811, loss [-0.30625305, -0.31584868, 0.0095956195]\n",
      "Iter 4812, loss [-0.30757987, -0.316998, 0.009418129]\n",
      "Iter 4813, loss [-0.22877954, -0.26546338, 0.03668384]\n",
      "Iter 4814, loss [-0.21657528, -0.27615577, 0.059580486]\n",
      "Iter 4815, loss [-0.22351938, -0.26291165, 0.039392263]\n",
      "Iter 4816, loss [-0.21556208, -0.25455633, 0.03899426]\n",
      "Iter 4817, loss [-0.21823345, -0.2569804, 0.038746934]\n",
      "Iter 4818, loss [-0.20983541, -0.24948949, 0.039654072]\n",
      "Iter 4819, loss [-0.20792218, -0.2510271, 0.04310493]\n",
      "Iter 4820, loss [-0.21770236, -0.25493765, 0.037235297]\n",
      "Iter 4821, loss [-0.21762273, -0.255372, 0.037749268]\n",
      "Iter 4822, loss [-0.2178171, -0.25515413, 0.037337042]\n",
      "Iter 4823, loss [-0.2213478, -0.25941718, 0.038069382]\n",
      "Iter 4824, loss [-0.20399445, -0.24031691, 0.03632246]\n",
      "Iter 4825, loss [-0.21595153, -0.25643083, 0.040479295]\n",
      "Iter 4826, loss [-0.22894731, -0.2731553, 0.044207983]\n",
      "Iter 4827, loss [-0.20702869, -0.24898736, 0.041958682]\n",
      "Iter 4828, loss [-0.20774393, -0.24657379, 0.038829863]\n",
      "Iter 4829, loss [-0.30612394, -0.31556165, 0.009437716]\n",
      "Iter 4830, loss [-0.21066514, -0.272001, 0.061335854]\n",
      "Iter 4831, loss [-0.22375686, -0.26181832, 0.03806146]\n",
      "Iter 4832, loss [-0.21054038, -0.24796094, 0.03742055]\n",
      "Iter 4833, loss [-0.21201888, -0.25681767, 0.044798784]\n",
      "Iter 4834, loss [-0.22459331, -0.2629544, 0.03836111]\n",
      "Iter 4835, loss [-0.21864423, -0.2574654, 0.038821153]\n",
      "Iter 4836, loss [-0.22727993, -0.2728466, 0.045566678]\n",
      "Iter 4837, loss [-0.22726692, -0.26615953, 0.03889261]\n",
      "Iter 4838, loss [-0.20726185, -0.24826027, 0.040998425]\n",
      "Iter 4839, loss [-0.22534238, -0.26388583, 0.038543444]\n",
      "Iter 4840, loss [-0.20979215, -0.25260288, 0.04281072]\n",
      "Iter 4841, loss [-0.20591447, -0.25388432, 0.047969844]\n",
      "Iter 4842, loss [-0.21941134, -0.25890172, 0.039490372]\n",
      "Iter 4843, loss [-0.20582342, -0.24333347, 0.03751006]\n",
      "Iter 4844, loss [-0.2266484, -0.26583418, 0.039185774]\n",
      "Iter 4845, loss [-0.22520763, -0.26551738, 0.040309757]\n",
      "Iter 4846, loss [-0.22658035, -0.2664016, 0.03982123]\n",
      "Iter 4847, loss [-0.2101855, -0.25051692, 0.04033142]\n",
      "Iter 4848, loss [-0.22856626, -0.27368575, 0.04511949]\n",
      "Iter 4849, loss [-0.21477155, -0.2535804, 0.038808838]\n",
      "Iter 4850, loss [-0.22110003, -0.2593777, 0.038277652]\n",
      "Iter 4851, loss [-0.2366589, -0.31034815, 0.073689245]\n",
      "Iter 4852, loss [-0.30795226, -0.31718808, 0.009235821]\n",
      "Iter 4853, loss [-0.21055737, -0.25843886, 0.047881477]\n",
      "Iter 4854, loss [-0.21282747, -0.24872786, 0.035900384]\n",
      "Iter 4855, loss [-0.21355538, -0.2537062, 0.040150806]\n",
      "Iter 4856, loss [-0.2121059, -0.24817733, 0.03607144]\n",
      "Iter 4857, loss [-0.22767118, -0.2659438, 0.038272616]\n",
      "Iter 4858, loss [-0.22761914, -0.26537496, 0.03775581]\n",
      "Iter 4859, loss [-0.23578659, -0.29101282, 0.05522623]\n",
      "Iter 4860, loss [-0.24678451, -0.31032798, 0.063543476]\n",
      "Iter 4861, loss [-0.21009097, -0.25091887, 0.040827893]\n",
      "Iter 4862, loss [-0.21897864, -0.26212075, 0.04314211]\n",
      "Iter 4863, loss [-0.21653345, -0.25775915, 0.04122571]\n",
      "Iter 4864, loss [-0.209761, -0.25052258, 0.040761597]\n",
      "Iter 4865, loss [-0.21699649, -0.25693014, 0.03993366]\n",
      "Iter 4866, loss [-0.23056932, -0.30693087, 0.07636155]\n",
      "Iter 4867, loss [-0.22608432, -0.26255187, 0.036467545]\n",
      "Iter 4868, loss [-0.20739949, -0.2430181, 0.035618618]\n",
      "Iter 4869, loss [-0.21082921, -0.25073665, 0.039907437]\n",
      "Iter 4870, loss [-0.20284212, -0.27808225, 0.07524013]\n",
      "Iter 4871, loss [-0.3069879, -0.31676885, 0.00978094]\n",
      "Iter 4872, loss [-0.19869834, -0.23643924, 0.0377409]\n",
      "Iter 4873, loss [-0.21424553, -0.25566328, 0.041417755]\n",
      "Iter 4874, loss [-0.20053992, -0.24452293, 0.043983012]\n",
      "Iter 4875, loss [-0.21147631, -0.24993874, 0.03846243]\n",
      "Iter 4876, loss [-0.2292965, -0.2683675, 0.039070994]\n",
      "Iter 4877, loss [-0.20456293, -0.24687535, 0.04231241]\n",
      "Iter 4878, loss [-0.20925757, -0.24810714, 0.03884957]\n",
      "Iter 4879, loss [-0.22655414, -0.26964697, 0.04309283]\n",
      "Iter 4880, loss [-0.20631509, -0.24676408, 0.040448993]\n",
      "Iter 4881, loss [-0.22720942, -0.263004, 0.035794582]\n",
      "Iter 4882, loss [-0.21727364, -0.2566604, 0.03938676]\n",
      "Iter 4883, loss [-0.21307853, -0.25367728, 0.040598754]\n",
      "Iter 4884, loss [-0.22520898, -0.26521918, 0.040010195]\n",
      "Iter 4885, loss [-0.21527164, -0.25534952, 0.04007788]\n",
      "Iter 4886, loss [-0.21189167, -0.27819192, 0.06630026]\n",
      "Iter 4887, loss [-0.21288791, -0.24828038, 0.035392463]\n",
      "Iter 4888, loss [-0.2025626, -0.24488658, 0.042323984]\n",
      "Iter 4889, loss [-0.20552243, -0.24151246, 0.035990026]\n",
      "Iter 4890, loss [-0.21393482, -0.2538936, 0.03995879]\n",
      "Iter 4891, loss [-0.21892786, -0.25586215, 0.036934294]\n",
      "Iter 4892, loss [-0.21081662, -0.24844994, 0.037633322]\n",
      "Iter 4893, loss [-0.2152385, -0.25631955, 0.041081056]\n",
      "Iter 4894, loss [-0.21928015, -0.26086706, 0.0415869]\n",
      "Iter 4895, loss [-0.20940602, -0.26036695, 0.050960936]\n",
      "Iter 4896, loss [-0.21437716, -0.25705954, 0.042682372]\n",
      "Iter 4897, loss [-0.21620989, -0.2637928, 0.04758292]\n",
      "Iter 4898, loss [-0.23125382, -0.26921296, 0.037959144]\n",
      "Iter 4899, loss [-0.23772047, -0.29965803, 0.061937552]\n",
      "Iter 4900, loss [-0.24007389, -0.30337882, 0.06330494]\n",
      "Iter 4901, loss [-0.21042639, -0.25377956, 0.04335317]\n",
      "Iter 4902, loss [-0.23968634, -0.27533886, 0.035652526]\n",
      "Iter 4903, loss [-0.20581897, -0.24804619, 0.04222722]\n",
      "Iter 4904, loss [-0.20980018, -0.24974011, 0.039939925]\n",
      "Iter 4905, loss [-0.21032926, -0.2507221, 0.040392846]\n",
      "Iter 4906, loss [-0.30695897, -0.31673184, 0.009772872]\n",
      "Iter 4907, loss [-0.21705696, -0.25683495, 0.03977799]\n",
      "Iter 4908, loss [-0.22565521, -0.26306644, 0.037411228]\n",
      "Iter 4909, loss [-0.21765175, -0.25805002, 0.040398262]\n",
      "Iter 4910, loss [-0.24065681, -0.28720474, 0.04654793]\n",
      "Iter 4911, loss [-0.22412506, -0.26569322, 0.041568164]\n",
      "Iter 4912, loss [-0.21882942, -0.25566894, 0.036839508]\n",
      "Iter 4913, loss [-0.22380707, -0.26159674, 0.037789665]\n",
      "Iter 4914, loss [-0.17664361, -0.28000718, 0.103363566]\n",
      "Iter 4915, loss [-0.21531855, -0.25026363, 0.034945082]\n",
      "Iter 4916, loss [-0.21865976, -0.2615966, 0.042936828]\n",
      "Iter 4917, loss [-0.21240357, -0.25510067, 0.0426971]\n",
      "Iter 4918, loss [-0.22588074, -0.26354843, 0.037667684]\n",
      "Iter 4919, loss [-0.21830422, -0.25704923, 0.03874502]\n",
      "Iter 4920, loss [-0.20532782, -0.24898186, 0.04365404]\n",
      "Iter 4921, loss [-0.22769786, -0.2917892, 0.06409134]\n",
      "Iter 4922, loss [-0.22468929, -0.29896232, 0.074273035]\n",
      "Iter 4923, loss [-0.22050929, -0.28531882, 0.06480953]\n",
      "Iter 4924, loss [-0.20428008, -0.24744156, 0.043161478]\n",
      "Iter 4925, loss [-0.21317878, -0.25540483, 0.042226054]\n",
      "Iter 4926, loss [-0.22150156, -0.26309097, 0.041589417]\n",
      "Iter 4927, loss [-0.20521915, -0.24389368, 0.038674533]\n",
      "Iter 4928, loss [-0.20729336, -0.24432415, 0.03703078]\n",
      "Iter 4929, loss [-0.2221786, -0.26541665, 0.04323806]\n",
      "Iter 4930, loss [-0.21925816, -0.2560445, 0.036786344]\n",
      "Iter 4931, loss [-0.30610192, -0.31678164, 0.010679728]\n",
      "Iter 4932, loss [-0.20281525, -0.2702609, 0.06744565]\n",
      "Iter 4933, loss [-0.22200605, -0.26081875, 0.038812693]\n",
      "Iter 4934, loss [-0.2266309, -0.2623856, 0.035754703]\n",
      "Iter 4935, loss [-0.20752884, -0.24585432, 0.03832547]\n",
      "Iter 4936, loss [-0.21063703, -0.24873644, 0.0380994]\n",
      "Iter 4937, loss [-0.23117255, -0.29869395, 0.06752141]\n",
      "Iter 4938, loss [-0.22453341, -0.26405638, 0.03952297]\n",
      "Iter 4939, loss [-0.22634359, -0.2649871, 0.038643528]\n",
      "Iter 4940, loss [-0.21630329, -0.25709212, 0.040788826]\n",
      "Iter 4941, loss [-0.21800837, -0.2590606, 0.04105222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4942, loss [-0.20863649, -0.24961747, 0.040980987]\n",
      "Iter 4943, loss [-0.20527974, -0.2472945, 0.04201477]\n",
      "Iter 4944, loss [-0.2157315, -0.2520814, 0.0363499]\n",
      "Iter 4945, loss [-0.23758586, -0.31285238, 0.075266525]\n",
      "Iter 4946, loss [-0.211396, -0.24896367, 0.037567675]\n",
      "Iter 4947, loss [-0.2180755, -0.25824067, 0.040165167]\n",
      "Iter 4948, loss [-0.23841256, -0.3110684, 0.07265582]\n",
      "Iter 4949, loss [-0.21011913, -0.25027525, 0.04015612]\n",
      "Iter 4950, loss [-0.20439652, -0.25421652, 0.049820006]\n",
      "Iter 4951, loss [-0.22660099, -0.26600343, 0.03940244]\n",
      "Iter 4952, loss [-0.20747706, -0.24650298, 0.03902591]\n",
      "Iter 4953, loss [-0.21725711, -0.2574245, 0.04016739]\n",
      "Iter 4954, loss [-0.23833892, -0.31918186, 0.08084294]\n",
      "Iter 4955, loss [-0.20337701, -0.2427573, 0.039380293]\n",
      "Iter 4956, loss [-0.22859848, -0.27126458, 0.0426661]\n",
      "Iter 4957, loss [-0.21812564, -0.25680643, 0.0386808]\n",
      "Iter 4958, loss [-0.21616529, -0.25633955, 0.04017426]\n",
      "Iter 4959, loss [-0.21071272, -0.2494561, 0.038743377]\n",
      "Iter 4960, loss [-0.21560162, -0.2540434, 0.038441777]\n",
      "Iter 4961, loss [-0.21124147, -0.25030148, 0.039060008]\n",
      "Iter 4962, loss [-0.23346774, -0.3095036, 0.07603584]\n",
      "Iter 4963, loss [-0.24052544, -0.2763967, 0.03587125]\n",
      "Iter 4964, loss [-0.22684042, -0.29890987, 0.07206945]\n",
      "Iter 4965, loss [-0.20275952, -0.24346572, 0.040706202]\n",
      "Iter 4966, loss [-0.23085813, -0.2680706, 0.037212476]\n",
      "Iter 4967, loss [-0.21541563, -0.25677845, 0.04136283]\n",
      "Iter 4968, loss [-0.2266869, -0.26540628, 0.038719382]\n",
      "Iter 4969, loss [-0.21255589, -0.25746298, 0.044907093]\n",
      "Iter 4970, loss [-0.2134022, -0.25175697, 0.038354766]\n",
      "Iter 4971, loss [-0.2204765, -0.25883386, 0.038357366]\n",
      "Iter 4972, loss [-0.23492272, -0.29034007, 0.055417344]\n",
      "Iter 4973, loss [-0.2110897, -0.2553488, 0.044259094]\n",
      "Iter 4974, loss [-0.22911873, -0.26850295, 0.039384224]\n",
      "Iter 4975, loss [-0.23533587, -0.3159352, 0.08059932]\n",
      "Iter 4976, loss [-0.21347663, -0.25598374, 0.042507112]\n",
      "Iter 4977, loss [-0.22591484, -0.27365133, 0.047736496]\n",
      "Iter 4978, loss [-0.21965194, -0.25941715, 0.0397652]\n",
      "Iter 4979, loss [-0.21992269, -0.2602552, 0.040332492]\n",
      "Iter 4980, loss [-0.23535931, -0.28999823, 0.054638915]\n",
      "Iter 4981, loss [-0.21607314, -0.25291914, 0.036845993]\n",
      "Iter 4982, loss [-0.204182, -0.24405444, 0.039872445]\n",
      "Iter 4983, loss [-0.22337615, -0.2611682, 0.037792053]\n",
      "Iter 4984, loss [-0.20704186, -0.24533197, 0.038290113]\n",
      "Iter 4985, loss [-0.22494331, -0.2648058, 0.039862476]\n",
      "Iter 4986, loss [-0.21069458, -0.2497234, 0.03902882]\n",
      "Iter 4987, loss [-0.21013977, -0.25022963, 0.04008986]\n",
      "Iter 4988, loss [-0.21773395, -0.25801465, 0.040280692]\n",
      "Iter 4989, loss [-0.2167137, -0.25664687, 0.039933175]\n",
      "Iter 4990, loss [-0.24819586, -0.29064196, 0.0424461]\n",
      "Iter 4991, loss [-0.20757374, -0.24707726, 0.039503515]\n",
      "Iter 4992, loss [-0.20970806, -0.25676912, 0.04706105]\n",
      "Iter 4993, loss [-0.214125, -0.27376264, 0.059637636]\n",
      "Iter 4994, loss [-0.22516635, -0.26861194, 0.04344558]\n",
      "Iter 4995, loss [-0.20798291, -0.24531057, 0.037327662]\n",
      "Iter 4996, loss [-0.21660672, -0.2578595, 0.041252777]\n",
      "Iter 4997, loss [-0.22524525, -0.2654482, 0.040202957]\n",
      "Iter 4998, loss [-0.20719215, -0.24968235, 0.04249019]\n",
      "Iter 4999, loss [-0.22082476, -0.26310772, 0.042282954]\n",
      "Iter 5000, loss [-0.21148466, -0.25632322, 0.04483856]\n",
      "Iter 5001, loss [-0.30621895, -0.3157453, 0.009526338]\n",
      "Iter 5002, loss [-0.2288726, -0.2972605, 0.06838789]\n",
      "Iter 5003, loss [-0.2059473, -0.25292173, 0.04697443]\n",
      "Iter 5004, loss [-0.21024936, -0.24699827, 0.036748897]\n",
      "Iter 5005, loss [-0.22403245, -0.26163453, 0.03760208]\n",
      "Iter 5006, loss [-0.21622846, -0.25791165, 0.041683204]\n",
      "Iter 5007, loss [-0.22467051, -0.2656611, 0.040990572]\n",
      "Iter 5008, loss [-0.3078766, -0.31714463, 0.009268041]\n",
      "Iter 5009, loss [-0.21853925, -0.2583199, 0.03978066]\n",
      "Iter 5010, loss [-0.2113176, -0.24865003, 0.037332438]\n",
      "Iter 5011, loss [-0.2379901, -0.3171781, 0.079188004]\n",
      "Iter 5012, loss [-0.21511902, -0.276511, 0.061391994]\n",
      "Iter 5013, loss [-0.20992452, -0.25241286, 0.042488344]\n",
      "Iter 5014, loss [-0.21558481, -0.27667025, 0.061085425]\n",
      "Iter 5015, loss [-0.22541429, -0.26788637, 0.04247208]\n",
      "Iter 5016, loss [-0.2199733, -0.30165708, 0.08168378]\n",
      "Iter 5017, loss [-0.20912187, -0.252824, 0.04370214]\n",
      "Iter 5018, loss [-0.22480956, -0.26252487, 0.037715312]\n",
      "Iter 5019, loss [-0.216856, -0.26123244, 0.044376433]\n",
      "Iter 5020, loss [-0.22023681, -0.26217848, 0.041941665]\n",
      "Iter 5021, loss [-0.2312034, -0.26792654, 0.036723144]\n",
      "Iter 5022, loss [-0.21495232, -0.2563092, 0.0413569]\n",
      "Iter 5023, loss [-0.21619646, -0.25366017, 0.03746371]\n",
      "Iter 5024, loss [-0.21851647, -0.25676087, 0.03824439]\n",
      "Iter 5025, loss [-0.21150795, -0.2506841, 0.03917616]\n",
      "Iter 5026, loss [-0.21811232, -0.25717607, 0.039063748]\n",
      "Iter 5027, loss [-0.20726979, -0.24420945, 0.036939666]\n",
      "Iter 5028, loss [-0.21030256, -0.2497358, 0.03943325]\n",
      "Iter 5029, loss [-0.22049326, -0.26084423, 0.04035097]\n",
      "Iter 5030, loss [-0.20518374, -0.24410821, 0.03892447]\n",
      "Iter 5031, loss [-0.22467092, -0.26616552, 0.041494615]\n",
      "Iter 5032, loss [-0.3076267, -0.31689134, 0.00926465]\n",
      "Iter 5033, loss [-0.22974475, -0.26693672, 0.037191972]\n",
      "Iter 5034, loss [-0.19652961, -0.24176598, 0.04523636]\n",
      "Iter 5035, loss [-0.18021667, -0.22773936, 0.047522694]\n",
      "Iter 5036, loss [-0.21935168, -0.2557147, 0.036363043]\n",
      "Iter 5037, loss [-0.24105784, -0.27619144, 0.035133597]\n",
      "Iter 5038, loss [-0.21036173, -0.24892905, 0.03856732]\n",
      "Iter 5039, loss [-0.22934166, -0.31214175, 0.08280008]\n",
      "Iter 5040, loss [-0.2250467, -0.26808882, 0.04304213]\n",
      "Iter 5041, loss [-0.2107229, -0.24702871, 0.036305808]\n",
      "Iter 5042, loss [-0.21349065, -0.25035495, 0.036864292]\n",
      "Iter 5043, loss [-0.2051904, -0.24109626, 0.03590585]\n",
      "Iter 5044, loss [-0.20678967, -0.24763456, 0.040844895]\n",
      "Iter 5045, loss [-0.22596262, -0.2691386, 0.043175977]\n",
      "Iter 5046, loss [-0.2406483, -0.276993, 0.0363447]\n",
      "Iter 5047, loss [-0.2104553, -0.24987139, 0.03941609]\n",
      "Iter 5048, loss [-0.21286073, -0.25533107, 0.04247033]\n",
      "Iter 5049, loss [-0.2072194, -0.24557047, 0.03835106]\n",
      "Iter 5050, loss [-0.22636946, -0.27266756, 0.046298098]\n",
      "Iter 5051, loss [-0.2281799, -0.26622862, 0.038048718]\n",
      "Iter 5052, loss [-0.20868498, -0.25163245, 0.042947467]\n",
      "Iter 5053, loss [-0.21772467, -0.26109403, 0.043369368]\n",
      "Iter 5054, loss [-0.30756697, -0.3167814, 0.009214427]\n",
      "Iter 5055, loss [-0.22112942, -0.2598081, 0.038678683]\n",
      "Iter 5056, loss [-0.21542421, -0.25462687, 0.039202653]\n",
      "Iter 5057, loss [-0.22441915, -0.26457402, 0.04015488]\n",
      "Iter 5058, loss [-0.22574173, -0.2622122, 0.036470454]\n",
      "Iter 5059, loss [-0.2158494, -0.25723696, 0.04138755]\n",
      "Iter 5060, loss [-0.21162793, -0.2494653, 0.037837375]\n",
      "Iter 5061, loss [-0.21150954, -0.24930674, 0.037797194]\n",
      "Iter 5062, loss [-0.2112943, -0.25103837, 0.03974407]\n",
      "Iter 5063, loss [-0.21866103, -0.25641754, 0.037756514]\n",
      "Iter 5064, loss [-0.22146133, -0.26015347, 0.038692147]\n",
      "Iter 5065, loss [-0.20433947, -0.24263114, 0.038291663]\n",
      "Iter 5066, loss [-0.20519342, -0.24465743, 0.039464008]\n",
      "Iter 5067, loss [-0.21205981, -0.25563562, 0.04357581]\n",
      "Iter 5068, loss [-0.24155541, -0.27676108, 0.035205673]\n",
      "Iter 5069, loss [-0.21753079, -0.2559606, 0.03842982]\n",
      "Iter 5070, loss [-0.21251385, -0.25367552, 0.041161668]\n",
      "Iter 5071, loss [-0.21192539, -0.2503527, 0.038427323]\n",
      "Iter 5072, loss [-0.21882781, -0.25530115, 0.036473326]\n",
      "Iter 5073, loss [-0.22501415, -0.26857787, 0.043563724]\n",
      "Iter 5074, loss [-0.21645959, -0.2554939, 0.039034322]\n",
      "Iter 5075, loss [-0.2148828, -0.25294605, 0.03806324]\n",
      "Iter 5076, loss [-0.3084, -0.3176591, 0.009259114]\n",
      "Iter 5077, loss [-0.20606446, -0.28049123, 0.07442677]\n",
      "Iter 5078, loss [-0.22678545, -0.26587388, 0.039088424]\n",
      "Iter 5079, loss [-0.21261525, -0.24984545, 0.037230186]\n",
      "Iter 5080, loss [-0.20708853, -0.2505162, 0.04342767]\n",
      "Iter 5081, loss [-0.21504055, -0.2623765, 0.047335934]\n",
      "Iter 5082, loss [-0.22839451, -0.26806784, 0.03967332]\n",
      "Iter 5083, loss [-0.30742234, -0.31672788, 0.009305545]\n",
      "Iter 5084, loss [-0.2075121, -0.24797912, 0.04046702]\n",
      "Iter 5085, loss [-0.21063039, -0.24987404, 0.039243657]\n",
      "Iter 5086, loss [-0.22913924, -0.2660145, 0.036875255]\n",
      "Iter 5087, loss [-0.22828324, -0.26396573, 0.03568248]\n",
      "Iter 5088, loss [-0.21120194, -0.27105922, 0.059857287]\n",
      "Iter 5089, loss [-0.23096217, -0.26747483, 0.036512654]\n",
      "Iter 5090, loss [-0.2291975, -0.2676521, 0.0384546]\n",
      "Iter 5091, loss [-0.22483568, -0.26807806, 0.043242376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5092, loss [-0.20994262, -0.25021043, 0.040267807]\n",
      "Iter 5093, loss [-0.20774154, -0.24919888, 0.04145734]\n",
      "Iter 5094, loss [-0.21411061, -0.25321493, 0.039104313]\n",
      "Iter 5095, loss [-0.22725475, -0.2659067, 0.038651936]\n",
      "Iter 5096, loss [-0.22596765, -0.26476428, 0.038796626]\n",
      "Iter 5097, loss [-0.2274808, -0.26492277, 0.037441965]\n",
      "Iter 5098, loss [-0.20720556, -0.2435496, 0.036344036]\n",
      "Iter 5099, loss [-0.21772628, -0.25563017, 0.037903886]\n",
      "Iter 5100, loss [-0.21325186, -0.25584242, 0.04259055]\n",
      "Iter 5101, loss [-0.20293678, -0.24330838, 0.0403716]\n",
      "Iter 5102, loss [-0.19752279, -0.24649717, 0.048974372]\n",
      "Iter 5103, loss [-0.23200719, -0.31114575, 0.07913856]\n",
      "Iter 5104, loss [-0.22557308, -0.26754415, 0.04197107]\n",
      "Iter 5105, loss [-0.20777525, -0.24410939, 0.036334142]\n",
      "Iter 5106, loss [-0.21234837, -0.24694927, 0.0346009]\n",
      "Iter 5107, loss [-0.20425282, -0.23899485, 0.034742024]\n",
      "Iter 5108, loss [-0.21272616, -0.25003716, 0.037311]\n",
      "Iter 5109, loss [-0.22597098, -0.2633471, 0.037376102]\n",
      "Iter 5110, loss [-0.22470412, -0.26191166, 0.037207544]\n",
      "Iter 5111, loss [-0.20826323, -0.24874419, 0.040480953]\n",
      "Iter 5112, loss [-0.21072891, -0.25640282, 0.0456739]\n",
      "Iter 5113, loss [-0.21914975, -0.26063126, 0.04148151]\n",
      "Iter 5114, loss [-0.2248634, -0.2696954, 0.044832002]\n",
      "Iter 5115, loss [-0.2124075, -0.25411344, 0.04170593]\n",
      "Iter 5116, loss [-0.21002609, -0.24992937, 0.039903283]\n",
      "Iter 5117, loss [-0.18022335, -0.22898279, 0.048759438]\n",
      "Iter 5118, loss [-0.20940414, -0.25805533, 0.04865118]\n",
      "Iter 5119, loss [-0.2163665, -0.2609989, 0.044632398]\n",
      "Iter 5120, loss [-0.21022086, -0.24766088, 0.037440017]\n",
      "Iter 5121, loss [-0.21791023, -0.25647178, 0.03856156]\n",
      "Iter 5122, loss [-0.2274977, -0.2741847, 0.046687]\n",
      "Iter 5123, loss [-0.20806015, -0.24640848, 0.03834833]\n",
      "Iter 5124, loss [-0.24127024, -0.27754995, 0.036279716]\n",
      "Iter 5125, loss [-0.21331254, -0.25578886, 0.04247632]\n",
      "Iter 5126, loss [-0.21705545, -0.25713986, 0.040084403]\n",
      "Iter 5127, loss [-0.20580241, -0.25390738, 0.04810497]\n",
      "Iter 5128, loss [-0.21364382, -0.24922387, 0.03558005]\n",
      "Iter 5129, loss [-0.2207954, -0.25990725, 0.039111856]\n",
      "Iter 5130, loss [-0.2212188, -0.25940216, 0.03818337]\n",
      "Iter 5131, loss [-0.2208719, -0.25998122, 0.039109312]\n",
      "Iter 5132, loss [-0.22831906, -0.26631027, 0.03799121]\n",
      "Iter 5133, loss [-0.2188265, -0.2560865, 0.037259996]\n",
      "Iter 5134, loss [-0.22044905, -0.28098103, 0.060531985]\n",
      "Iter 5135, loss [-0.21184444, -0.24891485, 0.0370704]\n",
      "Iter 5136, loss [-0.21008658, -0.25315967, 0.043073084]\n",
      "Iter 5137, loss [-0.21547493, -0.2545835, 0.039108567]\n",
      "Iter 5138, loss [-0.22828199, -0.26666743, 0.038385432]\n",
      "Iter 5139, loss [-0.22842777, -0.2669671, 0.038539324]\n",
      "Iter 5140, loss [-0.19833246, -0.2452498, 0.046917327]\n",
      "Iter 5141, loss [-0.2159526, -0.2762121, 0.060259484]\n",
      "Iter 5142, loss [-0.22848834, -0.27371204, 0.045223694]\n",
      "Iter 5143, loss [-0.22841933, -0.27350786, 0.045088526]\n",
      "Iter 5144, loss [-0.21542542, -0.25407913, 0.038653713]\n",
      "Iter 5145, loss [-0.21090963, -0.2477457, 0.03683605]\n",
      "Iter 5146, loss [-0.22540745, -0.2640513, 0.038643837]\n",
      "Iter 5147, loss [-0.21348085, -0.25567538, 0.042194527]\n",
      "Iter 5148, loss [-0.22070442, -0.25857732, 0.037872896]\n",
      "Iter 5149, loss [-0.24832615, -0.2929546, 0.044628438]\n",
      "Iter 5150, loss [-0.20829134, -0.24639285, 0.038101505]\n",
      "Iter 5151, loss [-0.21882035, -0.25999314, 0.041172784]\n",
      "Iter 5152, loss [-0.21438147, -0.27756023, 0.06317876]\n",
      "Iter 5153, loss [-0.21440542, -0.253255, 0.038849585]\n",
      "Iter 5154, loss [-0.22922534, -0.2663714, 0.037146058]\n",
      "Iter 5155, loss [-0.2188287, -0.25824594, 0.039417252]\n",
      "Iter 5156, loss [-0.21040648, -0.24866916, 0.03826268]\n",
      "Iter 5157, loss [-0.204081, -0.24290046, 0.038819455]\n",
      "Iter 5158, loss [-0.23604941, -0.293394, 0.057344586]\n",
      "Iter 5159, loss [-0.20564048, -0.24454448, 0.038903993]\n",
      "Iter 5160, loss [-0.2262544, -0.26364833, 0.037393928]\n",
      "Iter 5161, loss [-0.22990398, -0.26813295, 0.03822897]\n",
      "Iter 5162, loss [-0.20789053, -0.24468261, 0.036792085]\n",
      "Iter 5163, loss [-0.21301788, -0.24951778, 0.03649991]\n",
      "Iter 5164, loss [-0.20760027, -0.24811615, 0.04051588]\n",
      "Iter 5165, loss [-0.21619816, -0.25500038, 0.03880222]\n",
      "Iter 5166, loss [-0.21826793, -0.2546722, 0.036404267]\n",
      "Iter 5167, loss [-0.21843381, -0.25634527, 0.037911456]\n",
      "Iter 5168, loss [-0.2258346, -0.26536357, 0.039528977]\n",
      "Iter 5169, loss [-0.228524, -0.26840872, 0.039884716]\n",
      "Iter 5170, loss [-0.21878093, -0.2631945, 0.04441356]\n",
      "Iter 5171, loss [-0.22511749, -0.26970857, 0.04459108]\n",
      "Iter 5172, loss [-0.19854474, -0.24551308, 0.046968337]\n",
      "Iter 5173, loss [-0.21693385, -0.2557409, 0.038807057]\n",
      "Iter 5174, loss [-0.21607378, -0.254599, 0.038525216]\n",
      "Iter 5175, loss [-0.22870402, -0.2729214, 0.04421739]\n",
      "Iter 5176, loss [-0.22063276, -0.2587256, 0.03809286]\n",
      "Iter 5177, loss [-0.20501894, -0.29521888, 0.09019994]\n",
      "Iter 5178, loss [-0.23850463, -0.29438892, 0.055884287]\n",
      "Iter 5179, loss [-0.2434986, -0.30789912, 0.064400524]\n",
      "Iter 5180, loss [-0.2445055, -0.30936086, 0.06485536]\n",
      "Iter 5181, loss [-0.30709466, -0.31665042, 0.009555748]\n",
      "Iter 5182, loss [-0.21727934, -0.25569412, 0.038414784]\n",
      "Iter 5183, loss [-0.20425542, -0.24280581, 0.03855039]\n",
      "Iter 5184, loss [-0.21784057, -0.25494716, 0.03710659]\n",
      "Iter 5185, loss [-0.22886825, -0.26572484, 0.036856588]\n",
      "Iter 5186, loss [-0.2125761, -0.25091076, 0.03833465]\n",
      "Iter 5187, loss [-0.22394754, -0.26217917, 0.038231622]\n",
      "Iter 5188, loss [-0.21134397, -0.24908541, 0.037741445]\n",
      "Iter 5189, loss [-0.21601716, -0.25674736, 0.040730204]\n",
      "Iter 5190, loss [-0.22641623, -0.26587728, 0.039461054]\n",
      "Iter 5191, loss [-0.2205934, -0.26121646, 0.04062307]\n",
      "Iter 5192, loss [-0.3080613, -0.31734464, 0.009283321]\n",
      "Iter 5193, loss [-0.20426302, -0.24354415, 0.039281126]\n",
      "Iter 5194, loss [-0.21095964, -0.24786022, 0.036900576]\n",
      "Iter 5195, loss [-0.23701236, -0.3095546, 0.07254226]\n",
      "Iter 5196, loss [-0.20788151, -0.24852096, 0.040639445]\n",
      "Iter 5197, loss [-0.2116651, -0.2518251, 0.040159997]\n",
      "Iter 5198, loss [-0.18163477, -0.2295777, 0.047942936]\n",
      "Iter 5199, loss [-0.22812146, -0.26558337, 0.037461907]\n",
      "Iter 5200, loss [-0.21018273, -0.24839686, 0.03821414]\n",
      "Iter 5201, loss [-0.24132413, -0.27643365, 0.035109516]\n",
      "Iter 5202, loss [-0.2026425, -0.2426554, 0.040012904]\n",
      "Iter 5203, loss [-0.21323462, -0.25027606, 0.03704144]\n",
      "Iter 5204, loss [-0.22827668, -0.26727277, 0.03899608]\n",
      "Iter 5205, loss [-0.21371776, -0.25023568, 0.036517914]\n",
      "Iter 5206, loss [-0.20008928, -0.29142174, 0.091332465]\n",
      "Iter 5207, loss [-0.21448931, -0.25295818, 0.038468864]\n",
      "Iter 5208, loss [-0.22361934, -0.26128128, 0.037661932]\n",
      "Iter 5209, loss [-0.22542113, -0.2649915, 0.039570354]\n",
      "Iter 5210, loss [-0.22440155, -0.26410007, 0.039698526]\n",
      "Iter 5211, loss [-0.2239903, -0.26613158, 0.04214127]\n",
      "Iter 5212, loss [-0.22292662, -0.2628311, 0.03990448]\n",
      "Iter 5213, loss [-0.21532622, -0.25416514, 0.03883893]\n",
      "Iter 5214, loss [-0.22986415, -0.26783884, 0.03797468]\n",
      "Iter 5215, loss [-0.19770062, -0.24392483, 0.0462242]\n",
      "Iter 5216, loss [-0.23112716, -0.26702172, 0.035894558]\n",
      "Iter 5217, loss [-0.19702709, -0.24211839, 0.045091294]\n",
      "Iter 5218, loss [-0.2100201, -0.24801786, 0.037997764]\n",
      "Iter 5219, loss [-0.22796053, -0.26511657, 0.03715605]\n",
      "Iter 5220, loss [-0.21857274, -0.2551236, 0.036550857]\n",
      "Iter 5221, loss [-0.23554347, -0.3122626, 0.07671912]\n",
      "Iter 5222, loss [-0.20211917, -0.2454329, 0.04331372]\n",
      "Iter 5223, loss [-0.21973844, -0.25895154, 0.039213102]\n",
      "Iter 5224, loss [-0.20765525, -0.24853, 0.04087475]\n",
      "Iter 5225, loss [-0.22597545, -0.26178432, 0.035808858]\n",
      "Iter 5226, loss [-0.22076604, -0.2654804, 0.04471436]\n",
      "Iter 5227, loss [-0.2181679, -0.25786826, 0.03970035]\n",
      "Iter 5228, loss [-0.20496798, -0.2459071, 0.04093913]\n",
      "Iter 5229, loss [-0.22731757, -0.29886356, 0.07154599]\n",
      "Iter 5230, loss [-0.21078812, -0.25307918, 0.04229106]\n",
      "Iter 5231, loss [-0.21284707, -0.25191993, 0.039072856]\n",
      "Iter 5232, loss [-0.23074692, -0.29194683, 0.061199896]\n",
      "Iter 5233, loss [-0.20663956, -0.24982002, 0.043180466]\n",
      "Iter 5234, loss [-0.20189911, -0.2406278, 0.038728684]\n",
      "Iter 5235, loss [-0.22614136, -0.26573312, 0.03959176]\n",
      "Iter 5236, loss [-0.22542556, -0.26262084, 0.03719528]\n",
      "Iter 5237, loss [-0.22070561, -0.25824058, 0.037534967]\n",
      "Iter 5238, loss [-0.2145493, -0.2535712, 0.03902191]\n",
      "Iter 5239, loss [-0.22363666, -0.26005188, 0.036415216]\n",
      "Iter 5240, loss [-0.21842158, -0.2579629, 0.03954134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5241, loss [-0.21369176, -0.25410542, 0.04041366]\n",
      "Iter 5242, loss [-0.18113273, -0.23317437, 0.05204163]\n",
      "Iter 5243, loss [-0.2080687, -0.2511841, 0.043115407]\n",
      "Iter 5244, loss [-0.20796934, -0.24978778, 0.041818447]\n",
      "Iter 5245, loss [-0.20780411, -0.24940069, 0.04159657]\n",
      "Iter 5246, loss [-0.20317915, -0.24177313, 0.038593985]\n",
      "Iter 5247, loss [-0.21124774, -0.24939713, 0.038149394]\n",
      "Iter 5248, loss [-0.20799625, -0.24823347, 0.040237214]\n",
      "Iter 5249, loss [-0.20312057, -0.24270768, 0.03958711]\n",
      "Iter 5250, loss [-0.2244006, -0.26205248, 0.03765188]\n",
      "Iter 5251, loss [-0.23000452, -0.27356458, 0.043560065]\n",
      "Iter 5252, loss [-0.21648248, -0.2595516, 0.043069135]\n",
      "Iter 5253, loss [-0.21121617, -0.2511273, 0.039911132]\n",
      "Iter 5254, loss [-0.20664468, -0.24448973, 0.037845053]\n",
      "Iter 5255, loss [-0.24513048, -0.30912527, 0.06399479]\n",
      "Iter 5256, loss [-0.2112112, -0.24860653, 0.03739532]\n",
      "Iter 5257, loss [-0.20979564, -0.24661298, 0.03681734]\n",
      "Iter 5258, loss [-0.20850381, -0.24915281, 0.04064899]\n",
      "Iter 5259, loss [-0.22171718, -0.26058832, 0.03887113]\n",
      "Iter 5260, loss [-0.21692973, -0.2565304, 0.03960067]\n",
      "Iter 5261, loss [-0.2254947, -0.2670589, 0.04156421]\n",
      "Iter 5262, loss [-0.21953675, -0.2574689, 0.03793215]\n",
      "Iter 5263, loss [-0.2411814, -0.32173467, 0.080553256]\n",
      "Iter 5264, loss [-0.2492652, -0.31299478, 0.06372958]\n",
      "Iter 5265, loss [-0.21160644, -0.25086197, 0.039255522]\n",
      "Iter 5266, loss [-0.2186798, -0.25642776, 0.037747964]\n",
      "Iter 5267, loss [-0.2212334, -0.26137412, 0.04014071]\n",
      "Iter 5268, loss [-0.21497828, -0.25540265, 0.04042437]\n",
      "Iter 5269, loss [-0.20873795, -0.2458116, 0.037073642]\n",
      "Iter 5270, loss [-0.20648316, -0.25524896, 0.0487658]\n",
      "Iter 5271, loss [-0.21518792, -0.2546888, 0.039500877]\n",
      "Iter 5272, loss [-0.2296011, -0.2699842, 0.040383082]\n",
      "Iter 5273, loss [-0.2064525, -0.24431553, 0.03786303]\n",
      "Iter 5274, loss [-0.21961921, -0.25813732, 0.038518094]\n",
      "Iter 5275, loss [-0.22219574, -0.26288757, 0.040691815]\n",
      "Iter 5276, loss [-0.20858587, -0.24903685, 0.04045097]\n",
      "Iter 5277, loss [-0.21171457, -0.25018793, 0.038473375]\n",
      "Iter 5278, loss [-0.22968489, -0.2683261, 0.03864122]\n",
      "Iter 5279, loss [-0.2223558, -0.25875726, 0.03640147]\n",
      "Iter 5280, loss [-0.22621816, -0.26517385, 0.038955692]\n",
      "Iter 5281, loss [-0.22234085, -0.26418728, 0.041846417]\n",
      "Iter 5282, loss [-0.21345468, -0.25126842, 0.037813734]\n",
      "Iter 5283, loss [-0.228531, -0.26851177, 0.039980765]\n",
      "Iter 5284, loss [-0.21706985, -0.2575275, 0.040457647]\n",
      "Iter 5285, loss [-0.20467675, -0.24422199, 0.039545238]\n",
      "Iter 5286, loss [-0.22129437, -0.261444, 0.04014962]\n",
      "Iter 5287, loss [-0.21386334, -0.2544867, 0.040623374]\n",
      "Iter 5288, loss [-0.22928551, -0.26561442, 0.03632892]\n",
      "Iter 5289, loss [-0.21194494, -0.24971229, 0.037767354]\n",
      "Iter 5290, loss [-0.24529128, -0.30921316, 0.06392188]\n",
      "Iter 5291, loss [-0.21438758, -0.25909343, 0.04470585]\n",
      "Iter 5292, loss [-0.2149997, -0.25651157, 0.041511856]\n",
      "Iter 5293, loss [-0.21660304, -0.2575248, 0.040921744]\n",
      "Iter 5294, loss [-0.22474043, -0.26334766, 0.038607225]\n",
      "Iter 5295, loss [-0.22835198, -0.27387115, 0.045519166]\n",
      "Iter 5296, loss [-0.21942696, -0.25603154, 0.036604583]\n",
      "Iter 5297, loss [-0.2168358, -0.25628626, 0.039450474]\n",
      "Iter 5298, loss [-0.21519212, -0.25350586, 0.038313728]\n",
      "Iter 5299, loss [-0.22602786, -0.2677258, 0.041697934]\n",
      "Iter 5300, loss [-0.2193755, -0.25896093, 0.039585426]\n",
      "Iter 5301, loss [-0.21544194, -0.25615644, 0.040714502]\n",
      "Iter 5302, loss [-0.22606067, -0.26838338, 0.042322706]\n",
      "Iter 5303, loss [-0.21935639, -0.25900382, 0.039647426]\n",
      "Iter 5304, loss [-0.20678306, -0.24400651, 0.03722345]\n",
      "Iter 5305, loss [-0.20472819, -0.24440736, 0.03967917]\n",
      "Iter 5306, loss [-0.21547894, -0.25485656, 0.039377615]\n",
      "Iter 5307, loss [-0.30821395, -0.31763142, 0.009417489]\n",
      "Iter 5308, loss [-0.21038471, -0.2530473, 0.042662572]\n",
      "Iter 5309, loss [-0.21274462, -0.25618806, 0.04344344]\n",
      "Iter 5310, loss [-0.22570013, -0.28416073, 0.058460604]\n",
      "Iter 5311, loss [-0.20849806, -0.24863084, 0.040132772]\n",
      "Iter 5312, loss [-0.19903551, -0.24525197, 0.046216458]\n",
      "Iter 5313, loss [-0.23012276, -0.2690892, 0.038966432]\n",
      "Iter 5314, loss [-0.2254123, -0.30894953, 0.083537236]\n",
      "Iter 5315, loss [-0.23915607, -0.29534382, 0.05618774]\n",
      "Iter 5316, loss [-0.21294588, -0.25108364, 0.03813776]\n",
      "Iter 5317, loss [-0.21963921, -0.2595123, 0.039873086]\n",
      "Iter 5318, loss [-0.20291317, -0.24142036, 0.038507193]\n",
      "Iter 5319, loss [-0.20332149, -0.24172999, 0.038408503]\n",
      "Iter 5320, loss [-0.21930283, -0.2588691, 0.03956627]\n",
      "Iter 5321, loss [-0.2482419, -0.29077563, 0.042533718]\n",
      "Iter 5322, loss [-0.21592101, -0.25491777, 0.038996756]\n",
      "Iter 5323, loss [-0.21325065, -0.25179237, 0.038541716]\n",
      "Iter 5324, loss [-0.22644706, -0.26679888, 0.040351823]\n",
      "Iter 5325, loss [-0.21485256, -0.2545237, 0.039671134]\n",
      "Iter 5326, loss [-0.21300116, -0.2731045, 0.060103327]\n",
      "Iter 5327, loss [-0.2207695, -0.26301664, 0.042247143]\n",
      "Iter 5328, loss [-0.21303235, -0.25034893, 0.037316576]\n",
      "Iter 5329, loss [-0.21076885, -0.2502539, 0.039485037]\n",
      "Iter 5330, loss [-0.23504308, -0.293798, 0.058754917]\n",
      "Iter 5331, loss [-0.22152501, -0.26349023, 0.04196521]\n",
      "Iter 5332, loss [-0.21816564, -0.25699064, 0.038825005]\n",
      "Iter 5333, loss [-0.21441561, -0.2528247, 0.038409084]\n",
      "Iter 5334, loss [-0.21711959, -0.25548327, 0.038363677]\n",
      "Iter 5335, loss [-0.20703195, -0.24861123, 0.041579276]\n",
      "Iter 5336, loss [-0.19927755, -0.23545024, 0.036172684]\n",
      "Iter 5337, loss [-0.218297, -0.25908723, 0.040790226]\n",
      "Iter 5338, loss [-0.21035507, -0.24945907, 0.039104]\n",
      "Iter 5339, loss [-0.24014755, -0.3040213, 0.06387375]\n",
      "Iter 5340, loss [-0.21195981, -0.2533178, 0.041357987]\n",
      "Iter 5341, loss [-0.21586794, -0.25600353, 0.040135592]\n",
      "Iter 5342, loss [-0.21411768, -0.25360504, 0.039487366]\n",
      "Iter 5343, loss [-0.22037601, -0.25993913, 0.03956312]\n",
      "Iter 5344, loss [-0.2178967, -0.25676823, 0.038871527]\n",
      "Iter 5345, loss [-0.20472902, -0.25337416, 0.048645135]\n",
      "Iter 5346, loss [-0.22674851, -0.28949678, 0.06274827]\n",
      "Iter 5347, loss [-0.22221008, -0.26301387, 0.04080379]\n",
      "Iter 5348, loss [-0.21102633, -0.25941172, 0.048385393]\n",
      "Iter 5349, loss [-0.22165403, -0.25780433, 0.03615031]\n",
      "Iter 5350, loss [-0.21436453, -0.2525066, 0.038142085]\n",
      "Iter 5351, loss [-0.20592827, -0.25435722, 0.04842895]\n",
      "Iter 5352, loss [-0.21101823, -0.259372, 0.048353754]\n",
      "Iter 5353, loss [-0.21253565, -0.256343, 0.043807365]\n",
      "Iter 5354, loss [-0.21943408, -0.25623083, 0.03679674]\n",
      "Iter 5355, loss [-0.2084902, -0.24872763, 0.040237438]\n",
      "Iter 5356, loss [-0.20840135, -0.24511471, 0.03671337]\n",
      "Iter 5357, loss [-0.19893037, -0.24585699, 0.046926618]\n",
      "Iter 5358, loss [-0.2116316, -0.24990328, 0.03827168]\n",
      "Iter 5359, loss [-0.22847633, -0.26648995, 0.038013622]\n",
      "Iter 5360, loss [-0.21510942, -0.25646624, 0.041356813]\n",
      "Iter 5361, loss [-0.22116296, -0.2603454, 0.03918244]\n",
      "Iter 5362, loss [-0.2253015, -0.26962012, 0.044318624]\n",
      "Iter 5363, loss [-0.21925822, -0.2577602, 0.038501978]\n",
      "Iter 5364, loss [-0.21884367, -0.2581601, 0.039316453]\n",
      "Iter 5365, loss [-0.21173084, -0.2509338, 0.039202966]\n",
      "Iter 5366, loss [-0.2189723, -0.2580283, 0.039056]\n",
      "Iter 5367, loss [-0.21915892, -0.25851622, 0.039357305]\n",
      "Iter 5368, loss [-0.21534288, -0.2539767, 0.03863382]\n",
      "Iter 5369, loss [-0.21015786, -0.24768947, 0.037531614]\n",
      "Iter 5370, loss [-0.21969676, -0.26002327, 0.040326502]\n",
      "Iter 5371, loss [-0.21718332, -0.25659332, 0.03940999]\n",
      "Iter 5372, loss [-0.20660461, -0.24358143, 0.03697681]\n",
      "Iter 5373, loss [-0.20893453, -0.24753697, 0.03860244]\n",
      "Iter 5374, loss [-0.22443306, -0.2630424, 0.03860932]\n",
      "Iter 5375, loss [-0.21181709, -0.25179124, 0.03997416]\n",
      "Iter 5376, loss [-0.22558542, -0.26705968, 0.041474264]\n",
      "Iter 5377, loss [-0.21538539, -0.25658104, 0.041195642]\n",
      "Iter 5378, loss [-0.24219476, -0.3136548, 0.07146005]\n",
      "Iter 5379, loss [-0.21635294, -0.25570664, 0.03935369]\n",
      "Iter 5380, loss [-0.2167337, -0.25954553, 0.042811833]\n",
      "Iter 5381, loss [-0.21802789, -0.26371253, 0.045684636]\n",
      "Iter 5382, loss [-0.2030772, -0.24381942, 0.040742215]\n",
      "Iter 5383, loss [-0.20313707, -0.2437105, 0.040573426]\n",
      "Iter 5384, loss [-0.2126013, -0.2572415, 0.044640176]\n",
      "Iter 5385, loss [-0.20782436, -0.25001755, 0.042193186]\n",
      "Iter 5386, loss [-0.21702923, -0.25831085, 0.041281622]\n",
      "Iter 5387, loss [-0.21193017, -0.24877419, 0.03684401]\n",
      "Iter 5388, loss [-0.21724579, -0.25794604, 0.040700264]\n",
      "Iter 5389, loss [-0.20452662, -0.24310422, 0.0385776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5390, loss [-0.21819657, -0.25617796, 0.037981384]\n",
      "Iter 5391, loss [-0.21952438, -0.25786784, 0.03834346]\n",
      "Iter 5392, loss [-0.21064971, -0.25988668, 0.04923697]\n",
      "Iter 5393, loss [-0.22587661, -0.2682487, 0.04237209]\n",
      "Iter 5394, loss [-0.21765584, -0.2556214, 0.03796556]\n",
      "Iter 5395, loss [-0.20871721, -0.24513532, 0.036418114]\n",
      "Iter 5396, loss [-0.20672071, -0.2541743, 0.047453575]\n",
      "Iter 5397, loss [-0.22078395, -0.25892055, 0.0381366]\n",
      "Iter 5398, loss [-0.21599212, -0.2784271, 0.06243497]\n",
      "Iter 5399, loss [-0.22990796, -0.26902956, 0.039121605]\n",
      "Iter 5400, loss [-0.20815882, -0.24911019, 0.040951375]\n",
      "Iter 5401, loss [-0.22381592, -0.26100284, 0.037186924]\n",
      "Iter 5402, loss [-0.21888645, -0.25594682, 0.037060365]\n",
      "Iter 5403, loss [-0.2087026, -0.24585947, 0.037156887]\n",
      "Iter 5404, loss [-0.21880123, -0.25889483, 0.040093604]\n",
      "Iter 5405, loss [-0.22051111, -0.280069, 0.059557885]\n",
      "Iter 5406, loss [-0.21059094, -0.25088388, 0.040292934]\n",
      "Iter 5407, loss [-0.22819719, -0.26565483, 0.037457652]\n",
      "Iter 5408, loss [-0.2216952, -0.26264426, 0.04094906]\n",
      "Iter 5409, loss [-0.21334937, -0.25598913, 0.04263977]\n",
      "Iter 5410, loss [-0.22070107, -0.26045924, 0.039758183]\n",
      "Iter 5411, loss [-0.22192855, -0.2635035, 0.04157494]\n",
      "Iter 5412, loss [-0.21948865, -0.25855723, 0.03906858]\n",
      "Iter 5413, loss [-0.2165859, -0.25769675, 0.041110836]\n",
      "Iter 5414, loss [-0.20287596, -0.24185099, 0.03897503]\n",
      "Iter 5415, loss [-0.2120797, -0.24897756, 0.036897846]\n",
      "Iter 5416, loss [-0.216717, -0.257826, 0.041109003]\n",
      "Iter 5417, loss [-0.20035289, -0.23669103, 0.036338136]\n",
      "Iter 5418, loss [-0.21953005, -0.2600344, 0.040504374]\n",
      "Iter 5419, loss [-0.2119101, -0.26049274, 0.048582643]\n",
      "Iter 5420, loss [-0.21519442, -0.25365418, 0.038459763]\n",
      "Iter 5421, loss [-0.22242673, -0.2593632, 0.036936473]\n",
      "Iter 5422, loss [-0.21159017, -0.24847323, 0.036883056]\n",
      "Iter 5423, loss [-0.22224899, -0.2598626, 0.03761361]\n",
      "Iter 5424, loss [-0.20060086, -0.23715225, 0.036551386]\n",
      "Iter 5425, loss [-0.21687385, -0.25742492, 0.04055106]\n",
      "Iter 5426, loss [-0.21921127, -0.2589035, 0.039692238]\n",
      "Iter 5427, loss [-0.22557107, -0.26988187, 0.0443108]\n",
      "Iter 5428, loss [-0.21188055, -0.25062618, 0.038745627]\n",
      "Iter 5429, loss [-0.21964297, -0.25884002, 0.039197065]\n",
      "Iter 5430, loss [-0.21310943, -0.25123844, 0.038129006]\n",
      "Iter 5431, loss [-0.22572105, -0.26993734, 0.044216286]\n",
      "Iter 5432, loss [-0.22614616, -0.2651949, 0.03904874]\n",
      "Iter 5433, loss [-0.20872816, -0.250315, 0.041586846]\n",
      "Iter 5434, loss [-0.22641903, -0.26572266, 0.039303623]\n",
      "Iter 5435, loss [-0.22624393, -0.26923224, 0.04298831]\n",
      "Iter 5436, loss [-0.21941563, -0.25637347, 0.036957834]\n",
      "Iter 5437, loss [-0.22225094, -0.26257724, 0.040326305]\n",
      "Iter 5438, loss [-0.30700237, -0.316455, 0.009452652]\n",
      "Iter 5439, loss [-0.21969749, -0.2564699, 0.036772415]\n",
      "Iter 5440, loss [-0.21175545, -0.27002522, 0.058269765]\n",
      "Iter 5441, loss [-0.23029119, -0.26864156, 0.038350374]\n",
      "Iter 5442, loss [-0.21727416, -0.27905592, 0.061781757]\n",
      "Iter 5443, loss [-0.21823817, -0.2569197, 0.038681544]\n",
      "Iter 5444, loss [-0.23884407, -0.31374988, 0.07490581]\n",
      "Iter 5445, loss [-0.21880862, -0.26142135, 0.04261274]\n",
      "Iter 5446, loss [-0.21267042, -0.24798183, 0.035311416]\n",
      "Iter 5447, loss [-0.2225453, -0.25768846, 0.03514316]\n",
      "Iter 5448, loss [-0.2093301, -0.24734506, 0.03801496]\n",
      "Iter 5449, loss [-0.20513108, -0.24246886, 0.037337787]\n",
      "Iter 5450, loss [-0.20176974, -0.24205, 0.04028026]\n",
      "Iter 5451, loss [-0.21628901, -0.25862825, 0.042339228]\n",
      "Iter 5452, loss [-0.21269785, -0.2555715, 0.042873662]\n",
      "Iter 5453, loss [-0.21260896, -0.24921605, 0.036607087]\n",
      "Iter 5454, loss [-0.20721649, -0.25034675, 0.043130264]\n",
      "Iter 5455, loss [-0.21360677, -0.258281, 0.04467421]\n",
      "Iter 5456, loss [-0.2087371, -0.24852654, 0.03978943]\n",
      "Iter 5457, loss [-0.2167453, -0.2603834, 0.04363809]\n",
      "Iter 5458, loss [-0.22466886, -0.26250887, 0.037840012]\n",
      "Iter 5459, loss [-0.21788579, -0.25505906, 0.03717328]\n",
      "Iter 5460, loss [-0.22606494, -0.26422304, 0.038158108]\n",
      "Iter 5461, loss [-0.21061255, -0.24865061, 0.03803806]\n",
      "Iter 5462, loss [-0.22455686, -0.26445097, 0.0398941]\n",
      "Iter 5463, loss [-0.20784429, -0.24702577, 0.039181486]\n",
      "Iter 5464, loss [-0.22200182, -0.26905328, 0.047051467]\n",
      "Iter 5465, loss [-0.21947837, -0.25955236, 0.040074]\n",
      "Iter 5466, loss [-0.21460484, -0.25351495, 0.038910106]\n",
      "Iter 5467, loss [-0.21525474, -0.2540013, 0.03874655]\n",
      "Iter 5468, loss [-0.21618533, -0.2549452, 0.03875986]\n",
      "Iter 5469, loss [-0.22349247, -0.261569, 0.03807652]\n",
      "Iter 5470, loss [-0.20217587, -0.24068545, 0.038509574]\n",
      "Iter 5471, loss [-0.2377085, -0.29964855, 0.061940055]\n",
      "Iter 5472, loss [-0.20670286, -0.24563642, 0.038933568]\n",
      "Iter 5473, loss [-0.23722646, -0.32019296, 0.082966514]\n",
      "Iter 5474, loss [-0.20513858, -0.24418966, 0.039051082]\n",
      "Iter 5475, loss [-0.23057643, -0.26919162, 0.03861519]\n",
      "Iter 5476, loss [-0.20946082, -0.24979267, 0.040331833]\n",
      "Iter 5477, loss [-0.213079, -0.25504044, 0.041961428]\n",
      "Iter 5478, loss [-0.22058195, -0.25909343, 0.038511492]\n",
      "Iter 5479, loss [-0.227835, -0.26618567, 0.038350664]\n",
      "Iter 5480, loss [-0.21810348, -0.25590542, 0.037801936]\n",
      "Iter 5481, loss [-0.22356306, -0.26166075, 0.03809769]\n",
      "Iter 5482, loss [-0.20856768, -0.2517665, 0.04319883]\n",
      "Iter 5483, loss [-0.20988952, -0.2594143, 0.049524765]\n",
      "Iter 5484, loss [-0.20566656, -0.24308817, 0.037421614]\n",
      "Iter 5485, loss [-0.23913491, -0.31303284, 0.07389793]\n",
      "Iter 5486, loss [-0.23844038, -0.31767982, 0.07923944]\n",
      "Iter 5487, loss [-0.22346379, -0.26219055, 0.038726766]\n",
      "Iter 5488, loss [-0.2203505, -0.25962728, 0.039276775]\n",
      "Iter 5489, loss [-0.22484362, -0.2672085, 0.042364873]\n",
      "Iter 5490, loss [-0.22752474, -0.26656842, 0.039043676]\n",
      "Iter 5491, loss [-0.24589461, -0.28896776, 0.043073155]\n",
      "Iter 5492, loss [-0.2183092, -0.25901657, 0.040707376]\n",
      "Iter 5493, loss [-0.21641962, -0.25416034, 0.03774072]\n",
      "Iter 5494, loss [-0.2124778, -0.24914156, 0.036663756]\n",
      "Iter 5495, loss [-0.22086243, -0.26618457, 0.04532213]\n",
      "Iter 5496, loss [-0.22583812, -0.26546407, 0.039625946]\n",
      "Iter 5497, loss [-0.20788085, -0.24672042, 0.038839556]\n",
      "Iter 5498, loss [-0.2032333, -0.26497662, 0.06174331]\n",
      "Iter 5499, loss [-0.20545518, -0.2544606, 0.04900542]\n",
      "Iter 5500, loss [-0.19955829, -0.23651648, 0.036958195]\n",
      "Iter 5501, loss [-0.22608, -0.26251042, 0.036430415]\n",
      "Iter 5502, loss [-0.21158214, -0.25162253, 0.040040385]\n",
      "Iter 5503, loss [-0.2444426, -0.30647582, 0.062033217]\n",
      "Iter 5504, loss [-0.21139158, -0.24695039, 0.0355588]\n",
      "Iter 5505, loss [-0.22673076, -0.27257064, 0.045839872]\n",
      "Iter 5506, loss [-0.21555865, -0.25974837, 0.044189714]\n",
      "Iter 5507, loss [-0.23514682, -0.2940878, 0.058940984]\n",
      "Iter 5508, loss [-0.21538755, -0.27782363, 0.062436074]\n",
      "Iter 5509, loss [-0.2161022, -0.25575462, 0.039652422]\n",
      "Iter 5510, loss [-0.20203047, -0.24492975, 0.042899277]\n",
      "Iter 5511, loss [-0.21457648, -0.25367865, 0.039102174]\n",
      "Iter 5512, loss [-0.21844867, -0.25486022, 0.036411554]\n",
      "Iter 5513, loss [-0.21467078, -0.25404048, 0.039369706]\n",
      "Iter 5514, loss [-0.21818209, -0.2586351, 0.04045301]\n",
      "Iter 5515, loss [-0.2240437, -0.28504777, 0.061004072]\n",
      "Iter 5516, loss [-0.21234451, -0.2572472, 0.044902693]\n",
      "Iter 5517, loss [-0.21299034, -0.25025046, 0.03726011]\n",
      "Iter 5518, loss [-0.21664837, -0.256909, 0.04026065]\n",
      "Iter 5519, loss [-0.21422282, -0.2556188, 0.041395996]\n",
      "Iter 5520, loss [-0.20383361, -0.24239725, 0.03856363]\n",
      "Iter 5521, loss [-0.20727202, -0.24396223, 0.036690213]\n",
      "Iter 5522, loss [-0.20492111, -0.2461304, 0.04120929]\n",
      "Iter 5523, loss [-0.22832195, -0.26823926, 0.0399173]\n",
      "Iter 5524, loss [-0.20631012, -0.25593862, 0.049628492]\n",
      "Iter 5525, loss [-0.20296541, -0.2482383, 0.045272883]\n",
      "Iter 5526, loss [-0.21793763, -0.26287574, 0.044938102]\n",
      "Iter 5527, loss [-0.22609395, -0.2674793, 0.041385353]\n",
      "Iter 5528, loss [-0.20675108, -0.25327986, 0.04652878]\n",
      "Iter 5529, loss [-0.21599644, -0.25338128, 0.037384838]\n",
      "Iter 5530, loss [-0.24071822, -0.31648815, 0.07576993]\n",
      "Iter 5531, loss [-0.22087468, -0.26073608, 0.039861396]\n",
      "Iter 5532, loss [-0.20994747, -0.2531956, 0.043248147]\n",
      "Iter 5533, loss [-0.21204904, -0.25340962, 0.041360594]\n",
      "Iter 5534, loss [-0.20774907, -0.24569471, 0.037945647]\n",
      "Iter 5535, loss [-0.2177473, -0.25664166, 0.03889435]\n",
      "Iter 5536, loss [-0.22306749, -0.26639864, 0.043331154]\n",
      "Iter 5537, loss [-0.22660351, -0.26547232, 0.038868815]\n",
      "Iter 5538, loss [-0.21049023, -0.25813225, 0.04764202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5539, loss [-0.2234817, -0.26086232, 0.037380617]\n",
      "Iter 5540, loss [-0.21543011, -0.2557909, 0.040360775]\n",
      "Iter 5541, loss [-0.22411081, -0.26003045, 0.035919636]\n",
      "Iter 5542, loss [-0.20312895, -0.23850763, 0.035378683]\n",
      "Iter 5543, loss [-0.21945454, -0.2563648, 0.036910247]\n",
      "Iter 5544, loss [-0.23809353, -0.30503285, 0.06693932]\n",
      "Iter 5545, loss [-0.22072901, -0.25965485, 0.03892584]\n",
      "Iter 5546, loss [-0.20107952, -0.24551246, 0.044432946]\n",
      "Iter 5547, loss [-0.2245144, -0.26814967, 0.04363528]\n",
      "Iter 5548, loss [-0.22406499, -0.26090243, 0.036837444]\n",
      "Iter 5549, loss [-0.22520238, -0.26672557, 0.04152318]\n",
      "Iter 5550, loss [-0.20672974, -0.25469702, 0.047967285]\n",
      "Iter 5551, loss [-0.22164203, -0.260847, 0.03920497]\n",
      "Iter 5552, loss [-0.22597641, -0.26500955, 0.039033137]\n",
      "Iter 5553, loss [-0.21012735, -0.24840353, 0.038276188]\n",
      "Iter 5554, loss [-0.22016832, -0.26109025, 0.040921926]\n",
      "Iter 5555, loss [-0.21654402, -0.2601865, 0.043642476]\n",
      "Iter 5556, loss [-0.20826697, -0.24872762, 0.04046064]\n",
      "Iter 5557, loss [-0.22580603, -0.26904494, 0.043238908]\n",
      "Iter 5558, loss [-0.21172553, -0.25007966, 0.038354136]\n",
      "Iter 5559, loss [-0.20436648, -0.2449103, 0.040543824]\n",
      "Iter 5560, loss [-0.22670978, -0.26715907, 0.040449295]\n",
      "Iter 5561, loss [-0.21070226, -0.2470913, 0.036389038]\n",
      "Iter 5562, loss [-0.20996615, -0.24787988, 0.03791373]\n",
      "Iter 5563, loss [-0.20366031, -0.24168354, 0.03802323]\n",
      "Iter 5564, loss [-0.22129571, -0.2602181, 0.03892239]\n",
      "Iter 5565, loss [-0.22911039, -0.2672502, 0.038139813]\n",
      "Iter 5566, loss [-0.22409312, -0.26341668, 0.039323553]\n",
      "Iter 5567, loss [-0.23133776, -0.2702238, 0.03888604]\n",
      "Iter 5568, loss [-0.20857312, -0.24933663, 0.040763512]\n",
      "Iter 5569, loss [-0.2258621, -0.26424104, 0.038378935]\n",
      "Iter 5570, loss [-0.2040077, -0.24355526, 0.039547566]\n",
      "Iter 5571, loss [-0.2299402, -0.2658359, 0.03589571]\n",
      "Iter 5572, loss [-0.21117397, -0.24795724, 0.036783278]\n",
      "Iter 5573, loss [-0.21441594, -0.25204122, 0.037625283]\n",
      "Iter 5574, loss [-0.22824737, -0.26429522, 0.036047842]\n",
      "Iter 5575, loss [-0.21672176, -0.256171, 0.03944923]\n",
      "Iter 5576, loss [-0.20454443, -0.24516092, 0.04061649]\n",
      "Iter 5577, loss [-0.2114304, -0.25283918, 0.041408774]\n",
      "Iter 5578, loss [-0.22784783, -0.29145575, 0.063607916]\n",
      "Iter 5579, loss [-0.22960044, -0.2695136, 0.039913163]\n",
      "Iter 5580, loss [-0.21915424, -0.2624885, 0.043334283]\n",
      "Iter 5581, loss [-0.20356666, -0.24141455, 0.037847888]\n",
      "Iter 5582, loss [-0.21269026, -0.25610682, 0.043416552]\n",
      "Iter 5583, loss [-0.2083554, -0.24511406, 0.036758658]\n",
      "Iter 5584, loss [-0.22685605, -0.26728573, 0.040429685]\n",
      "Iter 5585, loss [-0.30662835, -0.3161979, 0.009569559]\n",
      "Iter 5586, loss [-0.20871407, -0.2445605, 0.035846423]\n",
      "Iter 5587, loss [-0.20647508, -0.24364452, 0.037169438]\n",
      "Iter 5588, loss [-0.2262183, -0.3064506, 0.08023231]\n",
      "Iter 5589, loss [-0.21036614, -0.25079927, 0.04043312]\n",
      "Iter 5590, loss [-0.2267434, -0.26779932, 0.041055918]\n",
      "Iter 5591, loss [-0.24038517, -0.31920174, 0.07881656]\n",
      "Iter 5592, loss [-0.22781762, -0.30871934, 0.08090171]\n",
      "Iter 5593, loss [-0.22181319, -0.26238877, 0.04057558]\n",
      "Iter 5594, loss [-0.22657244, -0.26336133, 0.036788892]\n",
      "Iter 5595, loss [-0.20776525, -0.24421085, 0.03644561]\n",
      "Iter 5596, loss [-0.20006497, -0.23601508, 0.03595011]\n",
      "Iter 5597, loss [-0.21090393, -0.25003234, 0.039128404]\n",
      "Iter 5598, loss [-0.3065362, -0.31602448, 0.009488298]\n",
      "Iter 5599, loss [-0.21148263, -0.24963887, 0.038156237]\n",
      "Iter 5600, loss [-0.21035829, -0.25024703, 0.039888736]\n",
      "Iter 5601, loss [-0.217156, -0.25478008, 0.03762409]\n",
      "Iter 5602, loss [-0.21932665, -0.25525185, 0.035925202]\n",
      "Iter 5603, loss [-0.21664892, -0.25634602, 0.039697092]\n",
      "Iter 5604, loss [-0.2202205, -0.25886682, 0.038646307]\n",
      "Iter 5605, loss [-0.22140369, -0.28994614, 0.06854245]\n",
      "Iter 5606, loss [-0.21082161, -0.24991444, 0.03909282]\n",
      "Iter 5607, loss [-0.22693533, -0.27050194, 0.04356661]\n",
      "Iter 5608, loss [-0.20183074, -0.29550034, 0.09366959]\n",
      "Iter 5609, loss [-0.23105371, -0.26831383, 0.037260123]\n",
      "Iter 5610, loss [-0.23106687, -0.26818678, 0.03711991]\n",
      "Iter 5611, loss [-0.2102119, -0.25113842, 0.040926516]\n",
      "Iter 5612, loss [-0.21698873, -0.2562853, 0.039296582]\n",
      "Iter 5613, loss [-0.2233229, -0.2615833, 0.038260408]\n",
      "Iter 5614, loss [-0.20916083, -0.24671288, 0.03755204]\n",
      "Iter 5615, loss [-0.21512553, -0.2543761, 0.03925059]\n",
      "Iter 5616, loss [-0.21195751, -0.25223207, 0.040274553]\n",
      "Iter 5617, loss [-0.21879753, -0.25955948, 0.040761955]\n",
      "Iter 5618, loss [-0.21078043, -0.25367984, 0.042899415]\n",
      "Iter 5619, loss [-0.20243244, -0.24329293, 0.04086049]\n",
      "Iter 5620, loss [-0.22781932, -0.26843023, 0.040610917]\n",
      "Iter 5621, loss [-0.23415549, -0.3169785, 0.08282302]\n",
      "Iter 5622, loss [-0.22583996, -0.26450709, 0.03866713]\n",
      "Iter 5623, loss [-0.21966834, -0.25669366, 0.037025318]\n",
      "Iter 5624, loss [-0.23087844, -0.29859152, 0.06771308]\n",
      "Iter 5625, loss [-0.20432791, -0.24311438, 0.038786475]\n",
      "Iter 5626, loss [-0.21627274, -0.25697735, 0.04070461]\n",
      "Iter 5627, loss [-0.2119595, -0.25994742, 0.047987923]\n",
      "Iter 5628, loss [-0.21755609, -0.25702655, 0.03947047]\n",
      "Iter 5629, loss [-0.21829319, -0.26080218, 0.04250899]\n",
      "Iter 5630, loss [-0.21216431, -0.25245196, 0.040287644]\n",
      "Iter 5631, loss [-0.22585745, -0.26323283, 0.037375376]\n",
      "Iter 5632, loss [-0.21835865, -0.25738448, 0.039025825]\n",
      "Iter 5633, loss [-0.24030441, -0.30545545, 0.065151036]\n",
      "Iter 5634, loss [-0.21994843, -0.25813824, 0.038189813]\n",
      "Iter 5635, loss [-0.2161791, -0.25286222, 0.036683105]\n",
      "Iter 5636, loss [-0.21327303, -0.25069174, 0.03741871]\n",
      "Iter 5637, loss [-0.21895404, -0.25836095, 0.039406907]\n",
      "Iter 5638, loss [-0.20455472, -0.24241345, 0.037858725]\n",
      "Iter 5639, loss [-0.22143231, -0.25890896, 0.03747664]\n",
      "Iter 5640, loss [-0.21616569, -0.25542593, 0.03926024]\n",
      "Iter 5641, loss [-0.21032499, -0.2497771, 0.039452102]\n",
      "Iter 5642, loss [-0.21925797, -0.25869045, 0.039432485]\n",
      "Iter 5643, loss [-0.23510595, -0.2982859, 0.063179955]\n",
      "Iter 5644, loss [-0.2048554, -0.24455832, 0.03970292]\n",
      "Iter 5645, loss [-0.22784947, -0.27284727, 0.044997796]\n",
      "Iter 5646, loss [-0.21926762, -0.26029685, 0.04102923]\n",
      "Iter 5647, loss [-0.20719217, -0.24565011, 0.03845794]\n",
      "Iter 5648, loss [-0.21154276, -0.2501343, 0.038591534]\n",
      "Iter 5649, loss [-0.20436785, -0.24157348, 0.037205644]\n",
      "Iter 5650, loss [-0.21680608, -0.25642583, 0.039619744]\n",
      "Iter 5651, loss [-0.21242532, -0.24979715, 0.037371837]\n",
      "Iter 5652, loss [-0.24201156, -0.3083007, 0.06628914]\n",
      "Iter 5653, loss [-0.20993829, -0.24910988, 0.0391716]\n",
      "Iter 5654, loss [-0.19870959, -0.23390777, 0.03519818]\n",
      "Iter 5655, loss [-0.21897344, -0.25872105, 0.03974761]\n",
      "Iter 5656, loss [-0.2161014, -0.25966105, 0.043559656]\n",
      "Iter 5657, loss [-0.20730084, -0.24337663, 0.036075786]\n",
      "Iter 5658, loss [-0.22004564, -0.2591766, 0.039130967]\n",
      "Iter 5659, loss [-0.18099006, -0.22940882, 0.048418757]\n",
      "Iter 5660, loss [-0.2275466, -0.26518464, 0.037638042]\n",
      "Iter 5661, loss [-0.3056809, -0.31531703, 0.009636136]\n",
      "Iter 5662, loss [-0.21311209, -0.24920587, 0.03609378]\n",
      "Iter 5663, loss [-0.2093725, -0.24862525, 0.03925274]\n",
      "Iter 5664, loss [-0.21103355, -0.25158772, 0.040554173]\n",
      "Iter 5665, loss [-0.20702675, -0.24797904, 0.04095229]\n",
      "Iter 5666, loss [-0.2163701, -0.2545223, 0.03815219]\n",
      "Iter 5667, loss [-0.22836861, -0.2659526, 0.03758397]\n",
      "Iter 5668, loss [-0.2260217, -0.26584104, 0.039819337]\n",
      "Iter 5669, loss [-0.21330623, -0.2488981, 0.03559187]\n",
      "Iter 5670, loss [-0.21168803, -0.2497961, 0.038108077]\n",
      "Iter 5671, loss [-0.22752634, -0.26541814, 0.037891805]\n",
      "Iter 5672, loss [-0.22522737, -0.29225895, 0.06703158]\n",
      "Iter 5673, loss [-0.20631136, -0.24434967, 0.038038313]\n",
      "Iter 5674, loss [-0.2268154, -0.28871897, 0.06190356]\n",
      "Iter 5675, loss [-0.21194178, -0.25260425, 0.040662467]\n",
      "Iter 5676, loss [-0.22709408, -0.27441576, 0.047321673]\n",
      "Iter 5677, loss [-0.20411247, -0.3000496, 0.09593713]\n",
      "Iter 5678, loss [-0.20565003, -0.24211529, 0.03646525]\n",
      "Iter 5679, loss [-0.22133988, -0.2605821, 0.039242204]\n",
      "Iter 5680, loss [-0.22638394, -0.26504266, 0.03865872]\n",
      "Iter 5681, loss [-0.21887232, -0.25495237, 0.036080047]\n",
      "Iter 5682, loss [-0.2142779, -0.2528983, 0.03862042]\n",
      "Iter 5683, loss [-0.21075003, -0.25060898, 0.039858952]\n",
      "Iter 5684, loss [-0.2224949, -0.28504524, 0.06255033]\n",
      "Iter 5685, loss [-0.21412599, -0.2548096, 0.040683594]\n",
      "Iter 5686, loss [-0.2089966, -0.25297168, 0.043975085]\n",
      "Iter 5687, loss [-0.21188524, -0.25411427, 0.042229034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5688, loss [-0.2400794, -0.31721258, 0.07713317]\n",
      "Iter 5689, loss [-0.21010226, -0.24731393, 0.037211668]\n",
      "Iter 5690, loss [-0.21339208, -0.25463444, 0.04124237]\n",
      "Iter 5691, loss [-0.21533027, -0.25566074, 0.040330462]\n",
      "Iter 5692, loss [-0.22073737, -0.25883785, 0.03810048]\n",
      "Iter 5693, loss [-0.2111612, -0.25155082, 0.040389635]\n",
      "Iter 5694, loss [-0.22417127, -0.2626724, 0.03850113]\n",
      "Iter 5695, loss [-0.21542044, -0.2579337, 0.042513262]\n",
      "Iter 5696, loss [-0.21220303, -0.25199148, 0.039788462]\n",
      "Iter 5697, loss [-0.20362186, -0.2962668, 0.09264493]\n",
      "Iter 5698, loss [-0.20398438, -0.2430641, 0.039079726]\n",
      "Iter 5699, loss [-0.22147693, -0.257292, 0.035815075]\n",
      "Iter 5700, loss [-0.23140728, -0.26754194, 0.036134653]\n",
      "Iter 5701, loss [-0.21574314, -0.25495675, 0.039213613]\n",
      "Iter 5702, loss [-0.2241824, -0.26494968, 0.040767282]\n",
      "Iter 5703, loss [-0.1803719, -0.22900297, 0.048631072]\n",
      "Iter 5704, loss [-0.30715752, -0.31667647, 0.009518946]\n",
      "Iter 5705, loss [-0.21894781, -0.25969067, 0.04074286]\n",
      "Iter 5706, loss [-0.22070523, -0.26207718, 0.04137196]\n",
      "Iter 5707, loss [-0.24679048, -0.29042113, 0.043630645]\n",
      "Iter 5708, loss [-0.2059633, -0.2436284, 0.037665095]\n",
      "Iter 5709, loss [-0.21646763, -0.26123914, 0.044771504]\n",
      "Iter 5710, loss [-0.21758467, -0.2558619, 0.038277242]\n",
      "Iter 5711, loss [-0.21316767, -0.25338358, 0.04021591]\n",
      "Iter 5712, loss [-0.22606365, -0.26537588, 0.039312225]\n",
      "Iter 5713, loss [-0.22801632, -0.29717782, 0.0691615]\n",
      "Iter 5714, loss [-0.21829537, -0.2587224, 0.040427025]\n",
      "Iter 5715, loss [-0.2162078, -0.25860643, 0.04239864]\n",
      "Iter 5716, loss [-0.20391789, -0.24400239, 0.04008449]\n",
      "Iter 5717, loss [-0.22159089, -0.26320034, 0.04160945]\n",
      "Iter 5718, loss [-0.20823327, -0.24636896, 0.038135692]\n",
      "Iter 5719, loss [-0.20297465, -0.24282132, 0.039846666]\n",
      "Iter 5720, loss [-0.21288812, -0.253347, 0.040458884]\n",
      "Iter 5721, loss [-0.24007049, -0.27555278, 0.035482295]\n",
      "Iter 5722, loss [-0.2094017, -0.25258458, 0.043182876]\n",
      "Iter 5723, loss [-0.22657076, -0.2642477, 0.03767693]\n",
      "Iter 5724, loss [-0.2167023, -0.2563559, 0.03965361]\n",
      "Iter 5725, loss [-0.21031061, -0.25833896, 0.048028357]\n",
      "Iter 5726, loss [-0.22143856, -0.2603057, 0.03886714]\n",
      "Iter 5727, loss [-0.2240232, -0.26170087, 0.037677683]\n",
      "Iter 5728, loss [-0.30783305, -0.31713414, 0.009301101]\n",
      "Iter 5729, loss [-0.22198686, -0.26637328, 0.044386417]\n",
      "Iter 5730, loss [-0.23575908, -0.31008512, 0.07432603]\n",
      "Iter 5731, loss [-0.2238004, -0.26170823, 0.037907824]\n",
      "Iter 5732, loss [-0.22484908, -0.26668084, 0.04183176]\n",
      "Iter 5733, loss [-0.21255122, -0.25095198, 0.038400758]\n",
      "Iter 5734, loss [-0.22802565, -0.26842183, 0.040396176]\n",
      "Iter 5735, loss [-0.17964554, -0.2838805, 0.104234956]\n",
      "Iter 5736, loss [-0.20682783, -0.2487503, 0.041922465]\n",
      "Iter 5737, loss [-0.20373562, -0.23871331, 0.034977682]\n",
      "Iter 5738, loss [-0.2199796, -0.254874, 0.03489439]\n",
      "Iter 5739, loss [-0.20349135, -0.23787874, 0.034387395]\n",
      "Iter 5740, loss [-0.21625306, -0.25369084, 0.03743778]\n",
      "Iter 5741, loss [-0.21345705, -0.2517931, 0.038336042]\n",
      "Iter 5742, loss [-0.20403655, -0.24086012, 0.03682357]\n",
      "Iter 5743, loss [-0.2056589, -0.24737045, 0.04171155]\n",
      "Iter 5744, loss [-0.21182837, -0.2533087, 0.041480344]\n",
      "Iter 5745, loss [-0.2092437, -0.25008786, 0.040844154]\n",
      "Iter 5746, loss [-0.21818636, -0.26700026, 0.048813894]\n",
      "Iter 5747, loss [-0.21706297, -0.25882885, 0.041765884]\n",
      "Iter 5748, loss [-0.20812136, -0.24869455, 0.04057319]\n",
      "Iter 5749, loss [-0.21568191, -0.2534454, 0.037763484]\n",
      "Iter 5750, loss [-0.20875311, -0.24776858, 0.039015464]\n",
      "Iter 5751, loss [-0.30582452, -0.31520143, 0.009376903]\n",
      "Iter 5752, loss [-0.2261379, -0.265625, 0.039487086]\n",
      "Iter 5753, loss [-0.2113232, -0.249945, 0.038621794]\n",
      "Iter 5754, loss [-0.21498922, -0.2569553, 0.04196608]\n",
      "Iter 5755, loss [-0.21716361, -0.2565286, 0.039364975]\n",
      "Iter 5756, loss [-0.2064818, -0.24882846, 0.042346656]\n",
      "Iter 5757, loss [-0.19362786, -0.26469535, 0.071067475]\n",
      "Iter 5758, loss [-0.21522605, -0.25535038, 0.04012432]\n",
      "Iter 5759, loss [-0.21105337, -0.2526521, 0.041598745]\n",
      "Iter 5760, loss [-0.21602778, -0.25549197, 0.03946419]\n",
      "Iter 5761, loss [-0.20933254, -0.2501017, 0.040769145]\n",
      "Iter 5762, loss [-0.2170235, -0.25315046, 0.036126953]\n",
      "Iter 5763, loss [-0.22045372, -0.25715387, 0.03670014]\n",
      "Iter 5764, loss [-0.22527286, -0.26409525, 0.038822383]\n",
      "Iter 5765, loss [-0.21936952, -0.2586572, 0.03928767]\n",
      "Iter 5766, loss [-0.20890445, -0.2502662, 0.041361753]\n",
      "Iter 5767, loss [-0.20108141, -0.24357656, 0.042495143]\n",
      "Iter 5768, loss [-0.2171252, -0.29257914, 0.07545394]\n",
      "Iter 5769, loss [-0.21808355, -0.25453615, 0.036452603]\n",
      "Iter 5770, loss [-0.21252367, -0.25260288, 0.040079206]\n",
      "Iter 5771, loss [-0.21483345, -0.25330335, 0.038469896]\n",
      "Iter 5772, loss [-0.2284865, -0.30678675, 0.07830025]\n",
      "Iter 5773, loss [-0.21116868, -0.25193653, 0.040767852]\n",
      "Iter 5774, loss [-0.22449875, -0.26398346, 0.039484702]\n",
      "Iter 5775, loss [-0.20799537, -0.25288534, 0.04488997]\n",
      "Iter 5776, loss [-0.21992993, -0.26254418, 0.04261426]\n",
      "Iter 5777, loss [-0.20704031, -0.2475919, 0.04055158]\n",
      "Iter 5778, loss [-0.22709641, -0.26729032, 0.040193923]\n",
      "Iter 5779, loss [-0.21817362, -0.2566617, 0.038488083]\n",
      "Iter 5780, loss [-0.20503317, -0.24221274, 0.03717957]\n",
      "Iter 5781, loss [-0.21104965, -0.2472209, 0.036171265]\n",
      "Iter 5782, loss [-0.21132675, -0.24865496, 0.03732822]\n",
      "Iter 5783, loss [-0.20737773, -0.24783613, 0.040458396]\n",
      "Iter 5784, loss [-0.21104333, -0.24821326, 0.037169933]\n",
      "Iter 5785, loss [-0.21147338, -0.25095975, 0.039486386]\n",
      "Iter 5786, loss [-0.21030499, -0.25962347, 0.049318474]\n",
      "Iter 5787, loss [-0.22874112, -0.27190107, 0.043159947]\n",
      "Iter 5788, loss [-0.20872289, -0.27069825, 0.061975352]\n",
      "Iter 5789, loss [-0.21868621, -0.25712997, 0.038443755]\n",
      "Iter 5790, loss [-0.22120714, -0.2602157, 0.03900855]\n",
      "Iter 5791, loss [-0.20629233, -0.24298035, 0.036688007]\n",
      "Iter 5792, loss [-0.22672808, -0.26342332, 0.03669524]\n",
      "Iter 5793, loss [-0.212949, -0.25009012, 0.037141126]\n",
      "Iter 5794, loss [-0.22898969, -0.2686082, 0.039618522]\n",
      "Iter 5795, loss [-0.20935029, -0.25348863, 0.044138335]\n",
      "Iter 5796, loss [-0.21896276, -0.25983673, 0.04087397]\n",
      "Iter 5797, loss [-0.22599655, -0.26530325, 0.039306697]\n",
      "Iter 5798, loss [-0.204531, -0.24410607, 0.039575066]\n",
      "Iter 5799, loss [-0.2079291, -0.24987791, 0.041948806]\n",
      "Iter 5800, loss [-0.24214955, -0.30564585, 0.06349631]\n",
      "Iter 5801, loss [-0.22075935, -0.25921494, 0.03845559]\n",
      "Iter 5802, loss [-0.22157116, -0.26015112, 0.038579956]\n",
      "Iter 5803, loss [-0.21876685, -0.25679988, 0.038033023]\n",
      "Iter 5804, loss [-0.21346915, -0.25553387, 0.04206472]\n",
      "Iter 5805, loss [-0.21812183, -0.25606415, 0.037942313]\n",
      "Iter 5806, loss [-0.24073195, -0.32143283, 0.080700874]\n",
      "Iter 5807, loss [-0.22507055, -0.26968732, 0.044616774]\n",
      "Iter 5808, loss [-0.21105807, -0.25929102, 0.048232954]\n",
      "Iter 5809, loss [-0.21364465, -0.25003448, 0.036389828]\n",
      "Iter 5810, loss [-0.22112961, -0.2591673, 0.0380377]\n",
      "Iter 5811, loss [-0.21611843, -0.25494772, 0.03882929]\n",
      "Iter 5812, loss [-0.21275592, -0.2522133, 0.039457377]\n",
      "Iter 5813, loss [-0.21931909, -0.25744352, 0.038124427]\n",
      "Iter 5814, loss [-0.19479866, -0.27952322, 0.08472456]\n",
      "Iter 5815, loss [-0.22820428, -0.2674924, 0.039288126]\n",
      "Iter 5816, loss [-0.19973692, -0.23791163, 0.038174704]\n",
      "Iter 5817, loss [-0.2312342, -0.27026188, 0.03902769]\n",
      "Iter 5818, loss [-0.21852855, -0.2600326, 0.041504044]\n",
      "Iter 5819, loss [-0.23816684, -0.3056153, 0.06744846]\n",
      "Iter 5820, loss [-0.21678004, -0.25578916, 0.039009124]\n",
      "Iter 5821, loss [-0.212854, -0.25099733, 0.038143344]\n",
      "Iter 5822, loss [-0.2109363, -0.2568395, 0.04590322]\n",
      "Iter 5823, loss [-0.225806, -0.26193023, 0.03612423]\n",
      "Iter 5824, loss [-0.21120141, -0.24736664, 0.036165223]\n",
      "Iter 5825, loss [-0.21832027, -0.25778088, 0.039460614]\n",
      "Iter 5826, loss [-0.22049679, -0.2605923, 0.040095523]\n",
      "Iter 5827, loss [-0.21803148, -0.25794223, 0.039910752]\n",
      "Iter 5828, loss [-0.19766706, -0.24659255, 0.048925485]\n",
      "Iter 5829, loss [-0.22922349, -0.26865235, 0.03942886]\n",
      "Iter 5830, loss [-0.21347502, -0.2556642, 0.042189173]\n",
      "Iter 5831, loss [-0.2110233, -0.25143197, 0.040408675]\n",
      "Iter 5832, loss [-0.22550634, -0.26417994, 0.038673617]\n",
      "Iter 5833, loss [-0.21069117, -0.24952391, 0.03883274]\n",
      "Iter 5834, loss [-0.22332582, -0.2603728, 0.037046976]\n",
      "Iter 5835, loss [-0.21362492, -0.2548448, 0.04121989]\n",
      "Iter 5836, loss [-0.22588187, -0.26386872, 0.037986852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5837, loss [-0.21177128, -0.2502844, 0.03851312]\n",
      "Iter 5838, loss [-0.30775562, -0.31741038, 0.00965476]\n",
      "Iter 5839, loss [-0.21912894, -0.25676766, 0.037638728]\n",
      "Iter 5840, loss [-0.20842771, -0.24605222, 0.037624512]\n",
      "Iter 5841, loss [-0.2110494, -0.26001003, 0.04896064]\n",
      "Iter 5842, loss [-0.22689551, -0.26549125, 0.038595736]\n",
      "Iter 5843, loss [-0.1956492, -0.28286153, 0.08721232]\n",
      "Iter 5844, loss [-0.20439124, -0.29417807, 0.08978682]\n",
      "Iter 5845, loss [-0.21629809, -0.25661695, 0.04031886]\n",
      "Iter 5846, loss [-0.21146989, -0.25373828, 0.042268388]\n",
      "Iter 5847, loss [-0.21997407, -0.2652851, 0.04531103]\n",
      "Iter 5848, loss [-0.20549649, -0.24677134, 0.041274842]\n",
      "Iter 5849, loss [-0.20833117, -0.2715326, 0.06320142]\n",
      "Iter 5850, loss [-0.22694477, -0.2631076, 0.03616283]\n",
      "Iter 5851, loss [-0.20721062, -0.24094802, 0.033737406]\n",
      "Iter 5852, loss [-0.2240538, -0.26048312, 0.036429316]\n",
      "Iter 5853, loss [-0.20269933, -0.24189073, 0.039191402]\n",
      "Iter 5854, loss [-0.2101107, -0.2485738, 0.03846311]\n",
      "Iter 5855, loss [-0.2231805, -0.2670037, 0.043823175]\n",
      "Iter 5856, loss [-0.22150397, -0.26178446, 0.0402805]\n",
      "Iter 5857, loss [-0.22646993, -0.26610827, 0.039638348]\n",
      "Iter 5858, loss [-0.20285016, -0.2444887, 0.041638535]\n",
      "Iter 5859, loss [-0.22712605, -0.26584977, 0.038723722]\n",
      "Iter 5860, loss [-0.226621, -0.26658705, 0.039966047]\n",
      "Iter 5861, loss [-0.21938129, -0.2592646, 0.039883304]\n",
      "Iter 5862, loss [-0.21083736, -0.25334892, 0.04251155]\n",
      "Iter 5863, loss [-0.21690044, -0.25489855, 0.037998106]\n",
      "Iter 5864, loss [-0.22095017, -0.27873707, 0.057786893]\n",
      "Iter 5865, loss [-0.21626866, -0.25434455, 0.0380759]\n",
      "Iter 5866, loss [-0.2221775, -0.26210645, 0.039928947]\n",
      "Iter 5867, loss [-0.21691023, -0.25784758, 0.040937353]\n",
      "Iter 5868, loss [-0.21576296, -0.25682035, 0.041057393]\n",
      "Iter 5869, loss [-0.2263177, -0.29001603, 0.06369832]\n",
      "Iter 5870, loss [-0.21686013, -0.25606903, 0.0392089]\n",
      "Iter 5871, loss [-0.2052391, -0.24266621, 0.037427112]\n",
      "Iter 5872, loss [-0.22517309, -0.2831476, 0.057974517]\n",
      "Iter 5873, loss [-0.22742362, -0.287393, 0.05996938]\n",
      "Iter 5874, loss [-0.2101085, -0.24773765, 0.03762914]\n",
      "Iter 5875, loss [-0.1994921, -0.23523232, 0.035740234]\n",
      "Iter 5876, loss [-0.21386325, -0.25481153, 0.04094828]\n",
      "Iter 5877, loss [-0.20292813, -0.24406348, 0.041135363]\n",
      "Iter 5878, loss [-0.23000449, -0.30206543, 0.07206094]\n",
      "Iter 5879, loss [-0.20241089, -0.24484134, 0.04243044]\n",
      "Iter 5880, loss [-0.22607756, -0.26523343, 0.03915587]\n",
      "Iter 5881, loss [-0.20858704, -0.24501798, 0.03643094]\n",
      "Iter 5882, loss [-0.21567965, -0.25424093, 0.03856128]\n",
      "Iter 5883, loss [-0.2376729, -0.29182845, 0.054155566]\n",
      "Iter 5884, loss [-0.2429096, -0.3204858, 0.077576205]\n",
      "Iter 5885, loss [-0.19799608, -0.24614133, 0.048145246]\n",
      "Iter 5886, loss [-0.21178284, -0.25305572, 0.04127288]\n",
      "Iter 5887, loss [-0.2018219, -0.24309607, 0.041274168]\n",
      "Iter 5888, loss [-0.21892886, -0.2587154, 0.039786536]\n",
      "Iter 5889, loss [-0.21920764, -0.25975648, 0.040548824]\n",
      "Iter 5890, loss [-0.22540483, -0.26610735, 0.040702514]\n",
      "Iter 5891, loss [-0.22151357, -0.25979188, 0.038278308]\n",
      "Iter 5892, loss [-0.24508275, -0.30840632, 0.06332357]\n",
      "Iter 5893, loss [-0.21267547, -0.24979235, 0.03711688]\n",
      "Iter 5894, loss [-0.22834009, -0.26598784, 0.03764776]\n",
      "Iter 5895, loss [-0.20840842, -0.24641353, 0.038005106]\n",
      "Iter 5896, loss [-0.21382114, -0.24964434, 0.03582319]\n",
      "Iter 5897, loss [-0.21234672, -0.25257564, 0.04022892]\n",
      "Iter 5898, loss [-0.22086962, -0.26261914, 0.041749522]\n",
      "Iter 5899, loss [-0.22056983, -0.2613839, 0.040814057]\n",
      "Iter 5900, loss [-0.2198734, -0.2574037, 0.037530303]\n",
      "Iter 5901, loss [-0.22102416, -0.2606374, 0.03961324]\n",
      "Iter 5902, loss [-0.23019502, -0.26789826, 0.03770325]\n",
      "Iter 5903, loss [-0.21654207, -0.25629196, 0.03974989]\n",
      "Iter 5904, loss [-0.20963922, -0.24725501, 0.03761579]\n",
      "Iter 5905, loss [-0.3077342, -0.31699955, 0.009265366]\n",
      "Iter 5906, loss [-0.21170971, -0.24839568, 0.036685966]\n",
      "Iter 5907, loss [-0.21383837, -0.25502688, 0.04118851]\n",
      "Iter 5908, loss [-0.3079328, -0.3172001, 0.0092672985]\n",
      "Iter 5909, loss [-0.20801055, -0.24956769, 0.04155714]\n",
      "Iter 5910, loss [-0.21719737, -0.2546216, 0.037424218]\n",
      "Iter 5911, loss [-0.22585249, -0.26162925, 0.035776757]\n",
      "Iter 5912, loss [-0.22550285, -0.2655434, 0.040040553]\n",
      "Iter 5913, loss [-0.22732033, -0.26342407, 0.036103737]\n",
      "Iter 5914, loss [-0.20973426, -0.24968207, 0.039947804]\n",
      "Iter 5915, loss [-0.22483346, -0.2623414, 0.03750796]\n",
      "Iter 5916, loss [-0.21533325, -0.2540606, 0.03872735]\n",
      "Iter 5917, loss [-0.2177062, -0.25617513, 0.03846892]\n",
      "Iter 5918, loss [-0.24508776, -0.30833107, 0.063243315]\n",
      "Iter 5919, loss [-0.20900705, -0.3011445, 0.092137456]\n",
      "Iter 5920, loss [-0.21174687, -0.25287214, 0.041125264]\n",
      "Iter 5921, loss [-0.21058711, -0.3015861, 0.09099897]\n",
      "Iter 5922, loss [-0.21956474, -0.2590932, 0.039528463]\n",
      "Iter 5923, loss [-0.22114676, -0.2603313, 0.039184548]\n",
      "Iter 5924, loss [-0.20365138, -0.24722165, 0.04357026]\n",
      "Iter 5925, loss [-0.22591853, -0.26449966, 0.038581133]\n",
      "Iter 5926, loss [-0.24775468, -0.29027256, 0.04251788]\n",
      "Iter 5927, loss [-0.21487655, -0.25634015, 0.041463595]\n",
      "Iter 5928, loss [-0.22959512, -0.2692647, 0.039669577]\n",
      "Iter 5929, loss [-0.21972238, -0.25686565, 0.037143275]\n",
      "Iter 5930, loss [-0.21634498, -0.2564817, 0.040136717]\n",
      "Iter 5931, loss [-0.1986211, -0.24578018, 0.047159087]\n",
      "Iter 5932, loss [-0.20925096, -0.24638851, 0.037137546]\n",
      "Iter 5933, loss [-0.20869336, -0.24705043, 0.03835708]\n",
      "Iter 5934, loss [-0.2186862, -0.2576834, 0.03899721]\n",
      "Iter 5935, loss [-0.21146166, -0.25946033, 0.047998663]\n",
      "Iter 5936, loss [-0.22509831, -0.2854195, 0.060321175]\n",
      "Iter 5937, loss [-0.21188863, -0.24822116, 0.036332533]\n",
      "Iter 5938, loss [-0.24567023, -0.30721277, 0.061542533]\n",
      "Iter 5939, loss [-0.21090695, -0.24867362, 0.037766665]\n",
      "Iter 5940, loss [-0.21372199, -0.25472012, 0.040998124]\n",
      "Iter 5941, loss [-0.21836062, -0.2796712, 0.06131057]\n",
      "Iter 5942, loss [-0.2280058, -0.27416232, 0.046156526]\n",
      "Iter 5943, loss [-0.30599004, -0.31561682, 0.009626785]\n",
      "Iter 5944, loss [-0.21243884, -0.2581094, 0.045670554]\n",
      "Iter 5945, loss [-0.21737032, -0.25613314, 0.03876282]\n",
      "Iter 5946, loss [-0.24016142, -0.27522972, 0.03506831]\n",
      "Iter 5947, loss [-0.24816039, -0.29143837, 0.043277975]\n",
      "Iter 5948, loss [-0.21096702, -0.2569397, 0.045972686]\n",
      "Iter 5949, loss [-0.22968966, -0.29811084, 0.06842118]\n",
      "Iter 5950, loss [-0.2187041, -0.25681722, 0.03811312]\n",
      "Iter 5951, loss [-0.21056925, -0.24967876, 0.039109513]\n",
      "Iter 5952, loss [-0.21888866, -0.26161358, 0.04272492]\n",
      "Iter 5953, loss [-0.20634997, -0.2442385, 0.03788852]\n",
      "Iter 5954, loss [-0.22288865, -0.26808548, 0.04519683]\n",
      "Iter 5955, loss [-0.21227662, -0.25172567, 0.03944905]\n",
      "Iter 5956, loss [-0.24083763, -0.31801555, 0.077177905]\n",
      "Iter 5957, loss [-0.23045342, -0.2676628, 0.037209373]\n",
      "Iter 5958, loss [-0.22559346, -0.26618183, 0.04058836]\n",
      "Iter 5959, loss [-0.2208726, -0.26126388, 0.040391278]\n",
      "Iter 5960, loss [-0.22822866, -0.27394077, 0.04571212]\n",
      "Iter 5961, loss [-0.20773962, -0.24976255, 0.04202292]\n",
      "Iter 5962, loss [-0.22070776, -0.26209274, 0.04138498]\n",
      "Iter 5963, loss [-0.22600836, -0.2650656, 0.039057247]\n",
      "Iter 5964, loss [-0.22837408, -0.26686907, 0.03849499]\n",
      "Iter 5965, loss [-0.3077036, -0.31703007, 0.009326473]\n",
      "Iter 5966, loss [-0.2062665, -0.24408425, 0.03781777]\n",
      "Iter 5967, loss [-0.23099305, -0.2669935, 0.03600044]\n",
      "Iter 5968, loss [-0.2481727, -0.29202503, 0.04385233]\n",
      "Iter 5969, loss [-0.21529758, -0.25372118, 0.038423605]\n",
      "Iter 5970, loss [-0.21240114, -0.2551496, 0.042748466]\n",
      "Iter 5971, loss [-0.2113357, -0.2587483, 0.047412585]\n",
      "Iter 5972, loss [-0.21190435, -0.25174534, 0.03984099]\n",
      "Iter 5973, loss [-0.21814366, -0.26231778, 0.044174116]\n",
      "Iter 5974, loss [-0.2163082, -0.25593853, 0.039630316]\n",
      "Iter 5975, loss [-0.21200636, -0.24944228, 0.03743592]\n",
      "Iter 5976, loss [-0.1931043, -0.29276073, 0.099656425]\n",
      "Iter 5977, loss [-0.21335848, -0.2533554, 0.039996937]\n",
      "Iter 5978, loss [-0.20429721, -0.27732247, 0.07302526]\n",
      "Iter 5979, loss [-0.2068365, -0.24618179, 0.03934528]\n",
      "Iter 5980, loss [-0.21755362, -0.25689918, 0.039345562]\n",
      "Iter 5981, loss [-0.21218601, -0.25058413, 0.038398113]\n",
      "Iter 5982, loss [-0.21062937, -0.25752485, 0.046895467]\n",
      "Iter 5983, loss [-0.22913757, -0.27001095, 0.040873375]\n",
      "Iter 5984, loss [-0.23039484, -0.3167473, 0.08635247]\n",
      "Iter 5985, loss [-0.22465023, -0.26722467, 0.042574428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5986, loss [-0.21056697, -0.24987625, 0.039309286]\n",
      "Iter 5987, loss [-0.20660773, -0.24188669, 0.03527896]\n",
      "Iter 5988, loss [-0.21415098, -0.25347674, 0.03932576]\n",
      "Iter 5989, loss [-0.21573406, -0.2552326, 0.039498538]\n",
      "Iter 5990, loss [-0.2282019, -0.26969427, 0.041492365]\n",
      "Iter 5991, loss [-0.22312719, -0.28263736, 0.059510164]\n",
      "Iter 5992, loss [-0.22152218, -0.25829127, 0.0367691]\n",
      "Iter 5993, loss [-0.20254076, -0.24350761, 0.040966853]\n",
      "Iter 5994, loss [-0.20424643, -0.24328598, 0.039039545]\n",
      "Iter 5995, loss [-0.20565021, -0.24379145, 0.038141236]\n",
      "Iter 5996, loss [-0.21327251, -0.24995914, 0.03668663]\n",
      "Iter 5997, loss [-0.18103229, -0.22815041, 0.047118124]\n",
      "Iter 5998, loss [-0.24338998, -0.30462375, 0.06123377]\n",
      "Iter 5999, loss [-0.21151875, -0.25144994, 0.03993119]\n",
      "Iter 6000, loss [-0.21523194, -0.25566578, 0.04043384]\n",
      "Iter 6001, loss [-0.22056723, -0.26089114, 0.04032392]\n",
      "Iter 6002, loss [-0.1984862, -0.24699017, 0.048503976]\n",
      "Iter 6003, loss [-0.22015715, -0.26324508, 0.04308793]\n",
      "Iter 6004, loss [-0.21041699, -0.24909295, 0.038675968]\n",
      "Iter 6005, loss [-0.21651025, -0.27842325, 0.061912995]\n",
      "Iter 6006, loss [-0.22617447, -0.26271525, 0.03654077]\n",
      "Iter 6007, loss [-0.21890914, -0.2608575, 0.04194834]\n",
      "Iter 6008, loss [-0.21130675, -0.24910386, 0.037797116]\n",
      "Iter 6009, loss [-0.22849134, -0.26638815, 0.037896812]\n",
      "Iter 6010, loss [-0.22051702, -0.26035485, 0.039837822]\n",
      "Iter 6011, loss [-0.21131557, -0.25826165, 0.046946075]\n",
      "Iter 6012, loss [-0.20846951, -0.24588993, 0.03742042]\n",
      "Iter 6013, loss [-0.30798587, -0.31720003, 0.009214152]\n",
      "Iter 6014, loss [-0.30791602, -0.31704924, 0.009133207]\n",
      "Iter 6015, loss [-0.22091463, -0.25929463, 0.038380004]\n",
      "Iter 6016, loss [-0.20495073, -0.24508585, 0.04013511]\n",
      "Iter 6017, loss [-0.2062901, -0.2422852, 0.035995103]\n",
      "Iter 6018, loss [-0.22641096, -0.2656665, 0.039255552]\n",
      "Iter 6019, loss [-0.20796175, -0.2453635, 0.037401747]\n",
      "Iter 6020, loss [-0.2109792, -0.24944386, 0.038464665]\n",
      "Iter 6021, loss [-0.20354664, -0.24219911, 0.038652465]\n",
      "Iter 6022, loss [-0.22839631, -0.26722708, 0.03883077]\n",
      "Iter 6023, loss [-0.21177995, -0.25277475, 0.040994786]\n",
      "Iter 6024, loss [-0.21673085, -0.25763696, 0.040906113]\n",
      "Iter 6025, loss [-0.22424607, -0.26192987, 0.0376838]\n",
      "Iter 6026, loss [-0.21487978, -0.2523237, 0.0374439]\n",
      "Iter 6027, loss [-0.22708936, -0.26465, 0.037560623]\n",
      "Iter 6028, loss [-0.22697212, -0.26379216, 0.036820035]\n",
      "Iter 6029, loss [-0.21902423, -0.2576047, 0.038580462]\n",
      "Iter 6030, loss [-0.2213184, -0.2615669, 0.040248513]\n",
      "Iter 6031, loss [-0.207886, -0.24914916, 0.041263163]\n",
      "Iter 6032, loss [-0.2215203, -0.26055124, 0.039030943]\n",
      "Iter 6033, loss [-0.20813254, -0.25033385, 0.042201307]\n",
      "Iter 6034, loss [-0.20825347, -0.24986319, 0.041609727]\n",
      "Iter 6035, loss [-0.21968874, -0.25995734, 0.040268607]\n",
      "Iter 6036, loss [-0.21946108, -0.25583136, 0.036370274]\n",
      "Iter 6037, loss [-0.22883072, -0.26597401, 0.03714329]\n",
      "Iter 6038, loss [-0.21518439, -0.2549868, 0.0398024]\n",
      "Iter 6039, loss [-0.2142027, -0.24985017, 0.035647463]\n",
      "Iter 6040, loss [-0.30863595, -0.31777802, 0.009142073]\n",
      "Iter 6041, loss [-0.21579804, -0.25434643, 0.038548395]\n",
      "Iter 6042, loss [-0.24098805, -0.3205155, 0.07952746]\n",
      "Iter 6043, loss [-0.24681596, -0.30889857, 0.0620826]\n",
      "Iter 6044, loss [-0.22108093, -0.2606015, 0.039520554]\n",
      "Iter 6045, loss [-0.22493118, -0.26800025, 0.04306906]\n",
      "Iter 6046, loss [-0.21940541, -0.25609833, 0.03669291]\n",
      "Iter 6047, loss [-0.22071292, -0.26055554, 0.03984262]\n",
      "Iter 6048, loss [-0.23518509, -0.31476647, 0.07958138]\n",
      "Iter 6049, loss [-0.20565978, -0.24331442, 0.037654646]\n",
      "Iter 6050, loss [-0.21057758, -0.24995048, 0.039372906]\n",
      "Iter 6051, loss [-0.21139002, -0.2529285, 0.041538477]\n",
      "Iter 6052, loss [-0.22047529, -0.26012462, 0.039649345]\n",
      "Iter 6053, loss [-0.21586739, -0.2558764, 0.040009003]\n",
      "Iter 6054, loss [-0.20876816, -0.25175825, 0.04299008]\n",
      "Iter 6055, loss [-0.21752721, -0.26235297, 0.044825755]\n",
      "Iter 6056, loss [-0.21874005, -0.2588523, 0.04011226]\n",
      "Iter 6057, loss [-0.21259779, -0.25084192, 0.038244132]\n",
      "Iter 6058, loss [-0.21536858, -0.25432748, 0.038958892]\n",
      "Iter 6059, loss [-0.21748137, -0.25557438, 0.038093]\n",
      "Iter 6060, loss [-0.2100384, -0.25304765, 0.04300925]\n",
      "Iter 6061, loss [-0.22067285, -0.26048163, 0.039808776]\n",
      "Iter 6062, loss [-0.20432451, -0.24399038, 0.039665863]\n",
      "Iter 6063, loss [-0.22114567, -0.26029864, 0.03915296]\n",
      "Iter 6064, loss [-0.20328057, -0.24670926, 0.043428686]\n",
      "Iter 6065, loss [-0.2078754, -0.24833404, 0.04045863]\n",
      "Iter 6066, loss [-0.22993281, -0.2673546, 0.037421785]\n",
      "Iter 6067, loss [-0.21440604, -0.25935423, 0.044948183]\n",
      "Iter 6068, loss [-0.18164226, -0.22969091, 0.04804864]\n",
      "Iter 6069, loss [-0.22159413, -0.26280832, 0.041214198]\n",
      "Iter 6070, loss [-0.21228416, -0.2528522, 0.040568035]\n",
      "Iter 6071, loss [-0.20453571, -0.24387029, 0.03933458]\n",
      "Iter 6072, loss [-0.21719989, -0.25770575, 0.040505853]\n",
      "Iter 6073, loss [-0.20839798, -0.24956018, 0.04116219]\n",
      "Iter 6074, loss [-0.2088128, -0.24535733, 0.036544528]\n",
      "Iter 6075, loss [-0.21354789, -0.25348043, 0.039932545]\n",
      "Iter 6076, loss [-0.21718326, -0.25722218, 0.04003891]\n",
      "Iter 6077, loss [-0.21190304, -0.24931139, 0.03740836]\n",
      "Iter 6078, loss [-0.21922556, -0.2579176, 0.03869205]\n",
      "Iter 6079, loss [-0.21082519, -0.24999903, 0.039173838]\n",
      "Iter 6080, loss [-0.22447652, -0.2627218, 0.038245283]\n",
      "Iter 6081, loss [-0.21788767, -0.25578076, 0.037893094]\n",
      "Iter 6082, loss [-0.21533696, -0.25619817, 0.0408612]\n",
      "Iter 6083, loss [-0.21188831, -0.25070286, 0.03881454]\n",
      "Iter 6084, loss [-0.20904858, -0.24532194, 0.03627336]\n",
      "Iter 6085, loss [-0.24918005, -0.29209718, 0.04291714]\n",
      "Iter 6086, loss [-0.24138246, -0.27601874, 0.03463627]\n",
      "Iter 6087, loss [-0.21097818, -0.24923658, 0.03825841]\n",
      "Iter 6088, loss [-0.20812652, -0.24932952, 0.041203015]\n",
      "Iter 6089, loss [-0.19882895, -0.24578945, 0.0469605]\n",
      "Iter 6090, loss [-0.21955872, -0.2601539, 0.04059518]\n",
      "Iter 6091, loss [-0.20860247, -0.2503529, 0.041750412]\n",
      "Iter 6092, loss [-0.22916408, -0.26722884, 0.03806476]\n",
      "Iter 6093, loss [-0.21145633, -0.2506919, 0.039235562]\n",
      "Iter 6094, loss [-0.22010168, -0.25756037, 0.037458688]\n",
      "Iter 6095, loss [-0.229272, -0.29209468, 0.062822685]\n",
      "Iter 6096, loss [-0.22577628, -0.26648194, 0.040705655]\n",
      "Iter 6097, loss [-0.21864632, -0.25495052, 0.036304213]\n",
      "Iter 6098, loss [-0.22475229, -0.2618549, 0.037102595]\n",
      "Iter 6099, loss [-0.22568808, -0.26603088, 0.040342793]\n",
      "Iter 6100, loss [-0.21258509, -0.2533071, 0.04072202]\n",
      "Iter 6101, loss [-0.24308893, -0.31516346, 0.072074525]\n",
      "Iter 6102, loss [-0.21287073, -0.25747135, 0.04460062]\n",
      "Iter 6103, loss [-0.2213239, -0.2615361, 0.040212177]\n",
      "Iter 6104, loss [-0.20821787, -0.25067532, 0.042457443]\n",
      "Iter 6105, loss [-0.22909991, -0.2673503, 0.03825037]\n",
      "Iter 6106, loss [-0.22698711, -0.2652098, 0.03822268]\n",
      "Iter 6107, loss [-0.21945074, -0.25791323, 0.038462497]\n",
      "Iter 6108, loss [-0.18200725, -0.22970869, 0.04770143]\n",
      "Iter 6109, loss [-0.22198044, -0.25835264, 0.0363722]\n",
      "Iter 6110, loss [-0.21932952, -0.25746426, 0.03813474]\n",
      "Iter 6111, loss [-0.21730727, -0.2589285, 0.041621245]\n",
      "Iter 6112, loss [-0.22861277, -0.2677589, 0.039146144]\n",
      "Iter 6113, loss [-0.21942508, -0.259071, 0.039645907]\n",
      "Iter 6114, loss [-0.22584675, -0.30780306, 0.08195631]\n",
      "Iter 6115, loss [-0.2144037, -0.25087053, 0.036466822]\n",
      "Iter 6116, loss [-0.22237943, -0.26311433, 0.040734902]\n",
      "Iter 6117, loss [-0.21701066, -0.2565997, 0.039589033]\n",
      "Iter 6118, loss [-0.21252382, -0.25127205, 0.038748242]\n",
      "Iter 6119, loss [-0.21088913, -0.2505661, 0.03967697]\n",
      "Iter 6120, loss [-0.21824744, -0.25595263, 0.03770518]\n",
      "Iter 6121, loss [-0.22696505, -0.26385713, 0.036892068]\n",
      "Iter 6122, loss [-0.22449902, -0.3045066, 0.080007575]\n",
      "Iter 6123, loss [-0.21192223, -0.25035354, 0.038431324]\n",
      "Iter 6124, loss [-0.21635446, -0.2583552, 0.042000733]\n",
      "Iter 6125, loss [-0.21776232, -0.25573906, 0.03797675]\n",
      "Iter 6126, loss [-0.22584021, -0.28876132, 0.06292111]\n",
      "Iter 6127, loss [-0.21221973, -0.25676554, 0.04454581]\n",
      "Iter 6128, loss [-0.21161737, -0.2510923, 0.03947495]\n",
      "Iter 6129, loss [-0.21778484, -0.25812906, 0.040344223]\n",
      "Iter 6130, loss [-0.21295333, -0.2570003, 0.044046964]\n",
      "Iter 6131, loss [-0.2058614, -0.24353237, 0.03767097]\n",
      "Iter 6132, loss [-0.21926278, -0.25769633, 0.038433548]\n",
      "Iter 6133, loss [-0.23211768, -0.26877952, 0.036661834]\n",
      "Iter 6134, loss [-0.22104678, -0.25957638, 0.038529605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6135, loss [-0.21933506, -0.2578738, 0.03853874]\n",
      "Iter 6136, loss [-0.21986485, -0.2572669, 0.03740207]\n",
      "Iter 6137, loss [-0.21142253, -0.25046587, 0.039043333]\n",
      "Iter 6138, loss [-0.22979994, -0.27357468, 0.04377474]\n",
      "Iter 6139, loss [-0.2091195, -0.24595979, 0.036840297]\n",
      "Iter 6140, loss [-0.21692173, -0.25817123, 0.041249495]\n",
      "Iter 6141, loss [-0.226171, -0.26765385, 0.04148285]\n",
      "Iter 6142, loss [-0.24259943, -0.31298527, 0.07038584]\n",
      "Iter 6143, loss [-0.22557902, -0.26854584, 0.042966813]\n",
      "Iter 6144, loss [-0.21691634, -0.2559003, 0.03898396]\n",
      "Iter 6145, loss [-0.21145587, -0.24963087, 0.038175005]\n",
      "Iter 6146, loss [-0.21936679, -0.26047817, 0.04111138]\n",
      "Iter 6147, loss [-0.21920215, -0.25707424, 0.03787209]\n",
      "Iter 6148, loss [-0.22927366, -0.26992482, 0.040651154]\n",
      "Iter 6149, loss [-0.23000996, -0.26993194, 0.039921988]\n",
      "Iter 6150, loss [-0.22463922, -0.26275712, 0.0381179]\n",
      "Iter 6151, loss [-0.23028272, -0.26832423, 0.038041502]\n",
      "Iter 6152, loss [-0.20570742, -0.29748604, 0.09177862]\n",
      "Iter 6153, loss [-0.22803122, -0.27209574, 0.044064514]\n",
      "Iter 6154, loss [-0.2212548, -0.2590965, 0.037841707]\n",
      "Iter 6155, loss [-0.22670925, -0.26256457, 0.035855316]\n",
      "Iter 6156, loss [-0.21478748, -0.25608465, 0.041297168]\n",
      "Iter 6157, loss [-0.21944788, -0.2592809, 0.039833006]\n",
      "Iter 6158, loss [-0.24128747, -0.27620736, 0.03491988]\n",
      "Iter 6159, loss [-0.22224075, -0.25955766, 0.03731691]\n",
      "Iter 6160, loss [-0.21136758, -0.25002813, 0.03866056]\n",
      "Iter 6161, loss [-0.2302775, -0.26840603, 0.038128536]\n",
      "Iter 6162, loss [-0.2179117, -0.25502318, 0.037111476]\n",
      "Iter 6163, loss [-0.2059668, -0.25500965, 0.049042847]\n",
      "Iter 6164, loss [-0.21424791, -0.2504163, 0.03616839]\n",
      "Iter 6165, loss [-0.22105344, -0.26213142, 0.041077983]\n",
      "Iter 6166, loss [-0.23694527, -0.31061435, 0.073669076]\n",
      "Iter 6167, loss [-0.24845675, -0.29070476, 0.04224801]\n",
      "Iter 6168, loss [-0.21670341, -0.25721565, 0.04051223]\n",
      "Iter 6169, loss [-0.21611752, -0.25367916, 0.037561636]\n",
      "Iter 6170, loss [-0.2009293, -0.24353936, 0.042610064]\n",
      "Iter 6171, loss [-0.23154134, -0.3018723, 0.07033097]\n",
      "Iter 6172, loss [-0.20385638, -0.24497274, 0.041116364]\n",
      "Iter 6173, loss [-0.21111932, -0.25460324, 0.04348391]\n",
      "Iter 6174, loss [-0.212516, -0.2571942, 0.044678196]\n",
      "Iter 6175, loss [-0.21599507, -0.2567724, 0.040777333]\n",
      "Iter 6176, loss [-0.20662339, -0.24887379, 0.04225039]\n",
      "Iter 6177, loss [-0.20733696, -0.27382416, 0.06648719]\n",
      "Iter 6178, loss [-0.24010149, -0.27414, 0.034038506]\n",
      "Iter 6179, loss [-0.22705057, -0.2877308, 0.06068024]\n",
      "Iter 6180, loss [-0.21029174, -0.24314028, 0.032848537]\n",
      "Iter 6181, loss [-0.21031946, -0.24918713, 0.038867675]\n",
      "Iter 6182, loss [-0.20627353, -0.282242, 0.075968474]\n",
      "Iter 6183, loss [-0.21023752, -0.24872017, 0.03848265]\n",
      "Iter 6184, loss [-0.23013528, -0.27013212, 0.039996844]\n",
      "Iter 6185, loss [-0.2174067, -0.259728, 0.042321306]\n",
      "Iter 6186, loss [-0.23178001, -0.3154198, 0.083639786]\n",
      "Iter 6187, loss [-0.20852801, -0.2500156, 0.041487567]\n",
      "Iter 6188, loss [-0.24740511, -0.29159948, 0.044194378]\n",
      "Iter 6189, loss [-0.20991528, -0.25394636, 0.04403109]\n",
      "Iter 6190, loss [-0.21653095, -0.2552782, 0.038747244]\n",
      "Iter 6191, loss [-0.21520942, -0.25048605, 0.035276614]\n",
      "Iter 6192, loss [-0.21255234, -0.24754658, 0.03499424]\n",
      "Iter 6193, loss [-0.21062373, -0.25196004, 0.04133631]\n",
      "Iter 6194, loss [-0.20776169, -0.24698666, 0.039224967]\n",
      "Iter 6195, loss [-0.20930684, -0.25980404, 0.0504972]\n",
      "Iter 6196, loss [-0.22018495, -0.2623708, 0.04218584]\n",
      "Iter 6197, loss [-0.21716948, -0.25741708, 0.040247608]\n",
      "Iter 6198, loss [-0.21567234, -0.25869414, 0.04302179]\n",
      "Iter 6199, loss [-0.22511944, -0.27032533, 0.045205884]\n",
      "Iter 6200, loss [-0.23656388, -0.294356, 0.05779211]\n",
      "Iter 6201, loss [-0.21170667, -0.25195143, 0.040244758]\n",
      "Iter 6202, loss [-0.22793359, -0.26356295, 0.035629354]\n",
      "Iter 6203, loss [-0.21529792, -0.24858947, 0.033291545]\n",
      "Iter 6204, loss [-0.20540339, -0.2508362, 0.0454328]\n",
      "Iter 6205, loss [-0.2094164, -0.25012162, 0.040705215]\n",
      "Iter 6206, loss [-0.20485511, -0.24423939, 0.039384276]\n",
      "Iter 6207, loss [-0.21808235, -0.25584856, 0.0377662]\n",
      "Iter 6208, loss [-0.21818598, -0.2572065, 0.039020523]\n",
      "Iter 6209, loss [-0.21589999, -0.25935072, 0.043450728]\n",
      "Iter 6210, loss [-0.22315142, -0.26416913, 0.041017704]\n",
      "Iter 6211, loss [-0.21299104, -0.25698408, 0.043993037]\n",
      "Iter 6212, loss [-0.21645384, -0.2566496, 0.040195774]\n",
      "Iter 6213, loss [-0.2206477, -0.2585975, 0.0379498]\n",
      "Iter 6214, loss [-0.21100718, -0.24660632, 0.035599135]\n",
      "Iter 6215, loss [-0.21830982, -0.25640896, 0.038099136]\n",
      "Iter 6216, loss [-0.21456698, -0.25354442, 0.038977444]\n",
      "Iter 6217, loss [-0.21789575, -0.2622875, 0.04439175]\n",
      "Iter 6218, loss [-0.2189482, -0.26008964, 0.041141436]\n",
      "Iter 6219, loss [-0.20426953, -0.24510834, 0.0408388]\n",
      "Iter 6220, loss [-0.21402314, -0.26072356, 0.046700414]\n",
      "Iter 6221, loss [-0.203301, -0.24350248, 0.04020148]\n",
      "Iter 6222, loss [-0.21828249, -0.2567994, 0.038516916]\n",
      "Iter 6223, loss [-0.21687335, -0.2591064, 0.042233046]\n",
      "Iter 6224, loss [-0.18080255, -0.22957017, 0.04876762]\n",
      "Iter 6225, loss [-0.22957683, -0.2671147, 0.037537873]\n",
      "Iter 6226, loss [-0.18165895, -0.22996324, 0.048304286]\n",
      "Iter 6227, loss [-0.21276397, -0.25660983, 0.04384586]\n",
      "Iter 6228, loss [-0.22726278, -0.28642544, 0.059162658]\n",
      "Iter 6229, loss [-0.22268042, -0.2672923, 0.04461188]\n",
      "Iter 6230, loss [-0.30646732, -0.31572032, 0.009252999]\n",
      "Iter 6231, loss [-0.21105133, -0.2573058, 0.046254467]\n",
      "Iter 6232, loss [-0.21859843, -0.25675604, 0.038157616]\n",
      "Iter 6233, loss [-0.21833773, -0.26150033, 0.0431626]\n",
      "Iter 6234, loss [-0.19972508, -0.23542866, 0.035703585]\n",
      "Iter 6235, loss [-0.21012312, -0.25260335, 0.04248023]\n",
      "Iter 6236, loss [-0.2129582, -0.25434214, 0.04138394]\n",
      "Iter 6237, loss [-0.21136472, -0.26025048, 0.04888577]\n",
      "Iter 6238, loss [-0.24582472, -0.3096429, 0.063818194]\n",
      "Iter 6239, loss [-0.21035898, -0.2533324, 0.04297343]\n",
      "Iter 6240, loss [-0.22726047, -0.2654256, 0.03816513]\n",
      "Iter 6241, loss [-0.21210282, -0.2513264, 0.039223593]\n",
      "Iter 6242, loss [-0.2029491, -0.24252401, 0.0395749]\n",
      "Iter 6243, loss [-0.2185677, -0.2633149, 0.04474721]\n",
      "Iter 6244, loss [-0.21619114, -0.2555452, 0.039354064]\n",
      "Iter 6245, loss [-0.22243881, -0.26005852, 0.037619703]\n",
      "Iter 6246, loss [-0.21220589, -0.25003797, 0.03783209]\n",
      "Iter 6247, loss [-0.2066814, -0.24369349, 0.03701208]\n",
      "Iter 6248, loss [-0.2468771, -0.3112909, 0.06441378]\n",
      "Iter 6249, loss [-0.22717191, -0.2662261, 0.039054196]\n",
      "Iter 6250, loss [-0.21149549, -0.25126112, 0.03976562]\n",
      "Iter 6251, loss [-0.21710587, -0.257021, 0.039915152]\n",
      "Iter 6252, loss [-0.20816466, -0.24984188, 0.04167723]\n",
      "Iter 6253, loss [-0.20669565, -0.2434652, 0.036769554]\n",
      "Iter 6254, loss [-0.20834005, -0.24913475, 0.040794704]\n",
      "Iter 6255, loss [-0.21856517, -0.25506464, 0.036499463]\n",
      "Iter 6256, loss [-0.21988623, -0.26004812, 0.040161893]\n",
      "Iter 6257, loss [-0.22994943, -0.2689016, 0.038952157]\n",
      "Iter 6258, loss [-0.22974311, -0.29288158, 0.06313847]\n",
      "Iter 6259, loss [-0.21184154, -0.25222564, 0.0403841]\n",
      "Iter 6260, loss [-0.21008134, -0.24848732, 0.038405985]\n",
      "Iter 6261, loss [-0.2213081, -0.2626818, 0.041373715]\n",
      "Iter 6262, loss [-0.21895206, -0.2567748, 0.037822753]\n",
      "Iter 6263, loss [-0.21611276, -0.25585806, 0.039745294]\n",
      "Iter 6264, loss [-0.22998288, -0.26817706, 0.03819418]\n",
      "Iter 6265, loss [-0.21679485, -0.25461215, 0.037817292]\n",
      "Iter 6266, loss [-0.21311578, -0.2559708, 0.042855024]\n",
      "Iter 6267, loss [-0.30800024, -0.31722492, 0.009224674]\n",
      "Iter 6268, loss [-0.21950541, -0.25633478, 0.03682937]\n",
      "Iter 6269, loss [-0.22774068, -0.27286243, 0.04512176]\n",
      "Iter 6270, loss [-0.22163112, -0.2606614, 0.039030273]\n",
      "Iter 6271, loss [-0.2409077, -0.276105, 0.03519728]\n",
      "Iter 6272, loss [-0.2214251, -0.26230535, 0.040880248]\n",
      "Iter 6273, loss [-0.21920896, -0.26176214, 0.042553186]\n",
      "Iter 6274, loss [-0.19861445, -0.24468108, 0.04606662]\n",
      "Iter 6275, loss [-0.21646473, -0.25638333, 0.03991861]\n",
      "Iter 6276, loss [-0.2198317, -0.25937063, 0.03953892]\n",
      "Iter 6277, loss [-0.21440193, -0.2555809, 0.04117897]\n",
      "Iter 6278, loss [-0.24117278, -0.275611, 0.03443824]\n",
      "Iter 6279, loss [-0.21257024, -0.25219727, 0.03962703]\n",
      "Iter 6280, loss [-0.22599894, -0.26898545, 0.04298652]\n",
      "Iter 6281, loss [-0.2174238, -0.2573474, 0.039923616]\n",
      "Iter 6282, loss [-0.21771118, -0.25572303, 0.038011853]\n",
      "Iter 6283, loss [-0.21731447, -0.2582274, 0.04091294]\n",
      "Iter 6284, loss [-0.22189343, -0.26143017, 0.03953675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6285, loss [-0.21258903, -0.25354525, 0.04095622]\n",
      "Iter 6286, loss [-0.2419684, -0.27762166, 0.03565326]\n",
      "Iter 6287, loss [-0.21960373, -0.2590684, 0.039464667]\n",
      "Iter 6288, loss [-0.30818683, -0.3175647, 0.009377863]\n",
      "Iter 6289, loss [-0.20937663, -0.24646825, 0.03709162]\n",
      "Iter 6290, loss [-0.21691632, -0.2558672, 0.038950887]\n",
      "Iter 6291, loss [-0.2196836, -0.25567853, 0.03599493]\n",
      "Iter 6292, loss [-0.21790333, -0.25595924, 0.03805591]\n",
      "Iter 6293, loss [-0.21555722, -0.2570353, 0.04147806]\n",
      "Iter 6294, loss [-0.21072248, -0.2503809, 0.039658435]\n",
      "Iter 6295, loss [-0.21732919, -0.25704327, 0.039714087]\n",
      "Iter 6296, loss [-0.21701641, -0.25675714, 0.039740726]\n",
      "Iter 6297, loss [-0.22115171, -0.26012158, 0.038969867]\n",
      "Iter 6298, loss [-0.22965689, -0.2731221, 0.043465212]\n",
      "Iter 6299, loss [-0.22619049, -0.2654151, 0.039224613]\n",
      "Iter 6300, loss [-0.21326043, -0.25479242, 0.041532]\n",
      "Iter 6301, loss [-0.21452291, -0.2559483, 0.041425396]\n",
      "Iter 6302, loss [-0.22984323, -0.26823956, 0.03839632]\n",
      "Iter 6303, loss [-0.22778086, -0.2955448, 0.06776394]\n",
      "Iter 6304, loss [-0.21717252, -0.25560057, 0.03842805]\n",
      "Iter 6305, loss [-0.21108383, -0.24906658, 0.037982747]\n",
      "Iter 6306, loss [-0.20620796, -0.25465107, 0.048443116]\n",
      "Iter 6307, loss [-0.22026277, -0.26176322, 0.04150045]\n",
      "Iter 6308, loss [-0.21241313, -0.25840804, 0.045994908]\n",
      "Iter 6309, loss [-0.205755, -0.24437147, 0.03861647]\n",
      "Iter 6310, loss [-0.30719075, -0.31667247, 0.009481731]\n",
      "Iter 6311, loss [-0.22663018, -0.2648993, 0.038269132]\n",
      "Iter 6312, loss [-0.23122194, -0.26700148, 0.035779536]\n",
      "Iter 6313, loss [-0.22619206, -0.26281485, 0.036622792]\n",
      "Iter 6314, loss [-0.22906545, -0.26682097, 0.03775552]\n",
      "Iter 6315, loss [-0.21847263, -0.25688452, 0.038411885]\n",
      "Iter 6316, loss [-0.23625317, -0.29641798, 0.06016481]\n",
      "Iter 6317, loss [-0.24005044, -0.2752643, 0.03521385]\n",
      "Iter 6318, loss [-0.22347164, -0.26190886, 0.038437225]\n",
      "Iter 6319, loss [-0.2078867, -0.24827002, 0.04038332]\n",
      "Iter 6320, loss [-0.21335554, -0.25495768, 0.041602127]\n",
      "Iter 6321, loss [-0.22284612, -0.26349282, 0.040646695]\n",
      "Iter 6322, loss [-0.22395821, -0.26257616, 0.03861795]\n",
      "Iter 6323, loss [-0.22121759, -0.26058224, 0.039364647]\n",
      "Iter 6324, loss [-0.2222516, -0.26295143, 0.040699832]\n",
      "Iter 6325, loss [-0.21579051, -0.25496405, 0.039173536]\n",
      "Iter 6326, loss [-0.21686493, -0.2542962, 0.03743128]\n",
      "Iter 6327, loss [-0.20875353, -0.24760993, 0.038856395]\n",
      "Iter 6328, loss [-0.20228116, -0.2414138, 0.03913264]\n",
      "Iter 6329, loss [-0.21551652, -0.25797218, 0.042455655]\n",
      "Iter 6330, loss [-0.22329669, -0.28925803, 0.065961346]\n",
      "Iter 6331, loss [-0.30557635, -0.31490275, 0.009326409]\n",
      "Iter 6332, loss [-0.20493001, -0.24306655, 0.03813654]\n",
      "Iter 6333, loss [-0.20977971, -0.24802987, 0.038250156]\n",
      "Iter 6334, loss [-0.22357294, -0.2607467, 0.037173748]\n",
      "Iter 6335, loss [-0.22129339, -0.25980362, 0.03851024]\n",
      "Iter 6336, loss [-0.22607905, -0.2644868, 0.038407736]\n",
      "Iter 6337, loss [-0.22720733, -0.2652229, 0.038015574]\n",
      "Iter 6338, loss [-0.1948691, -0.24545589, 0.050586782]\n",
      "Iter 6339, loss [-0.20469841, -0.24433833, 0.039639916]\n",
      "Iter 6340, loss [-0.22014622, -0.2856536, 0.06550737]\n",
      "Iter 6341, loss [-0.21097496, -0.25123012, 0.04025515]\n",
      "Iter 6342, loss [-0.22636245, -0.26423013, 0.037867676]\n",
      "Iter 6343, loss [-0.2205857, -0.2593332, 0.038747482]\n",
      "Iter 6344, loss [-0.21642345, -0.2600844, 0.04366093]\n",
      "Iter 6345, loss [-0.20700353, -0.24739431, 0.040390775]\n",
      "Iter 6346, loss [-0.2198904, -0.25787413, 0.03798373]\n",
      "Iter 6347, loss [-0.22898397, -0.26502362, 0.036039643]\n",
      "Iter 6348, loss [-0.21072944, -0.25546637, 0.044736933]\n",
      "Iter 6349, loss [-0.23716399, -0.31227508, 0.07511109]\n",
      "Iter 6350, loss [-0.22805664, -0.2690604, 0.041003767]\n",
      "Iter 6351, loss [-0.24169768, -0.32252154, 0.08082385]\n",
      "Iter 6352, loss [-0.20668799, -0.24683088, 0.0401429]\n",
      "Iter 6353, loss [-0.21278426, -0.25959426, 0.046809994]\n",
      "Iter 6354, loss [-0.21220145, -0.2572642, 0.045062743]\n",
      "Iter 6355, loss [-0.22782801, -0.2667535, 0.03892548]\n",
      "Iter 6356, loss [-0.22059068, -0.25978148, 0.039190795]\n",
      "Iter 6357, loss [-0.20344539, -0.24008626, 0.036640868]\n",
      "Iter 6358, loss [-0.20911056, -0.24886043, 0.03974988]\n",
      "Iter 6359, loss [-0.21264473, -0.2520264, 0.039381675]\n",
      "Iter 6360, loss [-0.20741299, -0.24339977, 0.03598679]\n",
      "Iter 6361, loss [-0.22493085, -0.26760727, 0.042676415]\n",
      "Iter 6362, loss [-0.21721424, -0.26363277, 0.04641853]\n",
      "Iter 6363, loss [-0.22711146, -0.26573014, 0.038618676]\n",
      "Iter 6364, loss [-0.21669471, -0.25793767, 0.04124295]\n",
      "Iter 6365, loss [-0.2100051, -0.25370312, 0.04369802]\n",
      "Iter 6366, loss [-0.2076635, -0.24948822, 0.041824706]\n",
      "Iter 6367, loss [-0.24521767, -0.31076115, 0.06554349]\n",
      "Iter 6368, loss [-0.21175542, -0.2526096, 0.04085418]\n",
      "Iter 6369, loss [-0.23008247, -0.26598984, 0.035907373]\n",
      "Iter 6370, loss [-0.21969727, -0.25675148, 0.03705421]\n",
      "Iter 6371, loss [-0.2144361, -0.2729835, 0.058547392]\n",
      "Iter 6372, loss [-0.24775577, -0.2902221, 0.04246634]\n",
      "Iter 6373, loss [-0.22454736, -0.28476802, 0.060220666]\n",
      "Iter 6374, loss [-0.23156166, -0.2681729, 0.03661123]\n",
      "Iter 6375, loss [-0.22121952, -0.25971362, 0.03849409]\n",
      "Iter 6376, loss [-0.21912825, -0.2594441, 0.04031583]\n",
      "Iter 6377, loss [-0.23004872, -0.26850823, 0.038459506]\n",
      "Iter 6378, loss [-0.21016113, -0.2508185, 0.04065736]\n",
      "Iter 6379, loss [-0.21006744, -0.2501554, 0.040087953]\n",
      "Iter 6380, loss [-0.22627023, -0.26425922, 0.037988983]\n",
      "Iter 6381, loss [-0.20738618, -0.24790367, 0.040517494]\n",
      "Iter 6382, loss [-0.23073459, -0.26829126, 0.037556674]\n",
      "Iter 6383, loss [-0.21711318, -0.25688586, 0.03977268]\n",
      "Iter 6384, loss [-0.20626834, -0.2433868, 0.037118465]\n",
      "Iter 6385, loss [-0.21934949, -0.26052153, 0.04117204]\n",
      "Iter 6386, loss [-0.21653408, -0.2598312, 0.04329712]\n",
      "Iter 6387, loss [-0.21466486, -0.26068345, 0.04601858]\n",
      "Iter 6388, loss [-0.2222534, -0.2698335, 0.047580108]\n",
      "Iter 6389, loss [-0.22779074, -0.2740041, 0.04621335]\n",
      "Iter 6390, loss [-0.22764161, -0.26620644, 0.03856484]\n",
      "Iter 6391, loss [-0.2262946, -0.26837215, 0.042077534]\n",
      "Iter 6392, loss [-0.20784831, -0.26694334, 0.05909502]\n",
      "Iter 6393, loss [-0.21001785, -0.25205, 0.042032164]\n",
      "Iter 6394, loss [-0.22259559, -0.267841, 0.04524542]\n",
      "Iter 6395, loss [-0.23200287, -0.26832882, 0.036325946]\n",
      "Iter 6396, loss [-0.23599453, -0.29085937, 0.054864835]\n",
      "Iter 6397, loss [-0.3073923, -0.31673247, 0.009340166]\n",
      "Iter 6398, loss [-0.20865178, -0.2588102, 0.050158404]\n",
      "Iter 6399, loss [-0.21670185, -0.26199043, 0.045288578]\n",
      "Iter 6400, loss [-0.19982627, -0.2360745, 0.036248244]\n",
      "Iter 6401, loss [-0.1811992, -0.23011415, 0.04891496]\n",
      "Iter 6402, loss [-0.21215323, -0.25579405, 0.04364082]\n",
      "Iter 6403, loss [-0.21683267, -0.2545065, 0.037673827]\n",
      "Iter 6404, loss [-0.22354788, -0.26034707, 0.036799185]\n",
      "Iter 6405, loss [-0.21771419, -0.25490028, 0.037186094]\n",
      "Iter 6406, loss [-0.21975394, -0.25783768, 0.038083747]\n",
      "Iter 6407, loss [-0.20956424, -0.24940804, 0.0398438]\n",
      "Iter 6408, loss [-0.24614722, -0.31001925, 0.06387203]\n",
      "Iter 6409, loss [-0.21103501, -0.2595736, 0.048538603]\n",
      "Iter 6410, loss [-0.20422363, -0.24414384, 0.039920207]\n",
      "Iter 6411, loss [-0.21636637, -0.2568254, 0.040459022]\n",
      "Iter 6412, loss [-0.2245846, -0.26234207, 0.03775747]\n",
      "Iter 6413, loss [-0.20638567, -0.24230006, 0.0359144]\n",
      "Iter 6414, loss [-0.22688031, -0.30846113, 0.08158082]\n",
      "Iter 6415, loss [-0.22733918, -0.2637233, 0.036384128]\n",
      "Iter 6416, loss [-0.21151447, -0.26106605, 0.04955157]\n",
      "Iter 6417, loss [-0.21235833, -0.25377256, 0.04141423]\n",
      "Iter 6418, loss [-0.22083883, -0.2602336, 0.03939478]\n",
      "Iter 6419, loss [-0.20894599, -0.24586064, 0.03691464]\n",
      "Iter 6420, loss [-0.21682243, -0.2591088, 0.04228638]\n",
      "Iter 6421, loss [-0.21793771, -0.25776446, 0.039826747]\n",
      "Iter 6422, loss [-0.21447156, -0.25540653, 0.04093497]\n",
      "Iter 6423, loss [-0.21527322, -0.27469462, 0.059421405]\n",
      "Iter 6424, loss [-0.21090804, -0.25985274, 0.048944693]\n",
      "Iter 6425, loss [-0.22294275, -0.26079658, 0.037853822]\n",
      "Iter 6426, loss [-0.1807394, -0.22940713, 0.04866772]\n",
      "Iter 6427, loss [-0.21224721, -0.2570627, 0.044815492]\n",
      "Iter 6428, loss [-0.22414988, -0.26236808, 0.038218208]\n",
      "Iter 6429, loss [-0.2157703, -0.25594798, 0.040177666]\n",
      "Iter 6430, loss [-0.18071674, -0.23119622, 0.050479487]\n",
      "Iter 6431, loss [-0.24333431, -0.3063337, 0.06299938]\n",
      "Iter 6432, loss [-0.2320607, -0.26736546, 0.035304755]\n",
      "Iter 6433, loss [-0.21106216, -0.24660362, 0.035541452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6434, loss [-0.24623631, -0.3076293, 0.061392974]\n",
      "Iter 6435, loss [-0.21023312, -0.24854851, 0.038315393]\n",
      "Iter 6436, loss [-0.21091884, -0.24884625, 0.037927404]\n",
      "Iter 6437, loss [-0.21105623, -0.25104216, 0.039985925]\n",
      "Iter 6438, loss [-0.2168359, -0.2556453, 0.0388094]\n",
      "Iter 6439, loss [-0.20643961, -0.24932735, 0.042887732]\n",
      "Iter 6440, loss [-0.21914724, -0.25992882, 0.040781584]\n",
      "Iter 6441, loss [-0.23610765, -0.29238093, 0.05627329]\n",
      "Iter 6442, loss [-0.239331, -0.31786993, 0.07853892]\n",
      "Iter 6443, loss [-0.24445543, -0.30886325, 0.06440782]\n",
      "Iter 6444, loss [-0.21419004, -0.256418, 0.04222796]\n",
      "Iter 6445, loss [-0.19956827, -0.24081844, 0.04125017]\n",
      "Iter 6446, loss [-0.23781678, -0.31176752, 0.07395073]\n",
      "Iter 6447, loss [-0.21578322, -0.256302, 0.040518776]\n",
      "Iter 6448, loss [-0.19829345, -0.23801449, 0.03972105]\n",
      "Iter 6449, loss [-0.20300823, -0.24090366, 0.037895422]\n",
      "Iter 6450, loss [-0.19995925, -0.29037663, 0.090417385]\n",
      "Iter 6451, loss [-0.22136398, -0.26794285, 0.04657887]\n",
      "Iter 6452, loss [-0.22339056, -0.26115808, 0.037767515]\n",
      "Iter 6453, loss [-0.21607028, -0.2561165, 0.04004623]\n",
      "Iter 6454, loss [-0.21846347, -0.2576369, 0.039173435]\n",
      "Iter 6455, loss [-0.21154968, -0.2519879, 0.040438216]\n",
      "Iter 6456, loss [-0.21627995, -0.25478104, 0.03850109]\n",
      "Iter 6457, loss [-0.21790227, -0.25754964, 0.039647378]\n",
      "Iter 6458, loss [-0.2120618, -0.25136173, 0.039299943]\n",
      "Iter 6459, loss [-0.20983505, -0.29504764, 0.08521259]\n",
      "Iter 6460, loss [-0.2379592, -0.27242476, 0.03446555]\n",
      "Iter 6461, loss [-0.23894499, -0.30074665, 0.061801653]\n",
      "Iter 6462, loss [-0.22945596, -0.2656462, 0.036190223]\n",
      "Iter 6463, loss [-0.21417081, -0.25912887, 0.044958055]\n",
      "Iter 6464, loss [-0.21876997, -0.3044058, 0.08563584]\n",
      "Iter 6465, loss [-0.20060512, -0.24506553, 0.04446041]\n",
      "Iter 6466, loss [-0.21696904, -0.25570378, 0.03873474]\n",
      "Iter 6467, loss [-0.21563531, -0.2570582, 0.041422885]\n",
      "Iter 6468, loss [-0.20328659, -0.24461843, 0.04133184]\n",
      "Iter 6469, loss [-0.20701641, -0.24700415, 0.03998775]\n",
      "Iter 6470, loss [-0.21105823, -0.27620646, 0.06514823]\n",
      "Iter 6471, loss [-0.20066507, -0.24067679, 0.04001172]\n",
      "Iter 6472, loss [-0.3060411, -0.3153904, 0.009349328]\n",
      "Iter 6473, loss [-0.21733013, -0.25422007, 0.036889937]\n",
      "Iter 6474, loss [-0.21100946, -0.2513155, 0.040306047]\n",
      "Iter 6475, loss [-0.22137816, -0.25800467, 0.0366265]\n",
      "Iter 6476, loss [-0.21672404, -0.25290468, 0.036180638]\n",
      "Iter 6477, loss [-0.22501493, -0.26505473, 0.040039804]\n",
      "Iter 6478, loss [-0.21117766, -0.24887268, 0.037695017]\n",
      "Iter 6479, loss [-0.22203586, -0.26167452, 0.03963866]\n",
      "Iter 6480, loss [-0.22224036, -0.26291806, 0.040677696]\n",
      "Iter 6481, loss [-0.22134879, -0.25918785, 0.037839048]\n",
      "Iter 6482, loss [-0.20861137, -0.24643055, 0.037819177]\n",
      "Iter 6483, loss [-0.21091789, -0.24842146, 0.037503563]\n",
      "Iter 6484, loss [-0.20683287, -0.24867621, 0.04184334]\n",
      "Iter 6485, loss [-0.22388053, -0.26776862, 0.043888092]\n",
      "Iter 6486, loss [-0.22085044, -0.25986776, 0.039017327]\n",
      "Iter 6487, loss [-0.20189178, -0.2407834, 0.038891606]\n",
      "Iter 6488, loss [-0.19976093, -0.23654893, 0.036788]\n",
      "Iter 6489, loss [-0.21355717, -0.2550781, 0.04152094]\n",
      "Iter 6490, loss [-0.24117298, -0.27720195, 0.036028966]\n",
      "Iter 6491, loss [-0.30758724, -0.3172241, 0.009636851]\n",
      "Iter 6492, loss [-0.22147922, -0.26121113, 0.0397319]\n",
      "Iter 6493, loss [-0.22560269, -0.2644784, 0.038875695]\n",
      "Iter 6494, loss [-0.2189143, -0.25628522, 0.037370928]\n",
      "Iter 6495, loss [-0.22520535, -0.29355934, 0.068353996]\n",
      "Iter 6496, loss [-0.20085782, -0.29174882, 0.090891]\n",
      "Iter 6497, loss [-0.22623105, -0.26262492, 0.036393866]\n",
      "Iter 6498, loss [-0.21229811, -0.24855503, 0.03625692]\n",
      "Iter 6499, loss [-0.23788738, -0.3040912, 0.0662038]\n",
      "Iter 6500, loss [-0.2040479, -0.24278739, 0.03873949]\n",
      "Iter 6501, loss [-0.19801383, -0.24414176, 0.046127927]\n",
      "Iter 6502, loss [-0.22838104, -0.26502395, 0.0366429]\n",
      "Iter 6503, loss [-0.22803998, -0.2945839, 0.0665439]\n",
      "Iter 6504, loss [-0.21327245, -0.24941413, 0.036141686]\n",
      "Iter 6505, loss [-0.22453868, -0.26816183, 0.043623146]\n",
      "Iter 6506, loss [-0.20652723, -0.2480246, 0.041497365]\n",
      "Iter 6507, loss [-0.21795733, -0.26451, 0.04655267]\n",
      "Iter 6508, loss [-0.21214199, -0.25540096, 0.043258958]\n",
      "Iter 6509, loss [-0.22373302, -0.2634449, 0.039711878]\n",
      "Iter 6510, loss [-0.22972468, -0.3021587, 0.07243404]\n",
      "Iter 6511, loss [-0.216864, -0.25644234, 0.039578333]\n",
      "Iter 6512, loss [-0.20340744, -0.24440418, 0.04099674]\n",
      "Iter 6513, loss [-0.21467464, -0.25293964, 0.038265005]\n",
      "Iter 6514, loss [-0.21922572, -0.2575646, 0.038338885]\n",
      "Iter 6515, loss [-0.21804407, -0.25461116, 0.036567096]\n",
      "Iter 6516, loss [-0.23798144, -0.29178342, 0.053801976]\n",
      "Iter 6517, loss [-0.22507319, -0.26618764, 0.041114442]\n",
      "Iter 6518, loss [-0.20265484, -0.24370383, 0.041048996]\n",
      "Iter 6519, loss [-0.197269, -0.24879956, 0.051530562]\n",
      "Iter 6520, loss [-0.20732886, -0.25273326, 0.045404404]\n",
      "Iter 6521, loss [-0.21752506, -0.2582278, 0.040702734]\n",
      "Iter 6522, loss [-0.22125915, -0.2611416, 0.03988245]\n",
      "Iter 6523, loss [-0.21877098, -0.25860506, 0.03983408]\n",
      "Iter 6524, loss [-0.3086426, -0.31761447, 0.008971866]\n",
      "Iter 6525, loss [-0.21989748, -0.25665215, 0.036754668]\n",
      "Iter 6526, loss [-0.21613747, -0.25410324, 0.037965782]\n",
      "Iter 6527, loss [-0.22024465, -0.2563137, 0.036069073]\n",
      "Iter 6528, loss [-0.22014613, -0.26077843, 0.04063229]\n",
      "Iter 6529, loss [-0.21735007, -0.2580683, 0.04071822]\n",
      "Iter 6530, loss [-0.21855298, -0.25929904, 0.040746063]\n",
      "Iter 6531, loss [-0.21628222, -0.25741678, 0.041134574]\n",
      "Iter 6532, loss [-0.21861596, -0.2589153, 0.040299337]\n",
      "Iter 6533, loss [-0.22375238, -0.26186532, 0.038112935]\n",
      "Iter 6534, loss [-0.22036207, -0.2591711, 0.03880904]\n",
      "Iter 6535, loss [-0.22853252, -0.2651875, 0.03665497]\n",
      "Iter 6536, loss [-0.22048545, -0.25825274, 0.0377673]\n",
      "Iter 6537, loss [-0.2082448, -0.24365112, 0.03540632]\n",
      "Iter 6538, loss [-0.2215361, -0.26137924, 0.03984314]\n",
      "Iter 6539, loss [-0.211793, -0.2506033, 0.038810287]\n",
      "Iter 6540, loss [-0.21414031, -0.25575012, 0.041609805]\n",
      "Iter 6541, loss [-0.2493, -0.31325808, 0.06395808]\n",
      "Iter 6542, loss [-0.22843017, -0.27416945, 0.04573928]\n",
      "Iter 6543, loss [-0.21840034, -0.25891006, 0.040509712]\n",
      "Iter 6544, loss [-0.22626582, -0.26660407, 0.04033824]\n",
      "Iter 6545, loss [-0.21495658, -0.25578538, 0.0408288]\n",
      "Iter 6546, loss [-0.21208993, -0.2514171, 0.039327174]\n",
      "Iter 6547, loss [-0.21126792, -0.25914738, 0.047879457]\n",
      "Iter 6548, loss [-0.20244126, -0.24094468, 0.03850342]\n",
      "Iter 6549, loss [-0.21677747, -0.25791225, 0.04113477]\n",
      "Iter 6550, loss [-0.22599173, -0.26974133, 0.043749593]\n",
      "Iter 6551, loss [-0.2154438, -0.25639382, 0.040950015]\n",
      "Iter 6552, loss [-0.22583753, -0.26870158, 0.042864054]\n",
      "Iter 6553, loss [-0.21686731, -0.25669652, 0.03982921]\n",
      "Iter 6554, loss [-0.20590371, -0.25558117, 0.049677454]\n",
      "Iter 6555, loss [-0.21009754, -0.25040057, 0.040303037]\n",
      "Iter 6556, loss [-0.21159185, -0.26002303, 0.04843117]\n",
      "Iter 6557, loss [-0.21807665, -0.2602595, 0.042182855]\n",
      "Iter 6558, loss [-0.21921894, -0.25708312, 0.03786418]\n",
      "Iter 6559, loss [-0.2174958, -0.27633387, 0.05883807]\n",
      "Iter 6560, loss [-0.21154356, -0.2576145, 0.046070933]\n",
      "Iter 6561, loss [-0.18119866, -0.22937404, 0.048175376]\n",
      "Iter 6562, loss [-0.2199836, -0.25864074, 0.03865714]\n",
      "Iter 6563, loss [-0.21921971, -0.2585369, 0.03931719]\n",
      "Iter 6564, loss [-0.22618525, -0.26545528, 0.03927003]\n",
      "Iter 6565, loss [-0.22092001, -0.26039368, 0.039473664]\n",
      "Iter 6566, loss [-0.22085337, -0.2606814, 0.039828017]\n",
      "Iter 6567, loss [-0.21412614, -0.25627744, 0.042151302]\n",
      "Iter 6568, loss [-0.21657135, -0.2567276, 0.04015626]\n",
      "Iter 6569, loss [-0.22760238, -0.26642314, 0.03882076]\n",
      "Iter 6570, loss [-0.21858455, -0.25766748, 0.039082926]\n",
      "Iter 6571, loss [-0.20004454, -0.23635839, 0.036313847]\n",
      "Iter 6572, loss [-0.21279147, -0.25660577, 0.043814294]\n",
      "Iter 6573, loss [-0.21751569, -0.25703192, 0.039516225]\n",
      "Iter 6574, loss [-0.21849787, -0.25691515, 0.038417272]\n",
      "Iter 6575, loss [-0.21126863, -0.24891329, 0.037644647]\n",
      "Iter 6576, loss [-0.21806762, -0.27932996, 0.061262332]\n",
      "Iter 6577, loss [-0.21409392, -0.25038707, 0.03629315]\n",
      "Iter 6578, loss [-0.21178372, -0.25103813, 0.03925441]\n",
      "Iter 6579, loss [-0.22632723, -0.26514664, 0.038819417]\n",
      "Iter 6580, loss [-0.21049379, -0.25084457, 0.040350776]\n",
      "Iter 6581, loss [-0.20973022, -0.24772619, 0.037995964]\n",
      "Iter 6582, loss [-0.23662543, -0.31725246, 0.080627024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6583, loss [-0.22134125, -0.2596362, 0.038294934]\n",
      "Iter 6584, loss [-0.2005265, -0.23643377, 0.035907265]\n",
      "Iter 6585, loss [-0.22525704, -0.26537165, 0.040114615]\n",
      "Iter 6586, loss [-0.22148165, -0.25978273, 0.038301077]\n",
      "Iter 6587, loss [-0.21038327, -0.24859518, 0.03821192]\n",
      "Iter 6588, loss [-0.21886304, -0.25548902, 0.03662599]\n",
      "Iter 6589, loss [-0.20059615, -0.2930358, 0.092439644]\n",
      "Iter 6590, loss [-0.21937828, -0.25707227, 0.03769399]\n",
      "Iter 6591, loss [-0.22569238, -0.30797374, 0.082281366]\n",
      "Iter 6592, loss [-0.22800061, -0.2668733, 0.038872696]\n",
      "Iter 6593, loss [-0.30713436, -0.3165464, 0.009412054]\n",
      "Iter 6594, loss [-0.22686528, -0.2640427, 0.037177425]\n",
      "Iter 6595, loss [-0.22411078, -0.26715207, 0.04304128]\n",
      "Iter 6596, loss [-0.21829352, -0.25685513, 0.038561612]\n",
      "Iter 6597, loss [-0.21614292, -0.25480917, 0.03866625]\n",
      "Iter 6598, loss [-0.24764077, -0.29037443, 0.04273365]\n",
      "Iter 6599, loss [-0.21285343, -0.2527637, 0.039910253]\n",
      "Iter 6600, loss [-0.2392048, -0.31187743, 0.072672635]\n",
      "Iter 6601, loss [-0.20340733, -0.243345, 0.039937675]\n",
      "Iter 6602, loss [-0.21186826, -0.25559938, 0.043731116]\n",
      "Iter 6603, loss [-0.21237181, -0.25009152, 0.037719708]\n",
      "Iter 6604, loss [-0.19814315, -0.24598843, 0.04784528]\n",
      "Iter 6605, loss [-0.22810502, -0.2718167, 0.043711673]\n",
      "Iter 6606, loss [-0.21320188, -0.24926549, 0.036063608]\n",
      "Iter 6607, loss [-0.2189635, -0.2583175, 0.039353997]\n",
      "Iter 6608, loss [-0.21446157, -0.2558164, 0.041354828]\n",
      "Iter 6609, loss [-0.2133932, -0.2521045, 0.03871129]\n",
      "Iter 6610, loss [-0.2253012, -0.28671333, 0.061412126]\n",
      "Iter 6611, loss [-0.2206192, -0.26086864, 0.040249437]\n",
      "Iter 6612, loss [-0.18186477, -0.23156962, 0.04970485]\n",
      "Iter 6613, loss [-0.21863367, -0.25562257, 0.0369889]\n",
      "Iter 6614, loss [-0.22307718, -0.2604362, 0.03735902]\n",
      "Iter 6615, loss [-0.21336088, -0.24907069, 0.03570982]\n",
      "Iter 6616, loss [-0.2374144, -0.29162875, 0.05421434]\n",
      "Iter 6617, loss [-0.22242394, -0.26785946, 0.045435525]\n",
      "Iter 6618, loss [-0.22808716, -0.26654008, 0.03845292]\n",
      "Iter 6619, loss [-0.21669513, -0.25622204, 0.03952691]\n",
      "Iter 6620, loss [-0.3071675, -0.3165817, 0.0094142]\n",
      "Iter 6621, loss [-0.19850469, -0.24604252, 0.04753783]\n",
      "Iter 6622, loss [-0.21389058, -0.25611445, 0.042223867]\n",
      "Iter 6623, loss [-0.21888064, -0.25880754, 0.039926898]\n",
      "Iter 6624, loss [-0.21423158, -0.25047594, 0.03624436]\n",
      "Iter 6625, loss [-0.21684045, -0.25620875, 0.039368294]\n",
      "Iter 6626, loss [-0.22594619, -0.2641943, 0.03824813]\n",
      "Iter 6627, loss [-0.21560413, -0.25612193, 0.0405178]\n",
      "Iter 6628, loss [-0.21975294, -0.25654784, 0.036794905]\n",
      "Iter 6629, loss [-0.22883362, -0.26651317, 0.037679557]\n",
      "Iter 6630, loss [-0.2171318, -0.258718, 0.041586213]\n",
      "Iter 6631, loss [-0.21945745, -0.2597569, 0.040299445]\n",
      "Iter 6632, loss [-0.21359396, -0.25328982, 0.039695855]\n",
      "Iter 6633, loss [-0.21415058, -0.2594445, 0.045293923]\n",
      "Iter 6634, loss [-0.22251904, -0.25945893, 0.03693988]\n",
      "Iter 6635, loss [-0.20984533, -0.24757254, 0.037727207]\n",
      "Iter 6636, loss [-0.2196156, -0.25986302, 0.040247425]\n",
      "Iter 6637, loss [-0.21960884, -0.2563638, 0.03675496]\n",
      "Iter 6638, loss [-0.21895036, -0.25672314, 0.03777278]\n",
      "Iter 6639, loss [-0.24622023, -0.310651, 0.06443077]\n",
      "Iter 6640, loss [-0.22013411, -0.26071733, 0.040583223]\n",
      "Iter 6641, loss [-0.22238287, -0.26273483, 0.040351957]\n",
      "Iter 6642, loss [-0.30818203, -0.31743494, 0.009252894]\n",
      "Iter 6643, loss [-0.21927738, -0.25770485, 0.03842748]\n",
      "Iter 6644, loss [-0.20317216, -0.24506828, 0.04189612]\n",
      "Iter 6645, loss [-0.21898146, -0.27878678, 0.059805315]\n",
      "Iter 6646, loss [-0.22604649, -0.26972955, 0.043683067]\n",
      "Iter 6647, loss [-0.21542323, -0.26078975, 0.045366533]\n",
      "Iter 6648, loss [-0.2211194, -0.26277438, 0.04165498]\n",
      "Iter 6649, loss [-0.21962655, -0.25956127, 0.039934717]\n",
      "Iter 6650, loss [-0.22115698, -0.2626154, 0.041458428]\n",
      "Iter 6651, loss [-0.21168126, -0.25103423, 0.039352965]\n",
      "Iter 6652, loss [-0.20840263, -0.24989797, 0.041495338]\n",
      "Iter 6653, loss [-0.22313362, -0.26848778, 0.045354158]\n",
      "Iter 6654, loss [-0.21319814, -0.25615036, 0.042952225]\n",
      "Iter 6655, loss [-0.20401731, -0.24221268, 0.03819537]\n",
      "Iter 6656, loss [-0.21986857, -0.25584617, 0.0359776]\n",
      "Iter 6657, loss [-0.21569973, -0.25635958, 0.040659852]\n",
      "Iter 6658, loss [-0.24186122, -0.32092512, 0.0790639]\n",
      "Iter 6659, loss [-0.21226001, -0.25113094, 0.038870923]\n",
      "Iter 6660, loss [-0.21695404, -0.25744024, 0.040486198]\n",
      "Iter 6661, loss [-0.21575888, -0.25687063, 0.04111175]\n",
      "Iter 6662, loss [-0.23970252, -0.3139784, 0.07427589]\n",
      "Iter 6663, loss [-0.22115675, -0.25969213, 0.03853538]\n",
      "Iter 6664, loss [-0.21205083, -0.24829249, 0.036241658]\n",
      "Iter 6665, loss [-0.22594477, -0.263043, 0.037098214]\n",
      "Iter 6666, loss [-0.24117278, -0.27525717, 0.0340844]\n",
      "Iter 6667, loss [-0.20259254, -0.24212138, 0.039528843]\n",
      "Iter 6668, loss [-0.2215229, -0.2605472, 0.039024286]\n",
      "Iter 6669, loss [-0.2150151, -0.25504145, 0.040026348]\n",
      "Iter 6670, loss [-0.20839584, -0.2458331, 0.037437253]\n",
      "Iter 6671, loss [-0.21996963, -0.25783408, 0.037864447]\n",
      "Iter 6672, loss [-0.23016348, -0.26894736, 0.038783878]\n",
      "Iter 6673, loss [-0.2358079, -0.29113096, 0.055323057]\n",
      "Iter 6674, loss [-0.2120867, -0.27222106, 0.06013435]\n",
      "Iter 6675, loss [-0.22902353, -0.27372774, 0.04470421]\n",
      "Iter 6676, loss [-0.21940134, -0.2608668, 0.041465446]\n",
      "Iter 6677, loss [-0.21336983, -0.25441238, 0.04104255]\n",
      "Iter 6678, loss [-0.22322026, -0.26258025, 0.03935999]\n",
      "Iter 6679, loss [-0.20636961, -0.24951752, 0.043147903]\n",
      "Iter 6680, loss [-0.21194136, -0.2534835, 0.04154214]\n",
      "Iter 6681, loss [-0.21089804, -0.25006315, 0.03916511]\n",
      "Iter 6682, loss [-0.21571907, -0.25398442, 0.038265355]\n",
      "Iter 6683, loss [-0.23050514, -0.26604605, 0.03554091]\n",
      "Iter 6684, loss [-0.24060309, -0.2751111, 0.034508027]\n",
      "Iter 6685, loss [-0.22009309, -0.26040986, 0.040316775]\n",
      "Iter 6686, loss [-0.18857187, -0.26006427, 0.071492404]\n",
      "Iter 6687, loss [-0.20741352, -0.24444942, 0.037035897]\n",
      "Iter 6688, loss [-0.21231516, -0.24853143, 0.036216274]\n",
      "Iter 6689, loss [-0.21814574, -0.25542295, 0.037277207]\n",
      "Iter 6690, loss [-0.20085439, -0.24135311, 0.04049871]\n",
      "Iter 6691, loss [-0.213389, -0.254502, 0.041113]\n",
      "Iter 6692, loss [-0.22632793, -0.27085093, 0.044522993]\n",
      "Iter 6693, loss [-0.20431274, -0.24400729, 0.039694544]\n",
      "Iter 6694, loss [-0.2155943, -0.25794923, 0.042354923]\n",
      "Iter 6695, loss [-0.21847425, -0.25830743, 0.039833173]\n",
      "Iter 6696, loss [-0.21106774, -0.25062215, 0.03955441]\n",
      "Iter 6697, loss [-0.21939069, -0.26112983, 0.041739132]\n",
      "Iter 6698, loss [-0.20167932, -0.29400605, 0.09232673]\n",
      "Iter 6699, loss [-0.21860278, -0.25900865, 0.040405877]\n",
      "Iter 6700, loss [-0.21512775, -0.25598338, 0.04085563]\n",
      "Iter 6701, loss [-0.24045826, -0.31344125, 0.07298298]\n",
      "Iter 6702, loss [-0.21050502, -0.24923567, 0.03873065]\n",
      "Iter 6703, loss [-0.20536178, -0.25466344, 0.049301654]\n",
      "Iter 6704, loss [-0.20992056, -0.24834076, 0.038420208]\n",
      "Iter 6705, loss [-0.21087107, -0.24869399, 0.03782292]\n",
      "Iter 6706, loss [-0.21578887, -0.25630936, 0.040520497]\n",
      "Iter 6707, loss [-0.24685094, -0.2895187, 0.042667784]\n",
      "Iter 6708, loss [-0.22793679, -0.2671569, 0.03922011]\n",
      "Iter 6709, loss [-0.22985834, -0.26884675, 0.03898842]\n",
      "Iter 6710, loss [-0.20308587, -0.24349865, 0.04041279]\n",
      "Iter 6711, loss [-0.2122895, -0.25773972, 0.045450225]\n",
      "Iter 6712, loss [-0.20342186, -0.24742548, 0.044003617]\n",
      "Iter 6713, loss [-0.22957766, -0.30109742, 0.07151976]\n",
      "Iter 6714, loss [-0.19884169, -0.24523695, 0.046395265]\n",
      "Iter 6715, loss [-0.22113156, -0.2585233, 0.03739173]\n",
      "Iter 6716, loss [-0.21921289, -0.25767967, 0.03846679]\n",
      "Iter 6717, loss [-0.21388398, -0.25378007, 0.039896086]\n",
      "Iter 6718, loss [-0.30786556, -0.317042, 0.009176435]\n",
      "Iter 6719, loss [-0.2171376, -0.25501794, 0.037880324]\n",
      "Iter 6720, loss [-0.21756732, -0.25486422, 0.037296884]\n",
      "Iter 6721, loss [-0.22594833, -0.26760995, 0.041661613]\n",
      "Iter 6722, loss [-0.20270166, -0.24258012, 0.03987845]\n",
      "Iter 6723, loss [-0.21409503, -0.25991622, 0.045821186]\n",
      "Iter 6724, loss [-0.20437364, -0.24414273, 0.039769083]\n",
      "Iter 6725, loss [-0.18207976, -0.23202829, 0.049948525]\n",
      "Iter 6726, loss [-0.22172697, -0.26143453, 0.039707553]\n",
      "Iter 6727, loss [-0.20352995, -0.24298908, 0.039459124]\n",
      "Iter 6728, loss [-0.21281528, -0.25138822, 0.038572945]\n",
      "Iter 6729, loss [-0.20815457, -0.24870923, 0.040554654]\n",
      "Iter 6730, loss [-0.20678, -0.24381581, 0.037035808]\n",
      "Iter 6731, loss [-0.21904534, -0.25603068, 0.036985338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6732, loss [-0.21894488, -0.26408118, 0.0451363]\n",
      "Iter 6733, loss [-0.2188897, -0.2570828, 0.03819309]\n",
      "Iter 6734, loss [-0.20836696, -0.25102416, 0.04265719]\n",
      "Iter 6735, loss [-0.2462407, -0.30772483, 0.061484136]\n",
      "Iter 6736, loss [-0.21275342, -0.25341302, 0.0406596]\n",
      "Iter 6737, loss [-0.22537349, -0.27029437, 0.044920873]\n",
      "Iter 6738, loss [-0.2284604, -0.29165056, 0.06319017]\n",
      "Iter 6739, loss [-0.21950239, -0.25535044, 0.03584805]\n",
      "Iter 6740, loss [-0.21883743, -0.26273164, 0.043894216]\n",
      "Iter 6741, loss [-0.21112058, -0.24782386, 0.036703296]\n",
      "Iter 6742, loss [-0.2091082, -0.29977825, 0.09067004]\n",
      "Iter 6743, loss [-0.21193635, -0.25065866, 0.0387223]\n",
      "Iter 6744, loss [-0.21809125, -0.2548316, 0.03674037]\n",
      "Iter 6745, loss [-0.21174636, -0.25145617, 0.039709803]\n",
      "Iter 6746, loss [-0.21534729, -0.2562135, 0.04086619]\n",
      "Iter 6747, loss [-0.22377113, -0.26197672, 0.038205586]\n",
      "Iter 6748, loss [-0.20205802, -0.24404517, 0.04198715]\n",
      "Iter 6749, loss [-0.21919414, -0.25754648, 0.03835234]\n",
      "Iter 6750, loss [-0.20818277, -0.25005963, 0.041876867]\n",
      "Iter 6751, loss [-0.2279594, -0.26515216, 0.03719276]\n",
      "Iter 6752, loss [-0.22415523, -0.2619129, 0.037757684]\n",
      "Iter 6753, loss [-0.21190709, -0.25135154, 0.03944445]\n",
      "Iter 6754, loss [-0.22684139, -0.26371497, 0.036873586]\n",
      "Iter 6755, loss [-0.20476711, -0.24418971, 0.0394226]\n",
      "Iter 6756, loss [-0.21212226, -0.25173172, 0.039609455]\n",
      "Iter 6757, loss [-0.21959084, -0.2595691, 0.03997826]\n",
      "Iter 6758, loss [-0.20654443, -0.24387254, 0.03732811]\n",
      "Iter 6759, loss [-0.21214631, -0.2502264, 0.0380801]\n",
      "Iter 6760, loss [-0.21258737, -0.25194603, 0.03935866]\n",
      "Iter 6761, loss [-0.19874439, -0.24624275, 0.047498357]\n",
      "Iter 6762, loss [-0.23036733, -0.26848215, 0.03811481]\n",
      "Iter 6763, loss [-0.22630215, -0.268777, 0.042474862]\n",
      "Iter 6764, loss [-0.22460172, -0.26116356, 0.03656184]\n",
      "Iter 6765, loss [-0.21786216, -0.26189867, 0.044036504]\n",
      "Iter 6766, loss [-0.2195642, -0.2594633, 0.039899103]\n",
      "Iter 6767, loss [-0.22162564, -0.2601279, 0.038502257]\n",
      "Iter 6768, loss [-0.21028125, -0.25327623, 0.04299497]\n",
      "Iter 6769, loss [-0.20914404, -0.24728824, 0.038144197]\n",
      "Iter 6770, loss [-0.22654945, -0.28597653, 0.059427083]\n",
      "Iter 6771, loss [-0.22750905, -0.26584038, 0.038331337]\n",
      "Iter 6772, loss [-0.2170884, -0.25681776, 0.039729357]\n",
      "Iter 6773, loss [-0.22854158, -0.26571983, 0.037178256]\n",
      "Iter 6774, loss [-0.21901588, -0.26143336, 0.042417478]\n",
      "Iter 6775, loss [-0.22192842, -0.259889, 0.037960585]\n",
      "Iter 6776, loss [-0.20683566, -0.25444713, 0.04761147]\n",
      "Iter 6777, loss [-0.20858823, -0.24534066, 0.03675243]\n",
      "Iter 6778, loss [-0.20378372, -0.29496214, 0.09117841]\n",
      "Iter 6779, loss [-0.30760345, -0.31703922, 0.009435776]\n",
      "Iter 6780, loss [-0.22586712, -0.26855856, 0.04269144]\n",
      "Iter 6781, loss [-0.21375631, -0.25599155, 0.042235237]\n",
      "Iter 6782, loss [-0.2161859, -0.25684792, 0.04066202]\n",
      "Iter 6783, loss [-0.21157958, -0.24960966, 0.038030084]\n",
      "Iter 6784, loss [-0.22756198, -0.26531845, 0.03775648]\n",
      "Iter 6785, loss [-0.2284413, -0.26551408, 0.03707277]\n",
      "Iter 6786, loss [-0.2026175, -0.24068901, 0.038071513]\n",
      "Iter 6787, loss [-0.22067699, -0.25858632, 0.037909336]\n",
      "Iter 6788, loss [-0.23579031, -0.2917023, 0.05591198]\n",
      "Iter 6789, loss [-0.24800509, -0.29199183, 0.043986738]\n",
      "Iter 6790, loss [-0.20187858, -0.29622132, 0.09434273]\n",
      "Iter 6791, loss [-0.22066677, -0.26802596, 0.04735919]\n",
      "Iter 6792, loss [-0.21723838, -0.25477934, 0.03754096]\n",
      "Iter 6793, loss [-0.20252582, -0.2432615, 0.04073567]\n",
      "Iter 6794, loss [-0.19982941, -0.24236268, 0.042533264]\n",
      "Iter 6795, loss [-0.20545858, -0.24306698, 0.037608393]\n",
      "Iter 6796, loss [-0.21342468, -0.25481072, 0.04138603]\n",
      "Iter 6797, loss [-0.21478814, -0.2545249, 0.03973674]\n",
      "Iter 6798, loss [-0.21787564, -0.25620124, 0.038325593]\n",
      "Iter 6799, loss [-0.21226944, -0.2538138, 0.041544367]\n",
      "Iter 6800, loss [-0.21579917, -0.25750652, 0.04170735]\n",
      "Iter 6801, loss [-0.21768034, -0.2585477, 0.040867366]\n",
      "Iter 6802, loss [-0.20632279, -0.24795158, 0.041628785]\n",
      "Iter 6803, loss [-0.21724263, -0.25722, 0.03997737]\n",
      "Iter 6804, loss [-0.21734315, -0.25544757, 0.038104422]\n",
      "Iter 6805, loss [-0.22466287, -0.26354837, 0.038885497]\n",
      "Iter 6806, loss [-0.18732104, -0.27685994, 0.089538895]\n",
      "Iter 6807, loss [-0.21217012, -0.2494893, 0.037319176]\n",
      "Iter 6808, loss [-0.21741009, -0.25918227, 0.041772194]\n",
      "Iter 6809, loss [-0.21718584, -0.254992, 0.03780617]\n",
      "Iter 6810, loss [-0.20312971, -0.2967034, 0.09357368]\n",
      "Iter 6811, loss [-0.21586972, -0.25641027, 0.040540546]\n",
      "Iter 6812, loss [-0.20462176, -0.2408943, 0.036272533]\n",
      "Iter 6813, loss [-0.21071997, -0.25444588, 0.043725904]\n",
      "Iter 6814, loss [-0.22709978, -0.2636598, 0.03656003]\n",
      "Iter 6815, loss [-0.22118604, -0.2666765, 0.04549044]\n",
      "Iter 6816, loss [-0.24011412, -0.30312014, 0.06300602]\n",
      "Iter 6817, loss [-0.21221206, -0.25290525, 0.040693186]\n",
      "Iter 6818, loss [-0.24032153, -0.27683613, 0.036514595]\n",
      "Iter 6819, loss [-0.22402732, -0.26840156, 0.04437424]\n",
      "Iter 6820, loss [-0.24234049, -0.30929297, 0.06695248]\n",
      "Iter 6821, loss [-0.20974468, -0.24894892, 0.03920424]\n",
      "Iter 6822, loss [-0.21765196, -0.25763252, 0.03998056]\n",
      "Iter 6823, loss [-0.2271432, -0.27201414, 0.04487095]\n",
      "Iter 6824, loss [-0.18019313, -0.22770067, 0.047507536]\n",
      "Iter 6825, loss [-0.2143019, -0.25268653, 0.038384628]\n",
      "Iter 6826, loss [-0.20204198, -0.23916848, 0.0371265]\n",
      "Iter 6827, loss [-0.30693558, -0.3161263, 0.009190707]\n",
      "Iter 6828, loss [-0.21569443, -0.25267908, 0.036984656]\n",
      "Iter 6829, loss [-0.2138862, -0.2544514, 0.040565193]\n",
      "Iter 6830, loss [-0.20517918, -0.24184813, 0.03666895]\n",
      "Iter 6831, loss [-0.21097514, -0.25084913, 0.039873984]\n",
      "Iter 6832, loss [-0.20351607, -0.24298877, 0.039472695]\n",
      "Iter 6833, loss [-0.21359792, -0.25476834, 0.041170415]\n",
      "Iter 6834, loss [-0.20814842, -0.24710438, 0.038955957]\n",
      "Iter 6835, loss [-0.22730145, -0.26658303, 0.03928158]\n",
      "Iter 6836, loss [-0.22620817, -0.26486683, 0.038658664]\n",
      "Iter 6837, loss [-0.22433493, -0.2628396, 0.038504653]\n",
      "Iter 6838, loss [-0.21179183, -0.2551854, 0.043393563]\n",
      "Iter 6839, loss [-0.21069674, -0.24773397, 0.03703722]\n",
      "Iter 6840, loss [-0.21779281, -0.26106992, 0.043277115]\n",
      "Iter 6841, loss [-0.23290448, -0.3078522, 0.07494773]\n",
      "Iter 6842, loss [-0.21605764, -0.25701302, 0.04095538]\n",
      "Iter 6843, loss [-0.22505622, -0.26904827, 0.043992054]\n",
      "Iter 6844, loss [-0.20699781, -0.2731658, 0.06616797]\n",
      "Iter 6845, loss [-0.2268663, -0.26615423, 0.039287917]\n",
      "Iter 6846, loss [-0.2287445, -0.26690745, 0.038162954]\n",
      "Iter 6847, loss [-0.21710701, -0.25494045, 0.037833437]\n",
      "Iter 6848, loss [-0.20579806, -0.2473865, 0.041588437]\n",
      "Iter 6849, loss [-0.2235595, -0.26504448, 0.041484978]\n",
      "Iter 6850, loss [-0.19537523, -0.24183926, 0.04646402]\n",
      "Iter 6851, loss [-0.210583, -0.24996577, 0.039382763]\n",
      "Iter 6852, loss [-0.19921926, -0.23946571, 0.040246457]\n",
      "Iter 6853, loss [-0.20976749, -0.25092065, 0.041153155]\n",
      "Iter 6854, loss [-0.2068748, -0.24623321, 0.039358404]\n",
      "Iter 6855, loss [-0.19826645, -0.24048841, 0.042221963]\n",
      "Iter 6856, loss [-0.21143611, -0.2540992, 0.042663082]\n",
      "Iter 6857, loss [-0.23774078, -0.30668157, 0.06894079]\n",
      "Iter 6858, loss [-0.21771398, -0.25549927, 0.0377853]\n",
      "Iter 6859, loss [-0.2046379, -0.26253074, 0.05789284]\n",
      "Iter 6860, loss [-0.20435692, -0.24289237, 0.038535442]\n",
      "Iter 6861, loss [-0.2144739, -0.25567365, 0.041199736]\n",
      "Iter 6862, loss [-0.22378594, -0.26406026, 0.040274322]\n",
      "Iter 6863, loss [-0.20804697, -0.24717674, 0.03912976]\n",
      "Iter 6864, loss [-0.21599007, -0.25637004, 0.040379964]\n",
      "Iter 6865, loss [-0.22394195, -0.26248837, 0.03854642]\n",
      "Iter 6866, loss [-0.22490479, -0.27171993, 0.04681514]\n",
      "Iter 6867, loss [-0.1912058, -0.28607506, 0.09486925]\n",
      "Iter 6868, loss [-0.19821954, -0.23555829, 0.037338752]\n",
      "Iter 6869, loss [-0.21195522, -0.25126004, 0.039304823]\n",
      "Iter 6870, loss [-0.20708711, -0.2449714, 0.037884276]\n",
      "Iter 6871, loss [-0.2188865, -0.25538033, 0.036493845]\n",
      "Iter 6872, loss [-0.22307864, -0.2638812, 0.04080257]\n",
      "Iter 6873, loss [-0.19785883, -0.23428343, 0.036424607]\n",
      "Iter 6874, loss [-0.21633059, -0.25424615, 0.037915554]\n",
      "Iter 6875, loss [-0.20264672, -0.24251632, 0.039869603]\n",
      "Iter 6876, loss [-0.20615658, -0.24974638, 0.043589797]\n",
      "Iter 6877, loss [-0.2219139, -0.2603193, 0.038405396]\n",
      "Iter 6878, loss [-0.21747583, -0.25530162, 0.037825786]\n",
      "Iter 6879, loss [-0.30221426, -0.312182, 0.009967729]\n",
      "Iter 6880, loss [-0.21523643, -0.25552985, 0.040293425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6881, loss [-0.19941981, -0.24329235, 0.043872535]\n",
      "Iter 6882, loss [-0.23450735, -0.29922724, 0.06471988]\n",
      "Iter 6883, loss [-0.20902978, -0.2451234, 0.036093622]\n",
      "Iter 6884, loss [-0.21255827, -0.25091043, 0.03835217]\n",
      "Iter 6885, loss [-0.22608599, -0.2625978, 0.03651181]\n",
      "Iter 6886, loss [-0.20294781, -0.24139886, 0.038451046]\n",
      "Iter 6887, loss [-0.24379504, -0.2881635, 0.04436847]\n",
      "Iter 6888, loss [-0.2239495, -0.2612517, 0.037302177]\n",
      "Iter 6889, loss [-0.21135688, -0.24804673, 0.03668984]\n",
      "Iter 6890, loss [-0.20867807, -0.2466862, 0.03800813]\n",
      "Iter 6891, loss [-0.2076273, -0.24585277, 0.038225465]\n",
      "Iter 6892, loss [-0.21761905, -0.25659382, 0.038974777]\n",
      "Iter 6893, loss [-0.21552007, -0.25816134, 0.042641263]\n",
      "Iter 6894, loss [-0.21581453, -0.2558927, 0.040078163]\n",
      "Iter 6895, loss [-0.22511888, -0.28852475, 0.06340587]\n",
      "Iter 6896, loss [-0.24057235, -0.27553287, 0.03496052]\n",
      "Iter 6897, loss [-0.21192153, -0.25597703, 0.044055503]\n",
      "Iter 6898, loss [-0.22405581, -0.26060155, 0.03654574]\n",
      "Iter 6899, loss [-0.22137904, -0.25960237, 0.038223326]\n",
      "Iter 6900, loss [-0.20973456, -0.25201035, 0.04227578]\n",
      "Iter 6901, loss [-0.20496224, -0.24545275, 0.04049051]\n",
      "Iter 6902, loss [-0.21121964, -0.2513463, 0.04012666]\n",
      "Iter 6903, loss [-0.2184821, -0.25670138, 0.038219273]\n",
      "Iter 6904, loss [-0.22498122, -0.2666195, 0.041638292]\n",
      "Iter 6905, loss [-0.24152422, -0.27691925, 0.03539502]\n",
      "Iter 6906, loss [-0.20872246, -0.24581611, 0.037093654]\n",
      "Iter 6907, loss [-0.22199829, -0.26082924, 0.038830947]\n",
      "Iter 6908, loss [-0.20327793, -0.24268605, 0.039408114]\n",
      "Iter 6909, loss [-0.20965008, -0.24719687, 0.03754678]\n",
      "Iter 6910, loss [-0.24464822, -0.30762747, 0.06297925]\n",
      "Iter 6911, loss [-0.21166268, -0.2515341, 0.039871417]\n",
      "Iter 6912, loss [-0.2243921, -0.26363134, 0.039239243]\n",
      "Iter 6913, loss [-0.21914977, -0.25828826, 0.039138492]\n",
      "Iter 6914, loss [-0.22252665, -0.27043292, 0.04790626]\n",
      "Iter 6915, loss [-0.21189614, -0.2514115, 0.039515357]\n",
      "Iter 6916, loss [-0.2147085, -0.259693, 0.044984486]\n",
      "Iter 6917, loss [-0.21700986, -0.25870258, 0.04169272]\n",
      "Iter 6918, loss [-0.2490713, -0.2922583, 0.04318699]\n",
      "Iter 6919, loss [-0.21664727, -0.25471085, 0.038063593]\n",
      "Iter 6920, loss [-0.22912216, -0.2651969, 0.036074735]\n",
      "Iter 6921, loss [-0.21985842, -0.25937068, 0.039512258]\n",
      "Iter 6922, loss [-0.2065517, -0.2445992, 0.03804749]\n",
      "Iter 6923, loss [-0.22524455, -0.26319617, 0.037951622]\n",
      "Iter 6924, loss [-0.21243814, -0.25203103, 0.039592884]\n",
      "Iter 6925, loss [-0.21660975, -0.2559218, 0.039312057]\n",
      "Iter 6926, loss [-0.21982929, -0.25997674, 0.040147457]\n",
      "Iter 6927, loss [-0.20442508, -0.24404079, 0.03961571]\n",
      "Iter 6928, loss [-0.21933901, -0.25892645, 0.03958743]\n",
      "Iter 6929, loss [-0.21979088, -0.26002738, 0.040236503]\n",
      "Iter 6930, loss [-0.22990507, -0.3000019, 0.07009682]\n",
      "Iter 6931, loss [-0.20705925, -0.2438103, 0.03675105]\n",
      "Iter 6932, loss [-0.21831945, -0.2559693, 0.037649836]\n",
      "Iter 6933, loss [-0.22638994, -0.26806685, 0.0416769]\n",
      "Iter 6934, loss [-0.21330652, -0.25223982, 0.038933303]\n",
      "Iter 6935, loss [-0.22570276, -0.26591307, 0.0402103]\n",
      "Iter 6936, loss [-0.2198947, -0.25754386, 0.037649162]\n",
      "Iter 6937, loss [-0.20331205, -0.24776293, 0.044450875]\n",
      "Iter 6938, loss [-0.21402839, -0.2567432, 0.042714804]\n",
      "Iter 6939, loss [-0.2191956, -0.2585656, 0.039369997]\n",
      "Iter 6940, loss [-0.20566116, -0.24716888, 0.04150772]\n",
      "Iter 6941, loss [-0.23705286, -0.2989083, 0.061855428]\n",
      "Iter 6942, loss [-0.22179858, -0.26197925, 0.040180665]\n",
      "Iter 6943, loss [-0.20733193, -0.24996577, 0.042633854]\n",
      "Iter 6944, loss [-0.21705417, -0.26428676, 0.04723258]\n",
      "Iter 6945, loss [-0.2114045, -0.25214654, 0.040742032]\n",
      "Iter 6946, loss [-0.20547016, -0.24376068, 0.038290516]\n",
      "Iter 6947, loss [-0.20827366, -0.2469344, 0.038660735]\n",
      "Iter 6948, loss [-0.22347267, -0.2879631, 0.06449042]\n",
      "Iter 6949, loss [-0.23719743, -0.31852606, 0.08132863]\n",
      "Iter 6950, loss [-0.21892059, -0.26060027, 0.041679688]\n",
      "Iter 6951, loss [-0.21227373, -0.2469636, 0.03468987]\n",
      "Iter 6952, loss [-0.21545303, -0.25397918, 0.03852614]\n",
      "Iter 6953, loss [-0.3064639, -0.3162437, 0.009779803]\n",
      "Iter 6954, loss [-0.20647846, -0.24699923, 0.040520776]\n",
      "Iter 6955, loss [-0.19988889, -0.238247, 0.038358115]\n",
      "Iter 6956, loss [-0.21480513, -0.255779, 0.04097387]\n",
      "Iter 6957, loss [-0.20492077, -0.24253647, 0.037615694]\n",
      "Iter 6958, loss [-0.2198151, -0.2606601, 0.040845014]\n",
      "Iter 6959, loss [-0.21925473, -0.25980344, 0.04054872]\n",
      "Iter 6960, loss [-0.21196151, -0.25387263, 0.041911118]\n",
      "Iter 6961, loss [-0.18097715, -0.22968939, 0.048712235]\n",
      "Iter 6962, loss [-0.22570479, -0.263157, 0.037452213]\n",
      "Iter 6963, loss [-0.20701545, -0.24734856, 0.040333103]\n",
      "Iter 6964, loss [-0.24095619, -0.27587965, 0.034923457]\n",
      "Iter 6965, loss [-0.19626299, -0.2645843, 0.06832132]\n",
      "Iter 6966, loss [-0.20011878, -0.26075658, 0.060637794]\n",
      "Iter 6967, loss [-0.22544134, -0.26697603, 0.041534692]\n",
      "Iter 6968, loss [-0.20460467, -0.26003057, 0.055425897]\n",
      "Iter 6969, loss [-0.20840998, -0.2526151, 0.04420511]\n",
      "Iter 6970, loss [-0.22884887, -0.3130511, 0.08420223]\n",
      "Iter 6971, loss [-0.20653716, -0.25632358, 0.04978642]\n",
      "Iter 6972, loss [-0.21739098, -0.2547753, 0.0373843]\n",
      "Iter 6973, loss [-0.21522519, -0.25173235, 0.036507163]\n",
      "Iter 6974, loss [-0.21601725, -0.25008777, 0.03407052]\n",
      "Iter 6975, loss [-0.2020796, -0.2912677, 0.0891881]\n",
      "Iter 6976, loss [-0.20644298, -0.24253331, 0.03609032]\n",
      "Iter 6977, loss [-0.23783274, -0.30998442, 0.072151676]\n",
      "Iter 6978, loss [-0.20458941, -0.24124727, 0.03665786]\n",
      "Iter 6979, loss [-0.22028801, -0.28582278, 0.06553476]\n",
      "Iter 6980, loss [-0.21325569, -0.25474545, 0.04148976]\n",
      "Iter 6981, loss [-0.20534122, -0.24170348, 0.036362257]\n",
      "Iter 6982, loss [-0.22807564, -0.26985377, 0.04177813]\n",
      "Iter 6983, loss [-0.20393367, -0.24188305, 0.037949383]\n",
      "Iter 6984, loss [-0.22614233, -0.26095444, 0.034812108]\n",
      "Iter 6985, loss [-0.21040708, -0.24952242, 0.039115336]\n",
      "Iter 6986, loss [-0.20683168, -0.24501202, 0.038180336]\n",
      "Iter 6987, loss [-0.22064245, -0.2599115, 0.039269052]\n",
      "Iter 6988, loss [-0.22727653, -0.29712114, 0.06984461]\n",
      "Iter 6989, loss [-0.21921514, -0.25707847, 0.03786333]\n",
      "Iter 6990, loss [-0.21057196, -0.2603297, 0.049757734]\n",
      "Iter 6991, loss [-0.21026865, -0.2504361, 0.040167443]\n",
      "Iter 6992, loss [-0.21092647, -0.24929392, 0.038367447]\n",
      "Iter 6993, loss [-0.21905038, -0.25652945, 0.03747907]\n",
      "Iter 6994, loss [-0.22044885, -0.2609005, 0.040451653]\n",
      "Iter 6995, loss [-0.24349065, -0.30675456, 0.06326391]\n",
      "Iter 6996, loss [-0.21494243, -0.25692436, 0.041981936]\n",
      "Iter 6997, loss [-0.30781722, -0.31735706, 0.009539856]\n",
      "Iter 6998, loss [-0.2182597, -0.25606242, 0.037802715]\n",
      "Iter 6999, loss [-0.2255812, -0.26291394, 0.03733275]\n",
      "Iter 7000, loss [-0.20619693, -0.24186091, 0.03566397]\n",
      "Iter 7001, loss [-0.22660647, -0.26352897, 0.036922496]\n",
      "Iter 7002, loss [-0.21134084, -0.25808877, 0.046747923]\n",
      "Iter 7003, loss [-0.21816061, -0.2562017, 0.038041096]\n",
      "Iter 7004, loss [-0.20574154, -0.25521836, 0.049476814]\n",
      "Iter 7005, loss [-0.21156949, -0.25013238, 0.038562886]\n",
      "Iter 7006, loss [-0.2143872, -0.26030844, 0.04592125]\n",
      "Iter 7007, loss [-0.21500824, -0.25532547, 0.04031722]\n",
      "Iter 7008, loss [-0.22806543, -0.26662976, 0.03856433]\n",
      "Iter 7009, loss [-0.22545195, -0.2660086, 0.040556632]\n",
      "Iter 7010, loss [-0.22230065, -0.26729771, 0.04499706]\n",
      "Iter 7011, loss [-0.21982938, -0.25590232, 0.03607294]\n",
      "Iter 7012, loss [-0.22627665, -0.2658157, 0.039539058]\n",
      "Iter 7013, loss [-0.21183014, -0.25006056, 0.038230427]\n",
      "Iter 7014, loss [-0.20871082, -0.24559358, 0.036882766]\n",
      "Iter 7015, loss [-0.217169, -0.25907362, 0.04190461]\n",
      "Iter 7016, loss [-0.22121263, -0.26228067, 0.041068047]\n",
      "Iter 7017, loss [-0.20835285, -0.24998038, 0.041627523]\n",
      "Iter 7018, loss [-0.20059785, -0.23728651, 0.036688663]\n",
      "Iter 7019, loss [-0.30796844, -0.31743294, 0.009464491]\n",
      "Iter 7020, loss [-0.22901765, -0.26629767, 0.03728002]\n",
      "Iter 7021, loss [-0.21772413, -0.25753084, 0.03980671]\n",
      "Iter 7022, loss [-0.22505727, -0.26157084, 0.036513563]\n",
      "Iter 7023, loss [-0.21982285, -0.25818095, 0.038358096]\n",
      "Iter 7024, loss [-0.2042774, -0.2470534, 0.042776]\n",
      "Iter 7025, loss [-0.22701693, -0.2668355, 0.039818577]\n",
      "Iter 7026, loss [-0.2128449, -0.2536352, 0.04079031]\n",
      "Iter 7027, loss [-0.22489038, -0.2628673, 0.037976928]\n",
      "Iter 7028, loss [-0.22253999, -0.25901255, 0.036472566]\n",
      "Iter 7029, loss [-0.21233034, -0.25140038, 0.039070047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7030, loss [-0.21895878, -0.25635695, 0.03739817]\n",
      "Iter 7031, loss [-0.22896498, -0.26767614, 0.038711157]\n",
      "Iter 7032, loss [-0.22004808, -0.25909296, 0.039044872]\n",
      "Iter 7033, loss [-0.21754189, -0.25968692, 0.04214503]\n",
      "Iter 7034, loss [-0.21757078, -0.25780675, 0.04023596]\n",
      "Iter 7035, loss [-0.24190718, -0.27700877, 0.0351016]\n",
      "Iter 7036, loss [-0.22287314, -0.26022866, 0.037355527]\n",
      "Iter 7037, loss [-0.22012039, -0.26008743, 0.039967045]\n",
      "Iter 7038, loss [-0.21774276, -0.25753972, 0.039796963]\n",
      "Iter 7039, loss [-0.20866868, -0.25038522, 0.04171654]\n",
      "Iter 7040, loss [-0.21288648, -0.2527118, 0.039825317]\n",
      "Iter 7041, loss [-0.21876621, -0.25726995, 0.03850373]\n",
      "Iter 7042, loss [-0.21878046, -0.25742355, 0.038643096]\n",
      "Iter 7043, loss [-0.23853335, -0.2937065, 0.05517315]\n",
      "Iter 7044, loss [-0.20869647, -0.2503933, 0.041696828]\n",
      "Iter 7045, loss [-0.22318234, -0.26075062, 0.037568286]\n",
      "Iter 7046, loss [-0.2254678, -0.26306528, 0.037597477]\n",
      "Iter 7047, loss [-0.182249, -0.23073305, 0.048484053]\n",
      "Iter 7048, loss [-0.21257646, -0.2503087, 0.03773223]\n",
      "Iter 7049, loss [-0.22504291, -0.26265487, 0.03761197]\n",
      "Iter 7050, loss [-0.2045371, -0.24771754, 0.04318046]\n",
      "Iter 7051, loss [-0.21564502, -0.2606169, 0.04497188]\n",
      "Iter 7052, loss [-0.20091516, -0.23755355, 0.036638387]\n",
      "Iter 7053, loss [-0.22771513, -0.2881339, 0.060418755]\n",
      "Iter 7054, loss [-0.21281472, -0.2523425, 0.039527778]\n",
      "Iter 7055, loss [-0.20885797, -0.24506858, 0.03621061]\n",
      "Iter 7056, loss [-0.21732894, -0.25627854, 0.0389496]\n",
      "Iter 7057, loss [-0.21898833, -0.27893367, 0.05994534]\n",
      "Iter 7058, loss [-0.3079594, -0.31732073, 0.009361319]\n",
      "Iter 7059, loss [-0.22530437, -0.263397, 0.038092636]\n",
      "Iter 7060, loss [-0.23016036, -0.26947227, 0.039311923]\n",
      "Iter 7061, loss [-0.22976187, -0.27262694, 0.042865075]\n",
      "Iter 7062, loss [-0.20576996, -0.2466511, 0.040881135]\n",
      "Iter 7063, loss [-0.20683047, -0.2554189, 0.04858842]\n",
      "Iter 7064, loss [-0.22792974, -0.26658246, 0.038652726]\n",
      "Iter 7065, loss [-0.22527629, -0.2638999, 0.038623594]\n",
      "Iter 7066, loss [-0.21907327, -0.26431188, 0.04523862]\n",
      "Iter 7067, loss [-0.21756439, -0.2581385, 0.04057412]\n",
      "Iter 7068, loss [-0.22230864, -0.2635359, 0.04122726]\n",
      "Iter 7069, loss [-0.21539801, -0.25349697, 0.03809896]\n",
      "Iter 7070, loss [-0.22594085, -0.26991752, 0.043976665]\n",
      "Iter 7071, loss [-0.21188839, -0.3033292, 0.09144081]\n",
      "Iter 7072, loss [-0.21272956, -0.25361088, 0.04088132]\n",
      "Iter 7073, loss [-0.22292528, -0.2600452, 0.03711993]\n",
      "Iter 7074, loss [-0.20902269, -0.24619898, 0.0371763]\n",
      "Iter 7075, loss [-0.2232576, -0.26978803, 0.046530426]\n",
      "Iter 7076, loss [-0.20457204, -0.24382983, 0.0392578]\n",
      "Iter 7077, loss [-0.213108, -0.2525, 0.039391994]\n",
      "Iter 7078, loss [-0.21783587, -0.2573896, 0.039553728]\n",
      "Iter 7079, loss [-0.2133652, -0.2529615, 0.039596293]\n",
      "Iter 7080, loss [-0.2050814, -0.24344245, 0.038361035]\n",
      "Iter 7081, loss [-0.21144319, -0.2604869, 0.049043722]\n",
      "Iter 7082, loss [-0.22373496, -0.26956382, 0.04582886]\n",
      "Iter 7083, loss [-0.22181275, -0.26061684, 0.038804084]\n",
      "Iter 7084, loss [-0.22969523, -0.27294043, 0.043245196]\n",
      "Iter 7085, loss [-0.21009912, -0.24867085, 0.038571734]\n",
      "Iter 7086, loss [-0.219968, -0.2586157, 0.038647696]\n",
      "Iter 7087, loss [-0.21232836, -0.24924883, 0.03692047]\n",
      "Iter 7088, loss [-0.21557416, -0.25980347, 0.04422931]\n",
      "Iter 7089, loss [-0.22203848, -0.26039726, 0.03835877]\n",
      "Iter 7090, loss [-0.24433966, -0.30897644, 0.06463678]\n",
      "Iter 7091, loss [-0.22708075, -0.2878372, 0.060756456]\n",
      "Iter 7092, loss [-0.21821105, -0.25635836, 0.0381473]\n",
      "Iter 7093, loss [-0.22875503, -0.26685345, 0.038098425]\n",
      "Iter 7094, loss [-0.2195403, -0.25705346, 0.037513167]\n",
      "Iter 7095, loss [-0.21299177, -0.24902734, 0.036035575]\n",
      "Iter 7096, loss [-0.20795792, -0.24427353, 0.036315612]\n",
      "Iter 7097, loss [-0.22531964, -0.26541787, 0.040098235]\n",
      "Iter 7098, loss [-0.22123961, -0.29402673, 0.07278712]\n",
      "Iter 7099, loss [-0.21774381, -0.2578398, 0.040095977]\n",
      "Iter 7100, loss [-0.22333688, -0.2646473, 0.041310422]\n",
      "Iter 7101, loss [-0.21027651, -0.2515203, 0.041243784]\n",
      "Iter 7102, loss [-0.17930514, -0.23304772, 0.053742595]\n",
      "Iter 7103, loss [-0.22854021, -0.26968706, 0.041146852]\n",
      "Iter 7104, loss [-0.22428173, -0.26667434, 0.04239262]\n",
      "Iter 7105, loss [-0.23529816, -0.30230543, 0.067007266]\n",
      "Iter 7106, loss [-0.20742077, -0.24661225, 0.039191492]\n",
      "Iter 7107, loss [-0.21014921, -0.24633656, 0.03618735]\n",
      "Iter 7108, loss [-0.20771302, -0.2488756, 0.041162577]\n",
      "Iter 7109, loss [-0.23340073, -0.30360517, 0.07020443]\n",
      "Iter 7110, loss [-0.20632017, -0.30346867, 0.0971485]\n",
      "Iter 7111, loss [-0.21599273, -0.25697502, 0.04098229]\n",
      "Iter 7112, loss [-0.22545782, -0.2643787, 0.038920883]\n",
      "Iter 7113, loss [-0.22772218, -0.2734843, 0.045762103]\n",
      "Iter 7114, loss [-0.22578526, -0.2647306, 0.03894534]\n",
      "Iter 7115, loss [-0.22835791, -0.26879066, 0.04043276]\n",
      "Iter 7116, loss [-0.22811049, -0.2651725, 0.037062015]\n",
      "Iter 7117, loss [-0.22838861, -0.26444983, 0.036061224]\n",
      "Iter 7118, loss [-0.21581495, -0.25443453, 0.038619585]\n",
      "Iter 7119, loss [-0.22449206, -0.2617101, 0.037218045]\n",
      "Iter 7120, loss [-0.21723655, -0.25412497, 0.036888413]\n",
      "Iter 7121, loss [-0.21096392, -0.25079548, 0.03983156]\n",
      "Iter 7122, loss [-0.21026914, -0.25777727, 0.04750813]\n",
      "Iter 7123, loss [-0.21656846, -0.25912488, 0.04255642]\n",
      "Iter 7124, loss [-0.21298495, -0.25045082, 0.037465863]\n",
      "Iter 7125, loss [-0.23636624, -0.29193786, 0.05557161]\n",
      "Iter 7126, loss [-0.19795173, -0.24432226, 0.04637052]\n",
      "Iter 7127, loss [-0.30719015, -0.3165391, 0.009348951]\n",
      "Iter 7128, loss [-0.2244737, -0.26139718, 0.036923483]\n",
      "Iter 7129, loss [-0.2164163, -0.29859453, 0.082178235]\n",
      "Iter 7130, loss [-0.22133034, -0.26095438, 0.039624035]\n",
      "Iter 7131, loss [-0.21655616, -0.2580675, 0.041511334]\n",
      "Iter 7132, loss [-0.21926482, -0.25589275, 0.036627933]\n",
      "Iter 7133, loss [-0.21901618, -0.25994503, 0.04092885]\n",
      "Iter 7134, loss [-0.20694858, -0.24893437, 0.04198579]\n",
      "Iter 7135, loss [-0.21306217, -0.25264132, 0.03957916]\n",
      "Iter 7136, loss [-0.21952535, -0.2572122, 0.037686836]\n",
      "Iter 7137, loss [-0.21152191, -0.24923848, 0.037716564]\n",
      "Iter 7138, loss [-0.20759094, -0.24864239, 0.04105144]\n",
      "Iter 7139, loss [-0.21636665, -0.2579208, 0.041554153]\n",
      "Iter 7140, loss [-0.21329466, -0.25429553, 0.04100088]\n",
      "Iter 7141, loss [-0.20806226, -0.24824344, 0.040181167]\n",
      "Iter 7142, loss [-0.21715623, -0.2580214, 0.04086518]\n",
      "Iter 7143, loss [-0.18561769, -0.26971254, 0.084094845]\n",
      "Iter 7144, loss [-0.2084237, -0.24613556, 0.037711862]\n",
      "Iter 7145, loss [-0.21166329, -0.25054497, 0.038881674]\n",
      "Iter 7146, loss [-0.2248966, -0.2674885, 0.04259191]\n",
      "Iter 7147, loss [-0.23057832, -0.27002338, 0.039445058]\n",
      "Iter 7148, loss [-0.21903741, -0.257566, 0.03852859]\n",
      "Iter 7149, loss [-0.20459953, -0.24606963, 0.04147009]\n",
      "Iter 7150, loss [-0.21036234, -0.24964346, 0.03928111]\n",
      "Iter 7151, loss [-0.19792524, -0.24404635, 0.046121113]\n",
      "Iter 7152, loss [-0.21780047, -0.25610706, 0.0383066]\n",
      "Iter 7153, loss [-0.21963781, -0.2822189, 0.062581085]\n",
      "Iter 7154, loss [-0.19939966, -0.23417571, 0.034776047]\n",
      "Iter 7155, loss [-0.21633327, -0.2535103, 0.03717702]\n",
      "Iter 7156, loss [-0.30799535, -0.31760582, 0.009610463]\n",
      "Iter 7157, loss [-0.20702177, -0.24606304, 0.03904126]\n",
      "Iter 7158, loss [-0.24349436, -0.3070032, 0.06350884]\n",
      "Iter 7159, loss [-0.21557096, -0.2582368, 0.04266583]\n",
      "Iter 7160, loss [-0.21231617, -0.256247, 0.043930843]\n",
      "Iter 7161, loss [-0.21170548, -0.25099194, 0.039286472]\n",
      "Iter 7162, loss [-0.22517926, -0.26671022, 0.04153097]\n",
      "Iter 7163, loss [-0.21963902, -0.25702515, 0.037386134]\n",
      "Iter 7164, loss [-0.2097108, -0.24973214, 0.040021338]\n",
      "Iter 7165, loss [-0.20838192, -0.24527043, 0.036888503]\n",
      "Iter 7166, loss [-0.20633155, -0.24348268, 0.037151128]\n",
      "Iter 7167, loss [-0.21923739, -0.25787303, 0.038635634]\n",
      "Iter 7168, loss [-0.21677983, -0.25836232, 0.041582488]\n",
      "Iter 7169, loss [-0.30888462, -0.31790653, 0.009021912]\n",
      "Iter 7170, loss [-0.211127, -0.24915329, 0.03802629]\n",
      "Iter 7171, loss [-0.22048092, -0.262874, 0.04239309]\n",
      "Iter 7172, loss [-0.2114226, -0.26064447, 0.049221855]\n",
      "Iter 7173, loss [-0.19806777, -0.245314, 0.04724623]\n",
      "Iter 7174, loss [-0.20844927, -0.24800466, 0.039555382]\n",
      "Iter 7175, loss [-0.21141484, -0.25714043, 0.045725577]\n",
      "Iter 7176, loss [-0.20672691, -0.2530393, 0.046312384]\n",
      "Iter 7177, loss [-0.2226463, -0.3021581, 0.07951179]\n",
      "Iter 7178, loss [-0.23221594, -0.3007024, 0.068486445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7179, loss [-0.22389652, -0.26164705, 0.037750527]\n",
      "Iter 7180, loss [-0.2399847, -0.31157714, 0.071592435]\n",
      "Iter 7181, loss [-0.22996643, -0.26955035, 0.03958393]\n",
      "Iter 7182, loss [-0.21436247, -0.25522998, 0.0408675]\n",
      "Iter 7183, loss [-0.21745451, -0.25626156, 0.038807046]\n",
      "Iter 7184, loss [-0.19992101, -0.23709814, 0.037177127]\n",
      "Iter 7185, loss [-0.21216683, -0.25365916, 0.041492324]\n",
      "Iter 7186, loss [-0.21010497, -0.260614, 0.050509043]\n",
      "Iter 7187, loss [-0.21264327, -0.25387752, 0.041234262]\n",
      "Iter 7188, loss [-0.24865027, -0.31117284, 0.062522575]\n",
      "Iter 7189, loss [-0.22888541, -0.2675039, 0.03861847]\n",
      "Iter 7190, loss [-0.22290182, -0.26751798, 0.044616155]\n",
      "Iter 7191, loss [-0.24909753, -0.31098196, 0.061884433]\n",
      "Iter 7192, loss [-0.21921654, -0.25851405, 0.039297506]\n",
      "Iter 7193, loss [-0.2255867, -0.26944646, 0.04385976]\n",
      "Iter 7194, loss [-0.21606946, -0.25611845, 0.040048994]\n",
      "Iter 7195, loss [-0.23938441, -0.2958807, 0.0564963]\n",
      "Iter 7196, loss [-0.2001378, -0.23748355, 0.037345752]\n",
      "Iter 7197, loss [-0.22806999, -0.26662707, 0.03855709]\n",
      "Iter 7198, loss [-0.22469798, -0.26176628, 0.037068315]\n",
      "Iter 7199, loss [-0.21440683, -0.2554735, 0.04106666]\n",
      "Iter 7200, loss [-0.24887337, -0.29182437, 0.042951003]\n",
      "Iter 7201, loss [-0.239568, -0.29483628, 0.055268288]\n",
      "Iter 7202, loss [-0.21923405, -0.25729576, 0.0380617]\n",
      "Iter 7203, loss [-0.20086354, -0.23751593, 0.03665238]\n",
      "Iter 7204, loss [-0.22170815, -0.26184344, 0.0401353]\n",
      "Iter 7205, loss [-0.23022434, -0.26951942, 0.039295077]\n",
      "Iter 7206, loss [-0.21987195, -0.2616958, 0.041823845]\n",
      "Iter 7207, loss [-0.23229264, -0.2700005, 0.03770785]\n",
      "Iter 7208, loss [-0.2122944, -0.25128064, 0.038986236]\n",
      "Iter 7209, loss [-0.30804372, -0.31724113, 0.009197408]\n",
      "Iter 7210, loss [-0.22993717, -0.27121127, 0.041274093]\n",
      "Iter 7211, loss [-0.21088812, -0.25605938, 0.045171253]\n",
      "Iter 7212, loss [-0.21732229, -0.25701284, 0.039690547]\n",
      "Iter 7213, loss [-0.20393534, -0.24496974, 0.0410344]\n",
      "Iter 7214, loss [-0.21122783, -0.3008114, 0.089583576]\n",
      "Iter 7215, loss [-0.30745748, -0.31654105, 0.009083562]\n",
      "Iter 7216, loss [-0.212951, -0.25326476, 0.040313758]\n",
      "Iter 7217, loss [-0.24140064, -0.32141042, 0.08000977]\n",
      "Iter 7218, loss [-0.21169096, -0.25127316, 0.03958219]\n",
      "Iter 7219, loss [-0.21962716, -0.25960603, 0.039978877]\n",
      "Iter 7220, loss [-0.22996277, -0.29732218, 0.06735941]\n",
      "Iter 7221, loss [-0.2177397, -0.25747362, 0.039733913]\n",
      "Iter 7222, loss [-0.21203154, -0.25003576, 0.038004227]\n",
      "Iter 7223, loss [-0.20404191, -0.24239029, 0.03834838]\n",
      "Iter 7224, loss [-0.2176454, -0.25757447, 0.03992906]\n",
      "Iter 7225, loss [-0.21714057, -0.2570494, 0.03990884]\n",
      "Iter 7226, loss [-0.21181987, -0.25157487, 0.039755]\n",
      "Iter 7227, loss [-0.30822244, -0.31739593, 0.009173473]\n",
      "Iter 7228, loss [-0.22794151, -0.28916696, 0.061225444]\n",
      "Iter 7229, loss [-0.2286303, -0.2652322, 0.036601894]\n",
      "Iter 7230, loss [-0.19868065, -0.24450383, 0.045823168]\n",
      "Iter 7231, loss [-0.22609502, -0.26712012, 0.041025106]\n",
      "Iter 7232, loss [-0.21755129, -0.25823253, 0.040681235]\n",
      "Iter 7233, loss [-0.20391044, -0.24634676, 0.042436313]\n",
      "Iter 7234, loss [-0.20947023, -0.24593213, 0.036461905]\n",
      "Iter 7235, loss [-0.21075103, -0.24997996, 0.039228927]\n",
      "Iter 7236, loss [-0.22175163, -0.26079944, 0.0390478]\n",
      "Iter 7237, loss [-0.18240035, -0.23233938, 0.04993903]\n",
      "Iter 7238, loss [-0.21796396, -0.25915, 0.041186027]\n",
      "Iter 7239, loss [-0.21872261, -0.26402268, 0.045300066]\n",
      "Iter 7240, loss [-0.20330718, -0.24362484, 0.04031766]\n",
      "Iter 7241, loss [-0.22124697, -0.26061824, 0.039371267]\n",
      "Iter 7242, loss [-0.21304514, -0.25352716, 0.04048203]\n",
      "Iter 7243, loss [-0.20767273, -0.24819249, 0.04051976]\n",
      "Iter 7244, loss [-0.21168964, -0.24907677, 0.03738713]\n",
      "Iter 7245, loss [-0.18267262, -0.2306724, 0.04799979]\n",
      "Iter 7246, loss [-0.22889332, -0.26595584, 0.03706251]\n",
      "Iter 7247, loss [-0.21358101, -0.2536066, 0.04002558]\n",
      "Iter 7248, loss [-0.22196987, -0.26038638, 0.038416505]\n",
      "Iter 7249, loss [-0.22851555, -0.27363235, 0.045116797]\n",
      "Iter 7250, loss [-0.21557187, -0.25666207, 0.041090205]\n",
      "Iter 7251, loss [-0.2198213, -0.2587531, 0.038931787]\n",
      "Iter 7252, loss [-0.22604202, -0.26971897, 0.043676954]\n",
      "Iter 7253, loss [-0.22001022, -0.25888664, 0.038876414]\n",
      "Iter 7254, loss [-0.21710551, -0.2559281, 0.038822588]\n",
      "Iter 7255, loss [-0.22030595, -0.26039842, 0.04009246]\n",
      "Iter 7256, loss [-0.224408, -0.26225707, 0.03784907]\n",
      "Iter 7257, loss [-0.20940009, -0.24615867, 0.036758583]\n",
      "Iter 7258, loss [-0.30886143, -0.31795126, 0.009089819]\n",
      "Iter 7259, loss [-0.21950057, -0.26345587, 0.04395529]\n",
      "Iter 7260, loss [-0.21971759, -0.25715134, 0.037433743]\n",
      "Iter 7261, loss [-0.22167, -0.26164076, 0.039970763]\n",
      "Iter 7262, loss [-0.21909335, -0.25866556, 0.03957221]\n",
      "Iter 7263, loss [-0.21767473, -0.26000956, 0.042334832]\n",
      "Iter 7264, loss [-0.21270882, -0.25202516, 0.03931634]\n",
      "Iter 7265, loss [-0.20988227, -0.25298917, 0.043106895]\n",
      "Iter 7266, loss [-0.21190374, -0.25041306, 0.038509324]\n",
      "Iter 7267, loss [-0.2111172, -0.25022408, 0.039106887]\n",
      "Iter 7268, loss [-0.21892159, -0.28030452, 0.061382934]\n",
      "Iter 7269, loss [-0.21341133, -0.25275734, 0.039346002]\n",
      "Iter 7270, loss [-0.21810572, -0.25920406, 0.04109834]\n",
      "Iter 7271, loss [-0.2096684, -0.24702606, 0.037357666]\n",
      "Iter 7272, loss [-0.23233171, -0.2691864, 0.036854696]\n",
      "Iter 7273, loss [-0.22744785, -0.26621285, 0.038764995]\n",
      "Iter 7274, loss [-0.23026946, -0.2686384, 0.038368937]\n",
      "Iter 7275, loss [-0.21374834, -0.25069174, 0.036943413]\n",
      "Iter 7276, loss [-0.21796778, -0.27948898, 0.061521195]\n",
      "Iter 7277, loss [-0.2170703, -0.25937447, 0.04230417]\n",
      "Iter 7278, loss [-0.20655918, -0.2549603, 0.04840111]\n",
      "Iter 7279, loss [-0.22912176, -0.2905176, 0.061395835]\n",
      "Iter 7280, loss [-0.22357753, -0.2613524, 0.03777486]\n",
      "Iter 7281, loss [-0.22683007, -0.26335937, 0.0365293]\n",
      "Iter 7282, loss [-0.20724596, -0.24342404, 0.036178082]\n",
      "Iter 7283, loss [-0.24135499, -0.2761568, 0.034801822]\n",
      "Iter 7284, loss [-0.2169373, -0.2572286, 0.040291306]\n",
      "Iter 7285, loss [-0.20471714, -0.2443342, 0.03961706]\n",
      "Iter 7286, loss [-0.22468051, -0.3081462, 0.083465695]\n",
      "Iter 7287, loss [-0.21150877, -0.2605964, 0.049087625]\n",
      "Iter 7288, loss [-0.20869152, -0.24624808, 0.037556555]\n",
      "Iter 7289, loss [-0.2186542, -0.29532447, 0.076670274]\n",
      "Iter 7290, loss [-0.22888252, -0.26630744, 0.03742493]\n",
      "Iter 7291, loss [-0.21528451, -0.25710225, 0.041817736]\n",
      "Iter 7292, loss [-0.21791583, -0.2570117, 0.039095886]\n",
      "Iter 7293, loss [-0.21709923, -0.25904983, 0.041950595]\n",
      "Iter 7294, loss [-0.2405542, -0.27756098, 0.03700678]\n",
      "Iter 7295, loss [-0.22065333, -0.26032588, 0.03967255]\n",
      "Iter 7296, loss [-0.21304469, -0.2501848, 0.037140116]\n",
      "Iter 7297, loss [-0.21816774, -0.25740203, 0.039234295]\n",
      "Iter 7298, loss [-0.22791308, -0.26625597, 0.0383429]\n",
      "Iter 7299, loss [-0.21394211, -0.24812767, 0.034185562]\n",
      "Iter 7300, loss [-0.22560768, -0.26423165, 0.03862397]\n",
      "Iter 7301, loss [-0.19944926, -0.2936751, 0.09422584]\n",
      "Iter 7302, loss [-0.20915724, -0.25066394, 0.04150669]\n",
      "Iter 7303, loss [-0.19702615, -0.2314981, 0.03447196]\n",
      "Iter 7304, loss [-0.20889983, -0.24449345, 0.03559362]\n",
      "Iter 7305, loss [-0.19274788, -0.23574065, 0.04299277]\n",
      "Iter 7306, loss [-0.21282819, -0.24699703, 0.034168836]\n",
      "Iter 7307, loss [-0.22380495, -0.2603159, 0.03651095]\n",
      "Iter 7308, loss [-0.20365438, -0.24107283, 0.037418462]\n",
      "Iter 7309, loss [-0.210002, -0.2537785, 0.043776482]\n",
      "Iter 7310, loss [-0.20922397, -0.25594905, 0.046725076]\n",
      "Iter 7311, loss [-0.19858973, -0.26300383, 0.0644141]\n",
      "Iter 7312, loss [-0.20917512, -0.25591132, 0.046736192]\n",
      "Iter 7313, loss [-0.20816875, -0.25675344, 0.048584696]\n",
      "Iter 7314, loss [-0.20894217, -0.25155646, 0.042614274]\n",
      "Iter 7315, loss [-0.22299132, -0.2631385, 0.040147193]\n",
      "Iter 7316, loss [-0.20278668, -0.24192621, 0.03913953]\n",
      "Iter 7317, loss [-0.22655606, -0.26304033, 0.036484268]\n",
      "Iter 7318, loss [-0.21494028, -0.27065116, 0.05571088]\n",
      "Iter 7319, loss [-0.20440374, -0.2394221, 0.03501835]\n",
      "Iter 7320, loss [-0.20337674, -0.24730699, 0.043930255]\n",
      "Iter 7321, loss [-0.21430662, -0.25944215, 0.045135535]\n",
      "Iter 7322, loss [-0.21510088, -0.28595698, 0.070856094]\n",
      "Iter 7323, loss [-0.2383013, -0.27792272, 0.03962141]\n",
      "Iter 7324, loss [-0.20497534, -0.24615239, 0.041177046]\n",
      "Iter 7325, loss [-0.21926329, -0.25750867, 0.038245387]\n",
      "Iter 7326, loss [-0.21989116, -0.2569057, 0.03701454]\n",
      "Iter 7327, loss [-0.21731535, -0.2596186, 0.042303264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7328, loss [-0.22501451, -0.2940552, 0.06904068]\n",
      "Iter 7329, loss [-0.21536765, -0.252123, 0.03675535]\n",
      "Iter 7330, loss [-0.2116968, -0.25339505, 0.041698247]\n",
      "Iter 7331, loss [-0.2182113, -0.25606436, 0.03785307]\n",
      "Iter 7332, loss [-0.22469363, -0.2854687, 0.060775064]\n",
      "Iter 7333, loss [-0.22002056, -0.25942442, 0.039403863]\n",
      "Iter 7334, loss [-0.2171942, -0.25575152, 0.03855733]\n",
      "Iter 7335, loss [-0.2238615, -0.26873183, 0.04487033]\n",
      "Iter 7336, loss [-0.20733991, -0.24858908, 0.041249167]\n",
      "Iter 7337, loss [-0.20875564, -0.24520847, 0.036452822]\n",
      "Iter 7338, loss [-0.23191519, -0.2678948, 0.035979614]\n",
      "Iter 7339, loss [-0.20512095, -0.24556367, 0.040442713]\n",
      "Iter 7340, loss [-0.20739648, -0.24865986, 0.041263383]\n",
      "Iter 7341, loss [-0.22013411, -0.25943437, 0.039300255]\n",
      "Iter 7342, loss [-0.22624294, -0.28495833, 0.058715384]\n",
      "Iter 7343, loss [-0.2277032, -0.27453908, 0.046835884]\n",
      "Iter 7344, loss [-0.21841398, -0.25977132, 0.041357342]\n",
      "Iter 7345, loss [-0.2216085, -0.26175907, 0.040150564]\n",
      "Iter 7346, loss [-0.2287121, -0.26755643, 0.038844336]\n",
      "Iter 7347, loss [-0.24882725, -0.3116744, 0.06284713]\n",
      "Iter 7348, loss [-0.20643076, -0.24335179, 0.036921024]\n",
      "Iter 7349, loss [-0.24272496, -0.32027087, 0.07754591]\n",
      "Iter 7350, loss [-0.22653322, -0.26654312, 0.040009897]\n",
      "Iter 7351, loss [-0.20980191, -0.24835397, 0.038552053]\n",
      "Iter 7352, loss [-0.22764748, -0.26672193, 0.039074443]\n",
      "Iter 7353, loss [-0.20995358, -0.24886006, 0.03890648]\n",
      "Iter 7354, loss [-0.22190511, -0.2633496, 0.041444477]\n",
      "Iter 7355, loss [-0.24481547, -0.30918044, 0.06436498]\n",
      "Iter 7356, loss [-0.21173623, -0.25094834, 0.039212115]\n",
      "Iter 7357, loss [-0.21150658, -0.25857538, 0.047068805]\n",
      "Iter 7358, loss [-0.22126165, -0.259032, 0.037770353]\n",
      "Iter 7359, loss [-0.22561371, -0.2650475, 0.039433785]\n",
      "Iter 7360, loss [-0.2183341, -0.2542658, 0.035931695]\n",
      "Iter 7361, loss [-0.22868168, -0.26492986, 0.03624817]\n",
      "Iter 7362, loss [-0.21290927, -0.25091338, 0.03800411]\n",
      "Iter 7363, loss [-0.20409748, -0.24464516, 0.040547684]\n",
      "Iter 7364, loss [-0.21152157, -0.25143132, 0.039909758]\n",
      "Iter 7365, loss [-0.21160263, -0.25184825, 0.04024563]\n",
      "Iter 7366, loss [-0.22425695, -0.26316467, 0.03890772]\n",
      "Iter 7367, loss [-0.21960767, -0.25851393, 0.038906258]\n",
      "Iter 7368, loss [-0.223082, -0.26955897, 0.046476956]\n",
      "Iter 7369, loss [-0.22011615, -0.2571162, 0.03700005]\n",
      "Iter 7370, loss [-0.24738121, -0.3080944, 0.06071321]\n",
      "Iter 7371, loss [-0.21995118, -0.26088327, 0.04093208]\n",
      "Iter 7372, loss [-0.21847573, -0.25759336, 0.03911764]\n",
      "Iter 7373, loss [-0.22002132, -0.25746846, 0.03744714]\n",
      "Iter 7374, loss [-0.21427149, -0.2563541, 0.042082604]\n",
      "Iter 7375, loss [-0.21947995, -0.2565205, 0.037040558]\n",
      "Iter 7376, loss [-0.22514941, -0.26946864, 0.044319227]\n",
      "Iter 7377, loss [-0.24194717, -0.3220895, 0.08014231]\n",
      "Iter 7378, loss [-0.2083579, -0.24518853, 0.036830634]\n",
      "Iter 7379, loss [-0.2160495, -0.25474438, 0.038694873]\n",
      "Iter 7380, loss [-0.21057299, -0.24982178, 0.039248787]\n",
      "Iter 7381, loss [-0.20278323, -0.2416684, 0.03888517]\n",
      "Iter 7382, loss [-0.20362392, -0.24252501, 0.038901098]\n",
      "Iter 7383, loss [-0.20617887, -0.24388844, 0.03770957]\n",
      "Iter 7384, loss [-0.20809612, -0.24862154, 0.04052542]\n",
      "Iter 7385, loss [-0.22256953, -0.28297356, 0.06040403]\n",
      "Iter 7386, loss [-0.22074312, -0.29989213, 0.079149]\n",
      "Iter 7387, loss [-0.20944345, -0.2611715, 0.051728047]\n",
      "Iter 7388, loss [-0.23344441, -0.2936615, 0.060217097]\n",
      "Iter 7389, loss [-0.19800168, -0.24575604, 0.047754362]\n",
      "Iter 7390, loss [-0.21811956, -0.26198345, 0.043863885]\n",
      "Iter 7391, loss [-0.21140525, -0.24866325, 0.037258]\n",
      "Iter 7392, loss [-0.20969391, -0.2465016, 0.036807686]\n",
      "Iter 7393, loss [-0.2239774, -0.2610833, 0.037105903]\n",
      "Iter 7394, loss [-0.2257042, -0.2634776, 0.037773393]\n",
      "Iter 7395, loss [-0.20595463, -0.24233268, 0.036378056]\n",
      "Iter 7396, loss [-0.19342741, -0.29336888, 0.099941455]\n",
      "Iter 7397, loss [-0.20935488, -0.24878205, 0.039427172]\n",
      "Iter 7398, loss [-0.23815611, -0.27323374, 0.03507763]\n",
      "Iter 7399, loss [-0.20569238, -0.24801093, 0.04231856]\n",
      "Iter 7400, loss [-0.21430475, -0.25364846, 0.039343722]\n",
      "Iter 7401, loss [-0.21417156, -0.25173154, 0.03755999]\n",
      "Iter 7402, loss [-0.2090798, -0.25676024, 0.047680434]\n",
      "Iter 7403, loss [-0.22541764, -0.26382494, 0.03840729]\n",
      "Iter 7404, loss [-0.2156175, -0.25238833, 0.036770836]\n",
      "Iter 7405, loss [-0.2068854, -0.24990034, 0.04301494]\n",
      "Iter 7406, loss [-0.2191166, -0.2604481, 0.041331492]\n",
      "Iter 7407, loss [-0.22309679, -0.26292142, 0.03982464]\n",
      "Iter 7408, loss [-0.21209185, -0.25559634, 0.043504488]\n",
      "Iter 7409, loss [-0.20917709, -0.25042793, 0.041250844]\n",
      "Iter 7410, loss [-0.21273214, -0.25808403, 0.04535189]\n",
      "Iter 7411, loss [-0.22003284, -0.2583325, 0.038299646]\n",
      "Iter 7412, loss [-0.21249211, -0.25181425, 0.03932213]\n",
      "Iter 7413, loss [-0.23210262, -0.26835507, 0.036252454]\n",
      "Iter 7414, loss [-0.2251681, -0.2687152, 0.043547105]\n",
      "Iter 7415, loss [-0.21147278, -0.25097546, 0.039502677]\n",
      "Iter 7416, loss [-0.19600818, -0.27009228, 0.074084096]\n",
      "Iter 7417, loss [-0.22297847, -0.26265743, 0.03967896]\n",
      "Iter 7418, loss [-0.20800361, -0.2533234, 0.045319796]\n",
      "Iter 7419, loss [-0.21945244, -0.26187202, 0.042419575]\n",
      "Iter 7420, loss [-0.22064586, -0.26856542, 0.047919553]\n",
      "Iter 7421, loss [-0.22289002, -0.2888856, 0.06599558]\n",
      "Iter 7422, loss [-0.22512957, -0.26731393, 0.04218436]\n",
      "Iter 7423, loss [-0.21416336, -0.29398507, 0.079821706]\n",
      "Iter 7424, loss [-0.20181593, -0.24202693, 0.040210992]\n",
      "Iter 7425, loss [-0.20649837, -0.2457429, 0.03924453]\n",
      "Iter 7426, loss [-0.224664, -0.2588784, 0.03421441]\n",
      "Iter 7427, loss [-0.21231453, -0.24774757, 0.03543304]\n",
      "Iter 7428, loss [-0.21889931, -0.25839704, 0.03949773]\n",
      "Iter 7429, loss [-0.23468113, -0.31669778, 0.082016654]\n",
      "Iter 7430, loss [-0.215064, -0.25615117, 0.04108716]\n",
      "Iter 7431, loss [-0.21519841, -0.25651032, 0.041311905]\n",
      "Iter 7432, loss [-0.24269594, -0.30836797, 0.065672025]\n",
      "Iter 7433, loss [-0.22320127, -0.2627641, 0.03956283]\n",
      "Iter 7434, loss [-0.2181571, -0.25516137, 0.037004273]\n",
      "Iter 7435, loss [-0.22102712, -0.25744376, 0.036416635]\n",
      "Iter 7436, loss [-0.20768861, -0.24521844, 0.037529822]\n",
      "Iter 7437, loss [-0.2034552, -0.24213915, 0.038683947]\n",
      "Iter 7438, loss [-0.21537596, -0.25716814, 0.04179218]\n",
      "Iter 7439, loss [-0.18043065, -0.23096627, 0.05053562]\n",
      "Iter 7440, loss [-0.22282316, -0.2837267, 0.06090353]\n",
      "Iter 7441, loss [-0.2093308, -0.253462, 0.044131197]\n",
      "Iter 7442, loss [-0.22646141, -0.2660231, 0.039561696]\n",
      "Iter 7443, loss [-0.20750354, -0.2456316, 0.03812806]\n",
      "Iter 7444, loss [-0.22052993, -0.25982246, 0.039292533]\n",
      "Iter 7445, loss [-0.20604062, -0.25419247, 0.048151843]\n",
      "Iter 7446, loss [-0.20873936, -0.2457448, 0.03700544]\n",
      "Iter 7447, loss [-0.20643534, -0.292746, 0.08631067]\n",
      "Iter 7448, loss [-0.20906551, -0.24688247, 0.037816953]\n",
      "Iter 7449, loss [-0.2208421, -0.26072714, 0.039885044]\n",
      "Iter 7450, loss [-0.24585158, -0.3120142, 0.066162616]\n",
      "Iter 7451, loss [-0.30637014, -0.31603977, 0.009669634]\n",
      "Iter 7452, loss [-0.19865549, -0.24578692, 0.047131427]\n",
      "Iter 7453, loss [-0.2368747, -0.31473854, 0.077863835]\n",
      "Iter 7454, loss [-0.21466152, -0.2543788, 0.03971727]\n",
      "Iter 7455, loss [-0.22572985, -0.26690578, 0.041175924]\n",
      "Iter 7456, loss [-0.21859074, -0.25630912, 0.037718385]\n",
      "Iter 7457, loss [-0.20762011, -0.247778, 0.040157884]\n",
      "Iter 7458, loss [-0.21905282, -0.2553242, 0.036271386]\n",
      "Iter 7459, loss [-0.21657346, -0.2566926, 0.040119123]\n",
      "Iter 7460, loss [-0.21888968, -0.25971285, 0.04082317]\n",
      "Iter 7461, loss [-0.21017218, -0.2514007, 0.041228533]\n",
      "Iter 7462, loss [-0.21955785, -0.25960353, 0.040045682]\n",
      "Iter 7463, loss [-0.21910243, -0.25840315, 0.039300725]\n",
      "Iter 7464, loss [-0.2063201, -0.24329641, 0.0369763]\n",
      "Iter 7465, loss [-0.2272277, -0.26558927, 0.038361564]\n",
      "Iter 7466, loss [-0.22862172, -0.26636454, 0.03774283]\n",
      "Iter 7467, loss [-0.2213549, -0.26024053, 0.038885616]\n",
      "Iter 7468, loss [-0.21814644, -0.25645486, 0.038308404]\n",
      "Iter 7469, loss [-0.23415624, -0.2981059, 0.06394966]\n",
      "Iter 7470, loss [-0.21775657, -0.2629442, 0.045187615]\n",
      "Iter 7471, loss [-0.2104252, -0.27189553, 0.06147033]\n",
      "Iter 7472, loss [-0.21543658, -0.276397, 0.06096041]\n",
      "Iter 7473, loss [-0.20863935, -0.2469126, 0.038273238]\n",
      "Iter 7474, loss [-0.21086213, -0.25635168, 0.04548955]\n",
      "Iter 7475, loss [-0.20719531, -0.24447682, 0.03728152]\n",
      "Iter 7476, loss [-0.2166513, -0.2580743, 0.041423008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7477, loss [-0.2196663, -0.25941768, 0.039751373]\n",
      "Iter 7478, loss [-0.21645011, -0.25468606, 0.038235947]\n",
      "Iter 7479, loss [-0.21536918, -0.25579312, 0.040423945]\n",
      "Iter 7480, loss [-0.20528902, -0.24312107, 0.037832048]\n",
      "Iter 7481, loss [-0.22313991, -0.261025, 0.037885092]\n",
      "Iter 7482, loss [-0.20707794, -0.24916999, 0.04209205]\n",
      "Iter 7483, loss [-0.22136164, -0.2593044, 0.03794276]\n",
      "Iter 7484, loss [-0.20732473, -0.25011864, 0.04279391]\n",
      "Iter 7485, loss [-0.20330063, -0.2432206, 0.039919972]\n",
      "Iter 7486, loss [-0.2155337, -0.2613634, 0.04582969]\n",
      "Iter 7487, loss [-0.2214047, -0.26088706, 0.039482348]\n",
      "Iter 7488, loss [-0.20856023, -0.24567449, 0.037114263]\n",
      "Iter 7489, loss [-0.30720362, -0.31655088, 0.00934726]\n",
      "Iter 7490, loss [-0.21869579, -0.25920463, 0.040508844]\n",
      "Iter 7491, loss [-0.2172626, -0.25639188, 0.039129287]\n",
      "Iter 7492, loss [-0.22618547, -0.26325747, 0.037072003]\n",
      "Iter 7493, loss [-0.22019804, -0.2589214, 0.038723387]\n",
      "Iter 7494, loss [-0.23188455, -0.29562542, 0.063740864]\n",
      "Iter 7495, loss [-0.22577955, -0.26602516, 0.04024561]\n",
      "Iter 7496, loss [-0.21150023, -0.25272965, 0.041229423]\n",
      "Iter 7497, loss [-0.22505248, -0.26450223, 0.039449744]\n",
      "Iter 7498, loss [-0.21985155, -0.26033747, 0.040485922]\n",
      "Iter 7499, loss [-0.20757113, -0.24546264, 0.03789151]\n",
      "Iter 7500, loss [-0.23049326, -0.26794022, 0.03744696]\n",
      "Iter 7501, loss [-0.20893112, -0.24732946, 0.038398337]\n",
      "Iter 7502, loss [-0.21217841, -0.25304285, 0.04086443]\n",
      "Iter 7503, loss [-0.21813153, -0.25611624, 0.03798471]\n",
      "Iter 7504, loss [-0.22523153, -0.2633549, 0.03812336]\n",
      "Iter 7505, loss [-0.21837206, -0.25543872, 0.037066653]\n",
      "Iter 7506, loss [-0.21086279, -0.25876746, 0.047904678]\n",
      "Iter 7507, loss [-0.21870434, -0.25632018, 0.037615836]\n",
      "Iter 7508, loss [-0.2191276, -0.2590071, 0.03987951]\n",
      "Iter 7509, loss [-0.21456815, -0.2554683, 0.040900156]\n",
      "Iter 7510, loss [-0.2265189, -0.2648994, 0.038380504]\n",
      "Iter 7511, loss [-0.21338521, -0.25217023, 0.03878503]\n",
      "Iter 7512, loss [-0.23060802, -0.26870152, 0.038093507]\n",
      "Iter 7513, loss [-0.20786695, -0.24938406, 0.041517105]\n",
      "Iter 7514, loss [-0.22140066, -0.26077902, 0.03937836]\n",
      "Iter 7515, loss [-0.22004327, -0.25766185, 0.03761857]\n",
      "Iter 7516, loss [-0.21923745, -0.25937936, 0.04014191]\n",
      "Iter 7517, loss [-0.21014464, -0.24772722, 0.037582576]\n",
      "Iter 7518, loss [-0.20347981, -0.2427438, 0.039263994]\n",
      "Iter 7519, loss [-0.22605653, -0.2698256, 0.043769073]\n",
      "Iter 7520, loss [-0.2309271, -0.26854634, 0.037619244]\n",
      "Iter 7521, loss [-0.21998909, -0.25799045, 0.038001366]\n",
      "Iter 7522, loss [-0.22599697, -0.30705222, 0.081055254]\n",
      "Iter 7523, loss [-0.22137147, -0.26216984, 0.04079836]\n",
      "Iter 7524, loss [-0.20344044, -0.2430156, 0.03957516]\n",
      "Iter 7525, loss [-0.2192733, -0.2586707, 0.03939738]\n",
      "Iter 7526, loss [-0.2047894, -0.24400246, 0.03921307]\n",
      "Iter 7527, loss [-0.22054878, -0.2574056, 0.036856823]\n",
      "Iter 7528, loss [-0.21235038, -0.25054175, 0.038191367]\n",
      "Iter 7529, loss [-0.21770376, -0.25794023, 0.04023648]\n",
      "Iter 7530, loss [-0.2365124, -0.31488913, 0.07837674]\n",
      "Iter 7531, loss [-0.21762757, -0.25990015, 0.04227258]\n",
      "Iter 7532, loss [-0.22172913, -0.26375723, 0.04202809]\n",
      "Iter 7533, loss [-0.203688, -0.24383017, 0.040142175]\n",
      "Iter 7534, loss [-0.24140643, -0.3152888, 0.073882386]\n",
      "Iter 7535, loss [-0.21441549, -0.25092927, 0.036513768]\n",
      "Iter 7536, loss [-0.21619417, -0.25569662, 0.039502457]\n",
      "Iter 7537, loss [-0.21689533, -0.2557498, 0.03885446]\n",
      "Iter 7538, loss [-0.21924487, -0.26197913, 0.04273426]\n",
      "Iter 7539, loss [-0.2194292, -0.258161, 0.03873181]\n",
      "Iter 7540, loss [-0.21475917, -0.26029062, 0.04553145]\n",
      "Iter 7541, loss [-0.22262055, -0.2599009, 0.03728035]\n",
      "Iter 7542, loss [-0.21981099, -0.26054633, 0.040735334]\n",
      "Iter 7543, loss [-0.21527326, -0.26135257, 0.046079308]\n",
      "Iter 7544, loss [-0.207134, -0.24520656, 0.038072567]\n",
      "Iter 7545, loss [-0.20901708, -0.24758074, 0.03856365]\n",
      "Iter 7546, loss [-0.2296818, -0.29124993, 0.061568122]\n",
      "Iter 7547, loss [-0.20516579, -0.24468964, 0.039523855]\n",
      "Iter 7548, loss [-0.20515771, -0.24454989, 0.03939217]\n",
      "Iter 7549, loss [-0.20858395, -0.25058225, 0.041998297]\n",
      "Iter 7550, loss [-0.22759837, -0.2651667, 0.03756833]\n",
      "Iter 7551, loss [-0.21207024, -0.26136455, 0.049294304]\n",
      "Iter 7552, loss [-0.22665574, -0.26514825, 0.038492512]\n",
      "Iter 7553, loss [-0.22605312, -0.2696257, 0.043572567]\n",
      "Iter 7554, loss [-0.21272138, -0.26064613, 0.047924764]\n",
      "Iter 7555, loss [-0.22676538, -0.26475644, 0.037991058]\n",
      "Iter 7556, loss [-0.22337644, -0.26884195, 0.045465514]\n",
      "Iter 7557, loss [-0.21806483, -0.2579095, 0.039844677]\n",
      "Iter 7558, loss [-0.24402714, -0.3221117, 0.07808456]\n",
      "Iter 7559, loss [-0.20908926, -0.2462165, 0.03712724]\n",
      "Iter 7560, loss [-0.2267736, -0.2659186, 0.039145008]\n",
      "Iter 7561, loss [-0.2067854, -0.24551941, 0.038734015]\n",
      "Iter 7562, loss [-0.21909475, -0.26467916, 0.045584403]\n",
      "Iter 7563, loss [-0.20841756, -0.2498566, 0.041439034]\n",
      "Iter 7564, loss [-0.21067259, -0.25377414, 0.04310154]\n",
      "Iter 7565, loss [-0.21240515, -0.2512803, 0.03887516]\n",
      "Iter 7566, loss [-0.22214705, -0.260802, 0.03865496]\n",
      "Iter 7567, loss [-0.22697368, -0.2667899, 0.039816238]\n",
      "Iter 7568, loss [-0.20709884, -0.24382325, 0.036724396]\n",
      "Iter 7569, loss [-0.2230582, -0.26068756, 0.037629362]\n",
      "Iter 7570, loss [-0.21828309, -0.25936934, 0.041086264]\n",
      "Iter 7571, loss [-0.21947795, -0.25948295, 0.040004995]\n",
      "Iter 7572, loss [-0.2129547, -0.25455382, 0.04159912]\n",
      "Iter 7573, loss [-0.22013134, -0.2608002, 0.040668882]\n",
      "Iter 7574, loss [-0.21237704, -0.2512324, 0.03885534]\n",
      "Iter 7575, loss [-0.20730262, -0.25476724, 0.04746462]\n",
      "Iter 7576, loss [-0.2280581, -0.2654843, 0.03742621]\n",
      "Iter 7577, loss [-0.20964663, -0.24560478, 0.035958156]\n",
      "Iter 7578, loss [-0.21296917, -0.25170222, 0.038733054]\n",
      "Iter 7579, loss [-0.20942539, -0.24770993, 0.038284548]\n",
      "Iter 7580, loss [-0.21219341, -0.25212628, 0.039932862]\n",
      "Iter 7581, loss [-0.21032575, -0.24938773, 0.03906197]\n",
      "Iter 7582, loss [-0.21720049, -0.2577885, 0.040588014]\n",
      "Iter 7583, loss [-0.21975866, -0.26333404, 0.043575373]\n",
      "Iter 7584, loss [-0.20425108, -0.2472035, 0.04295241]\n",
      "Iter 7585, loss [-0.20873684, -0.24898897, 0.040252134]\n",
      "Iter 7586, loss [-0.22647084, -0.26897112, 0.042500272]\n",
      "Iter 7587, loss [-0.21258494, -0.25009564, 0.03751069]\n",
      "Iter 7588, loss [-0.22118677, -0.2602163, 0.039029524]\n",
      "Iter 7589, loss [-0.20506106, -0.24445659, 0.039395526]\n",
      "Iter 7590, loss [-0.22929038, -0.26749563, 0.038205247]\n",
      "Iter 7591, loss [-0.22286496, -0.26092878, 0.038063817]\n",
      "Iter 7592, loss [-0.23031834, -0.2742397, 0.043921348]\n",
      "Iter 7593, loss [-0.23273176, -0.2704411, 0.037709318]\n",
      "Iter 7594, loss [-0.20948023, -0.24832565, 0.038845427]\n",
      "Iter 7595, loss [-0.22689444, -0.26588276, 0.03898833]\n",
      "Iter 7596, loss [-0.21992116, -0.25790268, 0.03798152]\n",
      "Iter 7597, loss [-0.21459866, -0.25634348, 0.04174482]\n",
      "Iter 7598, loss [-0.24384129, -0.31563386, 0.071792565]\n",
      "Iter 7599, loss [-0.22156827, -0.26089433, 0.039326053]\n",
      "Iter 7600, loss [-0.21524245, -0.2560688, 0.040826347]\n",
      "Iter 7601, loss [-0.21752027, -0.2573662, 0.03984594]\n",
      "Iter 7602, loss [-0.2204791, -0.26051128, 0.04003217]\n",
      "Iter 7603, loss [-0.2296091, -0.26683855, 0.037229456]\n",
      "Iter 7604, loss [-0.22029659, -0.25718328, 0.03688669]\n",
      "Iter 7605, loss [-0.21429203, -0.25037256, 0.036080528]\n",
      "Iter 7606, loss [-0.22815178, -0.30969307, 0.081541285]\n",
      "Iter 7607, loss [-0.22167915, -0.26147053, 0.03979137]\n",
      "Iter 7608, loss [-0.21279201, -0.25406536, 0.041273363]\n",
      "Iter 7609, loss [-0.21849078, -0.25783274, 0.03934195]\n",
      "Iter 7610, loss [-0.21256836, -0.2509415, 0.038373124]\n",
      "Iter 7611, loss [-0.21955867, -0.25606486, 0.036506187]\n",
      "Iter 7612, loss [-0.21138945, -0.2605885, 0.049199037]\n",
      "Iter 7613, loss [-0.248339, -0.29239628, 0.044057287]\n",
      "Iter 7614, loss [-0.19909376, -0.24608855, 0.046994783]\n",
      "Iter 7615, loss [-0.24085118, -0.31870264, 0.07785146]\n",
      "Iter 7616, loss [-0.21948898, -0.2590671, 0.039578103]\n",
      "Iter 7617, loss [-0.22922263, -0.2669063, 0.03768366]\n",
      "Iter 7618, loss [-0.21188775, -0.25255483, 0.04066708]\n",
      "Iter 7619, loss [-0.21612889, -0.25880137, 0.042672493]\n",
      "Iter 7620, loss [-0.20687068, -0.24384032, 0.03696964]\n",
      "Iter 7621, loss [-0.2194273, -0.26321065, 0.04378335]\n",
      "Iter 7622, loss [-0.30774963, -0.31713122, 0.009381582]\n",
      "Iter 7623, loss [-0.21889219, -0.2580512, 0.039158992]\n",
      "Iter 7624, loss [-0.21476178, -0.2531392, 0.038377423]\n",
      "Iter 7625, loss [-0.2166096, -0.25616384, 0.03955423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7626, loss [-0.22801068, -0.2659147, 0.037904024]\n",
      "Iter 7627, loss [-0.18200482, -0.23098515, 0.048980325]\n",
      "Iter 7628, loss [-0.2256212, -0.26634958, 0.040728383]\n",
      "Iter 7629, loss [-0.21722981, -0.26004374, 0.042813934]\n",
      "Iter 7630, loss [-0.20851904, -0.24975593, 0.041236885]\n",
      "Iter 7631, loss [-0.19916716, -0.24625173, 0.047084562]\n",
      "Iter 7632, loss [-0.21646118, -0.25619635, 0.039735164]\n",
      "Iter 7633, loss [-0.22202793, -0.26251397, 0.04048604]\n",
      "Iter 7634, loss [-0.21246722, -0.25141266, 0.03894543]\n",
      "Iter 7635, loss [-0.21086282, -0.25060633, 0.03974351]\n",
      "Iter 7636, loss [-0.19969615, -0.29784223, 0.09814608]\n",
      "Iter 7637, loss [-0.22824942, -0.26587364, 0.037624225]\n",
      "Iter 7638, loss [-0.22418784, -0.2630487, 0.038860876]\n",
      "Iter 7639, loss [-0.21666844, -0.2533113, 0.03664286]\n",
      "Iter 7640, loss [-0.21201396, -0.25508463, 0.043070666]\n",
      "Iter 7641, loss [-0.23054776, -0.26700133, 0.036453582]\n",
      "Iter 7642, loss [-0.2224487, -0.26163545, 0.03918674]\n",
      "Iter 7643, loss [-0.2021003, -0.2471048, 0.045004487]\n",
      "Iter 7644, loss [-0.16285595, -0.24589631, 0.08304036]\n",
      "Iter 7645, loss [-0.21918727, -0.261154, 0.041966718]\n",
      "Iter 7646, loss [-0.21643695, -0.2583043, 0.04186734]\n",
      "Iter 7647, loss [-0.2053833, -0.24982993, 0.04444664]\n",
      "Iter 7648, loss [-0.2044426, -0.2441666, 0.03972399]\n",
      "Iter 7649, loss [-0.2061836, -0.25054237, 0.04435877]\n",
      "Iter 7650, loss [-0.20639202, -0.24497372, 0.038581707]\n",
      "Iter 7651, loss [-0.24559921, -0.2903046, 0.0447054]\n",
      "Iter 7652, loss [-0.20975113, -0.24974921, 0.03999809]\n",
      "Iter 7653, loss [-0.21162292, -0.24932474, 0.037701823]\n",
      "Iter 7654, loss [-0.2181207, -0.2573154, 0.039194703]\n",
      "Iter 7655, loss [-0.21427396, -0.25497118, 0.040697217]\n",
      "Iter 7656, loss [-0.21446073, -0.30026296, 0.08580222]\n",
      "Iter 7657, loss [-0.21169402, -0.25221452, 0.040520504]\n",
      "Iter 7658, loss [-0.22330162, -0.26044345, 0.037141837]\n",
      "Iter 7659, loss [-0.19967097, -0.23781745, 0.03814648]\n",
      "Iter 7660, loss [-0.21164101, -0.24733408, 0.03569307]\n",
      "Iter 7661, loss [-0.21292897, -0.2501629, 0.03723393]\n",
      "Iter 7662, loss [-0.21724114, -0.2520235, 0.034782343]\n",
      "Iter 7663, loss [-0.19623363, -0.28805315, 0.091819525]\n",
      "Iter 7664, loss [-0.22168466, -0.2588756, 0.03719095]\n",
      "Iter 7665, loss [-0.22650748, -0.26416358, 0.0376561]\n",
      "Iter 7666, loss [-0.1967909, -0.24461523, 0.04782432]\n",
      "Iter 7667, loss [-0.20684215, -0.25074124, 0.04389908]\n",
      "Iter 7668, loss [-0.21116568, -0.2526492, 0.041483503]\n",
      "Iter 7669, loss [-0.22182384, -0.26050633, 0.038682487]\n",
      "Iter 7670, loss [-0.23181334, -0.29310668, 0.061293334]\n",
      "Iter 7671, loss [-0.22320607, -0.2643571, 0.041151017]\n",
      "Iter 7672, loss [-0.23732576, -0.3109234, 0.07359763]\n",
      "Iter 7673, loss [-0.21009697, -0.25109082, 0.040993854]\n",
      "Iter 7674, loss [-0.20177487, -0.24343552, 0.04166066]\n",
      "Iter 7675, loss [-0.21578646, -0.25811234, 0.042325884]\n",
      "Iter 7676, loss [-0.22970384, -0.3058384, 0.07613456]\n",
      "Iter 7677, loss [-0.23882926, -0.27461293, 0.035783686]\n",
      "Iter 7678, loss [-0.22708005, -0.27202624, 0.0449462]\n",
      "Iter 7679, loss [-0.21418312, -0.2536098, 0.03942668]\n",
      "Iter 7680, loss [-0.21703058, -0.25377023, 0.03673965]\n",
      "Iter 7681, loss [-0.21702325, -0.25485528, 0.03783202]\n",
      "Iter 7682, loss [-0.20723099, -0.246954, 0.039723013]\n",
      "Iter 7683, loss [-0.22095653, -0.2815534, 0.060596853]\n",
      "Iter 7684, loss [-0.30630216, -0.31652927, 0.010227106]\n",
      "Iter 7685, loss [-0.22061306, -0.25874212, 0.038129065]\n",
      "Iter 7686, loss [-0.2430135, -0.3068874, 0.06387388]\n",
      "Iter 7687, loss [-0.22709614, -0.2665514, 0.039455257]\n",
      "Iter 7688, loss [-0.21504112, -0.25661504, 0.041573927]\n",
      "Iter 7689, loss [-0.21437015, -0.25634432, 0.04197417]\n",
      "Iter 7690, loss [-0.18037704, -0.230097, 0.049719967]\n",
      "Iter 7691, loss [-0.23482469, -0.3168013, 0.081976615]\n",
      "Iter 7692, loss [-0.22312883, -0.26208162, 0.038952805]\n",
      "Iter 7693, loss [-0.21367115, -0.2524944, 0.038823243]\n",
      "Iter 7694, loss [-0.22380902, -0.26087964, 0.037070613]\n",
      "Iter 7695, loss [-0.21880485, -0.25899318, 0.040188324]\n",
      "Iter 7696, loss [-0.21768329, -0.2621798, 0.0444965]\n",
      "Iter 7697, loss [-0.20386758, -0.24325788, 0.039390292]\n",
      "Iter 7698, loss [-0.216888, -0.25553533, 0.038647335]\n",
      "Iter 7699, loss [-0.22471194, -0.26591897, 0.04120703]\n",
      "Iter 7700, loss [-0.21483299, -0.2565524, 0.041719414]\n",
      "Iter 7701, loss [-0.21575883, -0.25813103, 0.042372193]\n",
      "Iter 7702, loss [-0.3071692, -0.3165567, 0.009387496]\n",
      "Iter 7703, loss [-0.2160648, -0.25468698, 0.03862219]\n",
      "Iter 7704, loss [-0.21565603, -0.25436324, 0.03870721]\n",
      "Iter 7705, loss [-0.22293264, -0.28006208, 0.05712944]\n",
      "Iter 7706, loss [-0.22131322, -0.2592155, 0.03790228]\n",
      "Iter 7707, loss [-0.21113837, -0.24806388, 0.036925517]\n",
      "Iter 7708, loss [-0.22655627, -0.28760925, 0.061052985]\n",
      "Iter 7709, loss [-0.22888511, -0.27312592, 0.044240803]\n",
      "Iter 7710, loss [-0.21113677, -0.25058958, 0.039452802]\n",
      "Iter 7711, loss [-0.21373662, -0.25686806, 0.04313144]\n",
      "Iter 7712, loss [-0.2193403, -0.2604041, 0.041063815]\n",
      "Iter 7713, loss [-0.22788237, -0.28914675, 0.061264377]\n",
      "Iter 7714, loss [-0.22994795, -0.27209178, 0.04214382]\n",
      "Iter 7715, loss [-0.2182308, -0.25501406, 0.03678326]\n",
      "Iter 7716, loss [-0.21440506, -0.25873122, 0.044326156]\n",
      "Iter 7717, loss [-0.21875118, -0.2574862, 0.038735017]\n",
      "Iter 7718, loss [-0.20480394, -0.24605244, 0.041248493]\n",
      "Iter 7719, loss [-0.22839905, -0.26813483, 0.039735775]\n",
      "Iter 7720, loss [-0.21640417, -0.25696123, 0.040557053]\n",
      "Iter 7721, loss [-0.21890488, -0.25907227, 0.040167384]\n",
      "Iter 7722, loss [-0.22377224, -0.2652597, 0.041487467]\n",
      "Iter 7723, loss [-0.21874493, -0.258848, 0.040103078]\n",
      "Iter 7724, loss [-0.22208112, -0.2667624, 0.044681273]\n",
      "Iter 7725, loss [-0.20726407, -0.24284261, 0.035578545]\n",
      "Iter 7726, loss [-0.21171144, -0.25142175, 0.039710306]\n",
      "Iter 7727, loss [-0.22924098, -0.2709915, 0.041750513]\n",
      "Iter 7728, loss [-0.21368119, -0.2593219, 0.045640707]\n",
      "Iter 7729, loss [-0.21930641, -0.2590201, 0.03971369]\n",
      "Iter 7730, loss [-0.2083404, -0.2453436, 0.03700319]\n",
      "Iter 7731, loss [-0.21728067, -0.25837326, 0.041092593]\n",
      "Iter 7732, loss [-0.22626314, -0.26570642, 0.03944328]\n",
      "Iter 7733, loss [-0.21426198, -0.25688103, 0.04261905]\n",
      "Iter 7734, loss [-0.21954784, -0.25966713, 0.040119298]\n",
      "Iter 7735, loss [-0.21078375, -0.25112748, 0.040343724]\n",
      "Iter 7736, loss [-0.21695589, -0.25636372, 0.039407834]\n",
      "Iter 7737, loss [-0.22089367, -0.26032922, 0.039435554]\n",
      "Iter 7738, loss [-0.21957323, -0.2593263, 0.03975308]\n",
      "Iter 7739, loss [-0.22003919, -0.26059592, 0.040556736]\n",
      "Iter 7740, loss [-0.22465718, -0.2631702, 0.038513035]\n",
      "Iter 7741, loss [-0.24876589, -0.29275212, 0.043986227]\n",
      "Iter 7742, loss [-0.22199361, -0.26134306, 0.03934945]\n",
      "Iter 7743, loss [-0.228324, -0.2888041, 0.060480118]\n",
      "Iter 7744, loss [-0.20931837, -0.24613121, 0.03681284]\n",
      "Iter 7745, loss [-0.21843988, -0.2548807, 0.036440816]\n",
      "Iter 7746, loss [-0.2129769, -0.25281787, 0.039840974]\n",
      "Iter 7747, loss [-0.2304016, -0.26729232, 0.036890723]\n",
      "Iter 7748, loss [-0.21490678, -0.25341156, 0.038504772]\n",
      "Iter 7749, loss [-0.2194495, -0.26433057, 0.04488106]\n",
      "Iter 7750, loss [-0.21581459, -0.25539452, 0.039579935]\n",
      "Iter 7751, loss [-0.21801637, -0.257016, 0.03899963]\n",
      "Iter 7752, loss [-0.21739051, -0.25804183, 0.040651318]\n",
      "Iter 7753, loss [-0.21211676, -0.252018, 0.03990124]\n",
      "Iter 7754, loss [-0.22770262, -0.26482624, 0.037123628]\n",
      "Iter 7755, loss [-0.21994911, -0.2578571, 0.037908]\n",
      "Iter 7756, loss [-0.21757348, -0.25760302, 0.040029537]\n",
      "Iter 7757, loss [-0.21153024, -0.24978715, 0.038256913]\n",
      "Iter 7758, loss [-0.21172452, -0.2516588, 0.039934285]\n",
      "Iter 7759, loss [-0.20533952, -0.24610981, 0.04077029]\n",
      "Iter 7760, loss [-0.21165496, -0.25045502, 0.038800053]\n",
      "Iter 7761, loss [-0.22026676, -0.26056716, 0.040300407]\n",
      "Iter 7762, loss [-0.308286, -0.31769118, 0.009405156]\n",
      "Iter 7763, loss [-0.24692225, -0.30838707, 0.061464816]\n",
      "Iter 7764, loss [-0.21747752, -0.25935283, 0.041875314]\n",
      "Iter 7765, loss [-0.2121098, -0.2516109, 0.039501093]\n",
      "Iter 7766, loss [-0.22704884, -0.28781176, 0.06076292]\n",
      "Iter 7767, loss [-0.21312682, -0.25327227, 0.04014544]\n",
      "Iter 7768, loss [-0.20682636, -0.2437973, 0.036970947]\n",
      "Iter 7769, loss [-0.22002563, -0.25671342, 0.036687795]\n",
      "Iter 7770, loss [-0.22840342, -0.27331996, 0.044916548]\n",
      "Iter 7771, loss [-0.21907347, -0.2564561, 0.037382625]\n",
      "Iter 7772, loss [-0.2248185, -0.26247096, 0.037652455]\n",
      "Iter 7773, loss [-0.22227702, -0.25933552, 0.037058495]\n",
      "Iter 7774, loss [-0.2502513, -0.31278083, 0.06252954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7775, loss [-0.21539718, -0.25593534, 0.04053817]\n",
      "Iter 7776, loss [-0.21850944, -0.25670323, 0.038193785]\n",
      "Iter 7777, loss [-0.20328945, -0.24296282, 0.039673373]\n",
      "Iter 7778, loss [-0.20826802, -0.24923128, 0.040963262]\n",
      "Iter 7779, loss [-0.22015557, -0.2570919, 0.03693634]\n",
      "Iter 7780, loss [-0.24150309, -0.27692652, 0.03542343]\n",
      "Iter 7781, loss [-0.20311308, -0.24319999, 0.040086918]\n",
      "Iter 7782, loss [-0.22256266, -0.26046214, 0.037899476]\n",
      "Iter 7783, loss [-0.2193492, -0.2571927, 0.037843503]\n",
      "Iter 7784, loss [-0.21912476, -0.2565702, 0.03744543]\n",
      "Iter 7785, loss [-0.22862358, -0.26761895, 0.038995367]\n",
      "Iter 7786, loss [-0.20321389, -0.24299474, 0.039780855]\n",
      "Iter 7787, loss [-0.2274176, -0.26660565, 0.039188042]\n",
      "Iter 7788, loss [-0.2191092, -0.25671807, 0.03760887]\n",
      "Iter 7789, loss [-0.21103868, -0.25135985, 0.04032118]\n",
      "Iter 7790, loss [-0.2288386, -0.2662297, 0.037391104]\n",
      "Iter 7791, loss [-0.22137573, -0.2599952, 0.03861945]\n",
      "Iter 7792, loss [-0.2213765, -0.26178995, 0.040413454]\n",
      "Iter 7793, loss [-0.22012842, -0.2573242, 0.03719578]\n",
      "Iter 7794, loss [-0.22907585, -0.26796865, 0.038892813]\n",
      "Iter 7795, loss [-0.21930027, -0.25750032, 0.03820005]\n",
      "Iter 7796, loss [-0.2264731, -0.26925662, 0.04278352]\n",
      "Iter 7797, loss [-0.22707066, -0.26736444, 0.040293775]\n",
      "Iter 7798, loss [-0.21741186, -0.25884914, 0.041437283]\n",
      "Iter 7799, loss [-0.22663006, -0.26818255, 0.04155249]\n",
      "Iter 7800, loss [-0.21234679, -0.25078645, 0.038439654]\n",
      "Iter 7801, loss [-0.23032647, -0.26851416, 0.038187675]\n",
      "Iter 7802, loss [-0.20623091, -0.24610992, 0.039879005]\n",
      "Iter 7803, loss [-0.21909153, -0.2577533, 0.038661785]\n",
      "Iter 7804, loss [-0.22235638, -0.26137564, 0.03901925]\n",
      "Iter 7805, loss [-0.21279247, -0.25064006, 0.037847593]\n",
      "Iter 7806, loss [-0.23075564, -0.27400467, 0.043249022]\n",
      "Iter 7807, loss [-0.21263784, -0.25194147, 0.03930363]\n",
      "Iter 7808, loss [-0.2291981, -0.2900725, 0.060874403]\n",
      "Iter 7809, loss [-0.21074972, -0.25353637, 0.042786665]\n",
      "Iter 7810, loss [-0.20616066, -0.24618575, 0.040025078]\n",
      "Iter 7811, loss [-0.20514408, -0.24367541, 0.03853133]\n",
      "Iter 7812, loss [-0.22664736, -0.2646489, 0.038001552]\n",
      "Iter 7813, loss [-0.2067741, -0.25438046, 0.04760636]\n",
      "Iter 7814, loss [-0.24203426, -0.2771462, 0.035111934]\n",
      "Iter 7815, loss [-0.20639813, -0.24763489, 0.041236755]\n",
      "Iter 7816, loss [-0.23905848, -0.2940745, 0.055016026]\n",
      "Iter 7817, loss [-0.22881131, -0.26797783, 0.039166525]\n",
      "Iter 7818, loss [-0.21560347, -0.2579887, 0.042385228]\n",
      "Iter 7819, loss [-0.22184397, -0.26170287, 0.039858893]\n",
      "Iter 7820, loss [-0.2177085, -0.2595301, 0.041821606]\n",
      "Iter 7821, loss [-0.21466675, -0.2570242, 0.042357437]\n",
      "Iter 7822, loss [-0.22287443, -0.2592478, 0.036373377]\n",
      "Iter 7823, loss [-0.21536091, -0.2605976, 0.045236677]\n",
      "Iter 7824, loss [-0.21365927, -0.24968669, 0.036027413]\n",
      "Iter 7825, loss [-0.21185929, -0.24966756, 0.037808277]\n",
      "Iter 7826, loss [-0.20852374, -0.24930258, 0.04077884]\n",
      "Iter 7827, loss [-0.20869395, -0.2493433, 0.040649362]\n",
      "Iter 7828, loss [-0.22022066, -0.25888282, 0.03866217]\n",
      "Iter 7829, loss [-0.24461374, -0.32438028, 0.07976655]\n",
      "Iter 7830, loss [-0.21726511, -0.25694963, 0.039684515]\n",
      "Iter 7831, loss [-0.21756573, -0.25711447, 0.03954874]\n",
      "Iter 7832, loss [-0.21119122, -0.25925195, 0.048060726]\n",
      "Iter 7833, loss [-0.21184734, -0.25005993, 0.038212597]\n",
      "Iter 7834, loss [-0.22329313, -0.26038957, 0.037096437]\n",
      "Iter 7835, loss [-0.21954656, -0.25831327, 0.038766712]\n",
      "Iter 7836, loss [-0.2122933, -0.25273377, 0.040440463]\n",
      "Iter 7837, loss [-0.20605755, -0.24384572, 0.037788164]\n",
      "Iter 7838, loss [-0.208568, -0.24534199, 0.036773972]\n",
      "Iter 7839, loss [-0.21997494, -0.2599603, 0.039985362]\n",
      "Iter 7840, loss [-0.2129257, -0.25499737, 0.042071667]\n",
      "Iter 7841, loss [-0.2135181, -0.25106716, 0.037549064]\n",
      "Iter 7842, loss [-0.21914738, -0.25713575, 0.03798836]\n",
      "Iter 7843, loss [-0.21460827, -0.25078285, 0.03617458]\n",
      "Iter 7844, loss [-0.22045445, -0.25727922, 0.036824763]\n",
      "Iter 7845, loss [-0.21466787, -0.25066406, 0.035996184]\n",
      "Iter 7846, loss [-0.2196713, -0.25602522, 0.036353927]\n",
      "Iter 7847, loss [-0.22057132, -0.25729182, 0.0367205]\n",
      "Iter 7848, loss [-0.22800232, -0.26619005, 0.038187727]\n",
      "Iter 7849, loss [-0.2132347, -0.25725055, 0.044015855]\n",
      "Iter 7850, loss [-0.2200746, -0.25895193, 0.038877342]\n",
      "Iter 7851, loss [-0.22875851, -0.27422944, 0.045470923]\n",
      "Iter 7852, loss [-0.23935634, -0.2942319, 0.05487555]\n",
      "Iter 7853, loss [-0.22154565, -0.2622663, 0.040720657]\n",
      "Iter 7854, loss [-0.2202534, -0.26045668, 0.040203284]\n",
      "Iter 7855, loss [-0.21470013, -0.25619644, 0.0414963]\n",
      "Iter 7856, loss [-0.21082889, -0.25326824, 0.042439353]\n",
      "Iter 7857, loss [-0.22518308, -0.26268956, 0.037506472]\n",
      "Iter 7858, loss [-0.23075074, -0.29131237, 0.06056162]\n",
      "Iter 7859, loss [-0.21220909, -0.24902363, 0.036814537]\n",
      "Iter 7860, loss [-0.21282056, -0.25061312, 0.037792556]\n",
      "Iter 7861, loss [-0.22495782, -0.26311257, 0.038154744]\n",
      "Iter 7862, loss [-0.24573253, -0.3250689, 0.07933636]\n",
      "Iter 7863, loss [-0.22038798, -0.2612856, 0.040897623]\n",
      "Iter 7864, loss [-0.23266847, -0.30387658, 0.071208104]\n",
      "Iter 7865, loss [-0.2203072, -0.25855917, 0.03825196]\n",
      "Iter 7866, loss [-0.23088741, -0.26993468, 0.039047275]\n",
      "Iter 7867, loss [-0.30819666, -0.3174656, 0.009268946]\n",
      "Iter 7868, loss [-0.22200131, -0.2593584, 0.0373571]\n",
      "Iter 7869, loss [-0.3087536, -0.31776094, 0.0090073235]\n",
      "Iter 7870, loss [-0.21962085, -0.25403938, 0.034418523]\n",
      "Iter 7871, loss [-0.20720518, -0.29117188, 0.083966695]\n",
      "Iter 7872, loss [-0.20634201, -0.246577, 0.040234983]\n",
      "Iter 7873, loss [-0.21467784, -0.27813435, 0.06345651]\n",
      "Iter 7874, loss [-0.21293211, -0.25460467, 0.04167255]\n",
      "Iter 7875, loss [-0.2167308, -0.25814375, 0.041412942]\n",
      "Iter 7876, loss [-0.2079266, -0.25138968, 0.043463077]\n",
      "Iter 7877, loss [-0.24168658, -0.2771867, 0.035500105]\n",
      "Iter 7878, loss [-0.20792133, -0.24816717, 0.040245842]\n",
      "Iter 7879, loss [-0.23564008, -0.29152134, 0.05588127]\n",
      "Iter 7880, loss [-0.18148085, -0.22780117, 0.046320327]\n",
      "Iter 7881, loss [-0.21319981, -0.24853519, 0.035335373]\n",
      "Iter 7882, loss [-0.21993606, -0.25873604, 0.038799983]\n",
      "Iter 7883, loss [-0.22495073, -0.26309508, 0.038144358]\n",
      "Iter 7884, loss [-0.22673646, -0.26373926, 0.037002794]\n",
      "Iter 7885, loss [-0.23693052, -0.29355046, 0.05661995]\n",
      "Iter 7886, loss [-0.21124595, -0.25140586, 0.04015991]\n",
      "Iter 7887, loss [-0.20728835, -0.24391878, 0.036630414]\n",
      "Iter 7888, loss [-0.20601843, -0.24457972, 0.038561285]\n",
      "Iter 7889, loss [-0.2187872, -0.2627253, 0.043938093]\n",
      "Iter 7890, loss [-0.21259871, -0.25739247, 0.044793747]\n",
      "Iter 7891, loss [-0.21263856, -0.2540675, 0.04142896]\n",
      "Iter 7892, loss [-0.30621818, -0.31556424, 0.009346077]\n",
      "Iter 7893, loss [-0.2248072, -0.26425537, 0.03944818]\n",
      "Iter 7894, loss [-0.2082172, -0.24818365, 0.03996644]\n",
      "Iter 7895, loss [-0.20551611, -0.24068166, 0.03516555]\n",
      "Iter 7896, loss [-0.22956243, -0.27180097, 0.04223854]\n",
      "Iter 7897, loss [-0.22562043, -0.2683408, 0.04272036]\n",
      "Iter 7898, loss [-0.20325682, -0.24779607, 0.044539265]\n",
      "Iter 7899, loss [-0.24775404, -0.31075913, 0.06300508]\n",
      "Iter 7900, loss [-0.22903636, -0.26694292, 0.037906554]\n",
      "Iter 7901, loss [-0.20455322, -0.24378161, 0.03922839]\n",
      "Iter 7902, loss [-0.2085306, -0.24875715, 0.040226556]\n",
      "Iter 7903, loss [-0.20391935, -0.24502324, 0.041103877]\n",
      "Iter 7904, loss [-0.22477399, -0.26077625, 0.03600226]\n",
      "Iter 7905, loss [-0.21790221, -0.2554566, 0.037554387]\n"
     ]
    }
   ],
   "source": [
    "start_iter = 10000\n",
    "print(start_iter)\n",
    "n_train_iters = 90000\n",
    "vol_gen = ds.gen_vols_batch(['labeled_train', 'unlabeled_train'], batch_size=1, randomize=True)\n",
    "print(ds.files_labeled_train + ds.files_unlabeled_train)\n",
    "#vol_gen = data_utils.gen_batch(X_unlabeled, X_unlabeled, batch_size=1, randomize=True)\n",
    "target_X, _ = next(vol_gen)\n",
    "zeros_flow = np.zeros(target_X.shape[:-1] + (3,))\n",
    "\n",
    "for bi in range(n_train_iters + 1):\n",
    "    \n",
    "    target_X, _ = next(vol_gen)\n",
    "    vm_losses = vm_new_model.train_on_batch([source_X, target_X], [target_X, zeros_flow])\n",
    "    print('Iter {}, loss {}'.format(bi, vm_losses))\n",
    "    \n",
    "    if bi > 0 and bi % 2000 == 0:\n",
    "        vm_new_model.save('./experiments/voxelmorph/vm2_cc_AtoUMS_100k_CStoUMS_xy_iter{}.h5'.format(start_iter + bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save a voxelmorph wrapper\n",
    "# import sys\n",
    "# sys.path.append('../voxelmorph-sandbox')\n",
    "# import voxelmorph.networks as vm_networks\n",
    "# import tensorflow as tf\n",
    "# from voxelmorph import dense_3D_spatial_transformer\n",
    "# from keras.models import load_model\n",
    " \n",
    "# sys.path.append('../neuron')\n",
    "# import neuron.layers as nrn_layers\n",
    "# import neuron.utils as nrn_utils\n",
    "# sys.path.append('../voxelmorph-sandbox')\n",
    "# import voxelmorph.networks as vm_networks\n",
    "# from voxelmorph.dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "                                \n",
    "# vm_diffeo_model = load_model(\n",
    "#     #'/afs/csail.mit.edu/u/x/xamyzhao/voxelmorph/models/vm2_cc.h5',\n",
    "#     './experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter10000.h5',#.format(start_iter),\n",
    "#     custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "#                     'interp_upsampling': vm_networks.interp_upsampling,\n",
    "#                     'meshgrid': vm_networks.meshgrid,\n",
    "#                     'tf': tf,\n",
    "                    \n",
    "#                     'VecInt': nrn_layers.VecInt,\n",
    "#                     'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "#                     'nrn_utils': nrn_utils,\n",
    "#                     'nrn_layers': nrn_layers,\n",
    "#                    },\n",
    "#     compile=False,\n",
    "# )\n",
    "\n",
    "# from keras.layers import Input, Lambda\n",
    "# from keras.models import Model\n",
    "\n",
    "# vol_shape = (160, 192, 224, 1)\n",
    "# input_src = Input(vol_shape)\n",
    "# input_tgt = Input(vol_shape)\n",
    "\n",
    "# warped, backwarped, _ = vm_diffeo_model([input_src, input_tgt])\n",
    "# flow = vm_diffeo_model.get_layer('diffflow').output\n",
    "\n",
    "# wrapper_model = Model(inputs=[input_src, input_tgt], outputs=[flow, warped], name='vmmiccai_bidir_cc_wrapper')\n",
    "# wrapper_model.summary()\n",
    "# wrapper_model.save('./experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter10000_wrapper.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
