{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "../cnn_utils/vis_utils.py:14: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  mpl.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset_utils import adni_loader\n",
    "#from networks import transform_network_utils\n",
    "\n",
    "sys.path.append('../neuron')\n",
    "sys.path.append('../voxelmorph')\n",
    "import src.losses as vm_losses\n",
    "\n",
    "gpu_ids = [1]\n",
    "# set gpu id and tf settings\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(g) for g in gpu_ids])\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "import sys\n",
    "sys.path.append('../voxelmorph-sandbox')\n",
    "import voxelmorph.networks as vm_networks\n",
    "import tensorflow as tf\n",
    "from voxelmorph import dense_3D_spatial_transformer\n",
    "from keras.models import load_model\n",
    " \n",
    "sys.path.append('../neuron')\n",
    "import neuron.layers as nrn_layers\n",
    "import neuron.utils as nrn_utils\n",
    "sys.path.append('../voxelmorph-sandbox')\n",
    "import voxelmorph.networks as vm_networks\n",
    "from voxelmorph.dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "start_iter = 0\n",
    "voxelmorph_model = load_model(\n",
    "    #'/afs/csail.mit.edu/u/x/xamyzhao/voxelmorph/models/vm2_cc.h5',\n",
    "    './experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_iter100000.h5',#.format(start_iter),\n",
    "    custom_objects={'Dense3DSpatialTransformer': Dense3DSpatialTransformer,\n",
    "                   'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "                   },\n",
    "    compile=False,\n",
    ")\n",
    "# voxelmorph_model = load_model(\n",
    "#     './experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter{}.h5'.format(start_iter),\n",
    "#     custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "#                     'interp_upsampling': vm_networks.interp_upsampling,\n",
    "#                     'meshgrid': vm_networks.meshgrid,\n",
    "#                     'tf': tf,\n",
    "                    \n",
    "#                     'VecInt': nrn_layers.VecInt,\n",
    "#                     'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "#                     'nrn_utils': nrn_utils,\n",
    "#                     'nrn_layers': nrn_layers,\n",
    "#                    },\n",
    "#     compile=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cnn_utils/vis_utils.py:14: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  mpl.use('Agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adni dataset adni-unnorm-masked_100ul_subj-OASIS_OAS1_0327-l\n",
      "Params: {'dataset_name': 'adni', 'source_name': 'atl', 'target_name': 'subjs', 'unnormalized': True, 'masked': True, 'n_shot': 1, 'use_atlas_as_source': False, 'use_subject': 'OASIS_OAS1_0327_MR1_mri_talairach_orig', 'img_shape': (160, 192, 224, 1), 'pred_img_shape': (160, 192, 1), 'aug_img_shape': (160, 192, 224, 1), 'n_unlabeled': 100, 'n_validation': 50, 'load_vols': True, 'aug_in_gen': True, 'n_vte_aug': None, 'n_flow_aug': None, 'use_labels': [0, 16, 10, 49, 8, 47, 4, 43, 7, 46, 12, 51, 2, 41, 28, 60, 11, 50, 13, 52, 17, 53, 14, 15, 18, 54, 24, 3, 42, 31, 63], 'final_test': False, 'warp_labels': True, 'n_dims': 3, 'orig_img_shape': (160, 192, 224, 1), 'scale': 1.0, 'split_id': None}\n",
      "Got list of 7329 files from /data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/*.npz:\n",
      "ADNI_ADNI-3T-FS-5.3-Long_293689.long.016_S_4591_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_78841.long.016_S_1326_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_436815.long.094_S_1330_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_296323.long.068_S_2168_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_388923.long.135_S_5273_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_272700.long.009_S_4388_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_394785.long.027_S_0408_base_mri_talairach_orig.npz\n",
      "PPMI_3519_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_119158.long.053_S_0507_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_63306.long.007_S_0249_base_mri_talairach_orig.npz\n",
      "ABIDE_50685_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_121666.long.041_S_1423_base_mri_talairach_orig.npz\n",
      "GSP_120719_TT88SP_FS_mri_talairach_orig.npz\n",
      "COBRE_0040043_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_416015.long.021_S_2124_base_mri_talairach_orig.npz\n",
      "...\n",
      "Got 102 training and 50 validation files!\n",
      "Loaded 0 of 2 files\n",
      "Labeled train vols:\n",
      "X_labeled_train: (2, 160, 192, 224, 1)\n",
      "Y_labeled_train: (2, 160, 192, 224)\n",
      "ids_labeled_train: ['OASIS_OAS1_0327_MR1_mri_talairach_orig', 'OASIS_OAS1_0327_MR1_mri_talairach_orig']\n",
      "Loaded 0 of 50 files\n",
      "Loaded 0 of 100 files\n"
     ]
    }
   ],
   "source": [
    "dataset_key = 'adni-3d-100-unnorm-masked-csts2'\n",
    "import vte_runner\n",
    "data_params = vte_runner.named_vte_data_params[dataset_key]\n",
    "    \n",
    "ds = adni_loader.ADNIDataset(data_params)\n",
    "\n",
    "vol_shape = tuple(data_params['img_shape'])\n",
    "\n",
    "# just load some examples so we can get the image size, but actually use a generator later...\n",
    "(X_unlabeled, _, ids_unlabeled),\\\n",
    "(X_labeled_train, Y_labeled_train, ids_labeled_train), \\\n",
    "(X_labeled_valid, Y_labeled_valid, ids_labeled_valid), \\\n",
    "label_mapping \\\n",
    "= ds.load_dataset(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_unlabeled.shape)\n",
    "print(X_labeled_train.shape)\n",
    "print(X_labeled_valid.shape)\n",
    "print(ds.files_labeled_train)\n",
    "print(ds.params['load_vols'])\n",
    "import IPython\n",
    "import PIL\n",
    "IPython.display.display(PIL.Image.fromarray((X_labeled_train[0, :, :, 64, 0]*255).astype(np.uint8)))\n",
    "IPython.display.display(PIL.Image.fromarray((X_unlabeled[0, :, :, 64, 0]*255).astype(np.uint8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create diffeomorphic model\n",
    "sys.path.append('../voxelmorph')\n",
    "import src.networks as vm_networks\n",
    "start_iter = 0\n",
    "nf_enc = [16, 32, 32, 32]\n",
    "nf_dec = [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "# vm2 model\n",
    "vm_new_model = vm_networks.cvpr2018_net(\n",
    "    vol_size=(160, 192, 224),\n",
    "    enc_nf=nf_enc, \n",
    "    dec_nf=nf_dec,\n",
    "    indexing='xy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_new_model.summary()\n",
    "import data_utils\n",
    "import src.losses as vm_losses\n",
    "\n",
    "# just train voxelmorph\n",
    "vm_new_model.compile(\n",
    "    #loss=['mean_squared_error', vm_losses.gradientLoss('l2')],\n",
    "    #loss=[vm_losses.cc3D(), vm_losses.gradientLoss('l2')],\n",
    "    loss=[vm_losses.NCC().loss, vm_losses.Grad('l2').loss],\n",
    "          #vm_losses.gradientLoss('l2')],\n",
    "    #loss_weights=[1.0, ,0.01],\n",
    "    loss_weights=[1.0, 1.],#0.01],\n",
    "    #loss_weights=[1., 1., 1., 0.],#0.01],\n",
    "    optimizer=Adam(0.0001)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copy weights from regular voxelmorph as initialization\n",
    "for li, l in enumerate(vm_new_model.layers):\n",
    "    print(l.name)\n",
    "    if l.name == voxelmorph_model.layers[li].name:\n",
    "        print(l.name)\n",
    "        vm_new_model.layers[li].set_weights(voxelmorph_model.layers[li].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.files_labeled_train[0])\n",
    "# source_X = ds.X_atlas\n",
    "source_X, _ = adni_loader._load_vol_and_seg(ds.files_labeled_train[0], load_seg=False, mask_vol=ds.params['masked'])\n",
    "source_X = source_X[np.newaxis]\n",
    "IPython.display.display(PIL.Image.fromarray((source_X[0, :, :, 64, 0]*255).astype(np.uint8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(start_iter)\n",
    "n_train_iters = 100000\n",
    "vol_gen = ds.gen_vols_batch(['labeled_train', 'unlabeled_train'], batch_size=1, randomize=True)\n",
    "print(ds.files_labeled_train + ds.files_unlabeled_train)\n",
    "#vol_gen = data_utils.gen_batch(X_unlabeled, X_unlabeled, batch_size=1, randomize=True)\n",
    "target_X, _ = next(vol_gen)\n",
    "zeros_flow = np.zeros(target_X.shape[:-1] + (3,))\n",
    "\n",
    "for bi in range(n_train_iters + 1):\n",
    "    \n",
    "    target_X, _ = next(vol_gen)\n",
    "    vm_losses = vm_new_model.train_on_batch([target_X, source_X], [source_X, zeros_flow])\n",
    "    print('Iter {}, loss {}'.format(bi, vm_losses))\n",
    "    \n",
    "    if bi > 0 and bi % 2000 == 0:\n",
    "        vm_new_model.save('./experiments/voxelmorph/vm2_cc_AtoUMS_100k_UMS_to_CS_xy_iter{}.h5'.format(start_iter + bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save a voxelmorph wrapper\n",
    "# import sys\n",
    "# sys.path.append('../voxelmorph-sandbox')\n",
    "# import voxelmorph.networks as vm_networks\n",
    "# import tensorflow as tf\n",
    "# from voxelmorph import dense_3D_spatial_transformer\n",
    "# from keras.models import load_model\n",
    " \n",
    "# sys.path.append('../neuron')\n",
    "# import neuron.layers as nrn_layers\n",
    "# import neuron.utils as nrn_utils\n",
    "# sys.path.append('../voxelmorph-sandbox')\n",
    "# import voxelmorph.networks as vm_networks\n",
    "# from voxelmorph.dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "                                \n",
    "# vm_diffeo_model = load_model(\n",
    "#     #'/afs/csail.mit.edu/u/x/xamyzhao/voxelmorph/models/vm2_cc.h5',\n",
    "#     './experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter10000.h5',#.format(start_iter),\n",
    "#     custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "#                     'interp_upsampling': vm_networks.interp_upsampling,\n",
    "#                     'meshgrid': vm_networks.meshgrid,\n",
    "#                     'tf': tf,\n",
    "                    \n",
    "#                     'VecInt': nrn_layers.VecInt,\n",
    "#                     'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "#                     'nrn_utils': nrn_utils,\n",
    "#                     'nrn_layers': nrn_layers,\n",
    "#                    },\n",
    "#     compile=False,\n",
    "# )\n",
    "\n",
    "# from keras.layers import Input, Lambda\n",
    "# from keras.models import Model\n",
    "\n",
    "# vol_shape = (160, 192, 224, 1)\n",
    "# input_src = Input(vol_shape)\n",
    "# input_tgt = Input(vol_shape)\n",
    "\n",
    "# warped, backwarped, _ = vm_diffeo_model([input_src, input_tgt])\n",
    "# flow = vm_diffeo_model.get_layer('diffflow').output\n",
    "\n",
    "# wrapper_model = Model(inputs=[input_src, input_tgt], outputs=[flow, warped], name='vmmiccai_bidir_cc_wrapper')\n",
    "# wrapper_model.summary()\n",
    "# wrapper_model.save('./experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter10000_wrapper.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
