{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "../cnn_utils/vis_utils.py:14: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  mpl.use('Agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 160, 192, 224, 1), (None, 160, 192, 224, 3)]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset_utils import adni_loader\n",
    "#from networks import transform_network_utils\n",
    "\n",
    "sys.path.append('../neuron')\n",
    "sys.path.append('../voxelmorph')\n",
    "import src.losses as vm_losses\n",
    "\n",
    "gpu_ids = [3]\n",
    "# set gpu id and tf settings\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=','.join([str(g) for g in gpu_ids])\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "import sys\n",
    "sys.path.append('../voxelmorph-sandbox')\n",
    "import voxelmorph.networks as vm_networks\n",
    "import tensorflow as tf\n",
    "from voxelmorph import dense_3D_spatial_transformer\n",
    "from keras.models import load_model\n",
    " \n",
    "sys.path.append('../neuron')\n",
    "import neuron.layers as nrn_layers\n",
    "import neuron.utils as nrn_utils\n",
    "sys.path.append('../voxelmorph-sandbox')\n",
    "import voxelmorph.networks as vm_networks\n",
    "from voxelmorph.dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "start_iter = 10000\n",
    "# voxelmorph_model = load_model(\n",
    "#     #'/afs/csail.mit.edu/u/x/xamyzhao/voxelmorph/models/vm2_cc.h5',\n",
    "#     './experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_iter100000.h5',#.format(start_iter),\n",
    "#     custom_objects={'Dense3DSpatialTransformer': Dense3DSpatialTransformer,\n",
    "#                    'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "#                    },\n",
    "#     compile=False,\n",
    "# )\n",
    "voxelmorph_model = load_model(\n",
    "    #'./experiments/voxelmorph/vm2_cc_AtoUMS_100k_CStoUMS_xy_iter{}.h5'.format(start_iter),\n",
    "    #'./experiments/voxelmorph/vm2_cc_AtoUMS_100k_CStoUMS_xy_iter100000.h5',\n",
    "    './experiments/voxelmorph/vm2_cc_AtoUMS_100k_UMStoCS_xy_iter52000.h5',\n",
    "    custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "                    'interp_upsampling': vm_networks.interp_upsampling,\n",
    "                    'meshgrid': vm_networks.meshgrid,\n",
    "                    'tf': tf,\n",
    "                    \n",
    "                    'VecInt': nrn_layers.VecInt,\n",
    "                    'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "                    'nrn_utils': nrn_utils,\n",
    "                    'nrn_layers': nrn_layers,\n",
    "                   },\n",
    "    compile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../cnn_utils/vis_utils.py:14: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  mpl.use('Agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adni dataset adni-unnorm-masked_1000ul_subj-OASIS_OAS1_0327-l\n",
      "Params: {'dataset_name': 'adni', 'source_name': 'centroidsubj2', 'target_name': 'subjs', 'unnormalized': True, 'masked': True, 'n_shot': 1, 'use_atlas_as_source': False, 'use_subject': 'OASIS_OAS1_0327_MR1_mri_talairach_orig', 'img_shape': (160, 192, 224, 1), 'pred_img_shape': (160, 192, 1), 'aug_img_shape': (160, 192, 224, 1), 'n_unlabeled': 1000, 'n_validation': 50, 'load_vols': False, 'aug_in_gen': True, 'n_vte_aug': None, 'n_flow_aug': None, 'use_labels': [0, 16, 10, 49, 8, 47, 4, 43, 7, 46, 12, 51, 2, 41, 28, 60, 11, 50, 13, 52, 17, 53, 14, 15, 18, 54, 24, 3, 42, 31, 63], 'final_test': False, 'warp_labels': True, 'n_dims': 3, 'orig_img_shape': (160, 192, 224, 1), 'scale': 1.0, 'split_id': None}\n",
      "Got list of 7329 files from /data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/*.npz:\n",
      "ADNI_ADNI-3T-FS-5.3-Long_293689.long.016_S_4591_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_78841.long.016_S_1326_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_436815.long.094_S_1330_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_296323.long.068_S_2168_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_388923.long.135_S_5273_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_272700.long.009_S_4388_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_394785.long.027_S_0408_base_mri_talairach_orig.npz\n",
      "PPMI_3519_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_119158.long.053_S_0507_base_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_63306.long.007_S_0249_base_mri_talairach_orig.npz\n",
      "ABIDE_50685_mri_talairach_orig.npz\n",
      "ADNI_ADNI-1.5T-FS-5.3-Long_121666.long.041_S_1423_base_mri_talairach_orig.npz\n",
      "GSP_120719_TT88SP_FS_mri_talairach_orig.npz\n",
      "COBRE_0040043_mri_talairach_orig.npz\n",
      "ADNI_ADNI-3T-FS-5.3-Long_416015.long.021_S_2124_base_mri_talairach_orig.npz\n",
      "...\n",
      "Got list of 4392 files from /data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/validate/origs/*.npz:\n",
      "ABIDE_50008_mri_talairach_orig.npz\n",
      "ABIDE_50009_mri_talairach_orig.npz\n",
      "ABIDE_50011_mri_talairach_orig.npz\n",
      "ABIDE_50017_mri_talairach_orig.npz\n",
      "ABIDE_50020_mri_talairach_orig.npz\n",
      "ABIDE_50022_mri_talairach_orig.npz\n",
      "ABIDE_50024_mri_talairach_orig.npz\n",
      "ABIDE_50031_mri_talairach_orig.npz\n",
      "ABIDE_50032_mri_talairach_orig.npz\n",
      "ABIDE_50034_mri_talairach_orig.npz\n",
      "ABIDE_50036_mri_talairach_orig.npz\n",
      "ABIDE_50037_mri_talairach_orig.npz\n",
      "ABIDE_50040_mri_talairach_orig.npz\n",
      "ABIDE_50042_mri_talairach_orig.npz\n",
      "ABIDE_50047_mri_talairach_orig.npz\n",
      "...\n",
      "Got 1001 training and 50 validation files!\n",
      "Loaded 0 of 1 files\n",
      "Labeled train vols:\n",
      "X_labeled_train: (1, 160, 192, 224, 1)\n",
      "Y_labeled_train: (1, 160, 192, 224)\n",
      "ids_labeled_train: ['OASIS_OAS1_0327_MR1_mri_talairach_orig']\n"
     ]
    }
   ],
   "source": [
    "dataset_key = 'adni-1000-csts2'\n",
    "import vte_runner\n",
    "data_params = vte_runner.named_vte_data_params[dataset_key]\n",
    "    \n",
    "ds = adni_loader.ADNIDataset(data_params)\n",
    "data_params['load_vols'] = False\n",
    "\n",
    "vol_shape = tuple(data_params['img_shape'])\n",
    "\n",
    "# just load some examples so we can get the image size, but actually use a generator later...\n",
    "(X_unlabeled, _, ids_unlabeled),\\\n",
    "(X_labeled_train, Y_labeled_train, ids_labeled_train), \\\n",
    "(X_labeled_valid, Y_labeled_valid, ids_labeled_valid), \\\n",
    "label_mapping \\\n",
    "= ds.load_dataset(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 160, 192, 224, 1)\n",
      "(1, 160, 192, 224, 1)\n",
      "(1, 160, 192, 224, 1)\n",
      "['/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz']\n",
      "False\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAACgCAAAAAB/QzyBAAAcvUlEQVR4nO18XZMdx5HdOZlV3XcgrR1hh71aSfzCxwxmMCDBpVYbYYf/f4TDsigQxDdBUlrtyvaDHywRc7sq8/ih+g7AJTUzxIB+cExGIDDTc291na6qrJOZpxq4siu7siu7siu7siu7siu7siu7sit7I+OP1O5hIuPF7rf3vv6RbvOjAbhTldFCX45f9/Xsx7kPUN5aS8f5cP1pv9Im5pLEbTwGcOACcAuW+cVbu99qbw3AXfMP748fCdJrBBxFAK6750GoeOht3e2VvQUAB2YAvbAfb58BwBMck8UW0jf98C+/F52pnqUocMNTenFemxe3ywM4mGmAvJq67S5KhJCFAIFEyXhxUyUbzBn53VZ+Zu49LP/lh97ezv/IOTYRXupcp7lw5xJ6UhmQG+T4EixOSFbLDS8F351Jv9xMc/V5rr/4obe/PICe7vO1zTRVP3VpoilCLG40AEY8wRfBeW+eZ+d3XR/NrafRDAD+9t//PwHw/vjvUYas1uo04OauQ1Sk3K0Uxy13CIDS/82/3avufvplAMBN4A9JkzMF/OK99+bN3/74AG6grL3tKcCLmUPrszWjMlHd6qbc2dtzCUDKSjFYnQ72/bShd97jdSBFKxQBmnuZf/5jA9ifjnYzJqTodHo9XQRlMiSnqbrXa3s/mdESwDN3mCVKsdcm0UQ6wEwzmAkCjF7+7t9drCNv5oVuzSC0OpNEp1W6lfnluHRkzkybJgeLg5nRgVtzNeWypEmvLWMR+ODLIrrgWkCIoJXvcVXfZ282ApM7Ais9ePEgFUnC5slv7QM3WYtBXiszRVNf2hNgmifG8s0327aETnfk66BoHxhpUvYAADjJ8h8v1JU3GwFK4KuneP/j3grg014CQLVSvRmqRWsqjNYeAUfTxmN5+QDYb6/5oT4JLGm0BNQJAfQO2PQjAkgIn99+9XvIayV8L5h3jaxuVrxquzQK2RI4rPOk5eUC4Onp934xRzMTbHhbRU7443tuhGAX45lvBmBxAa9N0vt3SptI38g7aT45fM+w3fb0LsVDwKfJlpe/+3Y7U0EPgfBSWwCyipUhm+OD9k8/FoDnAPAUOH6wu9KW6mbceJeZFco8Tk62D44l6XPgaJoLevt2Mz8vZnNPQpo8SHA2wCjSDN9a6m8ZwHdsi9b2JDg9HUbAtWy3DwCMh16nwlg+//a3Zkuv6AH2ECDQ9V4yHU5IiZ/H//hxAewG4JfNph4G0CgChrTWWpz2/3iuptwNwC2ivwDetUyHSwZLUQIBN0aRAEXS/Pvu+i27PBcCAP9aOSgarYwmOf6ts2AzVb4e/dEAOAHKax3ThYTRzAlKykxY8XfO25J/0AjcQHw1frr+4raevPrD13h2z4yCQaAJFl7mxArgaJ4KAZuOQ0rtGIeRkKwoQ4TRBBORxVJShznh+NuzZ9EPAjChfzCi3Plu4b1+uoQP5KWuLJOCMpC2gX0ceSceY9oM8jCjZSDFgesL3EhRdDJJQEaCsIJECk7C4rweXhzAzQ156hdobpw/yd8CAG4XnzazgZJkBBIGcaL3nvlRmWbSxKhw5RKhnQv+4oMkQ7V0W2cYjUQHADNAyvPm+IUB3NpUKmy9cxSrky3x6/8K3EGpdW+eJAhIOTAYjmOKFoLVdVNyFmDTlt5227gJqZTTKVqQRrJLSZMhBdB+/s9vA8C7s5HQLhpsNSynkvFfegBepk3dkbsUNZYCVLyk5ICUhMEYdC/ftHUofwFXwBIuwUiSjkhAPngpzGQ/m89IK10QwN9dcyMjdwv3xS2AnLzUSMDdC9KQgFuILJQgAXRXggmzEKBlgRdA+OKGUb2nU7QMmbsZCFpEAmaGED0pEWcR0wsC2JsLCcXphWc4jraZJi8Q3SQF6CHQSNJSEmsAIMBB/Yh4+ZJ1QioBkgVKr4JF9OrmICUluWOKEiT96ayeXRDAxoyIfP1RPDjCNmOaDSShRBoMkAERkCCWJCm+2g5yuzw/TCQE0sQSygk5eBUdACknIOXgvDpvq7oggMlN/5ogPrzdew/tOTRuI4IglFIkR79pkqWUGAkv4hEA4Dpg7EDE4hxbGmgCRIcyAQkQQOLd318WwJ2pEMoej9cL+0Q8x2McRmp2IkfvBZHKJJE0U4ZYZJKiE076tGMTRshKkBly0mkDrGSK7OBAAPLsJXARAO/9ZCpk9jglk0fFiA/7QzzCR9YrBVEgoSRFB0WQvrTOyS2zf7NNnzaVtR4MP0AojaRRSsptLBJQqcikBgKHgmeS0gsA2KtG5dIe7S7s12IOtg/vYxeGUwYITCndKGpp8dNcGmlALCe/A+65+dRy/ymAfUjqBTQxIMGG0xKRAXgDh09iUvazM5bx+QCuT4WK9tlrl8y9FFj5dcZmUwBSpKBE23aV4qZ2stVkfYsyJbM1AK25lWndSSyFFC1hSWB1OwllpthkRkokQfEsTno+G50MUrZ3X13ZBsmy+elPrv3kb67tFQkcNMi1ffmXP//5//z5m29enmwlqUdK6xb3+bIEp8n2AZgVIxNj2ZsbtAYwktZ4kjQqlRJ/9u739QzARUZACfi3AsivD3yytFISsordGgbQe1+WasX1OxwYIZmRNOfhI6BZJU/jeSJBEmv8GzYuDlJOgoQEJZV5qSn0BMc1R7AKADefA2rOCjMAAoe7EKi+Te0cFaxQMDcjrJQO4OEh9xC7JJ0BSHOJgBkSBkBGU3LQUqxuSGeRoYu40a1ctrnxBQDc9Y8ViW6rZwcAUNLgvq+FsdPkLeRGwqaZAPDomFySwE1IRsvMgiCLg5JgjCRgLiIR0LiB/90ZSfeLAHgGHBvt+gsA1YtHhDiib8EgixQQwggiAeCo+FSzJc0hoEz4qH8OdCIS2LeRQCRSBWSxoAvjsZtISIGgZFzd66UAAAgzzgBAswnK8OoUYBkGQczWk/2UK20mL7YsQR9d8JJ5+zEeHz7CLd4e8aZoAsySlrThRQE6lZmp4ZOIsS9fFkCClvtPgd/cowo0ezGQSVDGsGwvF5giOnBn4+RU2ZYWtRoBk1VKh8sXCTzDARJUlxun1YE5qQRhCVpX5OpVIeHMNXxRAMUqxYOTr/Hph1Gs7lVbby0CRG5fLjBkf4R7UwV8qhE94AakXKDPmRVP1n7BKII+BXdZOEoOgDCkRK0OVfrD2T27QO9vTu61qhpt/ylaulWrIAkDBMmyL62PnfrDDZ1wzxb56NhJIpeeos/YURGSxqRBog3GlpTGLJJoAhMMUDin/xcAcFBqNbonSNMRSClC5JjElGBa2m6luU3ORETrARqobEuXuXmJo+0XwD4HTYAUUY3k6LolAIWSBgtY0pnnVuLPB7CH2bmmWy0LElbrhoAkAiSpZQnZwRMA96apmJQRvT0Azan28iThxZFKAvtGiBm0kGDuhCQDwQQVKZLU4Oa089KL5wL4qFhhLiMai7yPj0q9VicIoyAEwk5OWggO4HieqkkRiPYpYG7sJy9b8rMPDfEZAEQaQIXRmLamYoZbEhRdFMwMsMGFcNYucD6Aw1oqsi2RAXuE20A3K/OgBIYURS0ni4CHACavrmw90Rtw253Rlh4J3MfhGvQjDRSQNjJb4BhOAcxIQmMdGDIN+GC51AhU0DMjWjwfd0cCZqOQjUwxarQlV1ZYffKTbXbE8hng7swuPMX7wAjFDiNjPG9QmfKREc1TOkUTpXCJVBrEy4WUFOAKjdaPyl15dUcy0YugnrIQDTUAfGQFkdEzf7sP3CxldTS7mPhGMebKMs0i0qEgFQmQBtHHXqhuSDqCAM9MLp4HICOzbrzP+Q80hwtWy6SMyCy1GuGGUkVqtCZFb5F4CmxqoUD6KWt3jOyPhwAxWZydVCYkFidHPZNQEru4+swU9XkAwnKLaZpHfiAMosX/VvZI2vyTTaGB0zVm/93N58i+0KRPbz0DcDxVB+CuD/sWAHCzwgFPGDBWvTHCg8pMmVBgrhRJJaDuJoH2H/7XmwM4ISx72ZvZlkgRAFtDdvUsmmaLnrANtwECv70bqiSeAffcpuIUzLOsMiEHu9GcpY8wkm4yCopQmmigj8SpQcBIjK76gzcE8AIHT+62UgqWl0unROK3a2lpv7aw7dJsM19TQwHw2RFZCACzWXUCJjBXkkdEmIOAoeSoRRnGtDMFPGQOMAWAKVv50eXY6BN0IJW9ta4c8crwbF2Z+fKkMX1T6yfLnc+Bh/i1+dHD/b9xIgBD773t8gHJBUCaBY0GygkamD2TILIJ7iUGCYKYrwcYbwpgqBdIc8/PsP8U2BVKSWYsS7B1zT3QP7wPIMSCp782NZTqaq21HQd6ClxXUAg3S0No3QkpfQG8Lw/Vkf5iiqOiL56ZW7xIicnM+pJ1ro7juv/quhvR8v7nQobNm7n4hwBSo9G23fbelmVZlleFYUTvIgb/aa1nmpOILgBfPY/MaJmZgJmPdLUicIZdZAQM2rZaysxfdeH2adT79FeZMXQ0ktW1Gzl2pshUMHuLvlMsvmswA4ylItKiCQ3+esiSQgYIBWmWJiERl64P3D/Obr0WGEcac2eKngJM0TOTI3Wqkc0NcolHr7VyvVhJWqaVaq3nFEl0eSGSNfBLxZ8SVKJ45AgFSBFn9v9iAc0DHJQIt8w81agAQPRt8s7nhv6NkEzh+AHu/33pwFIU/TWN5Y1SzIrETCueKSjS1dXMJc79uqD3TUIGjZQCUMDibCp00YjsCQ6TABT5+NXVaInfAKllK6BGZABYYgEWUX59p058vxb3UcOT+eD/mYJS3Zk93Sm3HoSkPogSjFD0M6sDP6BG9gjYJ/JbCtxl8LLGTIgpRQMwvLgkO218MwIKAYagDBQECnIEoo3kkGcKZEJplJRSnL0AcGnp8S0N3QQA4FD59Hs/tV+NsF5c9BaVYO/yFmRzc/ZOMlXYlYKJ2UcwoDhf7XFJrcQzAAcO8SFWvvx9FkawBBIU3EalwzxphHvKvlUHEFJ/AN7/6p3v0Wd+x95sBG4VB6Qhlj62EZTc/+uf/2AuNjcgzTvdHL1njSZffPa+IEHKFBEgmmj2Ja6HwORZ1ZkfCmAfHNWJ/Y05iR73AdxjUZpnx6h673/fNHpvqpOEACibqvXsBa2bfLZYMggA2bqMXFjcEpkAoch2ptbgwlPoqDjJX/X2OTCZe/UYO26xiYIadbc9BlDvbJ/jriPjNXHN18C+jEo5CFU6YQDdKE6BTEm9w50qcDOlYCaEF79UQDPsBmolhAR46xkefGR1LksjgLsosyu2oUwBuO2O97+qTsRh8Ane2eV1nuIdNwGGbOlG0qaRWCIRS4jxT++6M0Wa5UiCJIkyn9W1iwG4phHFa1f19FpLX9eY15pLhHoLAOaFW6g4lj3pXmurPASAkqAZoZS5kWt+XlLbdv9nwMwDhJGj3gzTiOwvAeCg2Cr/WnOtBkA0d6zMQSy5xG7GuBkntGo+kUr6aUD4vpsh3IwyrZRppcvq4RVAofekmUXSDaPSRzvrBMuZAH4+z15MZOp3d5T5FMCd8djMKeD245WIWemrE3Q3TYioVpBBP318H1Q3yoqRMjHHUwYQkDhXO5CN/JnTsorQiJwvUaWcNhMdEYrE5+tJniSADBGwCMDNCXjxUX6Em6EeKESvW9ByV9qJ2UkYKZgSquiDGDLFmmkE3VVhhJmYI0knmd40vf7+3uyJ6K1nABjj+AgDgGGtypmbZMWjALhTaCaf+mAFfM1P//66rbngTEhYuKrkSPjcx4oyVTKFHJ+TnZufPgvAVIylb7ffPTBC0tIAA7xWh+RuDtx1NxJe0tSquKach704oHVRCDNJ1FC7UqQ7qTTaUAlFRtJWzV3mmQHNWSv8KYnsj06+B3YptOo2AdNcoWgJM6BUJxIs+WkmJje8rnDpmZkZEZHKSGWuyTg388ndSgGY0fsygmFCyvz6TEJ05hoglH3nyN/7GsCt8gjA8bQ3J6ZNlk98M1f11nqupUooHCQW9mpU4tPT5r7AgWJk0ZmSIUeNFYg0UnAXlD0FSwWZQGY/q4fnAZDlKUP76cET4Nk9fGRZ9vZKwK95N5RCtW2PTI1sTkQ6Hb/7ZDFXP12AR1ye4cn1NIFJwHJkztO4HtwaipceIpCSRvHhvGNB5+wDHBPgxt6Dj1nu9Ceo/6lIvjeBQLGkZEC2nooEBEidMgea15mt7QAY6gdf4gVw0wgKRDjEMYlsTBckMgJcQwpKsrM80LkAEop3/gDA+IkbWr9rNm0oVqMJdAMk0DAcC8LJVKoA6NGLl905hiMSgxJUihCKwYxpozJgKQBJZAyVFglDwnTeTnvm34W18OVmtbK2QCleIIqEAMEosKwiP0CEUdkBPPyoR62nlVf6OprGNCZHNTsr13r8WtQekhVLsiAEnDsCZ/KM3leNiht92uxdu7Y3F426GMixZiGVqbqZAT0Bm6f74D2gRc9a7EMAQGK3KY/SCAUoW0usJFBSQkmjuZnXaqkhqLgEgO1Omktz81Lnaz/dOHrCx9wVkIKSm725mH+Ih79VJoji5Q5a68GypmFS9HoIrMpexdJ6b73nOtcF0CBYMStlKBs5tCCXALDbwW6RNKSktFIdNGKngyNI+ebabEYA22VZAkYWPPs0engdk/Qp67S3d3gTUPQePbO3PqbLKOmNsydgcQMNyh0f/etKGwAXpNNOekFEB3LD3fklySSO4mJxLQns1PYxnly0Wur0YXsEgChdiusvIlIGJkXZTt+Ktf/jKYGZHAd1QP7yzTey1a6700y9tWRYhWwsgTVRwnQBhXp1vmRrDADb0r1M2wYcucNoROARbnLdZ+GFMQretuon0LtySACQYuq8wP4CAN6d3NzZ+9K6ZqaDGp47SWQahhN8zWIkFR98EunTNQEPPy5uo3wBGJkiAa8WkVZ85IlMCS0QkoRMIMXzDqJcRPQ3lVIKlBmRgPZKDoW6kCJdGpRgdZifKEPr/t96lrKnfwhzr+bulQCe3oELAGtpLWVwjj3AKMUQQnHU0blT010CwFGZa6kmjCRBs6mWU10DhA4DDG44eojjunHEqfPvy1SsbErArbBstLWjhwBkhLxwG0qhrzWB4Zw5igJD+yvaZQEcllqnUkbqJFPdlkmxMv3RuAyg18BHrHUuyKXrTice4+HxVKlSUiBCNttJBxCQgbSlUQTVK2ASdqX/3cSR8vvO7v4wAO5mxSmxSERXbzmqxmuV3UJJoOzZlKi1OlW3QhGOHuLBP3YX6Am0EOgeAMQco7nG691PzxzQV/nvUExQOLvKeiEvpLRMwJEomUrtigQExBQlg80eyeJQwDdeWiYBxIoW2fouzMWTfQLIIWhSFqVzHDyATz2osbsNOcg5Q3AugG4WHZK5l0gj4ByZZYhMppHMMLMpk7YSyUrPXAAQQUOmR29B5cg/RjWg+5qUGDMHLkodhkyJ0mme+3IAHh+VXLZCndx9yJEoQDFqYa4cst2RseVI86QVCHm3lVrWI0u9/eZVo1/sOxLBziJineg0oS9mZhHMXDWkvLQbXYosjE5TSkk3EtmXSDOuVYux8NY0cwJKM8qL5pksSLp6O3wte50peVcOKcdwQQSzp0A6MwnD+bvARQA8B45Ui4aKSV6cyvbyJOBeHHVor8ayJgyEuhkF1WtZi9EoUaeFvEPD53iOAwA9TDJKUca+nh0KmBkckEERec5hvgtxoYfXrSCj9daylsJcXv75BOaFSIXgGbaTXAGyCZIlWWRO2pCi7E5PzKUfPQQGV7AiWgZnS6xRfmfSaCExFTpPsnWx3OiLQypbay2s1MJ28s2nAPBhWC4Z6bMVjgMXECEjcnj2nRgLKDMP9Rj7m6muUuVHeK/UmlAkYYoOH1WmpByKsY+h//EtAMAyeWQujaVWy1zVC/d/lYsiwvUTYpzc0UrxKFKicvwKTixTvxc+bYZfzARqNfk2RUDZO0ZWOtNHLUf22sn9SwL44mjqyi6fqjNOuZu6eiYVQIK7TBSHCHfdTQHJiGqeEeHVWxDAc+B6MWVGGg2ZvdPM+3gCIi3G07hMWuU1e3h3yhgSJ0m0e58CwCL1tMlN0dOsmgAJpowhCF3F7WkArUQOnRxuxQsATkUqRatQj4SZGSxWz2mAFDynzHrxEtMdPjiq87SZEK21rT49/cvH094mTxaf9yqokVeg2ZCbYDzRAHbqdv35Zesj2DvoCZqXTdHJVvJS4wQruSUTajqvTnnxKuVfCujuDKQg76+59Ww9lsaFRhqiCSzMsauBINq2qVRJ0cVafPcanCVpVtzATCgAowUZEGmkyDPzoj8MwFdj0S1Edql/+uovUs/+WxximYosTk5EztXXjAnkuf3LoroplidLt029plU/kKw014IyTo5lFouAZaJIknTOCviBdeLI1klF5KcAcPzg7mcA0AccKQWgn/xFYEyVw18ZMtp/20dvm5on93EzNnUe/bohK1RGApkggZSHckT4UObyP98qgJdyEpntMQDcq/84BnhNvrib4MjMeAz8/QQzRag4M48bH91W133g+b7tzsobacgQTZkkoXBzQLAh4zmvSPxDATzHDZpWBd9HG/9WwH08VUY6aJYAlv/+n6eivoRv6qiHPb49Pv4UH1XceoYhFY3ei9m6BzLDQUuYlDzz4MMbAQBOBTQHtRbf5t3T42XHG+eWpcCLGYCO6EWxXYo5x358qnPZHScm0duLdyXRjBnpKuoo2SkF8hzl/ZsA2NlhKdOUuayLcd99ryAa60SvNQE8RoSgtsS0oQN+51Xd++HheLFMlnFA2TIgriWlVdnPuIDS400B7E+lThtfzAsA3DG6z+i9swu2W6KpIIDofZ4M5fUdZ/XAz/afAqjmuZitCd5EhjFFnetBAbzZeyWO5jrPk8lqrQA+3sxznQuiZ+8p+GR3AGDUPPSo9yQZ5ZNjADg8Orh12tJTADfNLBYxNNKUhp6mzAsCeIMROCpWi0Wn+8RPjG4w9x4pZE/JfDiZWCoyHx9IcFfkZHe3T1Et2+t6kPctmT3nkc2CaBYS1P/1i1jeHgCS2Xpm+GbebA1uoDJ6klQzM6sdAFrukiP0gkzbMzv22cO2B6n+1Wjtq1udisR6HCEhWmZewIG+KYB3ukHM3jm57V0DQaplZIrMXg1e/O7JM6SkUUwQ3FIqrJ1updg2XyUjk8z++9vmCSQyYcp+EQf6pgD+gBu1qD/BdY+ErwXtVIJi9iCtuBlgkCLB7K3UuZPw2lqDWYnl1Q7SDQpAa8EkaQxebPq8GQDgi/c9vwS60JdI0Ash0SQouxlLWQgUt1w+h7It9E1YkaDtCb3uqjIAgK/fi/wj4vQAqBAX8f+XAYCvAAC/xyf5DWClmNHM1AH1XmBroi0aOvD4oG1ZJ8gR2VqDh796OQlWCcPihWBKyPzqh/TlUq/n6YqTlycnS0/STAR6az3G6aN9Zu8C8KQvi6wUjKJM9tb1nUjx6x4Rf/yX3lv7Qf2/nGrxpI24j9NOz53Riii67Y/T8QCQvUcFoi0CLfuX39fW74GfAVs/Tyf6VgE8AfD+RG5FirQUshkImXfl6TxRhHuebBtdxPf2HwD+BJz7Rqrv2KXfsfUVjijJTDILqcMNXeYtdfoqEFK9b5dU2Hnp8h9qb+ElYQ8PrY/3AkFgZodal57hbqyvMKCFoi35GMCtizGEC9vbeMvZI9yiPT4GCUpxYohEBzSEBCBiUfQhDn3brz9+O69pe4YRl922TO/EUN6Hr85e0TOFx2e08Mb2lt4zt9raxRvjXWJLHau4e6b0/K9+61L2lpfUt+269y8BvOenNf8ru7Iru7Iru7Iru7Iru7Iru7Ir+//H/i9jWAb8U1VduwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x160 at 0x7F61384781D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x160 at 0x7F6138478358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_unlabeled.shape)\n",
    "print(X_labeled_train.shape)\n",
    "print(X_labeled_valid.shape)\n",
    "print(ds.files_labeled_train)\n",
    "print(ds.params['load_vols'])\n",
    "import IPython\n",
    "import PIL\n",
    "IPython.display.display(PIL.Image.fromarray((X_labeled_train[0, :, :, 64, 0]*255).astype(np.uint8)))\n",
    "IPython.display.display(PIL.Image.fromarray((X_unlabeled[0, :, :, 64, 0]*255).astype(np.uint8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 160, 192, 224, 1), (None, 160, 192, 224, 3)]\n"
     ]
    }
   ],
   "source": [
    "# create voxelmorph model\n",
    "sys.path.append('../voxelmorph')\n",
    "import src.networks as vm_networks\n",
    "\n",
    "nf_enc = [16, 32, 32, 32]\n",
    "nf_dec = [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "# vm2 model\n",
    "vm_new_model = vm_networks.cvpr2018_net(\n",
    "    vol_size=(160, 192, 224),\n",
    "    enc_nf=nf_enc, \n",
    "    dec_nf=nf_dec,\n",
    "    indexing='xy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 192, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 160, 192, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 160, 192, 224 0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 80, 96, 112,  880         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 80, 96, 112,  0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 40, 48, 56, 3 13856       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 40, 48, 56, 3 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 20, 24, 28, 3 27680       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 20, 24, 28, 3 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 10, 12, 14, 3 27680       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 10, 12, 14, 3 0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 10, 12, 14, 3 27680       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 10, 12, 14, 3 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 20, 24, 28, 3 0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 20, 24, 28, 6 0           up_sampling3d_1[0][0]            \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 20, 24, 28, 3 55328       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 20, 24, 28, 3 0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 40, 48, 56, 3 0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40, 48, 56, 6 0           up_sampling3d_2[0][0]            \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 40, 48, 56, 3 55328       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 40, 48, 56, 3 0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 80, 96, 112,  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 80, 96, 112,  0           up_sampling3d_3[0][0]            \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 80, 96, 112,  41504       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 80, 96, 112,  0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 80, 96, 112,  27680       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 80, 96, 112,  0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_4 (UpSampling3D)  (None, 160, 192, 224 0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 160, 192, 224 0           up_sampling3d_4[0][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 160, 192, 224 14704       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 160, 192, 224 0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 160, 192, 224 6928        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 160, 192, 224 0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flow (Conv3D)                   (None, 160, 192, 224 1299        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "spatial_transformer_1 (SpatialT [(None, 160, 192, 22 0           input_1[0][0]                    \n",
      "                                                                 flow[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 300,547\n",
      "Trainable params: 300,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vm_new_model.summary()\n",
    "import data_utils\n",
    "import src.losses as vm_losses\n",
    "\n",
    "# just train voxelmorph\n",
    "vm_new_model.compile(\n",
    "    #loss=['mean_squared_error', vm_losses.gradientLoss('l2')],\n",
    "    #loss=[vm_losses.cc3D(), vm_losses.gradientLoss('l2')],\n",
    "    loss=[vm_losses.NCC().loss, vm_losses.Grad('l2').loss],\n",
    "          #vm_losses.gradientLoss('l2')],\n",
    "    #loss_weights=[1.0, ,0.01],\n",
    "    loss_weights=[1.0, 1.],#0.01],\n",
    "    #loss_weights=[1., 1., 1., 0.],#0.01],\n",
    "    optimizer=Adam(0.0001)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "input_1\n",
      "input_2\n",
      "input_2\n",
      "concatenate_1\n",
      "concatenate_1\n",
      "conv3d_1\n",
      "conv3d_1\n",
      "leaky_re_lu_1\n",
      "leaky_re_lu_1\n",
      "conv3d_2\n",
      "conv3d_2\n",
      "leaky_re_lu_2\n",
      "leaky_re_lu_2\n",
      "conv3d_3\n",
      "conv3d_3\n",
      "leaky_re_lu_3\n",
      "leaky_re_lu_3\n",
      "conv3d_4\n",
      "conv3d_4\n",
      "leaky_re_lu_4\n",
      "leaky_re_lu_4\n",
      "conv3d_5\n",
      "conv3d_5\n",
      "leaky_re_lu_5\n",
      "leaky_re_lu_5\n",
      "up_sampling3d_1\n",
      "up_sampling3d_1\n",
      "concatenate_2\n",
      "concatenate_2\n",
      "conv3d_6\n",
      "conv3d_6\n",
      "leaky_re_lu_6\n",
      "leaky_re_lu_6\n",
      "up_sampling3d_2\n",
      "up_sampling3d_2\n",
      "concatenate_3\n",
      "concatenate_3\n",
      "conv3d_7\n",
      "conv3d_7\n",
      "leaky_re_lu_7\n",
      "leaky_re_lu_7\n",
      "up_sampling3d_3\n",
      "up_sampling3d_3\n",
      "concatenate_4\n",
      "concatenate_4\n",
      "conv3d_8\n",
      "conv3d_8\n",
      "leaky_re_lu_8\n",
      "leaky_re_lu_8\n",
      "conv3d_9\n",
      "conv3d_9\n",
      "leaky_re_lu_9\n",
      "leaky_re_lu_9\n",
      "up_sampling3d_4\n",
      "up_sampling3d_4\n",
      "concatenate_5\n",
      "concatenate_5\n",
      "conv3d_10\n",
      "conv3d_10\n",
      "leaky_re_lu_10\n",
      "leaky_re_lu_10\n",
      "conv3d_11\n",
      "conv3d_11\n",
      "leaky_re_lu_11\n",
      "leaky_re_lu_11\n",
      "flow\n",
      "flow\n",
      "spatial_transformer_1\n",
      "spatial_transformer_1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# copy weights from regular voxelmorph as initialization\n",
    "for li, l in enumerate(vm_new_model.layers):\n",
    "    print(l.name)\n",
    "    if l.name == voxelmorph_model.layers[li].name:\n",
    "        print(l.name)\n",
    "        vm_new_model.layers[li].set_weights(voxelmorph_model.layers[li].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=192x160 at 0x7F5F680F7048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ds.files_labeled_train[0])\n",
    "# source_X = ds.X_atlas\n",
    "source_X, _ = adni_loader._load_vol_and_seg(ds.files_labeled_train[0], load_seg=False, mask_vol=ds.params['masked'])\n",
    "source_X = source_X[np.newaxis]\n",
    "IPython.display.display(PIL.Image.fromarray((source_X[0, :, :, 64, 0]*255).astype(np.uint8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0327_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_263697.long.153_S_4077_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223532.long.153_S_2109_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_76615.long.021_S_0984_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_451346.long.009_S_0751_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100329_NW33DK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_282668.long.002_S_4270_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110314_JD99RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50558_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_424046.long.073_S_2225_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123092.long.036_S_0672_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_65343.long.027_S_0850_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_254813.long.116_S_4209_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_45933.long.137_S_0972_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_394756.long.011_S_4235_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118902.long.023_S_0926_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119324.long.123_S_0113_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_370676.long.033_S_0741_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349295.long.021_S_2142_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3787_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121812.long.029_S_1218_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036143_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3407_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119395.long.128_S_0310_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51305_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_313580.long.006_S_4546_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119656.long.133_S_1170_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_62599.long.005_S_0324_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_59923.long.007_S_1304_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50351_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3809_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120628_DZ38NB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0061_MR2_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121072.long.002_S_1070_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100627_BA34XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_64609.long.016_S_0702_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3650_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10120_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100920_GJ38UU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_342548.long.099_S_2042_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_416009.long.019_S_5012_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_96119.long.033_S_0723_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100916_QR67XU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59697.long.116_S_0649_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_357718.long.130_S_4641_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120621_KM56MK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_2559559_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_277027.long.153_S_2148_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_3466651_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_2123983_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100121_GF37CB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_377050.long.036_S_4736_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_376948.long.131_S_0384_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091222_EV77WH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100218_PX88NU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102414.long.128_S_0200_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349822.long.022_S_5004_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432130.long.037_S_4706_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0331_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_79126.long.002_S_1261_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_3994098_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_130240.long.068_S_0401_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_3004580_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_142044.long.037_S_0588_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3816_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090914_DJ48AU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_308100.long.041_S_4720_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101208_DQ73BH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0291_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100328_CA87HH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_103333.long.032_S_0147_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090709_WE83EH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398370.long.126_S_2405_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50243_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_111236.long.031_S_1066_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_7333005_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090914_WJ88NK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59725.long.116_S_0382_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10068_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100128_RX68QB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_140604_UW83SK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_300291.long.041_S_1425_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_335944.long.031_S_4476_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_363274.long.033_S_4508_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090923_PH66XU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100526_TE48VB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_66051.long.094_S_1188_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3612_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100308_CQ45RU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_69606.long.022_S_0544_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036298_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119090.long.032_S_0479_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119144.long.053_S_0389_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_294850.long.027_S_0408_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090724_ZN86HH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_140800.long.007_S_1222_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_122662.long.006_S_1130_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118706.long.010_S_0067_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_163740.long.136_S_0429_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_85547.long.002_S_0955_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_217623.long.023_S_0625_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_335420.long.135_S_4723_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118774.long.018_S_0369_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_410806.long.027_S_0074_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_424051.long.041_S_4004_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120412_NB86WC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322420.long.141_S_4711_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_78654.long.002_S_0729_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_D_A00036385_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_451330.long.035_S_4784_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_83380.long.022_S_0007_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110115_BJ98KH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349643.long.100_S_4556_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121570.long.123_S_0298_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121422.long.053_S_0919_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_68769.long.035_S_0048_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100215_HX52VK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_106524.long.100_S_0190_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_314439.long.021_S_4558_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NeuroIMAGE_3959823_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_398182.long.123_S_0106_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_369701.long.016_S_4902_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_403751.long.073_S_4393_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431682.long.006_S_4363_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101215_DH73ZU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100614_JG97XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123962.long.136_S_0579_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090427_VQ28GK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_498048.long.027_S_5110_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_204113.long.068_S_0401_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50468_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_225358.long.002_S_2073_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_51151.long.013_S_0240_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_82738.long.141_S_0696_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_350358.long.032_S_4823_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340553.long.098_S_2047_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_357769.long.153_S_2148_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_440930.long.036_S_4878_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119203.long.067_S_0607_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340486.long.135_S_4566_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0134_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_D_A00036357_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_451348.long.137_S_0668_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100330_YU53TH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_382270.long.041_S_4051_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090427_KW47TB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_75503.long.094_S_1267_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_321314.long.016_S_2031_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119512.long.133_S_0525_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_130410_VT93JP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432790.long.127_S_4992_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3054_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349541.long.035_S_4784_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119534.long.133_S_0727_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_2959809_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100209_DE33GC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_081122_PX56VB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119007.long.023_S_0139_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322262.long.035_S_4256_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398207.long.005_S_4168_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_151140.long.053_S_0507_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090818_HX87NH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_362991.long.019_S_5019_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_88252.long.011_S_0003_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51052_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110110_JV84UH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_392139.long.067_S_4184_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_081220_JS29GB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_342471.long.021_S_4245_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090709_UP72PU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_285123.long.033_S_4508_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120325_ZX36XK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_297287.long.006_S_4153_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_277078.long.011_S_4222_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100810_UY22YU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258643.long.072_S_2037_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_295877.long.007_S_4611_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_88072.long.123_S_0050_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_293742.long.022_S_1351_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_295933.long.037_S_0552_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_39601.long.035_S_0555_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_74353.long.067_S_0607_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091018_YB25JH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258690.long.082_S_4224_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_371443.long.137_S_4672_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_391088.long.016_S_4638_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_105747.long.032_S_0214_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_388564.long.082_S_5014_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_363036.long.022_S_4444_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_290934.long.067_S_2301_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110628_RT49DK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_39147.long.130_S_0102_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_80161.long.041_S_1411_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50496_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_130244.long.068_S_0473_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_425933.long.031_S_4005_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_293699.long.016_S_0359_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_389175.long.130_S_5142_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_67756.long.131_S_0384_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_89481.long.098_S_0172_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036454_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305498.long.130_S_4417_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431484.long.003_S_4119_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_99196.long.035_S_0204_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_121213_FM47PK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3607_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_414464.long.021_S_0984_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_312690.long.022_S_4444_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100621_QJ57HH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_86686.long.033_S_0567_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_265264.long.068_S_2315_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_63306.long.007_S_0249_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100123_UN59CH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_411334.long.029_S_2376_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_265199.long.067_S_4310_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_130314_PJ45SU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100329_NM38DP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305527.long.137_S_4258_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_137223.long.010_S_0829_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398171.long.021_S_4744_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_293721.long.094_S_4560_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_280564.long.136_S_4433_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_298425.long.099_S_0291_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_260245.long.006_S_4192_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_296526.long.052_S_0951_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_399902.long.082_S_2121_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_451352.long.016_S_4902_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110428_EE34RK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_65055.long.036_S_0577_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_351990.long.018_S_2155_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349265.long.135_S_4676_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101121_DZ73MH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091124_KM26WB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_255421.long.067_S_4212_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100902_FP62YK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3270_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090328_NP62FK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349333.long.137_S_4623_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432879.long.127_S_5132_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_122132.long.057_S_1265_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_32003.long.011_S_0183_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102136.long.141_S_1024_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_172347.long.116_S_0649_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_141107_PF88ZC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090530_SB54FK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090816_QM94TK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110303_MK63TU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_368982.long.941_S_5124_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0065_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_448973.long.037_S_5126_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100131_WK48QH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119531.long.133_S_0638_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_133901.long.033_S_1016_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_KKI_4601682_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091117_VK68WB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_351436.long.072_S_2164_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_142159.long.062_S_1182_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091117_YS49XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322474.long.021_S_4402_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_293689.long.016_S_4591_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_83359.long.012_S_0932_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59524.long.022_S_0130_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_331804.long.116_S_4175_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349254.long.037_S_4706_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51076_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119235.long.073_S_0909_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3501_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040103_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51294_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322529.long.068_S_4859_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_362957.long.009_S_4359_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100406_XY54GH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_280620.long.094_S_2238_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_81434.long.130_S_0449_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_358507.long.019_S_4835_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3616_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119118.long.032_S_1169_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_410918.long.027_S_0120_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111110_SP28EK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0013_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091112_MV73MU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0123_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100126_FV85TH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_92406.long.131_S_0457_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3268_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_4095229_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110411_EV77VH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036234_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3966_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3658_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222795.long.021_S_2125_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_125029.long.023_S_0926_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100709_GH46GU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_125100.long.012_S_1321_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_377040.long.016_S_0702_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120531_QH73NB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223359.long.082_S_2099_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090210_CF43BK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340523.long.129_S_4220_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101207_NX56KK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090815_EN97BB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110727_ZU78EM_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_KKI_2018106_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50956_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090616_ME56WB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222785.long.021_S_2077_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120126_KS46NK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091217_FD63MK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_376900.long.126_S_4507_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349232.long.002_S_4237_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100406_VC48XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398388.long.130_S_4883_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_4334113_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_314484.long.032_S_4386_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_21034_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100323_GU25GU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_105530.long.131_S_0384_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3104_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110418_GU83VU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_83503.long.035_S_0048_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223499.long.128_S_2002_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_65239.long.041_S_1260_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50379_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_286650.long.129_S_4371_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3237_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_389177.long.135_S_4863_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100621_CC66BU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040001_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_371434.long.041_S_5131_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223291.long.073_S_2190_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_337512.long.003_S_4119_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_427982.long.094_S_2238_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090817_GU35RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_KKI_2601925_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_80889.long.121_S_1322_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50377_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110120_UV37MK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_C_A00036129_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_277037.long.094_S_4162_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_7994085_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091122_EA96ZH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110208_BE99JM_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110209_DB46CB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_297631.long.098_S_4275_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121822.long.033_S_1279_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_357681.long.128_S_4653_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_67223.long.094_S_1164_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100304_TS78RU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100302_VB87QU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100401_PT85WK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_254758.long.029_S_2395_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090806_UG25DU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3666_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_60406.long.005_S_1224_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119735.long.136_S_0579_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091103_PB33FU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_466163.long.041_S_4974_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040069_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322953.long.135_S_4657_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111013_JN43ZH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_172332.long.116_S_0648_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_78860.long.020_S_1288_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340476.long.136_S_4433_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_112751.long.033_S_0514_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100531_GD57KU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090527_JT28FB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_63757.long.130_S_1201_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_282657.long.099_S_4202_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_312829.long.109_S_4455_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123101.long.036_S_0673_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_109722.long.128_S_0258_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431749.long.011_S_4105_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091117_BZ38BU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_278270.long.123_S_4170_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_394781.long.027_S_0307_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101014_JS49QM_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120315_XH44ZT_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091013_QC86BB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_72195.long.036_S_0577_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100211_NX44RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_66997.long.029_S_0843_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_379959.long.041_S_4060_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_2950672_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_88261.long.020_S_0883_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0047_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51363_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_431769.long.123_S_0106_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_300282.long.035_S_0997_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3233_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_413089.long.009_S_4388_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121404.long.041_S_1425_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_49776.long.137_S_0841_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090318_RF72RK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040043_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_78985.long.052_S_1251_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036491_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50332_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119522.long.133_S_0629_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119070.long.027_S_0120_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120110_CW65UC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091205_BB33PU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59704.long.116_S_0649_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50387_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100422_MQ98UP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100424_RJ52XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431646.long.137_S_4536_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_C_A00036213_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100320_AH36BU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_141017_SE68PC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_62917.long.037_S_0303_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100203_CU88QC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_91873.long.082_S_1119_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_82691.long.130_S_0956_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101018_HG74AB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432837.long.127_S_5058_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100218_US49SH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50805_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_101575.long.029_S_0999_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3559_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_72170.long.014_S_0520_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_63838.long.136_S_1227_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090914_JZ65YH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_91912.long.116_S_1232_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_132433.long.114_S_0979_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10063_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_408389.long.003_S_4288_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100221_VP45TH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119078.long.032_S_0095_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_288947.long.073_S_4382_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349916.long.127_S_5028_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51063_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258694.long.002_S_4219_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_338588.long.013_S_4791_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_162363.long.023_S_1046_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_162792.long.041_S_0898_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_171837.long.021_S_0159_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258654.long.941_S_4187_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_162707.long.137_S_0669_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119407.long.128_S_0770_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_86132.long.116_S_0752_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_399894.long.016_S_4951_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_413099.long.073_S_0746_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_372037.long.131_S_0123_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51471_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431857.long.130_S_4641_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118878.long.023_S_0887_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_162904.long.116_S_0834_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_58054.long.051_S_1123_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349339.long.006_S_4867_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_417079.long.036_S_5063_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090725_TU49CB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59411.long.022_S_0044_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222571.long.007_S_2106_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_221959.long.002_S_2010_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111117_SH55QH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_83814.long.131_S_0384_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090814_PT53EU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_92682.long.031_S_1066_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223365.long.082_S_2121_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_293755.long.014_S_0169_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111109_ZZ52MC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_388306.long.002_S_2010_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119406.long.128_S_0740_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10123_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120524_MK68HB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_394754.long.027_S_5109_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_163172.long.036_S_0945_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090618_XM97XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_388464.long.053_S_2396_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_49768.long.114_S_1118_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3311_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_293702.long.016_S_0702_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_312653.long.036_S_4736_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119405.long.128_S_0715_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_280587.long.011_S_4235_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040013_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_408371.long.033_S_1098_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090414_WZ32UK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_290959.long.128_S_4571_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50649_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51027_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_87265.long.041_S_1002_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102378.long.033_S_1308_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_300275.long.021_S_0984_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_392132.long.012_S_5157_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_81373.long.018_S_0335_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_388531.long.082_S_4090_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110505_QP35AU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340571.long.011_S_4845_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_295945.long.006_S_4357_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118796.long.023_S_0042_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120308_NC26FK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091208_TR25KB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_296513.long.051_S_1131_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222998.long.032_S_2119_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50737_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_121874.long.041_S_1010_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_299251.long.027_S_0120_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_72141.long.005_S_0448_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100912_TY23ZH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340903.long.031_S_4218_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090903_FG78UB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_334169.long.072_S_2027_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51150_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51205_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_277084.long.067_S_2196_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_422846.long.137_S_0301_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101009_BE47TH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_59174.long.012_S_0689_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_66087.long.100_S_0015_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_125038.long.057_S_0941_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0406_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_241354.long.098_S_4050_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_151204.long.131_S_0441_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_91096.long.116_S_1232_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100408_CR76NK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_3812101_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110516_NM22WK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100114_QP39HU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_139235.long.033_S_1283_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_134664.long.012_S_1009_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3318_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_363276.long.033_S_5013_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_348893.long.023_S_4501_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_60003.long.007_S_1222_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101108_NB65JH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110303_ND58EB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432842.long.127_S_5058_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_34249.long.027_S_0948_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100307_HB26XH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091207_TN73MB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123207.long.062_S_0690_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_412942.long.135_S_4446_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100408_KC55QB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_89888.long.128_S_0608_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_427971.long.027_S_2245_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0398_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120126_VV85HK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_101445.long.023_S_0625_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101116_TC69GT_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_439904.long.057_S_4888_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100422_PE46SU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_339181.long.116_S_4195_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118991.long.023_S_0331_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040060_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322418.long.141_S_4426_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NeuroIMAGE_1125505_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119398.long.128_S_0500_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_272687.long.031_S_4032_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100120_UN32HH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_2920716_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51217_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_130204.long.068_S_1075_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0001_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_34458.long.127_S_0684_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090910_PF28GH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110217_MJ94MP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_86948.long.007_S_0414_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100529_NG98KH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_286676.long.029_S_4327_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119135.long.033_S_0739_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120419_UB72FK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_225370.long.022_S_2167_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0339_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123364.long.128_S_1148_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305493.long.126_S_4458_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_63583.long.127_S_0393_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_313645.long.010_S_4345_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090606_MK27GB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0321_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_250621.long.123_S_4127_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_326594.long.024_S_4905_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223058.long.067_S_2301_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_78682.long.005_S_0222_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_90942.long.032_S_0677_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_290947.long.022_S_2263_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50038_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090903_UW95VH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100211_PX53XK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119192.long.067_S_0077_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091029_WZ62VK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100112_NK25EU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_377010.long.021_S_5194_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_89125.long.067_S_0812_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0224_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_432185.long.021_S_5099_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100519_PD76RK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_358066.long.037_S_4381_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100503_GD35ZU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102476.long.021_S_0231_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50188_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_423851.long.041_S_5141_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_138103.long.016_S_1117_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50019_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100114_RN64DH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_296313.long.037_S_4071_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_296347.long.099_S_4086_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_291017.long.094_S_2216_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_108286.long.037_S_0327_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_73529.long.005_S_0814_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3279_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_439902.long.022_S_4805_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040025_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090330_BE85YB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_68072.long.021_S_1109_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349597.long.019_S_4293_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_338624.long.009_S_4530_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_65606.long.010_S_0788_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_130312_ZD67KP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305468.long.116_S_4453_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090929_XQ38CH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_78841.long.016_S_1326_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_130502_MW73NP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50479_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119130.long.033_S_0725_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101111_KF45BT_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_299253.long.099_S_4202_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_5971050_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090407_ZH63KB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100727_PQ84YC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090217_EN45VB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_67244.long.116_S_1083_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_120811.long.023_S_1247_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_160356.long.133_S_0488_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50207_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090122_GQ43TK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_88065.long.037_S_0303_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090524_FM38MB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090304_ER76HB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040012_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_132642.long.133_S_1055_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040027_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118739.long.012_S_0637_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_350486.long.041_S_4200_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_94624.long.116_S_0649_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3421_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_400479.long.127_S_0925_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_296528.long.127_S_4645_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0075_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258641.long.011_S_2274_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_33799.long.021_S_0178_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_337565.long.067_S_4918_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_418775.long.002_S_4447_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_315336.long.941_S_4292_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_4529116_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3953_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_58043.long.051_S_1123_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_98804.long.033_S_1309_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040114_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_8328877_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_312791.long.126_S_2360_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110506_MU25GK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50002_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_130118_QC48VC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_118675.long.002_S_0413_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100224_UR52VK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_59981.long.007_S_1206_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51277_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_140522_CB75SC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50775_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_86318.long.016_S_1117_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091222_UH45WH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_331749.long.024_S_4674_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_39112.long.130_S_0289_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340575.long.007_S_4620_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_2174595_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091205_GQ87RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100422_HW48KK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0290_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_68522.long.036_S_0759_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_C_A00036128_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_205529.long.094_S_1241_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_280608.long.068_S_2187_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100610_DQ66BP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_97055.long.023_S_0217_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110809_YY34CB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_272762.long.021_S_2125_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_297633.long.127_S_4198_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090820_UK36VU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_297014.long.098_S_0896_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_274713.long.137_S_0668_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3958_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_312640.long.127_S_4624_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_297312.long.123_S_0108_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_277064.long.072_S_2164_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_132359.long.027_S_1082_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_121008_BR45GU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101213_JY35WH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50029_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_488785.long.128_S_4586_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_392153.long.003_S_4373_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50155_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091110_RQ82YH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110321_ES35JH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_296319.long.067_S_2195_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340563.long.023_S_4241_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322896.long.109_S_4594_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_2107638_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_86245.long.033_S_1016_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_130827_FU76QC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110416_NA77DU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100401_PF54YH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_162721.long.137_S_0722_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_350688.long.036_S_4878_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322303.long.036_S_4878_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0003_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_132800.long.012_S_1009_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10012_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_350369.long.099_S_2063_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_357695.long.141_S_4711_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_282692.long.014_S_2185_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118698.long.007_S_0414_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100907_HY25UU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_297655.long.013_S_4580_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50123_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_104466.long.012_S_1321_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0408_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110113_DF75WH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322309.long.012_S_4094_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322945.long.130_S_2391_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398167.long.009_S_4814_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_172374.long.116_S_1249_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_78903.long.029_S_0845_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_95628.long.020_S_0899_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_334124.long.141_S_4907_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_81437.long.130_S_0449_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_58000.long.051_S_1338_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_122843.long.014_S_0658_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_2141250_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090324_VR67VB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110106_CP94TK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091014_JU44RU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_299238.long.128_S_0227_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_282665.long.011_S_4120_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_340565.long.005_S_4185_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51099_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3960_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111222_QS44SB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090401_YV74BB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_350705.long.130_S_4605_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305422.long.135_S_4689_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_265256.long.116_S_4010_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50028_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_1700637_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Pittsburgh_16060_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_415793.long.116_S_0361_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118879.long.023_S_0916_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_162425.long.031_S_0830_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090113_WZ87JB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102555.long.137_S_0668_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100828_JY89GH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111003_NA56GU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_283952.long.116_S_4338_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100730_HJ53VU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090813_WB65MU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223240.long.072_S_2027_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040050_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_312670.long.073_S_4748_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_50575.long.062_S_1294_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_86236.long.027_S_1082_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110203_ZT54XB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_297643.long.941_S_4376_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119631.long.133_S_0912_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_155919.long.010_S_0419_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100412_YT33MH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50722_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0231_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0096_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50217_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_408345.long.067_S_0059_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_297269.long.098_S_0896_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_86452.long.100_S_0190_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3952_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091110_QQ34EH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_91935.long.123_S_0091_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_40799.long.016_S_1028_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_141167.long.003_S_1074_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_236982.long.941_S_4036_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_416100.long.137_S_0972_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_275492.long.127_S_1032_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100607_GE83PH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_338608.long.072_S_4539_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090618_MY83QK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51049_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3481_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_4265987_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_87565.long.027_S_1387_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_357889.long.072_S_4445_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_308102.long.073_S_4739_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50130_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101017_DB74VH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431679.long.003_S_4350_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431490.long.141_S_4160_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090827_DE62NU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036445_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_334131.long.033_S_4505_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110215_HQ34GU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0170_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110105_GD89PH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100920_PT93JU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_400448.long.128_S_1408_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_32855.long.005_S_0223_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_68563.long.098_S_0171_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_081121_RK89NK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258696.long.041_S_4037_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_91640.long.024_S_1171_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_236978.long.009_S_2381_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_203381.long.033_S_0514_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119655.long.133_S_1170_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_64876.long.029_S_0878_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_081118_EK52XB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_72821.long.116_S_1083_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120920_BS42EB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3776_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090327_PK44JK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431686.long.003_S_4354_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100628_RV78KH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091023_RX33WB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_47862.long.141_S_0340_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_371236.long.035_S_4414_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_166957.long.057_S_0839_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_81312.long.002_S_0938_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_D_A00036325_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50571_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_275494.long.137_S_0972_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_94649.long.127_S_1140_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_388311.long.002_S_5178_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_1117299_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_322407.long.130_S_4417_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_OHSU_3052540_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120525_XM37VC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_297888.long.135_S_4657_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398201.long.002_S_5230_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_369385.long.020_S_5140_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_358084.long.070_S_4856_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123908.long.057_S_0464_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_285911.long.014_S_4328_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100625_QU49EP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090723_MN72RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_92305.long.006_S_0681_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_278240.long.031_S_4042_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/COBRE_0040112_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100419_XF83TH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_466153.long.094_S_4858_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100423_RW64PB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123376.long.129_S_0778_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110502_KC87CB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_335942.long.072_S_2037_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305433.long.137_S_4631_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398205.long.003_S_4900_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100907_PG67QU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_435934.long.037_S_0377_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_74231.long.016_S_1117_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_3194757_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_73026.long.005_S_0572_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_392329.long.027_S_5079_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_95679.long.109_S_1343_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_376940.long.129_S_1246_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_NYU_10090_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100531_DV74CH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100915_EJ25HU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258670.long.023_S_4034_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100610_RR76JK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_123506.long.137_S_0800_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119174.long.053_S_0919_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_421268.long.094_S_2216_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_160894.long.114_S_0601_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_66176.long.109_S_1343_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100112_KC46FU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50471_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_349887.long.116_S_4898_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119392.long.128_S_0272_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_305464.long.002_S_4251_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3468_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_38790.long.127_S_0393_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100506_GR84UB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_248654.long.153_S_4133_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_171873.long.023_S_1190_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_39203.long.130_S_0969_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119733.long.136_S_0429_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_80415.long.094_S_1293_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_272788.long.153_S_4159_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50489_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110213_YC83QU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_94606.long.098_S_0667_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_388914.long.116_S_4855_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100422_NT84JU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50700_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_299365.long.128_S_0545_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090319_MU78QB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100915_FA38DU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_285147.long.073_S_4155_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100523_QF49EU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Pittsburgh_16046_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100227_RF77HU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_131015_UF43TC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_132247.long.016_S_1028_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_358509.long.128_S_5066_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_272764.long.072_S_4102_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120820_EG55GH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101011_ZS47TH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0416_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110131_GJ94RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100826_FF36BU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110425_BH36GB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_162460.long.032_S_0677_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_314466.long.137_S_4520_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091026_PT93KH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_296801.long.067_S_0257_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_2737106_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222783.long.021_S_2077_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_414490.long.037_S_5162_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102067.long.141_S_1152_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100208_KY77VH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_377483.long.033_S_0920_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110228_KT86UC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_49487.long.099_S_0111_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_138792.long.031_S_0830_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_326571.long.036_S_4430_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_260273.long.024_S_4084_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_272778.long.082_S_2121_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091028_TT32RH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090516_DY85BB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398331.long.041_S_4200_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223371.long.094_S_2216_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100615_PB38JU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119177.long.053_S_1044_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0368_MR2_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091013_QS27WB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_51271_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222793.long.021_S_2124_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120405_QZ74FB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119239.long.082_S_0469_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_295949.long.006_S_4546_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_120613_EN79FP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_C_A00036188_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_272800.long.035_S_4114_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_342430.long.041_S_4974_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_9002207_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100525_RS77WU_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_334110.long.005_S_1224_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_250655.long.073_S_2225_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100413_TA53SB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_140605_JB63MP_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_297865.long.131_S_0384_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100413_PB62VC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_87597.long.037_S_0377_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100902_EV55PH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_222692.long.002_S_2010_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100415_RY79BB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_297037.long.098_S_0172_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_417108.long.094_S_4089_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_102648.long.007_S_0249_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/MCIC_Site_A_A00036513_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_258717.long.072_S_4226_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_376829.long.137_S_4482_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_090606_BG34SK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_102675.long.016_S_1326_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_69492.long.057_S_1265_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110402_WE42PB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_86691.long.033_S_1086_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118685.long.002_S_0938_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_326588.long.027_S_4869_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110326_RT64SB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101014_AB76UC_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_081216_UQ55ZK_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_431631.long.067_S_4767_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_281859.long.002_S_4262_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_371905.long.126_S_4686_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_118909.long.023_S_1046_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_091205_AX69BH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_358181.long.021_S_4419_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_411357.long.037_S_4030_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_223381.long.098_S_2052_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50624_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119606.long.133_S_0771_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/OASIS_OAS1_0333_MR1_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_111229_MG85HB_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_394804.long.031_S_0618_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_118765.long.018_S_0450_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_KKI_1962503_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_63392.long.024_S_1063_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100913_CM26NH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ABIDE_50653_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_254772.long.127_S_4197_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_353877.long.027_S_4936_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_88386.long.027_S_0074_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADHD200_Peking_3672300_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_322465.long.052_S_0671_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_100221_XW78KH_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_394762.long.052_S_4885_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_3271_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_119160.long.053_S_0507_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_80672.long.100_S_1226_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_398094.long.051_S_5294_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_110207_KG37KT_FS_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_106542.long.127_S_0260_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/PPMI_4075_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-1.5T-FS-5.3-Long_119524.long.133_S_0629_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/ADNI_ADNI-3T-FS-5.3-Long_351374.long.128_S_4671_base_mri_talairach_orig.npz', '/data/ddmg/voxelmorph/data/t1_mix/proc/resize256-crop_x32/train/origs/GSP_101129_SP85HU_FS_mri_talairach_orig.npz']\n",
      "Sampling size 1 batches from 1001 files!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, loss [-0.22609183, -0.26408532, 0.0379935]\n",
      "Iter 1, loss [-0.21377166, -0.25163049, 0.037858833]\n",
      "Iter 2, loss [-0.22200379, -0.25844133, 0.03643754]\n",
      "Iter 3, loss [-0.21532628, -0.2538101, 0.038483825]\n",
      "Iter 4, loss [-0.2078653, -0.2487014, 0.0408361]\n",
      "Iter 5, loss [-0.21115392, -0.2566583, 0.04550436]\n",
      "Iter 6, loss [-0.20134342, -0.24899997, 0.047656547]\n",
      "Iter 7, loss [-0.21179242, -0.25262648, 0.04083405]\n",
      "Iter 8, loss [-0.22255135, -0.26197672, 0.039425373]\n",
      "Iter 9, loss [-0.22584291, -0.26018378, 0.034340873]\n",
      "Iter 10, loss [-0.22254509, -0.25721988, 0.034674793]\n",
      "Iter 11, loss [-0.2096554, -0.24907161, 0.03941621]\n",
      "Iter 12, loss [-0.21634585, -0.2553789, 0.039033055]\n",
      "Iter 13, loss [-0.1785507, -0.23180446, 0.05325375]\n",
      "Iter 14, loss [-0.21496022, -0.25482672, 0.039866515]\n",
      "Iter 15, loss [-0.23120248, -0.2681458, 0.036943316]\n",
      "Iter 16, loss [-0.22922026, -0.26578352, 0.036563262]\n",
      "Iter 17, loss [-0.22440614, -0.26196215, 0.037556008]\n",
      "Iter 18, loss [-0.22819817, -0.2646094, 0.036411222]\n",
      "Iter 19, loss [-0.23322365, -0.26854298, 0.035319325]\n",
      "Iter 20, loss [-0.22507714, -0.26154375, 0.03646661]\n",
      "Iter 21, loss [-0.16438058, -0.22024281, 0.055862226]\n",
      "Iter 22, loss [-0.22171976, -0.25879866, 0.037078902]\n",
      "Iter 23, loss [-0.21682233, -0.25737077, 0.040548436]\n",
      "Iter 24, loss [-0.22698586, -0.26352382, 0.03653796]\n",
      "Iter 25, loss [-0.21777956, -0.25625563, 0.03847606]\n",
      "Iter 26, loss [-0.22708414, -0.26395887, 0.036874726]\n",
      "Iter 27, loss [-0.22182024, -0.2598394, 0.038019158]\n",
      "Iter 28, loss [-0.2077899, -0.25170353, 0.043913625]\n",
      "Iter 29, loss [-0.20455217, -0.24533205, 0.04077987]\n",
      "Iter 30, loss [-0.19936937, -0.24345839, 0.04408902]\n",
      "Iter 31, loss [-0.21168083, -0.24924451, 0.03756369]\n",
      "Iter 32, loss [-0.21647182, -0.25211155, 0.035639733]\n",
      "Iter 33, loss [-0.20712174, -0.2440422, 0.036920454]\n",
      "Iter 34, loss [-0.22597545, -0.26200163, 0.03602618]\n",
      "Iter 35, loss [-0.21152921, -0.25432995, 0.042800736]\n",
      "Iter 36, loss [-0.2251789, -0.26361766, 0.038438775]\n",
      "Iter 37, loss [-0.22813746, -0.26630417, 0.0381667]\n",
      "Iter 38, loss [-0.22189553, -0.2629169, 0.041021362]\n",
      "Iter 39, loss [-0.22103529, -0.2602458, 0.03921051]\n",
      "Iter 40, loss [-0.1916184, -0.23296596, 0.04134756]\n",
      "Iter 41, loss [-0.22616324, -0.2639853, 0.037822068]\n",
      "Iter 42, loss [-0.21708623, -0.2564894, 0.03940317]\n",
      "Iter 43, loss [-0.1979838, -0.23809215, 0.04010835]\n",
      "Iter 44, loss [-0.2178966, -0.2548807, 0.0369841]\n",
      "Iter 45, loss [-0.22691756, -0.26275405, 0.035836484]\n",
      "Iter 46, loss [-0.22616088, -0.26140815, 0.03524726]\n",
      "Iter 47, loss [-0.21500893, -0.25496614, 0.03995721]\n",
      "Iter 48, loss [-0.22874196, -0.26620314, 0.037461177]\n",
      "Iter 49, loss [-0.20673102, -0.25240195, 0.045670923]\n",
      "Iter 50, loss [-0.21963915, -0.25992122, 0.040282067]\n",
      "Iter 51, loss [-0.22261268, -0.2613045, 0.03869182]\n",
      "Iter 52, loss [-0.21557802, -0.25496614, 0.039388113]\n",
      "Iter 53, loss [-0.23366395, -0.26619843, 0.032534488]\n",
      "Iter 54, loss [-0.22217777, -0.2577029, 0.035525113]\n",
      "Iter 55, loss [-0.22123298, -0.2565683, 0.03533534]\n",
      "Iter 56, loss [-0.21669403, -0.2569745, 0.040280458]\n",
      "Iter 57, loss [-0.22820395, -0.26345226, 0.035248317]\n",
      "Iter 58, loss [-0.19246168, -0.24052177, 0.04806009]\n",
      "Iter 59, loss [-0.21682975, -0.25901005, 0.042180292]\n",
      "Iter 60, loss [-0.22642821, -0.2643986, 0.037970394]\n",
      "Iter 61, loss [-0.22530466, -0.2655033, 0.04019863]\n",
      "Iter 62, loss [-0.19622746, -0.24674758, 0.050520115]\n",
      "Iter 63, loss [-0.2291101, -0.2665978, 0.037487697]\n",
      "Iter 64, loss [-0.22248676, -0.26160526, 0.0391185]\n",
      "Iter 65, loss [-0.16303018, -0.2162949, 0.05326472]\n",
      "Iter 66, loss [-0.21998432, -0.2565838, 0.036599495]\n",
      "Iter 67, loss [-0.21286461, -0.25003895, 0.03717434]\n",
      "Iter 68, loss [-0.21846138, -0.25694147, 0.038480088]\n",
      "Iter 69, loss [-0.22261782, -0.2599771, 0.037359282]\n",
      "Iter 70, loss [-0.22578642, -0.26285696, 0.037070535]\n",
      "Iter 71, loss [-0.22476566, -0.262593, 0.03782735]\n",
      "Iter 72, loss [-0.22307192, -0.26287937, 0.03980745]\n",
      "Iter 73, loss [-0.18485264, -0.23284326, 0.047990616]\n",
      "Iter 74, loss [-0.16474773, -0.22122726, 0.056479525]\n",
      "Iter 75, loss [-0.22001019, -0.25803483, 0.03802464]\n",
      "Iter 76, loss [-0.19746006, -0.23862907, 0.04116902]\n",
      "Iter 77, loss [-0.22621484, -0.26180238, 0.035587538]\n",
      "Iter 78, loss [-0.22200656, -0.2590317, 0.037025157]\n",
      "Iter 79, loss [-0.22310762, -0.26135445, 0.03824682]\n",
      "Iter 80, loss [-0.21340021, -0.24968974, 0.036289535]\n",
      "Iter 81, loss [-0.22399496, -0.26218304, 0.03818808]\n",
      "Iter 82, loss [-0.23335436, -0.26935863, 0.03600427]\n",
      "Iter 83, loss [-0.21084474, -0.2500085, 0.039163753]\n",
      "Iter 84, loss [-0.22922537, -0.26566276, 0.036437392]\n",
      "Iter 85, loss [-0.22374704, -0.26406676, 0.04031972]\n",
      "Iter 86, loss [-0.2266255, -0.26209378, 0.035468288]\n",
      "Iter 87, loss [-0.22133029, -0.25966296, 0.03833268]\n",
      "Iter 88, loss [-0.21415511, -0.25387514, 0.03972002]\n",
      "Iter 89, loss [-0.19122127, -0.23800081, 0.04677954]\n",
      "Iter 90, loss [-0.2227838, -0.26041222, 0.037628416]\n",
      "Iter 91, loss [-0.22379808, -0.2597875, 0.035989415]\n",
      "Iter 92, loss [-0.2246762, -0.2635907, 0.038914487]\n",
      "Iter 93, loss [-0.15498017, -0.21039338, 0.055413216]\n",
      "Iter 94, loss [-0.21547529, -0.25621802, 0.040742725]\n",
      "Iter 95, loss [-0.21945651, -0.25900546, 0.039548945]\n",
      "Iter 96, loss [-0.22896847, -0.26574427, 0.036775805]\n",
      "Iter 97, loss [-0.1348733, -0.19340919, 0.058535896]\n",
      "Iter 98, loss [-0.22211884, -0.26053718, 0.038418334]\n",
      "Iter 99, loss [-0.22594629, -0.2614985, 0.035552215]\n",
      "Iter 100, loss [-0.22772264, -0.26474667, 0.03702403]\n",
      "Iter 101, loss [-0.22723794, -0.2628625, 0.035624564]\n",
      "Iter 102, loss [-0.18533519, -0.23314252, 0.047807343]\n",
      "Iter 103, loss [-0.18294202, -0.23277435, 0.04983233]\n",
      "Iter 104, loss [-0.22686958, -0.2629137, 0.03604412]\n",
      "Iter 105, loss [-0.16748537, -0.2216065, 0.054121118]\n",
      "Iter 106, loss [-0.21136579, -0.2527744, 0.04140859]\n",
      "Iter 107, loss [-0.23211317, -0.2678194, 0.035706233]\n",
      "Iter 108, loss [-0.21100216, -0.2534478, 0.042445645]\n",
      "Iter 109, loss [-0.22680296, -0.2634032, 0.036600243]\n",
      "Iter 110, loss [-0.23527111, -0.270162, 0.034890875]\n",
      "Iter 111, loss [-0.22350733, -0.26079342, 0.037286084]\n",
      "Iter 112, loss [-0.22639441, -0.26326555, 0.036871135]\n",
      "Iter 113, loss [-0.22766896, -0.2632494, 0.035580438]\n",
      "Iter 114, loss [-0.19890586, -0.2409793, 0.04207345]\n",
      "Iter 115, loss [-0.2288436, -0.26596662, 0.037123017]\n",
      "Iter 116, loss [-0.23316514, -0.26915553, 0.035990395]\n",
      "Iter 117, loss [-0.2011899, -0.24339674, 0.042206835]\n",
      "Iter 118, loss [-0.22395912, -0.2620906, 0.038131468]\n",
      "Iter 119, loss [-0.22641906, -0.26458636, 0.038167298]\n",
      "Iter 120, loss [-0.2245518, -0.26048616, 0.035934355]\n",
      "Iter 121, loss [-0.20266175, -0.24534687, 0.042685118]\n",
      "Iter 122, loss [-0.2122093, -0.25278774, 0.040578436]\n",
      "Iter 123, loss [-0.22007944, -0.25855008, 0.038470637]\n",
      "Iter 124, loss [-0.22957504, -0.26671302, 0.037137993]\n",
      "Iter 125, loss [-0.22273993, -0.2625113, 0.039771385]\n",
      "Iter 126, loss [-0.21895945, -0.25898972, 0.04003027]\n",
      "Iter 127, loss [-0.22277582, -0.26107368, 0.038297858]\n",
      "Iter 128, loss [-0.21177095, -0.25120014, 0.039429195]\n",
      "Iter 129, loss [-0.21637593, -0.2561238, 0.03974788]\n",
      "Iter 130, loss [-0.21784684, -0.25763965, 0.0397928]\n",
      "Iter 131, loss [-0.15900809, -0.21479936, 0.055791274]\n",
      "Iter 132, loss [-0.188584, -0.2383831, 0.049799096]\n",
      "Iter 133, loss [-0.22681235, -0.26406735, 0.037255004]\n",
      "Iter 134, loss [-0.21153635, -0.246296, 0.034759656]\n",
      "Iter 135, loss [-0.21229938, -0.25288674, 0.040587366]\n",
      "Iter 136, loss [-0.22647116, -0.26240385, 0.035932682]\n",
      "Iter 137, loss [-0.21680215, -0.25806817, 0.04126602]\n",
      "Iter 138, loss [-0.22546281, -0.26453108, 0.039068267]\n",
      "Iter 139, loss [-0.22653782, -0.26280424, 0.03626641]\n",
      "Iter 140, loss [-0.18604942, -0.23694141, 0.050891995]\n",
      "Iter 141, loss [-0.2101443, -0.25027058, 0.040126275]\n",
      "Iter 142, loss [-0.18962894, -0.23786105, 0.04823211]\n",
      "Iter 143, loss [-0.22433282, -0.2615925, 0.037259687]\n",
      "Iter 144, loss [-0.22321732, -0.26135573, 0.038138404]\n",
      "Iter 145, loss [-0.22526313, -0.26252472, 0.037261594]\n",
      "Iter 146, loss [-0.22804376, -0.2628068, 0.03476303]\n",
      "Iter 147, loss [-0.14339992, -0.20038918, 0.056989253]\n",
      "Iter 148, loss [-0.22314279, -0.26150137, 0.038358584]\n",
      "Iter 149, loss [-0.21947372, -0.25767508, 0.038201362]\n",
      "Iter 150, loss [-0.21255335, -0.25036353, 0.03781017]\n",
      "Iter 151, loss [-0.21563509, -0.25503296, 0.039397858]\n",
      "Iter 152, loss [-0.20632458, -0.24794246, 0.041617893]\n",
      "Iter 153, loss [-0.21946838, -0.25874078, 0.039272398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 154, loss [-0.22966851, -0.26560587, 0.035937358]\n",
      "Iter 155, loss [-0.21334226, -0.2523008, 0.03895853]\n",
      "Iter 156, loss [-0.22144322, -0.26148418, 0.04004095]\n",
      "Iter 157, loss [-0.21077695, -0.24615465, 0.035377692]\n",
      "Iter 158, loss [-0.21767654, -0.25607613, 0.038399592]\n",
      "Iter 159, loss [-0.21904454, -0.25870976, 0.039665215]\n",
      "Iter 160, loss [-0.20712271, -0.24948712, 0.0423644]\n",
      "Iter 161, loss [-0.21799721, -0.25727543, 0.03927822]\n",
      "Iter 162, loss [-0.22102442, -0.25999272, 0.03896829]\n",
      "Iter 163, loss [-0.2208351, -0.25991288, 0.039077777]\n",
      "Iter 164, loss [-0.22389966, -0.26119965, 0.037299994]\n",
      "Iter 165, loss [-0.22171897, -0.26151693, 0.039797954]\n",
      "Iter 166, loss [-0.21861073, -0.25767857, 0.039067827]\n",
      "Iter 167, loss [-0.20739044, -0.246976, 0.03958556]\n",
      "Iter 168, loss [-0.21663237, -0.25476784, 0.03813547]\n",
      "Iter 169, loss [-0.21387985, -0.25137165, 0.0374918]\n",
      "Iter 170, loss [-0.21580677, -0.25517252, 0.03936575]\n",
      "Iter 171, loss [-0.22423252, -0.2605961, 0.036363572]\n",
      "Iter 172, loss [-0.22146884, -0.25934634, 0.037877496]\n",
      "Iter 173, loss [-0.21676409, -0.25567484, 0.03891075]\n",
      "Iter 174, loss [-0.22487235, -0.25946516, 0.034592815]\n",
      "Iter 175, loss [-0.21449767, -0.25408694, 0.039589267]\n",
      "Iter 176, loss [-0.21335307, -0.2534639, 0.04011082]\n",
      "Iter 177, loss [-0.22688305, -0.26270282, 0.035819776]\n",
      "Iter 178, loss [-0.22720528, -0.264202, 0.036996715]\n",
      "Iter 179, loss [-0.22454312, -0.2616733, 0.037130173]\n",
      "Iter 180, loss [-0.20690668, -0.25001216, 0.043105476]\n",
      "Iter 181, loss [-0.22342934, -0.26056066, 0.037131324]\n",
      "Iter 182, loss [-0.22487018, -0.26358742, 0.038717233]\n",
      "Iter 183, loss [-0.20871519, -0.24780656, 0.03909138]\n",
      "Iter 184, loss [-0.19451076, -0.24296796, 0.048457213]\n",
      "Iter 185, loss [-0.14281455, -0.20594895, 0.06313441]\n",
      "Iter 186, loss [-0.216669, -0.25360167, 0.036932684]\n",
      "Iter 187, loss [-0.22101787, -0.25708693, 0.036069065]\n",
      "Iter 188, loss [-0.21632822, -0.25430048, 0.037972253]\n",
      "Iter 189, loss [-0.22609144, -0.26463562, 0.038544178]\n",
      "Iter 190, loss [-0.19106728, -0.23658861, 0.04552133]\n",
      "Iter 191, loss [-0.22626339, -0.2629968, 0.036733404]\n",
      "Iter 192, loss [-0.221019, -0.2580984, 0.0370794]\n",
      "Iter 193, loss [-0.22678748, -0.26264235, 0.035854872]\n",
      "Iter 194, loss [-0.22339249, -0.2623061, 0.038913608]\n",
      "Iter 195, loss [-0.22591972, -0.26364025, 0.037720524]\n",
      "Iter 196, loss [-0.21817479, -0.25647515, 0.03830036]\n",
      "Iter 197, loss [-0.22316645, -0.2596437, 0.03647725]\n",
      "Iter 198, loss [-0.22713295, -0.26425624, 0.03712329]\n",
      "Iter 199, loss [-0.22025909, -0.25652248, 0.036263388]\n",
      "Iter 200, loss [-0.23075986, -0.26753137, 0.0367715]\n",
      "Iter 201, loss [-0.22673227, -0.26506233, 0.038330063]\n",
      "Iter 202, loss [-0.22190584, -0.26030666, 0.03840081]\n",
      "Iter 203, loss [-0.22525221, -0.26274666, 0.03749446]\n",
      "Iter 204, loss [-0.22139147, -0.25982878, 0.0384373]\n",
      "Iter 205, loss [-0.22785114, -0.26331362, 0.035462484]\n",
      "Iter 206, loss [-0.22689825, -0.26417384, 0.03727558]\n",
      "Iter 207, loss [-0.22244453, -0.25807098, 0.03562645]\n",
      "Iter 208, loss [-0.22596608, -0.26266357, 0.03669749]\n",
      "Iter 209, loss [-0.21544266, -0.25444674, 0.03900408]\n",
      "Iter 210, loss [-0.22439584, -0.2600041, 0.03560826]\n",
      "Iter 211, loss [-0.22519507, -0.26397973, 0.038784668]\n",
      "Iter 212, loss [-0.21821247, -0.25707203, 0.03885956]\n",
      "Iter 213, loss [-0.22047248, -0.2600347, 0.039562233]\n",
      "Iter 214, loss [-0.22896624, -0.26390785, 0.034941617]\n",
      "Iter 215, loss [-0.21962257, -0.26027346, 0.040650893]\n",
      "Iter 216, loss [-0.22428936, -0.26069248, 0.036403116]\n",
      "Iter 217, loss [-0.21030277, -0.25137714, 0.04107436]\n",
      "Iter 218, loss [-0.2226758, -0.26168132, 0.039005525]\n",
      "Iter 219, loss [-0.22877115, -0.26353872, 0.034767576]\n",
      "Iter 220, loss [-0.22380455, -0.26169887, 0.03789432]\n",
      "Iter 221, loss [-0.22568697, -0.2625592, 0.036872245]\n",
      "Iter 222, loss [-0.2300305, -0.26614252, 0.036112007]\n",
      "Iter 223, loss [-0.21829347, -0.25819245, 0.039898977]\n",
      "Iter 224, loss [-0.21941647, -0.26174715, 0.042330682]\n",
      "Iter 225, loss [-0.18942142, -0.23695512, 0.0475337]\n",
      "Iter 226, loss [-0.2269208, -0.26408398, 0.037163183]\n",
      "Iter 227, loss [-0.20732476, -0.24998957, 0.042664807]\n",
      "Iter 228, loss [-0.22043726, -0.25736097, 0.036923707]\n",
      "Iter 229, loss [-0.22108665, -0.26001373, 0.03892708]\n",
      "Iter 230, loss [-0.21694645, -0.25645643, 0.03950998]\n",
      "Iter 231, loss [-0.23087338, -0.26655075, 0.035677366]\n",
      "Iter 232, loss [-0.19250222, -0.23819432, 0.045692097]\n",
      "Iter 233, loss [-0.22266723, -0.25665718, 0.03398995]\n",
      "Iter 234, loss [-0.22660413, -0.26199645, 0.035392314]\n",
      "Iter 235, loss [-0.2148826, -0.25381616, 0.038933557]\n",
      "Iter 236, loss [-0.21979232, -0.2585453, 0.038752988]\n",
      "Iter 237, loss [-0.22354528, -0.2592214, 0.03567613]\n",
      "Iter 238, loss [-0.2266131, -0.26444003, 0.03782692]\n",
      "Iter 239, loss [-0.21805328, -0.25707582, 0.039022543]\n",
      "Iter 240, loss [-0.2135949, -0.25401774, 0.040422846]\n",
      "Iter 241, loss [-0.22372119, -0.26173118, 0.038009986]\n",
      "Iter 242, loss [-0.22213277, -0.2602317, 0.03809893]\n",
      "Iter 243, loss [-0.21967702, -0.25807127, 0.038394257]\n",
      "Iter 244, loss [-0.23143761, -0.26583433, 0.03439672]\n",
      "Iter 245, loss [-0.21473575, -0.25455108, 0.03981534]\n",
      "Iter 246, loss [-0.22015606, -0.25989813, 0.03974207]\n",
      "Iter 247, loss [-0.15873553, -0.22051105, 0.061775517]\n",
      "Iter 248, loss [-0.22147168, -0.26078746, 0.03931578]\n",
      "Iter 249, loss [-0.21366587, -0.25401652, 0.040350646]\n",
      "Iter 250, loss [-0.2260096, -0.2633068, 0.03729719]\n",
      "Iter 251, loss [-0.21436164, -0.25505403, 0.040692396]\n",
      "Iter 252, loss [-0.21824703, -0.2564358, 0.03818878]\n",
      "Iter 253, loss [-0.22952023, -0.2646024, 0.035082154]\n",
      "Iter 254, loss [-0.21797755, -0.2542573, 0.036279745]\n",
      "Iter 255, loss [-0.19383699, -0.23646927, 0.04263228]\n",
      "Iter 256, loss [-0.2285502, -0.26373288, 0.03518268]\n",
      "Iter 257, loss [-0.22228742, -0.26003447, 0.03774705]\n",
      "Iter 258, loss [-0.21967864, -0.25984487, 0.040166225]\n",
      "Iter 259, loss [-0.22204772, -0.2604535, 0.03840577]\n",
      "Iter 260, loss [-0.20926967, -0.24849154, 0.039221868]\n",
      "Iter 261, loss [-0.2190645, -0.25800803, 0.03894353]\n",
      "Iter 262, loss [-0.22754571, -0.2631966, 0.035650875]\n",
      "Iter 263, loss [-0.23091215, -0.26613098, 0.03521883]\n",
      "Iter 264, loss [-0.21361533, -0.25330275, 0.03968742]\n",
      "Iter 265, loss [-0.22235768, -0.25995815, 0.037600473]\n",
      "Iter 266, loss [-0.21881951, -0.2572643, 0.038444776]\n",
      "Iter 267, loss [-0.22484034, -0.2611352, 0.03629484]\n",
      "Iter 268, loss [-0.22617123, -0.26396742, 0.037796196]\n",
      "Iter 269, loss [-0.23014043, -0.26584843, 0.03570799]\n",
      "Iter 270, loss [-0.21901473, -0.25881508, 0.039800346]\n",
      "Iter 271, loss [-0.21928906, -0.25711527, 0.03782621]\n",
      "Iter 272, loss [-0.22319812, -0.262187, 0.038988885]\n",
      "Iter 273, loss [-0.22592968, -0.26248693, 0.036557265]\n",
      "Iter 274, loss [-0.20882949, -0.24868718, 0.03985768]\n",
      "Iter 275, loss [-0.23170516, -0.26562932, 0.03392417]\n",
      "Iter 276, loss [-0.21077691, -0.2541292, 0.043352287]\n",
      "Iter 277, loss [-0.21431094, -0.25197873, 0.037667774]\n",
      "Iter 278, loss [-0.22423546, -0.2623774, 0.03814195]\n",
      "Iter 279, loss [-0.21880743, -0.25969034, 0.040882915]\n",
      "Iter 280, loss [-0.21822007, -0.25816947, 0.0399494]\n",
      "Iter 281, loss [-0.22229058, -0.25980324, 0.037512656]\n",
      "Iter 282, loss [-0.22191161, -0.26056817, 0.038656555]\n",
      "Iter 283, loss [-0.22936374, -0.26529124, 0.035927508]\n",
      "Iter 284, loss [-0.22038534, -0.25970975, 0.039324403]\n",
      "Iter 285, loss [-0.22423808, -0.26149008, 0.037251994]\n",
      "Iter 286, loss [-0.22442219, -0.26062682, 0.03620464]\n",
      "Iter 287, loss [-0.22748798, -0.26296034, 0.035472363]\n",
      "Iter 288, loss [-0.21627289, -0.25894308, 0.04267019]\n",
      "Iter 289, loss [-0.22720249, -0.26434398, 0.037141487]\n",
      "Iter 290, loss [-0.21912825, -0.25841704, 0.03928878]\n",
      "Iter 291, loss [-0.2206654, -0.2582437, 0.037578322]\n",
      "Iter 292, loss [-0.2220087, -0.26077574, 0.038767036]\n",
      "Iter 293, loss [-0.22692472, -0.26386714, 0.036942415]\n",
      "Iter 294, loss [-0.2081812, -0.24787463, 0.03969343]\n",
      "Iter 295, loss [-0.22974347, -0.2653658, 0.035622343]\n",
      "Iter 296, loss [-0.22238415, -0.26107505, 0.038690895]\n",
      "Iter 297, loss [-0.20613721, -0.24633062, 0.0401934]\n",
      "Iter 298, loss [-0.22330675, -0.26117808, 0.03787133]\n",
      "Iter 299, loss [-0.21574758, -0.2563273, 0.040579725]\n",
      "Iter 300, loss [-0.21249509, -0.2527033, 0.040208213]\n",
      "Iter 301, loss [-0.22542499, -0.2624196, 0.03699462]\n",
      "Iter 302, loss [-0.23155323, -0.26660505, 0.03505182]\n",
      "Iter 303, loss [-0.16486543, -0.22136682, 0.05650139]\n",
      "Iter 304, loss [-0.17110059, -0.22412515, 0.05302456]\n",
      "Iter 305, loss [-0.15962704, -0.21510877, 0.05548173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 306, loss [-0.21668911, -0.25649512, 0.039806005]\n",
      "Iter 307, loss [-0.22227281, -0.26159894, 0.039326128]\n",
      "Iter 308, loss [-0.21507548, -0.25503606, 0.039960574]\n",
      "Iter 309, loss [-0.18823273, -0.23438011, 0.046147376]\n",
      "Iter 310, loss [-0.2223316, -0.2598259, 0.03749429]\n",
      "Iter 311, loss [-0.21402769, -0.2532486, 0.039220918]\n",
      "Iter 312, loss [-0.21654512, -0.2553223, 0.038777187]\n",
      "Iter 313, loss [-0.2058406, -0.24589197, 0.040051375]\n",
      "Iter 314, loss [-0.19833173, -0.241115, 0.04278327]\n",
      "Iter 315, loss [-0.23041052, -0.26618582, 0.035775296]\n",
      "Iter 316, loss [-0.2045076, -0.24772261, 0.043215003]\n",
      "Iter 317, loss [-0.22828275, -0.26530275, 0.03701999]\n",
      "Iter 318, loss [-0.22789581, -0.26554716, 0.03765135]\n",
      "Iter 319, loss [-0.22964941, -0.26775163, 0.03810222]\n",
      "Iter 320, loss [-0.20963491, -0.25381762, 0.0441827]\n",
      "Iter 321, loss [-0.22215357, -0.26090753, 0.038753957]\n",
      "Iter 322, loss [-0.22065288, -0.25773647, 0.037083596]\n",
      "Iter 323, loss [-0.19820195, -0.23555264, 0.037350684]\n",
      "Iter 324, loss [-0.2209433, -0.25959843, 0.038655125]\n",
      "Iter 325, loss [-0.21932906, -0.2557689, 0.036439836]\n",
      "Iter 326, loss [-0.21744126, -0.2549246, 0.037483335]\n",
      "Iter 327, loss [-0.21502973, -0.25324628, 0.038216546]\n",
      "Iter 328, loss [-0.2247733, -0.26250553, 0.037732232]\n",
      "Iter 329, loss [-0.225672, -0.26308024, 0.03740824]\n",
      "Iter 330, loss [-0.21701655, -0.25530237, 0.038285818]\n",
      "Iter 331, loss [-0.1410229, -0.19589916, 0.054876253]\n",
      "Iter 332, loss [-0.19550191, -0.23878169, 0.04327978]\n",
      "Iter 333, loss [-0.14426523, -0.20396955, 0.059704326]\n",
      "Iter 334, loss [-0.21896413, -0.2585034, 0.039539278]\n",
      "Iter 335, loss [-0.22972038, -0.26544857, 0.035728194]\n",
      "Iter 336, loss [-0.22485141, -0.262971, 0.038119595]\n",
      "Iter 337, loss [-0.22232679, -0.26070267, 0.038375877]\n",
      "Iter 338, loss [-0.22049007, -0.25779364, 0.037303574]\n",
      "Iter 339, loss [-0.21892002, -0.25976917, 0.040849146]\n",
      "Iter 340, loss [-0.21699505, -0.2561276, 0.03913255]\n",
      "Iter 341, loss [-0.2237192, -0.26017192, 0.036452726]\n",
      "Iter 342, loss [-0.2192778, -0.2579364, 0.038658597]\n",
      "Iter 343, loss [-0.22574963, -0.2624882, 0.03673856]\n",
      "Iter 344, loss [-0.22590768, -0.26394698, 0.038039297]\n",
      "Iter 345, loss [-0.21700558, -0.25435564, 0.037350055]\n",
      "Iter 346, loss [-0.21946597, -0.25826424, 0.03879828]\n",
      "Iter 347, loss [-0.22127636, -0.25961548, 0.03833912]\n",
      "Iter 348, loss [-0.22640693, -0.26177558, 0.03536866]\n",
      "Iter 349, loss [-0.2183489, -0.25812182, 0.039772913]\n",
      "Iter 350, loss [-0.22358277, -0.26116735, 0.03758458]\n",
      "Iter 351, loss [-0.2228871, -0.25866148, 0.035774387]\n",
      "Iter 352, loss [-0.21194394, -0.2511822, 0.03923826]\n",
      "Iter 353, loss [-0.2195826, -0.260186, 0.040603384]\n",
      "Iter 354, loss [-0.18360412, -0.23641394, 0.052809816]\n",
      "Iter 355, loss [-0.18766183, -0.2360231, 0.04836127]\n",
      "Iter 356, loss [-0.2183173, -0.25743103, 0.039113738]\n",
      "Iter 357, loss [-0.21835493, -0.25760695, 0.039252024]\n",
      "Iter 358, loss [-0.21632564, -0.25278652, 0.036460884]\n",
      "Iter 359, loss [-0.21655566, -0.25486398, 0.038308322]\n",
      "Iter 360, loss [-0.2183199, -0.25799862, 0.039678715]\n",
      "Iter 361, loss [-0.21982265, -0.2576486, 0.03782595]\n",
      "Iter 362, loss [-0.2160455, -0.25485474, 0.03880924]\n",
      "Iter 363, loss [-0.18942434, -0.23622197, 0.046797626]\n",
      "Iter 364, loss [-0.23028895, -0.26645163, 0.036162674]\n",
      "Iter 365, loss [-0.21392785, -0.25227144, 0.038343597]\n",
      "Iter 366, loss [-0.22563899, -0.26475766, 0.039118677]\n",
      "Iter 367, loss [-0.22668697, -0.2668067, 0.04011972]\n",
      "Iter 368, loss [-0.23320587, -0.26931202, 0.036106154]\n",
      "Iter 369, loss [-0.23163223, -0.26797336, 0.03634114]\n",
      "Iter 370, loss [-0.2249367, -0.2643196, 0.039382912]\n",
      "Iter 371, loss [-0.22481988, -0.26205587, 0.03723599]\n",
      "Iter 372, loss [-0.21702054, -0.25654545, 0.039524913]\n",
      "Iter 373, loss [-0.13397005, -0.19206432, 0.05809426]\n",
      "Iter 374, loss [-0.22186914, -0.25844452, 0.036575377]\n",
      "Iter 375, loss [-0.21789548, -0.25780523, 0.039909758]\n",
      "Iter 376, loss [-0.2280963, -0.26422453, 0.03612823]\n",
      "Iter 377, loss [-0.2191878, -0.25701734, 0.037829544]\n",
      "Iter 378, loss [-0.1939834, -0.23994443, 0.045961015]\n",
      "Iter 379, loss [-0.22544141, -0.26137024, 0.035928827]\n",
      "Iter 380, loss [-0.21999447, -0.254921, 0.034926515]\n",
      "Iter 381, loss [-0.21081938, -0.25110748, 0.040288106]\n",
      "Iter 382, loss [-0.2273508, -0.26400536, 0.03665456]\n",
      "Iter 383, loss [-0.21902966, -0.2598826, 0.040852934]\n",
      "Iter 384, loss [-0.22226268, -0.25860447, 0.03634178]\n",
      "Iter 385, loss [-0.20770185, -0.2504427, 0.042740867]\n",
      "Iter 386, loss [-0.22400163, -0.26030228, 0.036300644]\n",
      "Iter 387, loss [-0.22727156, -0.26368418, 0.036412627]\n",
      "Iter 388, loss [-0.21738046, -0.25645918, 0.03907871]\n",
      "Iter 389, loss [-0.21797594, -0.25901103, 0.04103508]\n",
      "Iter 390, loss [-0.21689266, -0.256142, 0.03924933]\n",
      "Iter 391, loss [-0.19940016, -0.24350889, 0.04410873]\n",
      "Iter 392, loss [-0.22194776, -0.25752994, 0.035582185]\n",
      "Iter 393, loss [-0.2243061, -0.26439148, 0.04008537]\n",
      "Iter 394, loss [-0.22914097, -0.2648195, 0.035678532]\n",
      "Iter 395, loss [-0.22420532, -0.26153785, 0.037332527]\n",
      "Iter 396, loss [-0.21966437, -0.25970697, 0.040042616]\n",
      "Iter 397, loss [-0.22992346, -0.2660376, 0.036114153]\n",
      "Iter 398, loss [-0.21788178, -0.25700808, 0.03912629]\n",
      "Iter 399, loss [-0.21836537, -0.25758, 0.03921465]\n",
      "Iter 400, loss [-0.21930411, -0.25766957, 0.03836546]\n",
      "Iter 401, loss [-0.2180452, -0.25705233, 0.039007124]\n",
      "Iter 402, loss [-0.22976893, -0.26523954, 0.035470597]\n",
      "Iter 403, loss [-0.2229722, -0.26094165, 0.037969455]\n",
      "Iter 404, loss [-0.22894955, -0.26617873, 0.03722918]\n",
      "Iter 405, loss [-0.22335534, -0.26152194, 0.038166594]\n",
      "Iter 406, loss [-0.22055322, -0.2595879, 0.039034687]\n",
      "Iter 407, loss [-0.2264549, -0.26463303, 0.038178127]\n",
      "Iter 408, loss [-0.22371857, -0.26095018, 0.037231605]\n",
      "Iter 409, loss [-0.21222372, -0.24971797, 0.03749424]\n",
      "Iter 410, loss [-0.20475912, -0.24621654, 0.04145742]\n",
      "Iter 411, loss [-0.22102898, -0.258858, 0.03782902]\n",
      "Iter 412, loss [-0.22967273, -0.26412144, 0.034448717]\n",
      "Iter 413, loss [-0.2101214, -0.2503358, 0.040214412]\n",
      "Iter 414, loss [-0.19409783, -0.23526032, 0.04116249]\n",
      "Iter 415, loss [-0.22294053, -0.26003906, 0.03709852]\n",
      "Iter 416, loss [-0.23326474, -0.26679674, 0.033531994]\n",
      "Iter 417, loss [-0.21145883, -0.25118583, 0.039727002]\n",
      "Iter 418, loss [-0.21875155, -0.25809774, 0.03934619]\n",
      "Iter 419, loss [-0.21188566, -0.25254053, 0.040654875]\n",
      "Iter 420, loss [-0.22884127, -0.26636538, 0.03752411]\n",
      "Iter 421, loss [-0.21591936, -0.25663042, 0.04071106]\n",
      "Iter 422, loss [-0.22172794, -0.26135507, 0.039627135]\n",
      "Iter 423, loss [-0.2262512, -0.26209104, 0.03583984]\n",
      "Iter 424, loss [-0.22757065, -0.26462957, 0.037058927]\n",
      "Iter 425, loss [-0.22714597, -0.26360154, 0.036455564]\n",
      "Iter 426, loss [-0.21828784, -0.25493827, 0.03665043]\n",
      "Iter 427, loss [-0.22679934, -0.26362935, 0.036830015]\n",
      "Iter 428, loss [-0.21821971, -0.25693178, 0.03871207]\n",
      "Iter 429, loss [-0.21553306, -0.2537001, 0.03816704]\n",
      "Iter 430, loss [-0.22374249, -0.26014543, 0.03640294]\n",
      "Iter 431, loss [-0.22371441, -0.26416078, 0.04044638]\n",
      "Iter 432, loss [-0.22939548, -0.26708707, 0.037691597]\n",
      "Iter 433, loss [-0.22442457, -0.26269805, 0.03827348]\n",
      "Iter 434, loss [-0.16588543, -0.22206421, 0.05617878]\n",
      "Iter 435, loss [-0.22089227, -0.25493726, 0.034044996]\n",
      "Iter 436, loss [-0.20687501, -0.24536116, 0.038486153]\n",
      "Iter 437, loss [-0.23262142, -0.26748118, 0.03485976]\n",
      "Iter 438, loss [-0.22129284, -0.25926384, 0.037971005]\n",
      "Iter 439, loss [-0.21110149, -0.25092286, 0.039821368]\n",
      "Iter 440, loss [-0.22831528, -0.26370397, 0.035388693]\n",
      "Iter 441, loss [-0.23092902, -0.26626456, 0.03533555]\n",
      "Iter 442, loss [-0.21554707, -0.25434455, 0.038797483]\n",
      "Iter 443, loss [-0.22050351, -0.25798535, 0.037481844]\n",
      "Iter 444, loss [-0.22124358, -0.2581886, 0.036945026]\n",
      "Iter 445, loss [-0.22090678, -0.25867808, 0.0377713]\n",
      "Iter 446, loss [-0.2071085, -0.24831761, 0.041209113]\n",
      "Iter 447, loss [-0.21475905, -0.2532704, 0.03851133]\n",
      "Iter 448, loss [-0.2161938, -0.25490886, 0.038715072]\n",
      "Iter 449, loss [-0.21902822, -0.2600482, 0.04101999]\n",
      "Iter 450, loss [-0.21660957, -0.256271, 0.039661437]\n",
      "Iter 451, loss [-0.16556413, -0.22141281, 0.055848673]\n",
      "Iter 452, loss [-0.2160714, -0.25573075, 0.03965936]\n",
      "Iter 453, loss [-0.22227785, -0.26027116, 0.037993312]\n",
      "Iter 454, loss [-0.222924, -0.2589004, 0.035976402]\n",
      "Iter 455, loss [-0.22891042, -0.26443532, 0.035524905]\n",
      "Iter 456, loss [-0.22613068, -0.26098937, 0.03485869]\n",
      "Iter 457, loss [-0.21798831, -0.25746965, 0.03948134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 458, loss [-0.22924574, -0.26605102, 0.03680529]\n",
      "Iter 459, loss [-0.21567436, -0.25594634, 0.04027198]\n",
      "Iter 460, loss [-0.22074686, -0.2608568, 0.040109947]\n",
      "Iter 461, loss [-0.20212612, -0.24654536, 0.044419236]\n",
      "Iter 462, loss [-0.21297917, -0.2541112, 0.041132025]\n",
      "Iter 463, loss [-0.2210914, -0.25926918, 0.03817777]\n",
      "Iter 464, loss [-0.22878906, -0.26412678, 0.03533772]\n",
      "Iter 465, loss [-0.22222146, -0.25860193, 0.036380462]\n",
      "Iter 466, loss [-0.22127914, -0.2590154, 0.03773626]\n",
      "Iter 467, loss [-0.20915984, -0.24967392, 0.040514078]\n",
      "Iter 468, loss [-0.2225255, -0.25792634, 0.035400838]\n",
      "Iter 469, loss [-0.22846928, -0.2656736, 0.037204318]\n",
      "Iter 470, loss [-0.23336214, -0.26987842, 0.03651627]\n",
      "Iter 471, loss [-0.21512243, -0.255139, 0.040016558]\n",
      "Iter 472, loss [-0.21920094, -0.2594676, 0.040266655]\n",
      "Iter 473, loss [-0.22322771, -0.26270244, 0.039474733]\n",
      "Iter 474, loss [-0.22833274, -0.264713, 0.036380243]\n",
      "Iter 475, loss [-0.22811443, -0.26441467, 0.03630024]\n",
      "Iter 476, loss [-0.21638432, -0.25544944, 0.039065123]\n",
      "Iter 477, loss [-0.2286478, -0.26607367, 0.03742588]\n",
      "Iter 478, loss [-0.20824727, -0.25046068, 0.042213406]\n",
      "Iter 479, loss [-0.2270129, -0.2650163, 0.03800338]\n",
      "Iter 480, loss [-0.2170893, -0.25571504, 0.038625743]\n",
      "Iter 481, loss [-0.17698237, -0.22701645, 0.05003407]\n",
      "Iter 482, loss [-0.14600876, -0.20411307, 0.058104303]\n",
      "Iter 483, loss [-0.22729912, -0.26326638, 0.035967268]\n",
      "Iter 484, loss [-0.22261423, -0.26012614, 0.037511908]\n",
      "Iter 485, loss [-0.21949, -0.25818446, 0.038694456]\n",
      "Iter 486, loss [-0.2280602, -0.26400477, 0.035944566]\n",
      "Iter 487, loss [-0.2184833, -0.25822362, 0.03974033]\n",
      "Iter 488, loss [-0.22568437, -0.26289836, 0.03721398]\n",
      "Iter 489, loss [-0.21528722, -0.2552953, 0.040008083]\n",
      "Iter 490, loss [-0.22575925, -0.26266167, 0.036902413]\n",
      "Iter 491, loss [-0.21843591, -0.25729153, 0.038855605]\n",
      "Iter 492, loss [-0.2296508, -0.26462865, 0.03497786]\n",
      "Iter 493, loss [-0.2314159, -0.269249, 0.0378331]\n",
      "Iter 494, loss [-0.22361326, -0.2609861, 0.037372828]\n",
      "Iter 495, loss [-0.23184091, -0.26948133, 0.037640415]\n",
      "Iter 496, loss [-0.23071721, -0.2649224, 0.03420519]\n",
      "Iter 497, loss [-0.22284639, -0.2613542, 0.038507827]\n",
      "Iter 498, loss [-0.22941217, -0.265674, 0.036261827]\n",
      "Iter 499, loss [-0.22110233, -0.25929812, 0.03819579]\n",
      "Iter 500, loss [-0.2229238, -0.25843516, 0.035511363]\n",
      "Iter 501, loss [-0.22684017, -0.26292136, 0.036081187]\n",
      "Iter 502, loss [-0.2168992, -0.25718525, 0.04028605]\n",
      "Iter 503, loss [-0.23460263, -0.27068433, 0.036081694]\n",
      "Iter 504, loss [-0.22227278, -0.26171073, 0.03943795]\n",
      "Iter 505, loss [-0.21021701, -0.25087953, 0.040662512]\n",
      "Iter 506, loss [-0.21380857, -0.2525922, 0.038783636]\n",
      "Iter 507, loss [-0.19005871, -0.23704262, 0.04698392]\n",
      "Iter 508, loss [-0.22522223, -0.2623679, 0.037145674]\n",
      "Iter 509, loss [-0.20801313, -0.24925403, 0.0412409]\n",
      "Iter 510, loss [-0.2315174, -0.2661108, 0.03459341]\n",
      "Iter 511, loss [-0.21532403, -0.25569156, 0.04036753]\n",
      "Iter 512, loss [-0.22652242, -0.26416662, 0.037644204]\n",
      "Iter 513, loss [-0.22384334, -0.26221588, 0.038372546]\n",
      "Iter 514, loss [-0.21553531, -0.2560291, 0.040493786]\n",
      "Iter 515, loss [-0.22042772, -0.25847352, 0.038045786]\n",
      "Iter 516, loss [-0.21991776, -0.2585113, 0.038593546]\n",
      "Iter 517, loss [-0.23015556, -0.26654986, 0.036394298]\n",
      "Iter 518, loss [-0.15718156, -0.21620554, 0.059023976]\n",
      "Iter 519, loss [-0.22548836, -0.26056755, 0.03507919]\n",
      "Iter 520, loss [-0.22239849, -0.26139015, 0.038991667]\n",
      "Iter 521, loss [-0.2070671, -0.24908546, 0.042018354]\n",
      "Iter 522, loss [-0.20533526, -0.24690217, 0.0415669]\n",
      "Iter 523, loss [-0.22229049, -0.26036277, 0.038072284]\n",
      "Iter 524, loss [-0.22599757, -0.26295385, 0.03695628]\n",
      "Iter 525, loss [-0.21610329, -0.2555448, 0.039441522]\n",
      "Iter 526, loss [-0.22338858, -0.26213488, 0.038746297]\n",
      "Iter 527, loss [-0.21975711, -0.25792003, 0.038162924]\n",
      "Iter 528, loss [-0.22440237, -0.26103693, 0.03663457]\n",
      "Iter 529, loss [-0.21607226, -0.25633794, 0.04026568]\n",
      "Iter 530, loss [-0.2197923, -0.25865757, 0.038865272]\n",
      "Iter 531, loss [-0.21394327, -0.25363493, 0.039691664]\n",
      "Iter 532, loss [-0.22683431, -0.2635718, 0.036737487]\n",
      "Iter 533, loss [-0.2213891, -0.2604687, 0.03907959]\n",
      "Iter 534, loss [-0.20977262, -0.24890375, 0.039131142]\n",
      "Iter 535, loss [-0.22705069, -0.26414585, 0.037095167]\n",
      "Iter 536, loss [-0.22142394, -0.25845316, 0.03702922]\n",
      "Iter 537, loss [-0.20910873, -0.2515592, 0.042450473]\n",
      "Iter 538, loss [-0.22961606, -0.26502198, 0.035405923]\n",
      "Iter 539, loss [-0.22612143, -0.26220307, 0.03608165]\n",
      "Iter 540, loss [-0.2230041, -0.26055527, 0.037551172]\n",
      "Iter 541, loss [-0.21858445, -0.2568903, 0.038305845]\n",
      "Iter 542, loss [-0.21404234, -0.25153628, 0.03749395]\n",
      "Iter 543, loss [-0.230054, -0.2671059, 0.0370519]\n",
      "Iter 544, loss [-0.22507694, -0.26311377, 0.03803682]\n",
      "Iter 545, loss [-0.22216891, -0.26097715, 0.038808238]\n",
      "Iter 546, loss [-0.21071164, -0.24751006, 0.036798414]\n",
      "Iter 547, loss [-0.22148241, -0.26007524, 0.038592827]\n",
      "Iter 548, loss [-0.22672708, -0.26247138, 0.035744295]\n",
      "Iter 549, loss [-0.22324978, -0.25919297, 0.035943195]\n",
      "Iter 550, loss [-0.23057687, -0.26452222, 0.03394536]\n",
      "Iter 551, loss [-0.22787185, -0.263367, 0.035495147]\n",
      "Iter 552, loss [-0.22240344, -0.26090583, 0.038502403]\n",
      "Iter 553, loss [-0.22822541, -0.26486242, 0.036637016]\n",
      "Iter 554, loss [-0.19423085, -0.24219835, 0.047967486]\n",
      "Iter 555, loss [-0.21396294, -0.254378, 0.040415045]\n",
      "Iter 556, loss [-0.22451523, -0.2613403, 0.03682506]\n",
      "Iter 557, loss [-0.22574814, -0.26308373, 0.037335586]\n",
      "Iter 558, loss [-0.21887337, -0.25779077, 0.038917407]\n",
      "Iter 559, loss [-0.22183332, -0.25967047, 0.03783714]\n",
      "Iter 560, loss [-0.22115214, -0.2596066, 0.038454454]\n",
      "Iter 561, loss [-0.2152621, -0.25237304, 0.03711094]\n",
      "Iter 562, loss [-0.2146801, -0.2521454, 0.037465304]\n",
      "Iter 563, loss [-0.21268582, -0.25296178, 0.04027597]\n",
      "Iter 564, loss [-0.20078218, -0.2444557, 0.043673523]\n",
      "Iter 565, loss [-0.22070852, -0.25889587, 0.038187362]\n",
      "Iter 566, loss [-0.22165473, -0.25936812, 0.03771339]\n",
      "Iter 567, loss [-0.19795549, -0.24242193, 0.04446643]\n",
      "Iter 568, loss [-0.21922845, -0.25680274, 0.03757429]\n",
      "Iter 569, loss [-0.22719526, -0.2629314, 0.035736144]\n",
      "Iter 570, loss [-0.22964078, -0.26445103, 0.034810252]\n",
      "Iter 571, loss [-0.12849, -0.1856071, 0.057117097]\n",
      "Iter 572, loss [-0.22460571, -0.2624777, 0.037871987]\n",
      "Iter 573, loss [-0.22238608, -0.26024094, 0.03785486]\n",
      "Iter 574, loss [-0.21276681, -0.25412956, 0.041362748]\n",
      "Iter 575, loss [-0.22007123, -0.26103565, 0.040964417]\n",
      "Iter 576, loss [-0.22596003, -0.2641819, 0.038221885]\n",
      "Iter 577, loss [-0.22481957, -0.2619683, 0.03714874]\n",
      "Iter 578, loss [-0.21699148, -0.25627276, 0.039281286]\n",
      "Iter 579, loss [-0.22891814, -0.26523224, 0.0363141]\n",
      "Iter 580, loss [-0.22541152, -0.2611481, 0.035736572]\n",
      "Iter 581, loss [-0.20623764, -0.24594596, 0.03970832]\n",
      "Iter 582, loss [-0.22724566, -0.2637856, 0.036539935]\n",
      "Iter 583, loss [-0.22585844, -0.2627109, 0.036852464]\n",
      "Iter 584, loss [-0.14353558, -0.198891, 0.055355422]\n",
      "Iter 585, loss [-0.13953137, -0.19888373, 0.05935235]\n",
      "Iter 586, loss [-0.2090525, -0.2517125, 0.042660005]\n",
      "Iter 587, loss [-0.21893433, -0.25980133, 0.040866997]\n",
      "Iter 588, loss [-0.18627012, -0.24093883, 0.054668702]\n",
      "Iter 589, loss [-0.21622902, -0.2552704, 0.039041366]\n",
      "Iter 590, loss [-0.21307904, -0.25062177, 0.03754273]\n",
      "Iter 591, loss [-0.21227917, -0.25051278, 0.03823361]\n",
      "Iter 592, loss [-0.17264995, -0.22550443, 0.05285448]\n",
      "Iter 593, loss [-0.15611371, -0.21423042, 0.0581167]\n",
      "Iter 594, loss [-0.22233093, -0.26157498, 0.039244052]\n",
      "Iter 595, loss [-0.2235805, -0.26147386, 0.037893374]\n",
      "Iter 596, loss [-0.22218078, -0.261023, 0.03884224]\n",
      "Iter 597, loss [-0.22579257, -0.2645473, 0.038754717]\n",
      "Iter 598, loss [-0.2260157, -0.2632852, 0.037269488]\n",
      "Iter 599, loss [-0.20754859, -0.24826439, 0.040715806]\n",
      "Iter 600, loss [-0.22191978, -0.25771624, 0.035796456]\n",
      "Iter 601, loss [-0.20498209, -0.24518982, 0.040207725]\n",
      "Iter 602, loss [-0.2134347, -0.251139, 0.037704296]\n",
      "Iter 603, loss [-0.22394358, -0.2613855, 0.03744192]\n",
      "Iter 604, loss [-0.18752316, -0.23243135, 0.04490819]\n",
      "Iter 605, loss [-0.2157674, -0.25533852, 0.03957112]\n",
      "Iter 606, loss [-0.22551255, -0.26261315, 0.037100594]\n",
      "Iter 607, loss [-0.21482098, -0.25189587, 0.037074894]\n",
      "Iter 608, loss [-0.21250108, -0.25363728, 0.041136198]\n",
      "Iter 609, loss [-0.22818226, -0.2635263, 0.035344042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 610, loss [-0.22228144, -0.2593171, 0.03703566]\n",
      "Iter 611, loss [-0.21353944, -0.25097188, 0.037432447]\n",
      "Iter 612, loss [-0.21884036, -0.2574577, 0.03861734]\n",
      "Iter 613, loss [-0.22125341, -0.261166, 0.039912593]\n",
      "Iter 614, loss [-0.22915302, -0.2655108, 0.03635777]\n",
      "Iter 615, loss [-0.22938071, -0.2662904, 0.036909685]\n",
      "Iter 616, loss [-0.1459207, -0.2051613, 0.059240617]\n",
      "Iter 617, loss [-0.21727294, -0.25606307, 0.038790133]\n",
      "Iter 618, loss [-0.2114676, -0.2520244, 0.04055682]\n",
      "Iter 619, loss [-0.21813664, -0.2553075, 0.037170865]\n",
      "Iter 620, loss [-0.22611333, -0.26350182, 0.03738849]\n",
      "Iter 621, loss [-0.226235, -0.26435417, 0.038119167]\n",
      "Iter 622, loss [-0.21285924, -0.25444558, 0.041586332]\n",
      "Iter 623, loss [-0.22240953, -0.26147556, 0.039066028]\n",
      "Iter 624, loss [-0.22272247, -0.2631563, 0.040433824]\n",
      "Iter 625, loss [-0.21960779, -0.25803685, 0.03842907]\n",
      "Iter 626, loss [-0.22561516, -0.2625272, 0.036912035]\n",
      "Iter 627, loss [-0.17799667, -0.22811243, 0.05011576]\n",
      "Iter 628, loss [-0.210038, -0.24800368, 0.03796567]\n",
      "Iter 629, loss [-0.20925036, -0.24910638, 0.039856017]\n",
      "Iter 630, loss [-0.22333682, -0.26028612, 0.036949307]\n",
      "Iter 631, loss [-0.19537309, -0.24167672, 0.046303622]\n",
      "Iter 632, loss [-0.22161505, -0.26155293, 0.03993788]\n",
      "Iter 633, loss [-0.21734226, -0.25794742, 0.040605158]\n",
      "Iter 634, loss [-0.20722032, -0.2466298, 0.039409496]\n",
      "Iter 635, loss [-0.21884426, -0.2573839, 0.038539648]\n",
      "Iter 636, loss [-0.22550173, -0.26575875, 0.04025702]\n",
      "Iter 637, loss [-0.21755448, -0.25497568, 0.0374212]\n",
      "Iter 638, loss [-0.2165668, -0.25295845, 0.03639165]\n",
      "Iter 639, loss [-0.21377347, -0.2546374, 0.040863916]\n",
      "Iter 640, loss [-0.21955384, -0.25853497, 0.03898112]\n",
      "Iter 641, loss [-0.12819713, -0.18842448, 0.060227357]\n",
      "Iter 642, loss [-0.22673091, -0.26197523, 0.03524432]\n",
      "Iter 643, loss [-0.22159383, -0.25890094, 0.037307106]\n",
      "Iter 644, loss [-0.21513471, -0.25552443, 0.04038971]\n",
      "Iter 645, loss [-0.21639876, -0.25645867, 0.040059913]\n",
      "Iter 646, loss [-0.21896273, -0.25486478, 0.03590205]\n",
      "Iter 647, loss [-0.22956313, -0.26565924, 0.03609611]\n",
      "Iter 648, loss [-0.22994119, -0.26573622, 0.035795026]\n",
      "Iter 649, loss [-0.23059872, -0.26639825, 0.03579954]\n",
      "Iter 650, loss [-0.22314532, -0.26202813, 0.038882807]\n",
      "Iter 651, loss [-0.19436955, -0.24085958, 0.046490036]\n",
      "Iter 652, loss [-0.22763805, -0.2674827, 0.039844647]\n",
      "Iter 653, loss [-0.22029695, -0.25914976, 0.038852807]\n",
      "Iter 654, loss [-0.21828723, -0.25851098, 0.040223755]\n",
      "Iter 655, loss [-0.22927521, -0.26627085, 0.03699563]\n",
      "Iter 656, loss [-0.22379504, -0.2610366, 0.03724156]\n",
      "Iter 657, loss [-0.22057252, -0.2577756, 0.03720309]\n",
      "Iter 658, loss [-0.22674173, -0.26365384, 0.036912106]\n",
      "Iter 659, loss [-0.22414729, -0.26008642, 0.035939135]\n",
      "Iter 660, loss [-0.22677024, -0.26406783, 0.03729759]\n",
      "Iter 661, loss [-0.22262523, -0.26183537, 0.039210144]\n",
      "Iter 662, loss [-0.21737455, -0.25805104, 0.040676486]\n",
      "Iter 663, loss [-0.20728865, -0.25091493, 0.04362628]\n",
      "Iter 664, loss [-0.22636348, -0.26393363, 0.037570156]\n",
      "Iter 665, loss [-0.21829386, -0.2571218, 0.03882794]\n",
      "Iter 666, loss [-0.21929395, -0.25744718, 0.03815324]\n",
      "Iter 667, loss [-0.16935971, -0.21953408, 0.05017437]\n",
      "Iter 668, loss [-0.22767925, -0.26395148, 0.036272235]\n",
      "Iter 669, loss [-0.23200804, -0.26619452, 0.03418648]\n",
      "Iter 670, loss [-0.15708995, -0.21364701, 0.05655706]\n",
      "Iter 671, loss [-0.21995762, -0.2592451, 0.03928747]\n",
      "Iter 672, loss [-0.2103519, -0.2528851, 0.042533204]\n",
      "Iter 673, loss [-0.22313067, -0.26002872, 0.03689805]\n",
      "Iter 674, loss [-0.17682783, -0.22676937, 0.049941536]\n",
      "Iter 675, loss [-0.2197989, -0.25849098, 0.038692083]\n",
      "Iter 676, loss [-0.22848466, -0.26322526, 0.034740604]\n",
      "Iter 677, loss [-0.16375116, -0.22139102, 0.05763986]\n",
      "Iter 678, loss [-0.22311398, -0.26201284, 0.03889886]\n",
      "Iter 679, loss [-0.21785653, -0.25592506, 0.03806854]\n",
      "Iter 680, loss [-0.21504997, -0.25559124, 0.040541273]\n",
      "Iter 681, loss [-0.22410157, -0.2626245, 0.038522936]\n",
      "Iter 682, loss [-0.22757581, -0.26562813, 0.03805232]\n",
      "Iter 683, loss [-0.22721076, -0.26273414, 0.03552338]\n",
      "Iter 684, loss [-0.22418596, -0.26182073, 0.03763477]\n",
      "Iter 685, loss [-0.21704261, -0.257111, 0.0400684]\n",
      "Iter 686, loss [-0.22235626, -0.26290774, 0.040551484]\n",
      "Iter 687, loss [-0.22431411, -0.2623779, 0.03806378]\n",
      "Iter 688, loss [-0.22415021, -0.26196066, 0.037810445]\n",
      "Iter 689, loss [-0.22685483, -0.26400232, 0.037147492]\n",
      "Iter 690, loss [-0.22698262, -0.26357868, 0.036596067]\n",
      "Iter 691, loss [-0.23116659, -0.26587054, 0.03470395]\n",
      "Iter 692, loss [-0.21942994, -0.25713933, 0.037709393]\n",
      "Iter 693, loss [-0.21801837, -0.25613537, 0.03811701]\n",
      "Iter 694, loss [-0.22600073, -0.26088488, 0.034884155]\n",
      "Iter 695, loss [-0.20428142, -0.25147587, 0.04719445]\n",
      "Iter 696, loss [-0.2202537, -0.25753796, 0.037284255]\n",
      "Iter 697, loss [-0.21878573, -0.25894284, 0.040157117]\n",
      "Iter 698, loss [-0.22243161, -0.25836864, 0.035937022]\n",
      "Iter 699, loss [-0.22381459, -0.2612778, 0.037463203]\n",
      "Iter 700, loss [-0.22480309, -0.2622212, 0.037418094]\n",
      "Iter 701, loss [-0.22725166, -0.26427612, 0.037024453]\n",
      "Iter 702, loss [-0.1970781, -0.24063891, 0.043560814]\n",
      "Iter 703, loss [-0.2120581, -0.25314808, 0.04108998]\n",
      "Iter 704, loss [-0.22771323, -0.26463926, 0.03692604]\n",
      "Iter 705, loss [-0.2194084, -0.2578116, 0.038403213]\n",
      "Iter 706, loss [-0.20579174, -0.2436291, 0.037837356]\n",
      "Iter 707, loss [-0.2207487, -0.25730497, 0.036556266]\n",
      "Iter 708, loss [-0.21907136, -0.25754508, 0.038473718]\n",
      "Iter 709, loss [-0.2270579, -0.26581064, 0.038752727]\n",
      "Iter 710, loss [-0.22052099, -0.2566421, 0.036121115]\n",
      "Iter 711, loss [-0.21200094, -0.2542296, 0.04222867]\n",
      "Iter 712, loss [-0.22930232, -0.2677998, 0.038497478]\n",
      "Iter 713, loss [-0.20237279, -0.24398519, 0.041612398]\n",
      "Iter 714, loss [-0.2280077, -0.2649213, 0.036913604]\n",
      "Iter 715, loss [-0.21432534, -0.25296387, 0.03863854]\n",
      "Iter 716, loss [-0.22943845, -0.26579177, 0.036353312]\n",
      "Iter 717, loss [-0.20701988, -0.24744116, 0.040421277]\n",
      "Iter 718, loss [-0.22208144, -0.25868726, 0.03660582]\n",
      "Iter 719, loss [-0.22628704, -0.26311803, 0.036831]\n",
      "Iter 720, loss [-0.22880785, -0.26518485, 0.036376998]\n",
      "Iter 721, loss [-0.21258976, -0.24774852, 0.03515877]\n",
      "Iter 722, loss [-0.22494292, -0.26265585, 0.03771293]\n",
      "Iter 723, loss [-0.22393836, -0.26237735, 0.038438987]\n",
      "Iter 724, loss [-0.21624956, -0.25746045, 0.041210882]\n",
      "Iter 725, loss [-0.21099198, -0.2511117, 0.040119715]\n",
      "Iter 726, loss [-0.2209877, -0.26040366, 0.03941595]\n",
      "Iter 727, loss [-0.21498698, -0.25480893, 0.039821945]\n",
      "Iter 728, loss [-0.22450447, -0.2611913, 0.036686845]\n",
      "Iter 729, loss [-0.21741419, -0.25634506, 0.038930878]\n",
      "Iter 730, loss [-0.23020768, -0.2655567, 0.03534902]\n",
      "Iter 731, loss [-0.22845335, -0.26439148, 0.035938125]\n",
      "Iter 732, loss [-0.22944486, -0.26621014, 0.03676527]\n",
      "Iter 733, loss [-0.22745228, -0.2643377, 0.036885407]\n",
      "Iter 734, loss [-0.21853296, -0.25824276, 0.03970979]\n",
      "Iter 735, loss [-0.23069175, -0.26815075, 0.037458997]\n",
      "Iter 736, loss [-0.1953629, -0.24190797, 0.04654508]\n",
      "Iter 737, loss [-0.22774318, -0.26389876, 0.03615558]\n",
      "Iter 738, loss [-0.21774471, -0.2558207, 0.03807599]\n",
      "Iter 739, loss [-0.22257009, -0.26013446, 0.037564375]\n",
      "Iter 740, loss [-0.21180165, -0.25258124, 0.04077959]\n",
      "Iter 741, loss [-0.18509576, -0.23273274, 0.047636986]\n",
      "Iter 742, loss [-0.22526976, -0.26136395, 0.036094196]\n",
      "Iter 743, loss [-0.21308275, -0.2519707, 0.038887963]\n",
      "Iter 744, loss [-0.22631255, -0.26318926, 0.036876705]\n",
      "Iter 745, loss [-0.22380535, -0.2611281, 0.037322745]\n",
      "Iter 746, loss [-0.2268932, -0.26369908, 0.036805883]\n",
      "Iter 747, loss [-0.2128663, -0.2539523, 0.04108598]\n",
      "Iter 748, loss [-0.22066614, -0.26070565, 0.04003951]\n",
      "Iter 749, loss [-0.21901685, -0.25929877, 0.04028192]\n",
      "Iter 750, loss [-0.22972426, -0.26588956, 0.036165304]\n",
      "Iter 751, loss [-0.20854862, -0.24905372, 0.040505093]\n",
      "Iter 752, loss [-0.22312593, -0.25841522, 0.03528928]\n",
      "Iter 753, loss [-0.23371373, -0.26854128, 0.034827545]\n",
      "Iter 754, loss [-0.22489576, -0.26321515, 0.03831939]\n",
      "Iter 755, loss [-0.21290222, -0.2555056, 0.04260337]\n",
      "Iter 756, loss [-0.22887416, -0.26598623, 0.037112072]\n",
      "Iter 757, loss [-0.21859835, -0.2571719, 0.038573552]\n",
      "Iter 758, loss [-0.22201245, -0.25908622, 0.037073772]\n",
      "Iter 759, loss [-0.22707066, -0.26478904, 0.03771839]\n",
      "Iter 760, loss [-0.22575098, -0.2625512, 0.036800206]\n",
      "Iter 761, loss [-0.21300936, -0.25391787, 0.040908515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 762, loss [-0.23316813, -0.26776507, 0.034596946]\n",
      "Iter 763, loss [-0.22591302, -0.26222733, 0.0363143]\n",
      "Iter 764, loss [-0.13429765, -0.19668385, 0.062386196]\n",
      "Iter 765, loss [-0.21620062, -0.2566215, 0.04042089]\n",
      "Iter 766, loss [-0.22613832, -0.26185, 0.035711672]\n",
      "Iter 767, loss [-0.22309259, -0.26023754, 0.03714495]\n",
      "Iter 768, loss [-0.21633962, -0.25408968, 0.037750073]\n",
      "Iter 769, loss [-0.21652092, -0.25619677, 0.039675847]\n",
      "Iter 770, loss [-0.22431692, -0.26187924, 0.037562303]\n",
      "Iter 771, loss [-0.14951465, -0.2043074, 0.054792758]\n",
      "Iter 772, loss [-0.2274192, -0.26436412, 0.03694493]\n",
      "Iter 773, loss [-0.22558841, -0.26251116, 0.03692276]\n",
      "Iter 774, loss [-0.2222879, -0.25982794, 0.037540045]\n",
      "Iter 775, loss [-0.21744093, -0.2556017, 0.038160764]\n",
      "Iter 776, loss [-0.22873123, -0.26227728, 0.033546045]\n",
      "Iter 777, loss [-0.21920592, -0.25814018, 0.038934257]\n",
      "Iter 778, loss [-0.23017466, -0.2659584, 0.035783745]\n",
      "Iter 779, loss [-0.22433552, -0.26199472, 0.0376592]\n",
      "Iter 780, loss [-0.22146736, -0.25968972, 0.03822236]\n",
      "Iter 781, loss [-0.18866259, -0.23784515, 0.049182557]\n",
      "Iter 782, loss [-0.21662839, -0.25717938, 0.04055099]\n",
      "Iter 783, loss [-0.2127849, -0.25303024, 0.040245336]\n",
      "Iter 784, loss [-0.22765037, -0.26418424, 0.03653386]\n",
      "Iter 785, loss [-0.22440216, -0.26389635, 0.039494183]\n",
      "Iter 786, loss [-0.21546635, -0.2557959, 0.040329546]\n",
      "Iter 787, loss [-0.22650842, -0.26289877, 0.03639035]\n",
      "Iter 788, loss [-0.22327958, -0.26034757, 0.037067994]\n",
      "Iter 789, loss [-0.18562749, -0.23194717, 0.046319686]\n",
      "Iter 790, loss [-0.209153, -0.2498169, 0.0406639]\n",
      "Iter 791, loss [-0.19509858, -0.24183752, 0.046738945]\n",
      "Iter 792, loss [-0.21179014, -0.24705188, 0.035261728]\n",
      "Iter 793, loss [-0.22013144, -0.25783715, 0.0377057]\n",
      "Iter 794, loss [-0.21746331, -0.25807062, 0.040607296]\n",
      "Iter 795, loss [-0.22945918, -0.266463, 0.037003826]\n",
      "Iter 796, loss [-0.21157454, -0.25236717, 0.04079263]\n",
      "Iter 797, loss [-0.22807518, -0.2650837, 0.03700853]\n",
      "Iter 798, loss [-0.19325158, -0.23586813, 0.042616546]\n",
      "Iter 799, loss [-0.22240463, -0.25983927, 0.037434634]\n",
      "Iter 800, loss [-0.22797434, -0.26363257, 0.035658225]\n",
      "Iter 801, loss [-0.22205427, -0.25862193, 0.03656765]\n",
      "Iter 802, loss [-0.240422, -0.27489668, 0.034474686]\n",
      "Iter 803, loss [-0.22153907, -0.26093286, 0.039393794]\n",
      "Iter 804, loss [-0.2179009, -0.25856477, 0.040663876]\n",
      "Iter 805, loss [-0.22002864, -0.25823927, 0.038210623]\n",
      "Iter 806, loss [-0.21458904, -0.24970385, 0.035114806]\n",
      "Iter 807, loss [-0.22226533, -0.2600041, 0.037738774]\n",
      "Iter 808, loss [-0.22739536, -0.2654765, 0.038081147]\n",
      "Iter 809, loss [-0.22322968, -0.2617504, 0.038520724]\n",
      "Iter 810, loss [-0.21199632, -0.2538606, 0.04186427]\n",
      "Iter 811, loss [-0.14511302, -0.20273142, 0.057618387]\n",
      "Iter 812, loss [-0.22402656, -0.2613623, 0.037335746]\n",
      "Iter 813, loss [-0.21372753, -0.25299218, 0.039264653]\n",
      "Iter 814, loss [-0.15446112, -0.2108938, 0.05643267]\n",
      "Iter 815, loss [-0.22285128, -0.25918514, 0.036333866]\n",
      "Iter 816, loss [-0.22018346, -0.2583609, 0.03817743]\n",
      "Iter 817, loss [-0.22215551, -0.25965604, 0.03750053]\n",
      "Iter 818, loss [-0.2232069, -0.26080364, 0.037596747]\n",
      "Iter 819, loss [-0.23036419, -0.26635167, 0.03598748]\n",
      "Iter 820, loss [-0.2109708, -0.25454575, 0.043574944]\n",
      "Iter 821, loss [-0.21421136, -0.25346, 0.039248627]\n",
      "Iter 822, loss [-0.2023759, -0.24245688, 0.04008098]\n",
      "Iter 823, loss [-0.22798173, -0.26253483, 0.034553092]\n",
      "Iter 824, loss [-0.20376709, -0.24448562, 0.04071852]\n",
      "Iter 825, loss [-0.2250161, -0.2653636, 0.0403475]\n",
      "Iter 826, loss [-0.22753102, -0.26542756, 0.037896544]\n",
      "Iter 827, loss [-0.22633158, -0.26453665, 0.038205072]\n",
      "Iter 828, loss [-0.22025675, -0.26089367, 0.040636934]\n",
      "Iter 829, loss [-0.22942293, -0.26661637, 0.037193455]\n",
      "Iter 830, loss [-0.22145559, -0.26032823, 0.038872644]\n",
      "Iter 831, loss [-0.2150838, -0.2526985, 0.037614718]\n",
      "Iter 832, loss [-0.22458282, -0.26230383, 0.037721004]\n",
      "Iter 833, loss [-0.22362566, -0.26074636, 0.037120692]\n",
      "Iter 834, loss [-0.22023195, -0.25937968, 0.03914773]\n",
      "Iter 835, loss [-0.22509566, -0.26233888, 0.037243225]\n",
      "Iter 836, loss [-0.22071464, -0.2591547, 0.03844006]\n",
      "Iter 837, loss [-0.22846192, -0.26664877, 0.03818684]\n",
      "Iter 838, loss [-0.22518295, -0.26192984, 0.03674689]\n",
      "Iter 839, loss [-0.2158789, -0.2552051, 0.0393262]\n",
      "Iter 840, loss [-0.23283753, -0.26970148, 0.036863957]\n",
      "Iter 841, loss [-0.21473017, -0.25487462, 0.040144444]\n",
      "Iter 842, loss [-0.2270404, -0.26422992, 0.037189525]\n",
      "Iter 843, loss [-0.20921157, -0.24891976, 0.039708182]\n",
      "Iter 844, loss [-0.20885415, -0.2467876, 0.037933435]\n",
      "Iter 845, loss [-0.21945748, -0.2578663, 0.038408816]\n",
      "Iter 846, loss [-0.2229663, -0.26080725, 0.037840944]\n",
      "Iter 847, loss [-0.21342732, -0.2553856, 0.041958284]\n",
      "Iter 848, loss [-0.22310138, -0.26199678, 0.0388954]\n",
      "Iter 849, loss [-0.21637446, -0.25609583, 0.039721377]\n",
      "Iter 850, loss [-0.22229621, -0.26158193, 0.039285716]\n",
      "Iter 851, loss [-0.1935161, -0.24103147, 0.047515355]\n",
      "Iter 852, loss [-0.23352717, -0.26721272, 0.03368555]\n",
      "Iter 853, loss [-0.17739657, -0.22721794, 0.049821377]\n",
      "Iter 854, loss [-0.22380327, -0.260735, 0.03693174]\n",
      "Iter 855, loss [-0.23059505, -0.26407456, 0.03347952]\n",
      "Iter 856, loss [-0.31029338, -0.31769955, 0.0074061784]\n",
      "Iter 857, loss [-0.2149882, -0.2553943, 0.0404061]\n",
      "Iter 858, loss [-0.20666131, -0.2504017, 0.043740388]\n",
      "Iter 859, loss [-0.20774253, -0.24964531, 0.04190278]\n",
      "Iter 860, loss [-0.2176448, -0.2556298, 0.037985012]\n",
      "Iter 861, loss [-0.22213158, -0.25956488, 0.03743329]\n",
      "Iter 862, loss [-0.21202816, -0.2525514, 0.040523242]\n",
      "Iter 863, loss [-0.22473308, -0.26044402, 0.03571093]\n",
      "Iter 864, loss [-0.20625325, -0.24632172, 0.04006848]\n",
      "Iter 865, loss [-0.22202057, -0.25900942, 0.03698885]\n",
      "Iter 866, loss [-0.21572046, -0.2570038, 0.041283354]\n",
      "Iter 867, loss [-0.1557258, -0.20900339, 0.053277574]\n",
      "Iter 868, loss [-0.21681574, -0.25770554, 0.040889807]\n",
      "Iter 869, loss [-0.21944396, -0.25886285, 0.03941889]\n",
      "Iter 870, loss [-0.22023082, -0.2600393, 0.039808482]\n",
      "Iter 871, loss [-0.20240341, -0.24750024, 0.04509683]\n",
      "Iter 872, loss [-0.21723293, -0.25492513, 0.037692204]\n",
      "Iter 873, loss [-0.22306423, -0.26055574, 0.03749151]\n",
      "Iter 874, loss [-0.22036219, -0.25959185, 0.039229658]\n",
      "Iter 875, loss [-0.20862135, -0.24672179, 0.038100436]\n",
      "Iter 876, loss [-0.21761401, -0.25715727, 0.039543252]\n",
      "Iter 877, loss [-0.22807066, -0.26591912, 0.037848458]\n",
      "Iter 878, loss [-0.1927017, -0.24121605, 0.048514344]\n",
      "Iter 879, loss [-0.2129775, -0.254599, 0.041621502]\n",
      "Iter 880, loss [-0.23334399, -0.2699543, 0.0366103]\n",
      "Iter 881, loss [-0.2253052, -0.26265123, 0.03734604]\n",
      "Iter 882, loss [-0.21888745, -0.2587664, 0.039878957]\n",
      "Iter 883, loss [-0.22264837, -0.2576862, 0.035037827]\n",
      "Iter 884, loss [-0.22706804, -0.2622769, 0.035208847]\n",
      "Iter 885, loss [-0.21847919, -0.2554961, 0.037016936]\n",
      "Iter 886, loss [-0.22492272, -0.2608324, 0.035909675]\n",
      "Iter 887, loss [-0.22161603, -0.25855806, 0.036942035]\n",
      "Iter 888, loss [-0.23014672, -0.2675611, 0.037414387]\n",
      "Iter 889, loss [-0.2022725, -0.24176383, 0.039491326]\n",
      "Iter 890, loss [-0.22170617, -0.2598964, 0.03819023]\n",
      "Iter 891, loss [-0.22109395, -0.25938997, 0.038296014]\n",
      "Iter 892, loss [-0.20629218, -0.24422562, 0.037933446]\n",
      "Iter 893, loss [-0.21510169, -0.25119022, 0.036088523]\n",
      "Iter 894, loss [-0.22042763, -0.25527874, 0.034851108]\n",
      "Iter 895, loss [-0.22403443, -0.25903946, 0.035005033]\n",
      "Iter 896, loss [-0.22457628, -0.26220843, 0.037632152]\n",
      "Iter 897, loss [-0.18561397, -0.23285781, 0.047243834]\n",
      "Iter 898, loss [-0.22348846, -0.26151487, 0.038026407]\n",
      "Iter 899, loss [-0.22022568, -0.25848615, 0.038260475]\n",
      "Iter 900, loss [-0.2251639, -0.2639877, 0.038823783]\n",
      "Iter 901, loss [-0.13292155, -0.19102211, 0.05810056]\n",
      "Iter 902, loss [-0.21883523, -0.25590944, 0.03707421]\n",
      "Iter 903, loss [-0.23204407, -0.2665105, 0.034466412]\n",
      "Iter 904, loss [-0.1729364, -0.2247039, 0.0517675]\n",
      "Iter 905, loss [-0.207802, -0.24864452, 0.040842526]\n",
      "Iter 906, loss [-0.21706888, -0.2598456, 0.04277674]\n",
      "Iter 907, loss [-0.2254718, -0.26162663, 0.03615483]\n",
      "Iter 908, loss [-0.21601644, -0.25597742, 0.03996098]\n",
      "Iter 909, loss [-0.20770642, -0.24800937, 0.040302947]\n",
      "Iter 910, loss [-0.16785559, -0.22491722, 0.05706162]\n",
      "Iter 911, loss [-0.2125099, -0.24936959, 0.036859684]\n",
      "Iter 912, loss [-0.2170347, -0.2568038, 0.039769113]\n",
      "Iter 913, loss [-0.2246936, -0.2596784, 0.034984794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 914, loss [-0.22272694, -0.26071692, 0.03798998]\n",
      "Iter 915, loss [-0.22379933, -0.2616087, 0.037809357]\n",
      "Iter 916, loss [-0.22564326, -0.26300684, 0.037363574]\n",
      "Iter 917, loss [-0.20733953, -0.25160196, 0.04426243]\n",
      "Iter 918, loss [-0.21668643, -0.2558177, 0.03913128]\n",
      "Iter 919, loss [-0.23027055, -0.26758623, 0.037315678]\n",
      "Iter 920, loss [-0.22211349, -0.26290268, 0.04078918]\n",
      "Iter 921, loss [-0.20659617, -0.24794957, 0.041353405]\n",
      "Iter 922, loss [-0.21171135, -0.25485343, 0.043142073]\n",
      "Iter 923, loss [-0.2174597, -0.25852513, 0.041065436]\n",
      "Iter 924, loss [-0.23067531, -0.26663882, 0.0359635]\n",
      "Iter 925, loss [-0.22970499, -0.26574087, 0.03603588]\n",
      "Iter 926, loss [-0.19807538, -0.23926048, 0.04118509]\n",
      "Iter 927, loss [-0.22248021, -0.2616367, 0.03915649]\n",
      "Iter 928, loss [-0.2251526, -0.26365525, 0.03850265]\n",
      "Iter 929, loss [-0.20811442, -0.25216824, 0.044053815]\n",
      "Iter 930, loss [-0.22550793, -0.26390857, 0.038400635]\n",
      "Iter 931, loss [-0.2223374, -0.26043713, 0.03809973]\n",
      "Iter 932, loss [-0.22294302, -0.2599562, 0.037013184]\n",
      "Iter 933, loss [-0.20869063, -0.2503212, 0.04163058]\n",
      "Iter 934, loss [-0.22041094, -0.2586719, 0.038260974]\n",
      "Iter 935, loss [-0.22096199, -0.26040062, 0.039438635]\n",
      "Iter 936, loss [-0.23222925, -0.26875558, 0.036526334]\n",
      "Iter 937, loss [-0.16663176, -0.22280397, 0.0561722]\n",
      "Iter 938, loss [-0.2224633, -0.2597082, 0.0372449]\n",
      "Iter 939, loss [-0.2205705, -0.25988293, 0.03931243]\n",
      "Iter 940, loss [-0.22355957, -0.26332477, 0.039765194]\n",
      "Iter 941, loss [-0.19409056, -0.24136148, 0.047270924]\n",
      "Iter 942, loss [-0.19809712, -0.24044266, 0.042345535]\n",
      "Iter 943, loss [-0.22848742, -0.26242325, 0.03393583]\n",
      "Iter 944, loss [-0.21205135, -0.25080428, 0.03875293]\n",
      "Iter 945, loss [-0.22310615, -0.26173455, 0.038628407]\n",
      "Iter 946, loss [-0.22910377, -0.26433322, 0.03522944]\n",
      "Iter 947, loss [-0.21814, -0.25917763, 0.04103762]\n",
      "Iter 948, loss [-0.2262643, -0.26329982, 0.037035525]\n",
      "Iter 949, loss [-0.19568259, -0.24267717, 0.046994574]\n",
      "Iter 950, loss [-0.22274166, -0.2614848, 0.03874313]\n",
      "Iter 951, loss [-0.22636464, -0.2630939, 0.036729246]\n",
      "Iter 952, loss [-0.21209575, -0.2539169, 0.041821137]\n",
      "Iter 953, loss [-0.2178751, -0.25885978, 0.040984683]\n",
      "Iter 954, loss [-0.21991138, -0.26002225, 0.04011087]\n",
      "Iter 955, loss [-0.21843879, -0.25770065, 0.039261863]\n",
      "Iter 956, loss [-0.22172557, -0.25714117, 0.03541561]\n",
      "Iter 957, loss [-0.22276413, -0.26008105, 0.03731692]\n",
      "Iter 958, loss [-0.21336547, -0.24956784, 0.036202364]\n",
      "Iter 959, loss [-0.21482629, -0.25428045, 0.03945417]\n",
      "Iter 960, loss [-0.20616005, -0.2504614, 0.044301342]\n",
      "Iter 961, loss [-0.22437364, -0.26129633, 0.03692269]\n",
      "Iter 962, loss [-0.22317657, -0.26133227, 0.038155697]\n",
      "Iter 963, loss [-0.224789, -0.26182425, 0.037035257]\n",
      "Iter 964, loss [-0.16627455, -0.21729991, 0.051025353]\n",
      "Iter 965, loss [-0.23225623, -0.2687439, 0.03648766]\n",
      "Iter 966, loss [-0.21480364, -0.25381374, 0.039010108]\n",
      "Iter 967, loss [-0.21297836, -0.2544137, 0.04143533]\n",
      "Iter 968, loss [-0.22123416, -0.2585468, 0.037312645]\n",
      "Iter 969, loss [-0.22436574, -0.2609708, 0.03660506]\n",
      "Iter 970, loss [-0.22235414, -0.25901532, 0.03666117]\n",
      "Iter 971, loss [-0.16985807, -0.22224775, 0.052389678]\n",
      "Iter 972, loss [-0.21632262, -0.25394362, 0.037621003]\n",
      "Iter 973, loss [-0.21856424, -0.2554958, 0.036931537]\n",
      "Iter 974, loss [-0.21614188, -0.25627318, 0.0401313]\n",
      "Iter 975, loss [-0.22816713, -0.26310694, 0.03493981]\n",
      "Iter 976, loss [-0.21598858, -0.25148314, 0.035494566]\n",
      "Iter 977, loss [-0.19509712, -0.24212553, 0.0470284]\n",
      "Iter 978, loss [-0.21748705, -0.25548306, 0.03799601]\n",
      "Iter 979, loss [-0.22276074, -0.26250902, 0.03974829]\n",
      "Iter 980, loss [-0.20689116, -0.24998133, 0.04309016]\n",
      "Iter 981, loss [-0.22293183, -0.26281106, 0.039879233]\n",
      "Iter 982, loss [-0.2212351, -0.25797307, 0.03673797]\n",
      "Iter 983, loss [-0.22295852, -0.25743064, 0.034472123]\n",
      "Iter 984, loss [-0.18407677, -0.22896981, 0.04489304]\n",
      "Iter 985, loss [-0.23172632, -0.26544675, 0.033720434]\n",
      "Iter 986, loss [-0.21975759, -0.25675738, 0.0369998]\n",
      "Iter 987, loss [-0.23234957, -0.2679177, 0.03556812]\n",
      "Iter 988, loss [-0.2232297, -0.2617233, 0.038493596]\n",
      "Iter 989, loss [-0.22188382, -0.26070532, 0.0388215]\n",
      "Iter 990, loss [-0.22424603, -0.2624011, 0.038155086]\n",
      "Iter 991, loss [-0.22778189, -0.2638502, 0.03606832]\n",
      "Iter 992, loss [-0.21810889, -0.2587055, 0.040596604]\n",
      "Iter 993, loss [-0.21299878, -0.2503015, 0.037302725]\n",
      "Iter 994, loss [-0.21492027, -0.25572523, 0.04080497]\n",
      "Iter 995, loss [-0.21334903, -0.25338095, 0.040031925]\n",
      "Iter 996, loss [-0.22443938, -0.2616414, 0.03720203]\n",
      "Iter 997, loss [-0.21579376, -0.2560634, 0.040269636]\n",
      "Iter 998, loss [-0.2197163, -0.25871092, 0.03899462]\n",
      "Iter 999, loss [-0.22295672, -0.26128107, 0.03832435]\n",
      "Iter 1000, loss [-0.21921216, -0.25915286, 0.039940704]\n",
      "Iter 1001, loss [-0.23071614, -0.26593104, 0.0352149]\n",
      "Iter 1002, loss [-0.2307411, -0.26550925, 0.034768146]\n",
      "Iter 1003, loss [-0.21861032, -0.25638244, 0.03777211]\n",
      "Iter 1004, loss [-0.22487408, -0.2617905, 0.036916427]\n",
      "Iter 1005, loss [-0.21288899, -0.2528647, 0.039975695]\n",
      "Iter 1006, loss [-0.21557751, -0.2564436, 0.040866073]\n",
      "Iter 1007, loss [-0.22310516, -0.2607331, 0.037627935]\n",
      "Iter 1008, loss [-0.22875667, -0.26422602, 0.035469353]\n",
      "Iter 1009, loss [-0.21170634, -0.2468652, 0.035158865]\n",
      "Iter 1010, loss [-0.22232887, -0.25923508, 0.03690622]\n",
      "Iter 1011, loss [-0.17830698, -0.23215863, 0.05385165]\n",
      "Iter 1012, loss [-0.21988347, -0.25824144, 0.03835798]\n",
      "Iter 1013, loss [-0.22253163, -0.25970656, 0.03717493]\n",
      "Iter 1014, loss [-0.22629401, -0.26226547, 0.035971466]\n",
      "Iter 1015, loss [-0.21801303, -0.25659454, 0.0385815]\n",
      "Iter 1016, loss [-0.21022753, -0.25248405, 0.042256515]\n",
      "Iter 1017, loss [-0.22010213, -0.25816655, 0.03806442]\n",
      "Iter 1018, loss [-0.21835665, -0.25702462, 0.038667962]\n",
      "Iter 1019, loss [-0.21308753, -0.25334758, 0.04026004]\n",
      "Iter 1020, loss [-0.22382155, -0.26158455, 0.037763]\n",
      "Iter 1021, loss [-0.21496174, -0.25189403, 0.03693229]\n",
      "Iter 1022, loss [-0.20230693, -0.24528547, 0.042978536]\n",
      "Iter 1023, loss [-0.18550508, -0.22935602, 0.04385094]\n",
      "Iter 1024, loss [-0.21922874, -0.25440553, 0.03517679]\n",
      "Iter 1025, loss [-0.2191829, -0.25562978, 0.03644688]\n",
      "Iter 1026, loss [-0.22929305, -0.2654384, 0.03614535]\n",
      "Iter 1027, loss [-0.22236033, -0.25889662, 0.036536295]\n",
      "Iter 1028, loss [-0.21313158, -0.25323322, 0.040101647]\n",
      "Iter 1029, loss [-0.22316855, -0.2609355, 0.037766926]\n",
      "Iter 1030, loss [-0.23017767, -0.2644699, 0.034292217]\n",
      "Iter 1031, loss [-0.2225861, -0.25796258, 0.035376497]\n",
      "Iter 1032, loss [-0.21169585, -0.25231603, 0.040620174]\n",
      "Iter 1033, loss [-0.22229064, -0.26058418, 0.038293537]\n",
      "Iter 1034, loss [-0.22633699, -0.2643107, 0.03797371]\n",
      "Iter 1035, loss [-0.23318087, -0.26798332, 0.03480245]\n",
      "Iter 1036, loss [-0.22735612, -0.26490787, 0.037551746]\n",
      "Iter 1037, loss [-0.20601024, -0.24958834, 0.0435781]\n",
      "Iter 1038, loss [-0.22619405, -0.26392007, 0.037726022]\n",
      "Iter 1039, loss [-0.23348346, -0.2686316, 0.035148136]\n",
      "Iter 1040, loss [-0.15629068, -0.21541427, 0.059123583]\n",
      "Iter 1041, loss [-0.22364023, -0.2610759, 0.037435688]\n",
      "Iter 1042, loss [-0.21371676, -0.2531737, 0.039456952]\n",
      "Iter 1043, loss [-0.22490273, -0.2628877, 0.037984956]\n",
      "Iter 1044, loss [-0.22394566, -0.26224574, 0.038300082]\n",
      "Iter 1045, loss [-0.21808682, -0.2583829, 0.040296063]\n",
      "Iter 1046, loss [-0.21373238, -0.25174442, 0.038012043]\n",
      "Iter 1047, loss [-0.22630028, -0.26284847, 0.036548182]\n",
      "Iter 1048, loss [-0.12852982, -0.18779881, 0.059268996]\n",
      "Iter 1049, loss [-0.21679366, -0.2567187, 0.03992504]\n",
      "Iter 1050, loss [-0.21594998, -0.2538159, 0.037865914]\n",
      "Iter 1051, loss [-0.22131318, -0.25845125, 0.037138075]\n",
      "Iter 1052, loss [-0.22632198, -0.26303062, 0.036708634]\n",
      "Iter 1053, loss [-0.22464682, -0.2597884, 0.03514157]\n",
      "Iter 1054, loss [-0.22600085, -0.2635827, 0.037581854]\n",
      "Iter 1055, loss [-0.22568622, -0.2640738, 0.03838756]\n",
      "Iter 1056, loss [-0.2123717, -0.25438073, 0.042009022]\n",
      "Iter 1057, loss [-0.21090922, -0.2526098, 0.04170057]\n",
      "Iter 1058, loss [-0.2300596, -0.26601645, 0.035956856]\n",
      "Iter 1059, loss [-0.22815385, -0.26485366, 0.036699794]\n",
      "Iter 1060, loss [-0.22544995, -0.26496276, 0.039512813]\n",
      "Iter 1061, loss [-0.20770943, -0.25101653, 0.043307096]\n",
      "Iter 1062, loss [-0.22236802, -0.2619358, 0.039567783]\n",
      "Iter 1063, loss [-0.22283843, -0.25945604, 0.036617614]\n",
      "Iter 1064, loss [-0.21472383, -0.25536647, 0.040642645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1065, loss [-0.21231546, -0.25407448, 0.04175903]\n",
      "Iter 1066, loss [-0.22391218, -0.2610119, 0.037099726]\n",
      "Iter 1067, loss [-0.23374975, -0.26873028, 0.034980543]\n",
      "Iter 1068, loss [-0.22428733, -0.25961202, 0.0353247]\n",
      "Iter 1069, loss [-0.15063724, -0.20507248, 0.054435235]\n",
      "Iter 1070, loss [-0.19668242, -0.24061581, 0.04393339]\n",
      "Iter 1071, loss [-0.22220224, -0.26064256, 0.038440324]\n",
      "Iter 1072, loss [-0.2305319, -0.2666306, 0.03609868]\n",
      "Iter 1073, loss [-0.22310206, -0.26086274, 0.03776067]\n",
      "Iter 1074, loss [-0.21915847, -0.25852782, 0.039369337]\n",
      "Iter 1075, loss [-0.21889642, -0.25814942, 0.039252996]\n",
      "Iter 1076, loss [-0.14583227, -0.20800741, 0.062175136]\n",
      "Iter 1077, loss [-0.22312602, -0.26064837, 0.03752235]\n",
      "Iter 1078, loss [-0.21844874, -0.25709614, 0.038647395]\n",
      "Iter 1079, loss [-0.22427005, -0.2604977, 0.036227636]\n",
      "Iter 1080, loss [-0.22714274, -0.26293844, 0.035795704]\n",
      "Iter 1081, loss [-0.21362932, -0.24986434, 0.03623502]\n",
      "Iter 1082, loss [-0.22828537, -0.26412782, 0.03584245]\n",
      "Iter 1083, loss [-0.22303075, -0.2625848, 0.039554052]\n",
      "Iter 1084, loss [-0.21800025, -0.25910267, 0.041102424]\n",
      "Iter 1085, loss [-0.22062206, -0.2593255, 0.03870345]\n",
      "Iter 1086, loss [-0.22684526, -0.2626476, 0.035802342]\n",
      "Iter 1087, loss [-0.22236335, -0.25872838, 0.036365025]\n",
      "Iter 1088, loss [-0.21376356, -0.2518627, 0.038099144]\n",
      "Iter 1089, loss [-0.22827595, -0.26243857, 0.034162603]\n",
      "Iter 1090, loss [-0.22526178, -0.26213565, 0.03687388]\n",
      "Iter 1091, loss [-0.21483397, -0.25317493, 0.03834095]\n",
      "Iter 1092, loss [-0.21348153, -0.254094, 0.040612474]\n",
      "Iter 1093, loss [-0.22292499, -0.26196757, 0.039042577]\n",
      "Iter 1094, loss [-0.21860358, -0.25985062, 0.041247033]\n",
      "Iter 1095, loss [-0.22187936, -0.26114267, 0.039263308]\n",
      "Iter 1096, loss [-0.21944347, -0.25971687, 0.040273406]\n",
      "Iter 1097, loss [-0.22054426, -0.25837523, 0.037830964]\n",
      "Iter 1098, loss [-0.22714554, -0.2653434, 0.03819786]\n",
      "Iter 1099, loss [-0.22830433, -0.2642574, 0.03595307]\n",
      "Iter 1100, loss [-0.22598216, -0.2623847, 0.03640256]\n",
      "Iter 1101, loss [-0.22740245, -0.26461008, 0.03720764]\n",
      "Iter 1102, loss [-0.17098734, -0.22315346, 0.052166127]\n",
      "Iter 1103, loss [-0.20051417, -0.2450945, 0.04458032]\n",
      "Iter 1104, loss [-0.22950779, -0.26550066, 0.035992876]\n",
      "Iter 1105, loss [-0.22142833, -0.25991917, 0.038490824]\n",
      "Iter 1106, loss [-0.21996804, -0.25967845, 0.039710417]\n",
      "Iter 1107, loss [-0.22200252, -0.25901163, 0.037009105]\n",
      "Iter 1108, loss [-0.16538757, -0.22477444, 0.059386864]\n",
      "Iter 1109, loss [-0.2204423, -0.25968072, 0.03923842]\n",
      "Iter 1110, loss [-0.22977807, -0.2657198, 0.03594173]\n",
      "Iter 1111, loss [-0.22377506, -0.25959903, 0.035823964]\n",
      "Iter 1112, loss [-0.22942393, -0.26605973, 0.036635805]\n",
      "Iter 1113, loss [-0.21278852, -0.2528345, 0.04004597]\n",
      "Iter 1114, loss [-0.2182942, -0.25752175, 0.039227538]\n",
      "Iter 1115, loss [-0.21847609, -0.25629374, 0.03781765]\n",
      "Iter 1116, loss [-0.23017755, -0.26842654, 0.038248986]\n",
      "Iter 1117, loss [-0.22297755, -0.26220775, 0.03923019]\n",
      "Iter 1118, loss [-0.22566622, -0.26151645, 0.035850227]\n",
      "Iter 1119, loss [-0.22163476, -0.26157624, 0.03994147]\n",
      "Iter 1120, loss [-0.22749078, -0.2638329, 0.036342107]\n",
      "Iter 1121, loss [-0.22035532, -0.2597057, 0.039350376]\n",
      "Iter 1122, loss [-0.2206505, -0.2595925, 0.038942017]\n",
      "Iter 1123, loss [-0.21718001, -0.25615662, 0.038976602]\n",
      "Iter 1124, loss [-0.2203792, -0.25953192, 0.039152704]\n",
      "Iter 1125, loss [-0.16726346, -0.22145845, 0.054194983]\n",
      "Iter 1126, loss [-0.22457814, -0.2621526, 0.03757447]\n",
      "Iter 1127, loss [-0.22707686, -0.26284832, 0.03577146]\n",
      "Iter 1128, loss [-0.223212, -0.26048347, 0.037271474]\n",
      "Iter 1129, loss [-0.21762583, -0.25703365, 0.039407816]\n",
      "Iter 1130, loss [-0.23073323, -0.266604, 0.035870776]\n",
      "Iter 1131, loss [-0.21896026, -0.2573597, 0.038399458]\n",
      "Iter 1132, loss [-0.17856714, -0.2297797, 0.05121257]\n",
      "Iter 1133, loss [-0.22765014, -0.26283002, 0.03517988]\n",
      "Iter 1134, loss [-0.22288406, -0.26166856, 0.0387845]\n",
      "Iter 1135, loss [-0.22482188, -0.2631526, 0.03833072]\n",
      "Iter 1136, loss [-0.22463173, -0.26173705, 0.037105322]\n",
      "Iter 1137, loss [-0.22710428, -0.2639273, 0.03682304]\n",
      "Iter 1138, loss [-0.22632125, -0.26219496, 0.035873704]\n",
      "Iter 1139, loss [-0.22529766, -0.26153043, 0.036232762]\n",
      "Iter 1140, loss [-0.22469145, -0.26071915, 0.036027707]\n",
      "Iter 1141, loss [-0.207661, -0.25098324, 0.04332223]\n",
      "Iter 1142, loss [-0.20455803, -0.24842651, 0.04386848]\n",
      "Iter 1143, loss [-0.21667467, -0.25745752, 0.040782854]\n",
      "Iter 1144, loss [-0.2162855, -0.2600128, 0.0437273]\n",
      "Iter 1145, loss [-0.22466013, -0.2627423, 0.03808219]\n",
      "Iter 1146, loss [-0.22057277, -0.2564355, 0.035862744]\n",
      "Iter 1147, loss [-0.14513516, -0.20633414, 0.061198987]\n",
      "Iter 1148, loss [-0.22297536, -0.26155892, 0.038583558]\n",
      "Iter 1149, loss [-0.2158966, -0.25495252, 0.039055906]\n",
      "Iter 1150, loss [-0.20657955, -0.24680345, 0.040223897]\n",
      "Iter 1151, loss [-0.23197556, -0.2680845, 0.036108933]\n",
      "Iter 1152, loss [-0.22393908, -0.26159886, 0.037659775]\n",
      "Iter 1153, loss [-0.22303556, -0.2600504, 0.037014827]\n",
      "Iter 1154, loss [-0.22124621, -0.2606863, 0.039440095]\n",
      "Iter 1155, loss [-0.23020151, -0.26862553, 0.038424015]\n",
      "Iter 1156, loss [-0.16503012, -0.22533002, 0.06029991]\n",
      "Iter 1157, loss [-0.21904486, -0.25896063, 0.039915763]\n",
      "Iter 1158, loss [-0.21889266, -0.25883627, 0.039943613]\n",
      "Iter 1159, loss [-0.17715809, -0.21772376, 0.040565677]\n",
      "Iter 1160, loss [-0.19655901, -0.23985274, 0.043293722]\n",
      "Iter 1161, loss [-0.2103006, -0.25041267, 0.040112086]\n",
      "Iter 1162, loss [-0.22203518, -0.25803322, 0.03599803]\n",
      "Iter 1163, loss [-0.22327155, -0.25939924, 0.036127694]\n",
      "Iter 1164, loss [-0.22370389, -0.26089743, 0.037193544]\n",
      "Iter 1165, loss [-0.22683278, -0.26596323, 0.039130457]\n",
      "Iter 1166, loss [-0.18998578, -0.23990867, 0.049922876]\n",
      "Iter 1167, loss [-0.21823844, -0.25861892, 0.04038048]\n",
      "Iter 1168, loss [-0.22459933, -0.2633348, 0.038735475]\n",
      "Iter 1169, loss [-0.22191812, -0.25844923, 0.036531102]\n",
      "Iter 1170, loss [-0.18452793, -0.2349325, 0.050404556]\n",
      "Iter 1171, loss [-0.2143094, -0.25327104, 0.038961645]\n",
      "Iter 1172, loss [-0.22270355, -0.26113656, 0.038433015]\n",
      "Iter 1173, loss [-0.21703939, -0.25690088, 0.03986148]\n",
      "Iter 1174, loss [-0.2292413, -0.26568842, 0.036447123]\n",
      "Iter 1175, loss [-0.22999276, -0.26767814, 0.037685376]\n",
      "Iter 1176, loss [-0.15383025, -0.2085935, 0.054763258]\n",
      "Iter 1177, loss [-0.22122747, -0.26133856, 0.0401111]\n",
      "Iter 1178, loss [-0.2040424, -0.24844642, 0.04440401]\n",
      "Iter 1179, loss [-0.22779065, -0.266304, 0.038513336]\n",
      "Iter 1180, loss [-0.212398, -0.2525925, 0.04019451]\n",
      "Iter 1181, loss [-0.20946868, -0.2495269, 0.04005822]\n",
      "Iter 1182, loss [-0.22385637, -0.26096243, 0.03710605]\n",
      "Iter 1183, loss [-0.21530634, -0.25386178, 0.03855545]\n",
      "Iter 1184, loss [-0.22248642, -0.2620273, 0.03954087]\n",
      "Iter 1185, loss [-0.22609325, -0.2618091, 0.035715863]\n",
      "Iter 1186, loss [-0.19840759, -0.24268861, 0.044281013]\n",
      "Iter 1187, loss [-0.19838338, -0.24494936, 0.04656598]\n",
      "Iter 1188, loss [-0.2211487, -0.25913557, 0.03798687]\n",
      "Iter 1189, loss [-0.22135434, -0.258132, 0.03677768]\n",
      "Iter 1190, loss [-0.2196202, -0.25888073, 0.03926053]\n",
      "Iter 1191, loss [-0.21660787, -0.25578988, 0.039182007]\n",
      "Iter 1192, loss [-0.2243756, -0.26114592, 0.036770314]\n",
      "Iter 1193, loss [-0.21443243, -0.2554104, 0.04097797]\n",
      "Iter 1194, loss [-0.20736177, -0.24770738, 0.040345613]\n",
      "Iter 1195, loss [-0.21995094, -0.2606702, 0.04071927]\n",
      "Iter 1196, loss [-0.18757448, -0.2398617, 0.05228722]\n",
      "Iter 1197, loss [-0.22837561, -0.26498902, 0.036613405]\n",
      "Iter 1198, loss [-0.22504197, -0.2617196, 0.03667764]\n",
      "Iter 1199, loss [-0.23090647, -0.264848, 0.033941522]\n",
      "Iter 1200, loss [-0.21651813, -0.2556329, 0.039114773]\n",
      "Iter 1201, loss [-0.22047281, -0.2546513, 0.0341785]\n",
      "Iter 1202, loss [-0.22512285, -0.26256225, 0.03743939]\n",
      "Iter 1203, loss [-0.22140318, -0.26091436, 0.039511174]\n",
      "Iter 1204, loss [-0.21457067, -0.25407413, 0.039503448]\n",
      "Iter 1205, loss [-0.21855569, -0.25833505, 0.039779365]\n",
      "Iter 1206, loss [-0.31096685, -0.3183613, 0.0073944638]\n",
      "Iter 1207, loss [-0.22758368, -0.26375782, 0.03617414]\n",
      "Iter 1208, loss [-0.16750944, -0.2194341, 0.05192466]\n",
      "Iter 1209, loss [-0.2080773, -0.25129652, 0.04321922]\n",
      "Iter 1210, loss [-0.22369102, -0.2629326, 0.039241582]\n",
      "Iter 1211, loss [-0.23025572, -0.26623237, 0.035976645]\n",
      "Iter 1212, loss [-0.21950206, -0.25825152, 0.03874945]\n",
      "Iter 1213, loss [-0.17128041, -0.22429559, 0.05301518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1214, loss [-0.20769161, -0.24921563, 0.04152403]\n",
      "Iter 1215, loss [-0.21753357, -0.25681195, 0.039278373]\n",
      "Iter 1216, loss [-0.18573457, -0.23203129, 0.046296716]\n",
      "Iter 1217, loss [-0.22504647, -0.2597429, 0.034696415]\n",
      "Iter 1218, loss [-0.20983036, -0.24604052, 0.03621016]\n",
      "Iter 1219, loss [-0.22285147, -0.2590735, 0.036222022]\n",
      "Iter 1220, loss [-0.2127186, -0.2508027, 0.038084086]\n",
      "Iter 1221, loss [-0.22363968, -0.26059264, 0.036952958]\n",
      "Iter 1222, loss [-0.23204651, -0.26776594, 0.03571942]\n",
      "Iter 1223, loss [-0.22898668, -0.26751465, 0.038527966]\n",
      "Iter 1224, loss [-0.18630435, -0.23641314, 0.050108787]\n",
      "Iter 1225, loss [-0.21964847, -0.2603696, 0.04072113]\n",
      "Iter 1226, loss [-0.22878776, -0.2648, 0.036012247]\n",
      "Iter 1227, loss [-0.22096953, -0.25955343, 0.0385839]\n",
      "Iter 1228, loss [-0.22420767, -0.2601486, 0.03594094]\n",
      "Iter 1229, loss [-0.22054657, -0.25904417, 0.03849759]\n",
      "Iter 1230, loss [-0.22681603, -0.26229033, 0.035474293]\n",
      "Iter 1231, loss [-0.1967759, -0.24041523, 0.04363933]\n",
      "Iter 1232, loss [-0.22365515, -0.26075733, 0.03710218]\n",
      "Iter 1233, loss [-0.23167953, -0.2667731, 0.03509357]\n",
      "Iter 1234, loss [-0.23311189, -0.2679905, 0.03487861]\n",
      "Iter 1235, loss [-0.22577018, -0.26252797, 0.036757804]\n",
      "Iter 1236, loss [-0.22317213, -0.25990513, 0.03673301]\n",
      "Iter 1237, loss [-0.23344839, -0.2671066, 0.033658206]\n",
      "Iter 1238, loss [-0.21923399, -0.25730646, 0.03807246]\n",
      "Iter 1239, loss [-0.21718127, -0.25531086, 0.038129605]\n",
      "Iter 1240, loss [-0.21628919, -0.25493595, 0.038646758]\n",
      "Iter 1241, loss [-0.21936725, -0.25834927, 0.038982015]\n",
      "Iter 1242, loss [-0.23100856, -0.26536936, 0.034360804]\n",
      "Iter 1243, loss [-0.22556543, -0.2639429, 0.03837747]\n",
      "Iter 1244, loss [-0.22628675, -0.2637382, 0.037451435]\n",
      "Iter 1245, loss [-0.22515793, -0.26458788, 0.039429944]\n",
      "Iter 1246, loss [-0.22208273, -0.26264966, 0.04056692]\n",
      "Iter 1247, loss [-0.21994604, -0.25935304, 0.039407004]\n",
      "Iter 1248, loss [-0.21303925, -0.25243637, 0.03939712]\n",
      "Iter 1249, loss [-0.22460194, -0.26107472, 0.03647278]\n",
      "Iter 1250, loss [-0.18708852, -0.23185532, 0.044766795]\n",
      "Iter 1251, loss [-0.21481153, -0.25046128, 0.035649747]\n",
      "Iter 1252, loss [-0.22317815, -0.26246068, 0.039282538]\n",
      "Iter 1253, loss [-0.2258687, -0.26444975, 0.038581036]\n",
      "Iter 1254, loss [-0.2258487, -0.26402587, 0.038177162]\n",
      "Iter 1255, loss [-0.22632775, -0.2648851, 0.038557343]\n",
      "Iter 1256, loss [-0.22809932, -0.2655252, 0.037425872]\n",
      "Iter 1257, loss [-0.22093499, -0.2587072, 0.03777221]\n",
      "Iter 1258, loss [-0.22601634, -0.26433992, 0.038323577]\n",
      "Iter 1259, loss [-0.22144069, -0.25987774, 0.038437054]\n",
      "Iter 1260, loss [-0.21612205, -0.25305054, 0.03692849]\n",
      "Iter 1261, loss [-0.22511125, -0.26305616, 0.03794491]\n",
      "Iter 1262, loss [-0.22950208, -0.26468652, 0.03518445]\n",
      "Iter 1263, loss [-0.22897732, -0.26545963, 0.0364823]\n",
      "Iter 1264, loss [-0.22396272, -0.26043963, 0.036476914]\n",
      "Iter 1265, loss [-0.18862747, -0.2359886, 0.047361135]\n",
      "Iter 1266, loss [-0.21489204, -0.25353688, 0.038644835]\n",
      "Iter 1267, loss [-0.22882828, -0.26428565, 0.03545737]\n",
      "Iter 1268, loss [-0.19991359, -0.24625379, 0.046340205]\n",
      "Iter 1269, loss [-0.22908998, -0.26584008, 0.0367501]\n",
      "Iter 1270, loss [-0.24061152, -0.2755508, 0.03493929]\n",
      "Iter 1271, loss [-0.21640745, -0.25605515, 0.039647706]\n",
      "Iter 1272, loss [-0.21110785, -0.24893919, 0.037831333]\n",
      "Iter 1273, loss [-0.22240874, -0.26121804, 0.038809307]\n",
      "Iter 1274, loss [-0.21584712, -0.25667596, 0.04082884]\n",
      "Iter 1275, loss [-0.22406948, -0.26268065, 0.03861117]\n",
      "Iter 1276, loss [-0.22168452, -0.2596069, 0.037922386]\n",
      "Iter 1277, loss [-0.21151364, -0.25159276, 0.040079117]\n",
      "Iter 1278, loss [-0.22271013, -0.25842586, 0.03571572]\n",
      "Iter 1279, loss [-0.21668112, -0.25440967, 0.037728556]\n",
      "Iter 1280, loss [-0.22678491, -0.2618568, 0.035071872]\n",
      "Iter 1281, loss [-0.21612181, -0.25539485, 0.03927304]\n",
      "Iter 1282, loss [-0.22347423, -0.261346, 0.037871785]\n",
      "Iter 1283, loss [-0.22309276, -0.26077542, 0.037682645]\n",
      "Iter 1284, loss [-0.2074997, -0.2509757, 0.043475997]\n",
      "Iter 1285, loss [-0.2323744, -0.26825705, 0.035882644]\n",
      "Iter 1286, loss [-0.21312569, -0.2545398, 0.041414093]\n",
      "Iter 1287, loss [-0.16449784, -0.22371118, 0.05921334]\n",
      "Iter 1288, loss [-0.23035975, -0.26673594, 0.03637619]\n",
      "Iter 1289, loss [-0.22576575, -0.26257303, 0.036807284]\n",
      "Iter 1290, loss [-0.22814903, -0.26486236, 0.036713332]\n",
      "Iter 1291, loss [-0.21803552, -0.25676882, 0.038733304]\n",
      "Iter 1292, loss [-0.21230774, -0.25155967, 0.03925194]\n",
      "Iter 1293, loss [-0.22865696, -0.2646887, 0.036031738]\n",
      "Iter 1294, loss [-0.21999092, -0.2565526, 0.03656168]\n",
      "Iter 1295, loss [-0.23195504, -0.26673195, 0.03477691]\n",
      "Iter 1296, loss [-0.22402425, -0.262743, 0.038718745]\n",
      "Iter 1297, loss [-0.22452646, -0.26056704, 0.03604058]\n",
      "Iter 1298, loss [-0.22845648, -0.2661057, 0.03764923]\n",
      "Iter 1299, loss [-0.22071476, -0.25859272, 0.037877962]\n",
      "Iter 1300, loss [-0.23054492, -0.26685944, 0.036314514]\n",
      "Iter 1301, loss [-0.22751868, -0.26446003, 0.036941357]\n",
      "Iter 1302, loss [-0.22730231, -0.2641757, 0.0368734]\n",
      "Iter 1303, loss [-0.22616088, -0.2613504, 0.03518951]\n",
      "Iter 1304, loss [-0.21706906, -0.25696537, 0.039896306]\n",
      "Iter 1305, loss [-0.22637433, -0.2648185, 0.03844416]\n",
      "Iter 1306, loss [-0.21344535, -0.25342932, 0.039983973]\n",
      "Iter 1307, loss [-0.22569105, -0.26270527, 0.03701421]\n",
      "Iter 1308, loss [-0.23156889, -0.26778385, 0.036214963]\n",
      "Iter 1309, loss [-0.22573256, -0.262896, 0.037163433]\n",
      "Iter 1310, loss [-0.22280528, -0.26055688, 0.0377516]\n",
      "Iter 1311, loss [-0.21645112, -0.2568983, 0.040447187]\n",
      "Iter 1312, loss [-0.21721604, -0.2560364, 0.038820356]\n",
      "Iter 1313, loss [-0.20802806, -0.25025916, 0.042231098]\n",
      "Iter 1314, loss [-0.22270706, -0.260907, 0.03819993]\n",
      "Iter 1315, loss [-0.21573791, -0.25565633, 0.039918423]\n",
      "Iter 1316, loss [-0.2283338, -0.2655435, 0.037209686]\n",
      "Iter 1317, loss [-0.23024967, -0.2678213, 0.03757163]\n",
      "Iter 1318, loss [-0.22799955, -0.26412633, 0.036126774]\n",
      "Iter 1319, loss [-0.21818425, -0.25907472, 0.04089047]\n",
      "Iter 1320, loss [-0.23384184, -0.269071, 0.03522917]\n",
      "Iter 1321, loss [-0.21619429, -0.25464916, 0.038454875]\n",
      "Iter 1322, loss [-0.20961228, -0.24965118, 0.040038906]\n",
      "Iter 1323, loss [-0.22743782, -0.26405367, 0.03661585]\n",
      "Iter 1324, loss [-0.19555742, -0.24299969, 0.047442265]\n",
      "Iter 1325, loss [-0.2246775, -0.2615977, 0.036920186]\n",
      "Iter 1326, loss [-0.22089657, -0.26115593, 0.04025937]\n",
      "Iter 1327, loss [-0.23145273, -0.26751506, 0.036062326]\n",
      "Iter 1328, loss [-0.22656333, -0.26307553, 0.036512204]\n",
      "Iter 1329, loss [-0.21851599, -0.25845715, 0.03994116]\n",
      "Iter 1330, loss [-0.22072238, -0.26008362, 0.039361242]\n",
      "Iter 1331, loss [-0.21057722, -0.25007868, 0.039501455]\n",
      "Iter 1332, loss [-0.22459674, -0.26269647, 0.038099736]\n",
      "Iter 1333, loss [-0.22957167, -0.266957, 0.037385337]\n",
      "Iter 1334, loss [-0.2142095, -0.25381523, 0.03960574]\n",
      "Iter 1335, loss [-0.23272564, -0.26894757, 0.036221936]\n",
      "Iter 1336, loss [-0.20782615, -0.25009373, 0.042267572]\n",
      "Iter 1337, loss [-0.23037869, -0.26641718, 0.03603848]\n",
      "Iter 1338, loss [-0.2199711, -0.2599322, 0.039961085]\n",
      "Iter 1339, loss [-0.21083981, -0.25063413, 0.03979432]\n",
      "Iter 1340, loss [-0.22515878, -0.26176116, 0.036602378]\n",
      "Iter 1341, loss [-0.2272322, -0.26197478, 0.034742575]\n",
      "Iter 1342, loss [-0.21662283, -0.25362423, 0.0370014]\n",
      "Iter 1343, loss [-0.16661859, -0.22223592, 0.055617332]\n",
      "Iter 1344, loss [-0.21142723, -0.25220874, 0.04078151]\n",
      "Iter 1345, loss [-0.22089103, -0.25895005, 0.038059026]\n",
      "Iter 1346, loss [-0.22283436, -0.2604817, 0.037647318]\n",
      "Iter 1347, loss [-0.22574592, -0.26274976, 0.037003852]\n",
      "Iter 1348, loss [-0.22571434, -0.2644051, 0.038690757]\n",
      "Iter 1349, loss [-0.23418558, -0.26980639, 0.0356208]\n",
      "Iter 1350, loss [-0.21362379, -0.25333145, 0.039707653]\n",
      "Iter 1351, loss [-0.22236165, -0.26225698, 0.039895326]\n",
      "Iter 1352, loss [-0.22236998, -0.2615983, 0.039228305]\n",
      "Iter 1353, loss [-0.21930502, -0.25891772, 0.039612696]\n",
      "Iter 1354, loss [-0.23460671, -0.270005, 0.03539827]\n",
      "Iter 1355, loss [-0.2279732, -0.264864, 0.036890805]\n",
      "Iter 1356, loss [-0.22695214, -0.2643004, 0.037348267]\n",
      "Iter 1357, loss [-0.224757, -0.26177377, 0.03701676]\n",
      "Iter 1358, loss [-0.22609413, -0.26323652, 0.037142403]\n",
      "Iter 1359, loss [-0.214638, -0.25512996, 0.040491972]\n",
      "Iter 1360, loss [-0.22400364, -0.26139778, 0.03739413]\n",
      "Iter 1361, loss [-0.22691259, -0.26452443, 0.03761184]\n",
      "Iter 1362, loss [-0.19737771, -0.24105984, 0.04368212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1363, loss [-0.21680358, -0.2562605, 0.039456926]\n",
      "Iter 1364, loss [-0.21229887, -0.2524388, 0.040139936]\n",
      "Iter 1365, loss [-0.22910765, -0.2652924, 0.036184754]\n",
      "Iter 1366, loss [-0.1706922, -0.22500262, 0.05431041]\n",
      "Iter 1367, loss [-0.1567229, -0.20848992, 0.051767014]\n",
      "Iter 1368, loss [-0.14564581, -0.2035643, 0.057918485]\n",
      "Iter 1369, loss [-0.16807665, -0.22094804, 0.052871387]\n",
      "Iter 1370, loss [-0.2222195, -0.2612888, 0.039069302]\n",
      "Iter 1371, loss [-0.22601877, -0.2620287, 0.03600992]\n",
      "Iter 1372, loss [-0.22266102, -0.25949013, 0.036829107]\n",
      "Iter 1373, loss [-0.21956147, -0.25869745, 0.039135978]\n",
      "Iter 1374, loss [-0.16536437, -0.22129948, 0.055935115]\n",
      "Iter 1375, loss [-0.21433364, -0.25382894, 0.039495304]\n",
      "Iter 1376, loss [-0.22675774, -0.26165044, 0.0348927]\n",
      "Iter 1377, loss [-0.19277644, -0.23962852, 0.046852082]\n",
      "Iter 1378, loss [-0.22291072, -0.25917315, 0.036262438]\n",
      "Iter 1379, loss [-0.21283558, -0.25305617, 0.040220585]\n",
      "Iter 1380, loss [-0.2294667, -0.26463988, 0.03517317]\n",
      "Iter 1381, loss [-0.21484391, -0.25502488, 0.040180966]\n",
      "Iter 1382, loss [-0.22633564, -0.26341826, 0.03708262]\n",
      "Iter 1383, loss [-0.21539709, -0.2568603, 0.04146319]\n",
      "Iter 1384, loss [-0.13469172, -0.19681436, 0.06212265]\n",
      "Iter 1385, loss [-0.2133643, -0.2537359, 0.04037159]\n",
      "Iter 1386, loss [-0.21566248, -0.25426614, 0.03860367]\n",
      "Iter 1387, loss [-0.22337729, -0.2586716, 0.035294324]\n",
      "Iter 1388, loss [-0.20845225, -0.24717106, 0.038718797]\n",
      "Iter 1389, loss [-0.22616872, -0.26053548, 0.034366757]\n",
      "Iter 1390, loss [-0.21346028, -0.25259468, 0.039134398]\n",
      "Iter 1391, loss [-0.2175716, -0.25617853, 0.038606927]\n",
      "Iter 1392, loss [-0.21420673, -0.25132617, 0.03711945]\n",
      "Iter 1393, loss [-0.21704046, -0.25304466, 0.0360042]\n",
      "Iter 1394, loss [-0.22061461, -0.25970572, 0.03909111]\n",
      "Iter 1395, loss [-0.2258882, -0.2631275, 0.037239306]\n",
      "Iter 1396, loss [-0.19973448, -0.24225657, 0.042522088]\n",
      "Iter 1397, loss [-0.22234719, -0.25965473, 0.03730755]\n",
      "Iter 1398, loss [-0.21627268, -0.2549057, 0.03863301]\n",
      "Iter 1399, loss [-0.21971363, -0.2592061, 0.039492458]\n",
      "Iter 1400, loss [-0.22397456, -0.26160228, 0.037627734]\n",
      "Iter 1401, loss [-0.22401994, -0.26392823, 0.039908297]\n",
      "Iter 1402, loss [-0.22989038, -0.26755774, 0.037667356]\n",
      "Iter 1403, loss [-0.2130403, -0.25259775, 0.039557442]\n",
      "Iter 1404, loss [-0.22543311, -0.26297185, 0.03753873]\n",
      "Iter 1405, loss [-0.22513175, -0.2623021, 0.037170347]\n",
      "Iter 1406, loss [-0.22359584, -0.26093104, 0.037335202]\n",
      "Iter 1407, loss [-0.2302096, -0.26730764, 0.03709804]\n",
      "Iter 1408, loss [-0.2202882, -0.258273, 0.0379848]\n",
      "Iter 1409, loss [-0.21886382, -0.25778702, 0.03892321]\n",
      "Iter 1410, loss [-0.23102129, -0.26666084, 0.035639547]\n",
      "Iter 1411, loss [-0.22840711, -0.26592004, 0.037512925]\n",
      "Iter 1412, loss [-0.22098428, -0.26142254, 0.04043827]\n",
      "Iter 1413, loss [-0.2239188, -0.2617969, 0.037878104]\n",
      "Iter 1414, loss [-0.22506008, -0.2598437, 0.03478363]\n",
      "Iter 1415, loss [-0.22518411, -0.26187158, 0.03668746]\n",
      "Iter 1416, loss [-0.22375713, -0.26174518, 0.037988048]\n",
      "Iter 1417, loss [-0.19231899, -0.236, 0.043681007]\n",
      "Iter 1418, loss [-0.22009966, -0.2590076, 0.03890795]\n",
      "Iter 1419, loss [-0.22277275, -0.2593077, 0.036534965]\n",
      "Iter 1420, loss [-0.21986309, -0.25916305, 0.039299972]\n",
      "Iter 1421, loss [-0.16541079, -0.22250068, 0.057089895]\n",
      "Iter 1422, loss [-0.22237349, -0.25945997, 0.03708648]\n",
      "Iter 1423, loss [-0.22029442, -0.2585738, 0.03827939]\n",
      "Iter 1424, loss [-0.22099786, -0.25941464, 0.038416788]\n",
      "Iter 1425, loss [-0.22403198, -0.2629184, 0.038886424]\n",
      "Iter 1426, loss [-0.22720456, -0.2633057, 0.036101125]\n",
      "Iter 1427, loss [-0.2299065, -0.265825, 0.0359185]\n",
      "Iter 1428, loss [-0.22774234, -0.26660076, 0.03885841]\n",
      "Iter 1429, loss [-0.21534537, -0.25473717, 0.039391797]\n",
      "Iter 1430, loss [-0.22660401, -0.26413658, 0.037532568]\n",
      "Iter 1431, loss [-0.2218213, -0.2607522, 0.03893091]\n",
      "Iter 1432, loss [-0.1939823, -0.24028106, 0.046298765]\n",
      "Iter 1433, loss [-0.2327695, -0.26761812, 0.03484861]\n",
      "Iter 1434, loss [-0.22556241, -0.2625159, 0.036953494]\n",
      "Iter 1435, loss [-0.2219376, -0.2594469, 0.037509292]\n",
      "Iter 1436, loss [-0.21994483, -0.25732958, 0.037384745]\n",
      "Iter 1437, loss [-0.22290304, -0.2616118, 0.038708746]\n",
      "Iter 1438, loss [-0.22788458, -0.26421037, 0.036325797]\n",
      "Iter 1439, loss [-0.21613716, -0.2559756, 0.03983845]\n",
      "Iter 1440, loss [-0.22431722, -0.26272473, 0.038407512]\n",
      "Iter 1441, loss [-0.20383154, -0.24723354, 0.043401998]\n",
      "Iter 1442, loss [-0.2136965, -0.25249404, 0.038797542]\n",
      "Iter 1443, loss [-0.23175499, -0.26653796, 0.034782972]\n",
      "Iter 1444, loss [-0.22277662, -0.26203755, 0.03926092]\n",
      "Iter 1445, loss [-0.21217202, -0.24778518, 0.035613164]\n",
      "Iter 1446, loss [-0.21439114, -0.25680494, 0.042413797]\n",
      "Iter 1447, loss [-0.23394428, -0.27021256, 0.036268275]\n",
      "Iter 1448, loss [-0.22417784, -0.26197386, 0.037796013]\n",
      "Iter 1449, loss [-0.22109666, -0.25665742, 0.035560753]\n",
      "Iter 1450, loss [-0.20800838, -0.2500359, 0.042027533]\n",
      "Iter 1451, loss [-0.22440511, -0.26025248, 0.035847373]\n",
      "Iter 1452, loss [-0.21948242, -0.259221, 0.03973857]\n",
      "Iter 1453, loss [-0.22811723, -0.26533586, 0.037218634]\n",
      "Iter 1454, loss [-0.22409159, -0.2627744, 0.03868281]\n",
      "Iter 1455, loss [-0.22901167, -0.2638455, 0.034833834]\n",
      "Iter 1456, loss [-0.21902138, -0.25750646, 0.038485087]\n",
      "Iter 1457, loss [-0.2191073, -0.25574303, 0.036635734]\n",
      "Iter 1458, loss [-0.22467826, -0.26216203, 0.03748377]\n",
      "Iter 1459, loss [-0.21083088, -0.25073215, 0.03990127]\n",
      "Iter 1460, loss [-0.22772422, -0.26564506, 0.037920836]\n",
      "Iter 1461, loss [-0.21689267, -0.25757498, 0.0406823]\n",
      "Iter 1462, loss [-0.22797313, -0.26612604, 0.038152903]\n",
      "Iter 1463, loss [-0.22255073, -0.26013792, 0.037587177]\n",
      "Iter 1464, loss [-0.23368259, -0.26897958, 0.03529699]\n",
      "Iter 1465, loss [-0.2170922, -0.25526595, 0.038173746]\n",
      "Iter 1466, loss [-0.21978737, -0.25702888, 0.0372415]\n",
      "Iter 1467, loss [-0.22368474, -0.26074156, 0.037056815]\n",
      "Iter 1468, loss [-0.22823343, -0.26452518, 0.036291752]\n",
      "Iter 1469, loss [-0.22480735, -0.26319203, 0.038384672]\n",
      "Iter 1470, loss [-0.22421074, -0.26379076, 0.039580014]\n",
      "Iter 1471, loss [-0.2199335, -0.25960076, 0.039667264]\n",
      "Iter 1472, loss [-0.2236657, -0.26297984, 0.039314136]\n",
      "Iter 1473, loss [-0.2182358, -0.25798178, 0.039745975]\n",
      "Iter 1474, loss [-0.21026799, -0.25210848, 0.041840494]\n",
      "Iter 1475, loss [-0.2243253, -0.2603169, 0.03599161]\n",
      "Iter 1476, loss [-0.22223407, -0.2604128, 0.03817875]\n",
      "Iter 1477, loss [-0.22465831, -0.26218128, 0.037522964]\n",
      "Iter 1478, loss [-0.22812733, -0.2648812, 0.03675386]\n",
      "Iter 1479, loss [-0.19724491, -0.24742691, 0.050181996]\n",
      "Iter 1480, loss [-0.21840365, -0.25804928, 0.039645623]\n",
      "Iter 1481, loss [-0.21752317, -0.25526848, 0.03774531]\n",
      "Iter 1482, loss [-0.22414364, -0.2621367, 0.037993055]\n",
      "Iter 1483, loss [-0.15594035, -0.20762573, 0.051685385]\n",
      "Iter 1484, loss [-0.22461417, -0.2628064, 0.03819222]\n",
      "Iter 1485, loss [-0.22401832, -0.26275158, 0.038733263]\n",
      "Iter 1486, loss [-0.22187646, -0.26320395, 0.04132749]\n",
      "Iter 1487, loss [-0.16691366, -0.22277585, 0.055862196]\n",
      "Iter 1488, loss [-0.22661148, -0.2627837, 0.036172222]\n",
      "Iter 1489, loss [-0.22586484, -0.26263097, 0.036766123]\n",
      "Iter 1490, loss [-0.2202403, -0.2572889, 0.037048616]\n",
      "Iter 1491, loss [-0.21909729, -0.2572489, 0.038151614]\n",
      "Iter 1492, loss [-0.22866608, -0.26390898, 0.0352429]\n",
      "Iter 1493, loss [-0.21944837, -0.25679636, 0.037347987]\n",
      "Iter 1494, loss [-0.22126618, -0.25657785, 0.035311665]\n",
      "Iter 1495, loss [-0.21925707, -0.25989008, 0.040633004]\n",
      "Iter 1496, loss [-0.22063592, -0.262318, 0.04168206]\n",
      "Iter 1497, loss [-0.20699096, -0.25015, 0.04315903]\n",
      "Iter 1498, loss [-0.22880846, -0.2673342, 0.03852573]\n",
      "Iter 1499, loss [-0.16377737, -0.21973644, 0.055959072]\n",
      "Iter 1500, loss [-0.22036964, -0.25978503, 0.039415397]\n",
      "Iter 1501, loss [-0.21827771, -0.25796592, 0.03968821]\n",
      "Iter 1502, loss [-0.21122633, -0.25202745, 0.040801123]\n",
      "Iter 1503, loss [-0.15493397, -0.21115777, 0.05622379]\n",
      "Iter 1504, loss [-0.22617623, -0.26291916, 0.036742933]\n",
      "Iter 1505, loss [-0.22978124, -0.2646492, 0.03486798]\n",
      "Iter 1506, loss [-0.21216068, -0.25198606, 0.039825387]\n",
      "Iter 1507, loss [-0.2346006, -0.26951286, 0.034912255]\n",
      "Iter 1508, loss [-0.21879134, -0.257542, 0.03875068]\n",
      "Iter 1509, loss [-0.21582666, -0.25470123, 0.038874574]\n",
      "Iter 1510, loss [-0.2086851, -0.24665648, 0.037971385]\n",
      "Iter 1511, loss [-0.18740094, -0.23446454, 0.0470636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1512, loss [-0.22406484, -0.26073676, 0.036671918]\n",
      "Iter 1513, loss [-0.15913239, -0.2145145, 0.05538211]\n",
      "Iter 1514, loss [-0.22260554, -0.26040375, 0.037798215]\n",
      "Iter 1515, loss [-0.22943088, -0.2678186, 0.038387723]\n",
      "Iter 1516, loss [-0.2075428, -0.2496077, 0.042064898]\n",
      "Iter 1517, loss [-0.22921324, -0.26589015, 0.03667692]\n",
      "Iter 1518, loss [-0.17366311, -0.22490634, 0.05124324]\n",
      "Iter 1519, loss [-0.21745268, -0.2569381, 0.039485417]\n",
      "Iter 1520, loss [-0.22856744, -0.26577297, 0.037205532]\n",
      "Iter 1521, loss [-0.22554506, -0.2621413, 0.03659622]\n",
      "Iter 1522, loss [-0.2268381, -0.26316148, 0.036323383]\n",
      "Iter 1523, loss [-0.210545, -0.25163642, 0.04109141]\n",
      "Iter 1524, loss [-0.22639942, -0.26400498, 0.037605546]\n",
      "Iter 1525, loss [-0.14856383, -0.20954357, 0.060979735]\n",
      "Iter 1526, loss [-0.22300825, -0.26038966, 0.03738141]\n",
      "Iter 1527, loss [-0.22007158, -0.2583452, 0.03827361]\n",
      "Iter 1528, loss [-0.2145704, -0.2552665, 0.04069608]\n",
      "Iter 1529, loss [-0.21697377, -0.2564617, 0.039487943]\n",
      "Iter 1530, loss [-0.23001498, -0.26480836, 0.034793377]\n",
      "Iter 1531, loss [-0.21909246, -0.26040146, 0.041308995]\n",
      "Iter 1532, loss [-0.2260458, -0.263105, 0.037059203]\n",
      "Iter 1533, loss [-0.2098631, -0.25075957, 0.040896483]\n",
      "Iter 1534, loss [-0.22137626, -0.26045492, 0.039078664]\n",
      "Iter 1535, loss [-0.21868926, -0.2575111, 0.038821846]\n",
      "Iter 1536, loss [-0.22370401, -0.26225218, 0.03854817]\n",
      "Iter 1537, loss [-0.21371733, -0.25391334, 0.040196016]\n",
      "Iter 1538, loss [-0.22691749, -0.26317433, 0.03625683]\n",
      "Iter 1539, loss [-0.31108466, -0.3186073, 0.007522657]\n",
      "Iter 1540, loss [-0.21558833, -0.2563758, 0.04078745]\n",
      "Iter 1541, loss [-0.2222343, -0.25909767, 0.036863368]\n",
      "Iter 1542, loss [-0.22238584, -0.2589557, 0.03656985]\n",
      "Iter 1543, loss [-0.20537145, -0.24344602, 0.038074564]\n",
      "Iter 1544, loss [-0.21863598, -0.25753745, 0.038901478]\n",
      "Iter 1545, loss [-0.2245225, -0.26057738, 0.036054883]\n",
      "Iter 1546, loss [-0.16453415, -0.21874845, 0.054214306]\n",
      "Iter 1547, loss [-0.22030693, -0.25961566, 0.039308727]\n",
      "Iter 1548, loss [-0.22211558, -0.26025578, 0.038140208]\n",
      "Iter 1549, loss [-0.22121859, -0.259872, 0.0386534]\n",
      "Iter 1550, loss [-0.21825099, -0.25755912, 0.03930814]\n",
      "Iter 1551, loss [-0.2276258, -0.263191, 0.035565212]\n",
      "Iter 1552, loss [-0.21833618, -0.25753206, 0.039195884]\n",
      "Iter 1553, loss [-0.21410479, -0.24988301, 0.035778224]\n",
      "Iter 1554, loss [-0.22497898, -0.26044974, 0.03547076]\n",
      "Iter 1555, loss [-0.2250278, -0.2613366, 0.036308795]\n",
      "Iter 1556, loss [-0.22215003, -0.2616047, 0.03945467]\n",
      "Iter 1557, loss [-0.22063923, -0.25944066, 0.03880144]\n",
      "Iter 1558, loss [-0.21926314, -0.2585804, 0.039317258]\n",
      "Iter 1559, loss [-0.16131371, -0.21367694, 0.05236324]\n",
      "Iter 1560, loss [-0.21844447, -0.2580746, 0.039630145]\n",
      "Iter 1561, loss [-0.21588354, -0.25583887, 0.03995533]\n",
      "Iter 1562, loss [-0.21125594, -0.25256935, 0.04131341]\n",
      "Iter 1563, loss [-0.2266493, -0.26320314, 0.036553845]\n",
      "Iter 1564, loss [-0.20300749, -0.24668927, 0.043681778]\n",
      "Iter 1565, loss [-0.21638954, -0.25602633, 0.03963679]\n",
      "Iter 1566, loss [-0.2306602, -0.26751158, 0.036851373]\n",
      "Iter 1567, loss [-0.22935075, -0.26638308, 0.037032336]\n",
      "Iter 1568, loss [-0.2201777, -0.2585814, 0.038403705]\n",
      "Iter 1569, loss [-0.22902876, -0.26606232, 0.037033565]\n",
      "Iter 1570, loss [-0.21312177, -0.25501543, 0.041893654]\n",
      "Iter 1571, loss [-0.22453886, -0.26022798, 0.03568911]\n",
      "Iter 1572, loss [-0.21233371, -0.25046298, 0.038129263]\n",
      "Iter 1573, loss [-0.22619586, -0.2626464, 0.03645055]\n",
      "Iter 1574, loss [-0.20939574, -0.25125188, 0.04185614]\n",
      "Iter 1575, loss [-0.22026989, -0.25926358, 0.038993686]\n",
      "Iter 1576, loss [-0.21343955, -0.25459635, 0.041156802]\n",
      "Iter 1577, loss [-0.19306165, -0.24047732, 0.047415666]\n",
      "Iter 1578, loss [-0.22336599, -0.26211974, 0.038753744]\n",
      "Iter 1579, loss [-0.2200701, -0.25779867, 0.037728585]\n",
      "Iter 1580, loss [-0.13114196, -0.1947595, 0.06361755]\n",
      "Iter 1581, loss [-0.2237309, -0.26104695, 0.03731604]\n",
      "Iter 1582, loss [-0.22152716, -0.25834385, 0.036816694]\n",
      "Iter 1583, loss [-0.22998828, -0.26376498, 0.033776708]\n",
      "Iter 1584, loss [-0.22155182, -0.25658813, 0.03503631]\n",
      "Iter 1585, loss [-0.21839485, -0.25647682, 0.038081974]\n",
      "Iter 1586, loss [-0.20426741, -0.24687955, 0.042612135]\n",
      "Iter 1587, loss [-0.2277971, -0.26474375, 0.03694664]\n",
      "Iter 1588, loss [-0.22394703, -0.26383376, 0.039886724]\n",
      "Iter 1589, loss [-0.22470589, -0.2647226, 0.040016696]\n",
      "Iter 1590, loss [-0.22236836, -0.2613803, 0.039011955]\n",
      "Iter 1591, loss [-0.2178904, -0.2553931, 0.037502695]\n",
      "Iter 1592, loss [-0.21987976, -0.2574452, 0.03756542]\n",
      "Iter 1593, loss [-0.23002839, -0.26531374, 0.03528536]\n",
      "Iter 1594, loss [-0.13011152, -0.18344459, 0.053333074]\n",
      "Iter 1595, loss [-0.21132526, -0.25174826, 0.040423]\n",
      "Iter 1596, loss [-0.22349127, -0.26072407, 0.0372328]\n",
      "Iter 1597, loss [-0.18822402, -0.23515376, 0.04692974]\n",
      "Iter 1598, loss [-0.20234925, -0.24283661, 0.04048737]\n",
      "Iter 1599, loss [-0.22278133, -0.2626403, 0.039858975]\n",
      "Iter 1600, loss [-0.20171948, -0.24471606, 0.04299658]\n",
      "Iter 1601, loss [-0.20882073, -0.24942961, 0.04060888]\n",
      "Iter 1602, loss [-0.22360028, -0.2611964, 0.03759612]\n",
      "Iter 1603, loss [-0.22099754, -0.25914237, 0.038144834]\n",
      "Iter 1604, loss [-0.21697555, -0.25371078, 0.036735218]\n",
      "Iter 1605, loss [-0.22280538, -0.2613423, 0.03853691]\n",
      "Iter 1606, loss [-0.2219111, -0.25787154, 0.03596043]\n",
      "Iter 1607, loss [-0.14873737, -0.20597075, 0.05723337]\n",
      "Iter 1608, loss [-0.22359864, -0.26328346, 0.039684813]\n",
      "Iter 1609, loss [-0.21575262, -0.25102153, 0.035268914]\n",
      "Iter 1610, loss [-0.22145703, -0.2595489, 0.038091876]\n",
      "Iter 1611, loss [-0.17044553, -0.22289343, 0.052447893]\n",
      "Iter 1612, loss [-0.22192731, -0.26052958, 0.038602255]\n",
      "Iter 1613, loss [-0.22258279, -0.26034895, 0.03776616]\n",
      "Iter 1614, loss [-0.18012705, -0.23267777, 0.052550726]\n",
      "Iter 1615, loss [-0.2135572, -0.25272548, 0.039168287]\n",
      "Iter 1616, loss [-0.21793482, -0.25734735, 0.03941253]\n",
      "Iter 1617, loss [-0.21724312, -0.25902086, 0.041777745]\n",
      "Iter 1618, loss [-0.22337234, -0.2626163, 0.03924396]\n",
      "Iter 1619, loss [-0.21366313, -0.25442424, 0.040761106]\n",
      "Iter 1620, loss [-0.22788478, -0.26380122, 0.035916433]\n",
      "Iter 1621, loss [-0.23017198, -0.266338, 0.036166012]\n",
      "Iter 1622, loss [-0.22346196, -0.26058087, 0.037118908]\n",
      "Iter 1623, loss [-0.22938073, -0.265922, 0.036541283]\n",
      "Iter 1624, loss [-0.21596737, -0.25150377, 0.035536394]\n",
      "Iter 1625, loss [-0.21315858, -0.25310126, 0.03994269]\n",
      "Iter 1626, loss [-0.22217159, -0.26204616, 0.039874565]\n",
      "Iter 1627, loss [-0.2158767, -0.25363457, 0.03775787]\n",
      "Iter 1628, loss [-0.22909254, -0.265355, 0.03626246]\n",
      "Iter 1629, loss [-0.2125696, -0.25076836, 0.038198765]\n",
      "Iter 1630, loss [-0.212973, -0.253528, 0.040555008]\n",
      "Iter 1631, loss [-0.23384628, -0.26837173, 0.03452546]\n",
      "Iter 1632, loss [-0.22331633, -0.2619524, 0.038636077]\n",
      "Iter 1633, loss [-0.22580905, -0.26276, 0.036950957]\n",
      "Iter 1634, loss [-0.21279359, -0.25172192, 0.03892833]\n",
      "Iter 1635, loss [-0.22255602, -0.26038972, 0.037833687]\n",
      "Iter 1636, loss [-0.21396783, -0.2545724, 0.04060456]\n",
      "Iter 1637, loss [-0.19663784, -0.2396189, 0.042981055]\n",
      "Iter 1638, loss [-0.13561484, -0.1937346, 0.058119755]\n",
      "Iter 1639, loss [-0.22442527, -0.26093212, 0.03650685]\n",
      "Iter 1640, loss [-0.2342816, -0.26925144, 0.034969836]\n",
      "Iter 1641, loss [-0.22163926, -0.26012486, 0.038485598]\n",
      "Iter 1642, loss [-0.21419242, -0.2496341, 0.03544168]\n",
      "Iter 1643, loss [-0.2266263, -0.2648847, 0.038258407]\n",
      "Iter 1644, loss [-0.20848428, -0.2500417, 0.041557413]\n",
      "Iter 1645, loss [-0.21659163, -0.25489643, 0.038304806]\n",
      "Iter 1646, loss [-0.22444105, -0.26159018, 0.037149135]\n",
      "Iter 1647, loss [-0.22182217, -0.2584456, 0.03662341]\n",
      "Iter 1648, loss [-0.22389288, -0.2603814, 0.036488514]\n",
      "Iter 1649, loss [-0.2227187, -0.26011994, 0.03740124]\n",
      "Iter 1650, loss [-0.19376203, -0.23764062, 0.043878585]\n",
      "Iter 1651, loss [-0.21550778, -0.25365445, 0.038146675]\n",
      "Iter 1652, loss [-0.22918093, -0.26609716, 0.036916226]\n",
      "Iter 1653, loss [-0.21991117, -0.26035455, 0.040443372]\n",
      "Iter 1654, loss [-0.22432862, -0.26194242, 0.03761379]\n",
      "Iter 1655, loss [-0.22041482, -0.25813165, 0.037716836]\n",
      "Iter 1656, loss [-0.2261464, -0.26255354, 0.036407143]\n",
      "Iter 1657, loss [-0.2195707, -0.25593054, 0.036359847]\n",
      "Iter 1658, loss [-0.22778301, -0.2624985, 0.03471549]\n",
      "Iter 1659, loss [-0.22393394, -0.2624697, 0.038535766]\n",
      "Iter 1660, loss [-0.2227497, -0.26043144, 0.037681747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1661, loss [-0.2220782, -0.26132053, 0.039242327]\n",
      "Iter 1662, loss [-0.20829418, -0.25005746, 0.04176327]\n",
      "Iter 1663, loss [-0.22864914, -0.26598832, 0.03733919]\n",
      "Iter 1664, loss [-0.20613867, -0.24693884, 0.04080017]\n",
      "Iter 1665, loss [-0.2196001, -0.25848156, 0.038881466]\n",
      "Iter 1666, loss [-0.22835243, -0.26395878, 0.035606354]\n",
      "Iter 1667, loss [-0.22978874, -0.2636438, 0.03385507]\n",
      "Iter 1668, loss [-0.22788237, -0.26509407, 0.037211705]\n",
      "Iter 1669, loss [-0.22011387, -0.2581989, 0.038085014]\n",
      "Iter 1670, loss [-0.18793952, -0.2400765, 0.05213697]\n",
      "Iter 1671, loss [-0.22167382, -0.25842273, 0.036748916]\n",
      "Iter 1672, loss [-0.21578722, -0.25623104, 0.040443823]\n",
      "Iter 1673, loss [-0.21982682, -0.260507, 0.040680163]\n",
      "Iter 1674, loss [-0.22498298, -0.26388133, 0.03889835]\n",
      "Iter 1675, loss [-0.22378916, -0.26100278, 0.037213616]\n",
      "Iter 1676, loss [-0.22730067, -0.26345605, 0.036155373]\n",
      "Iter 1677, loss [-0.22215827, -0.25976267, 0.037604406]\n",
      "Iter 1678, loss [-0.22395161, -0.26024228, 0.036290675]\n",
      "Iter 1679, loss [-0.22572675, -0.26288062, 0.037153877]\n",
      "Iter 1680, loss [-0.22830522, -0.26535997, 0.037054747]\n",
      "Iter 1681, loss [-0.21746469, -0.25673008, 0.03926539]\n",
      "Iter 1682, loss [-0.22636133, -0.26542416, 0.03906282]\n",
      "Iter 1683, loss [-0.2292375, -0.26462582, 0.035388317]\n",
      "Iter 1684, loss [-0.21563426, -0.25678468, 0.04115043]\n",
      "Iter 1685, loss [-0.23001188, -0.26728275, 0.037270866]\n",
      "Iter 1686, loss [-0.20488113, -0.24882357, 0.043942437]\n",
      "Iter 1687, loss [-0.22227412, -0.26008487, 0.037810735]\n",
      "Iter 1688, loss [-0.21589392, -0.24988404, 0.03399011]\n",
      "Iter 1689, loss [-0.22260654, -0.2593064, 0.03669987]\n",
      "Iter 1690, loss [-0.22989453, -0.26595274, 0.036058206]\n",
      "Iter 1691, loss [-0.22448432, -0.26232892, 0.03784459]\n",
      "Iter 1692, loss [-0.2204318, -0.25953293, 0.039101116]\n",
      "Iter 1693, loss [-0.1787142, -0.23114586, 0.052431658]\n",
      "Iter 1694, loss [-0.22340494, -0.2632838, 0.039878845]\n",
      "Iter 1695, loss [-0.186863, -0.23381475, 0.04695175]\n",
      "Iter 1696, loss [-0.22043365, -0.25940594, 0.03897229]\n",
      "Iter 1697, loss [-0.22278918, -0.26189354, 0.039104354]\n",
      "Iter 1698, loss [-0.22493437, -0.2632619, 0.038327537]\n",
      "Iter 1699, loss [-0.22603647, -0.26314294, 0.037106466]\n",
      "Iter 1700, loss [-0.21820065, -0.2563855, 0.03818486]\n",
      "Iter 1701, loss [-0.22258937, -0.26008952, 0.037500143]\n",
      "Iter 1702, loss [-0.21865837, -0.25647372, 0.037815344]\n",
      "Iter 1703, loss [-0.2301946, -0.26699373, 0.036799125]\n",
      "Iter 1704, loss [-0.21761449, -0.2573975, 0.039783016]\n",
      "Iter 1705, loss [-0.22932081, -0.2647013, 0.035380494]\n",
      "Iter 1706, loss [-0.22597867, -0.26270092, 0.03672225]\n",
      "Iter 1707, loss [-0.22086027, -0.2602075, 0.039347224]\n",
      "Iter 1708, loss [-0.21312265, -0.253708, 0.040585354]\n",
      "Iter 1709, loss [-0.21814321, -0.25741282, 0.039269608]\n",
      "Iter 1710, loss [-0.21653351, -0.25562698, 0.039093465]\n",
      "Iter 1711, loss [-0.22100547, -0.25888664, 0.037881166]\n",
      "Iter 1712, loss [-0.23350814, -0.26838595, 0.034877814]\n",
      "Iter 1713, loss [-0.21633781, -0.25614518, 0.039807364]\n",
      "Iter 1714, loss [-0.21558765, -0.25638503, 0.040797375]\n",
      "Iter 1715, loss [-0.23199208, -0.2670202, 0.03502811]\n",
      "Iter 1716, loss [-0.21738505, -0.2573531, 0.039968044]\n",
      "Iter 1717, loss [-0.22930539, -0.2660166, 0.03671121]\n",
      "Iter 1718, loss [-0.21897057, -0.25877577, 0.03980521]\n",
      "Iter 1719, loss [-0.21957278, -0.25820497, 0.038632177]\n",
      "Iter 1720, loss [-0.22195622, -0.26082566, 0.038869433]\n",
      "Iter 1721, loss [-0.22650394, -0.26274574, 0.0362418]\n",
      "Iter 1722, loss [-0.2031492, -0.24329332, 0.040144112]\n",
      "Iter 1723, loss [-0.22156727, -0.25655335, 0.03498607]\n",
      "Iter 1724, loss [-0.21376781, -0.25505993, 0.041292116]\n",
      "Iter 1725, loss [-0.2253088, -0.2628326, 0.037523806]\n",
      "Iter 1726, loss [-0.22470704, -0.26321143, 0.0385044]\n",
      "Iter 1727, loss [-0.21230899, -0.25206405, 0.039755065]\n",
      "Iter 1728, loss [-0.21528915, -0.25730255, 0.042013403]\n",
      "Iter 1729, loss [-0.22028163, -0.25801024, 0.0377286]\n",
      "Iter 1730, loss [-0.22085437, -0.25915167, 0.0382973]\n",
      "Iter 1731, loss [-0.22649533, -0.26411882, 0.03762349]\n",
      "Iter 1732, loss [-0.20675577, -0.24584481, 0.039089035]\n",
      "Iter 1733, loss [-0.23328955, -0.26891896, 0.035629403]\n",
      "Iter 1734, loss [-0.22960599, -0.2650431, 0.035437122]\n",
      "Iter 1735, loss [-0.22524147, -0.26259837, 0.0373569]\n",
      "Iter 1736, loss [-0.22612733, -0.26306212, 0.036934793]\n",
      "Iter 1737, loss [-0.21964552, -0.25740373, 0.03775822]\n",
      "Iter 1738, loss [-0.22439712, -0.26058415, 0.03618703]\n",
      "Iter 1739, loss [-0.2229994, -0.25984496, 0.03684556]\n",
      "Iter 1740, loss [-0.21422897, -0.25282025, 0.038591277]\n",
      "Iter 1741, loss [-0.21473074, -0.254803, 0.040072262]\n",
      "Iter 1742, loss [-0.22057751, -0.26022142, 0.03964391]\n",
      "Iter 1743, loss [-0.22105208, -0.25999358, 0.03894151]\n",
      "Iter 1744, loss [-0.22588879, -0.2634191, 0.037530303]\n",
      "Iter 1745, loss [-0.21777633, -0.2583376, 0.040561266]\n",
      "Iter 1746, loss [-0.23152462, -0.26621076, 0.03468614]\n",
      "Iter 1747, loss [-0.2284233, -0.26375788, 0.03533458]\n",
      "Iter 1748, loss [-0.20174882, -0.24240519, 0.04065638]\n",
      "Iter 1749, loss [-0.22719584, -0.26453206, 0.03733621]\n",
      "Iter 1750, loss [-0.22363248, -0.26227358, 0.038641103]\n",
      "Iter 1751, loss [-0.19251677, -0.23882896, 0.046312183]\n",
      "Iter 1752, loss [-0.20173016, -0.24643223, 0.044702064]\n",
      "Iter 1753, loss [-0.21710917, -0.25735468, 0.04024551]\n",
      "Iter 1754, loss [-0.22046907, -0.2581038, 0.03763471]\n",
      "Iter 1755, loss [-0.22086853, -0.25804856, 0.03718004]\n",
      "Iter 1756, loss [-0.22179757, -0.25893402, 0.03713645]\n",
      "Iter 1757, loss [-0.22143924, -0.25940633, 0.037967093]\n",
      "Iter 1758, loss [-0.22700134, -0.26400775, 0.037006408]\n",
      "Iter 1759, loss [-0.22643968, -0.26347473, 0.037035044]\n",
      "Iter 1760, loss [-0.22348535, -0.26097617, 0.037490822]\n",
      "Iter 1761, loss [-0.2230058, -0.26184717, 0.038841374]\n",
      "Iter 1762, loss [-0.22434065, -0.2640847, 0.039744057]\n",
      "Iter 1763, loss [-0.2184138, -0.25878274, 0.040368937]\n",
      "Iter 1764, loss [-0.21888158, -0.25871563, 0.03983406]\n",
      "Iter 1765, loss [-0.22006251, -0.25959164, 0.039529126]\n",
      "Iter 1766, loss [-0.19808668, -0.24181348, 0.043726794]\n",
      "Iter 1767, loss [-0.21341018, -0.2535081, 0.040097903]\n",
      "Iter 1768, loss [-0.22686523, -0.26405618, 0.03719094]\n",
      "Iter 1769, loss [-0.22461988, -0.26057878, 0.0359589]\n",
      "Iter 1770, loss [-0.21530858, -0.25532353, 0.040014945]\n",
      "Iter 1771, loss [-0.23470668, -0.27029762, 0.035590928]\n",
      "Iter 1772, loss [-0.21803717, -0.2554741, 0.037436917]\n",
      "Iter 1773, loss [-0.22537929, -0.26216745, 0.036788173]\n",
      "Iter 1774, loss [-0.2311481, -0.26649314, 0.035345048]\n",
      "Iter 1775, loss [-0.21278161, -0.25034943, 0.037567824]\n",
      "Iter 1776, loss [-0.22182891, -0.25883394, 0.037005033]\n",
      "Iter 1777, loss [-0.22191808, -0.2596597, 0.037741624]\n",
      "Iter 1778, loss [-0.22788024, -0.26505294, 0.037172697]\n",
      "Iter 1779, loss [-0.23030573, -0.26739225, 0.03708651]\n",
      "Iter 1780, loss [-0.22162119, -0.26036134, 0.038740166]\n",
      "Iter 1781, loss [-0.22508118, -0.26235735, 0.03727617]\n",
      "Iter 1782, loss [-0.23068327, -0.26752207, 0.036838792]\n",
      "Iter 1783, loss [-0.22955345, -0.26546448, 0.03591104]\n",
      "Iter 1784, loss [-0.22976357, -0.26494062, 0.03517705]\n",
      "Iter 1785, loss [-0.22350898, -0.2601236, 0.03661462]\n",
      "Iter 1786, loss [-0.21877977, -0.2574809, 0.038701124]\n",
      "Iter 1787, loss [-0.22603372, -0.26281267, 0.036778957]\n",
      "Iter 1788, loss [-0.22113428, -0.25722364, 0.03608937]\n",
      "Iter 1789, loss [-0.21792355, -0.25868297, 0.040759407]\n",
      "Iter 1790, loss [-0.2284973, -0.26663435, 0.038137056]\n",
      "Iter 1791, loss [-0.21487175, -0.25196737, 0.037095625]\n",
      "Iter 1792, loss [-0.22073036, -0.2604781, 0.039747752]\n",
      "Iter 1793, loss [-0.22445023, -0.26213053, 0.037680294]\n",
      "Iter 1794, loss [-0.21691005, -0.25549835, 0.038588297]\n",
      "Iter 1795, loss [-0.22175851, -0.26087925, 0.039120726]\n",
      "Iter 1796, loss [-0.22109862, -0.26038814, 0.039289523]\n",
      "Iter 1797, loss [-0.17839347, -0.22397715, 0.045583677]\n",
      "Iter 1798, loss [-0.22164682, -0.26010358, 0.038456764]\n",
      "Iter 1799, loss [-0.21866214, -0.25662592, 0.037963778]\n",
      "Iter 1800, loss [-0.22236185, -0.25952542, 0.03716357]\n",
      "Iter 1801, loss [-0.22709803, -0.26425773, 0.037159692]\n",
      "Iter 1802, loss [-0.2161056, -0.25548556, 0.03937997]\n",
      "Iter 1803, loss [-0.22539988, -0.2608775, 0.035477605]\n",
      "Iter 1804, loss [-0.2289907, -0.2658456, 0.03685489]\n",
      "Iter 1805, loss [-0.13357928, -0.19463134, 0.06105206]\n",
      "Iter 1806, loss [-0.22641328, -0.26219156, 0.035778284]\n",
      "Iter 1807, loss [-0.22372913, -0.26253524, 0.038806118]\n",
      "Iter 1808, loss [-0.18405622, -0.23380944, 0.04975322]\n",
      "Iter 1809, loss [-0.2140492, -0.25297558, 0.03892638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1810, loss [-0.22135794, -0.260789, 0.039431065]\n",
      "Iter 1811, loss [-0.13315335, -0.19618282, 0.06302947]\n",
      "Iter 1812, loss [-0.22653562, -0.26331443, 0.036778808]\n",
      "Iter 1813, loss [-0.2160568, -0.25564453, 0.039587732]\n",
      "Iter 1814, loss [-0.2229298, -0.2601712, 0.037241396]\n",
      "Iter 1815, loss [-0.22464845, -0.26179883, 0.037150383]\n",
      "Iter 1816, loss [-0.22778729, -0.26366282, 0.03587553]\n",
      "Iter 1817, loss [-0.2213541, -0.2596116, 0.03825751]\n",
      "Iter 1818, loss [-0.22177926, -0.26083168, 0.039052427]\n",
      "Iter 1819, loss [-0.2292746, -0.26566005, 0.036385443]\n",
      "Iter 1820, loss [-0.22755937, -0.26343226, 0.035872895]\n",
      "Iter 1821, loss [-0.21052638, -0.25290358, 0.042377196]\n",
      "Iter 1822, loss [-0.21532463, -0.25468642, 0.03936179]\n",
      "Iter 1823, loss [-0.22121784, -0.26038566, 0.03916782]\n",
      "Iter 1824, loss [-0.20809844, -0.24535823, 0.037259787]\n",
      "Iter 1825, loss [-0.21543795, -0.25328344, 0.037845485]\n",
      "Iter 1826, loss [-0.21456221, -0.25365612, 0.03909391]\n",
      "Iter 1827, loss [-0.22542739, -0.26195064, 0.036523245]\n",
      "Iter 1828, loss [-0.2271572, -0.26508528, 0.037928082]\n",
      "Iter 1829, loss [-0.23063868, -0.2689572, 0.038318507]\n",
      "Iter 1830, loss [-0.2336776, -0.2706228, 0.03694519]\n",
      "Iter 1831, loss [-0.22282803, -0.26118726, 0.038359217]\n",
      "Iter 1832, loss [-0.18513818, -0.23728053, 0.05214235]\n",
      "Iter 1833, loss [-0.22342505, -0.26221845, 0.038793396]\n",
      "Iter 1834, loss [-0.22562568, -0.26342896, 0.037803274]\n",
      "Iter 1835, loss [-0.22059321, -0.25876182, 0.0381686]\n",
      "Iter 1836, loss [-0.22778565, -0.2657174, 0.037931737]\n",
      "Iter 1837, loss [-0.22263846, -0.25932658, 0.036688127]\n",
      "Iter 1838, loss [-0.21957472, -0.25855955, 0.038984843]\n",
      "Iter 1839, loss [-0.22183788, -0.26093256, 0.03909468]\n",
      "Iter 1840, loss [-0.22611552, -0.2630366, 0.03692109]\n",
      "Iter 1841, loss [-0.22646026, -0.26253167, 0.036071405]\n",
      "Iter 1842, loss [-0.23022035, -0.26673904, 0.036518693]\n",
      "Iter 1843, loss [-0.22575536, -0.26249433, 0.03673896]\n",
      "Iter 1844, loss [-0.20866498, -0.24755614, 0.03889115]\n",
      "Iter 1845, loss [-0.17100543, -0.22542231, 0.054416876]\n",
      "Iter 1846, loss [-0.2295108, -0.26606753, 0.036556732]\n",
      "Iter 1847, loss [-0.22772905, -0.26527634, 0.037547283]\n",
      "Iter 1848, loss [-0.22191702, -0.25982696, 0.03790994]\n",
      "Iter 1849, loss [-0.20797402, -0.24725212, 0.039278097]\n",
      "Iter 1850, loss [-0.22325128, -0.25959274, 0.036341466]\n",
      "Iter 1851, loss [-0.21328455, -0.25587296, 0.042588413]\n",
      "Iter 1852, loss [-0.22464788, -0.2629979, 0.038350023]\n",
      "Iter 1853, loss [-0.21965137, -0.2574094, 0.037758026]\n",
      "Iter 1854, loss [-0.21356913, -0.2538724, 0.040303256]\n",
      "Iter 1855, loss [-0.16168447, -0.21424295, 0.05255848]\n",
      "Iter 1856, loss [-0.21925959, -0.2592718, 0.040012218]\n",
      "Iter 1857, loss [-0.22232953, -0.26004997, 0.037720434]\n",
      "Iter 1858, loss [-0.22018088, -0.25845143, 0.03827055]\n",
      "Iter 1859, loss [-0.22458085, -0.2621444, 0.037563533]\n",
      "Iter 1860, loss [-0.22272883, -0.2604642, 0.037735354]\n",
      "Iter 1861, loss [-0.21488513, -0.25334814, 0.038463008]\n",
      "Iter 1862, loss [-0.20506555, -0.24582578, 0.040760227]\n",
      "Iter 1863, loss [-0.24052775, -0.2749893, 0.034461558]\n",
      "Iter 1864, loss [-0.23021704, -0.2656295, 0.035412468]\n",
      "Iter 1865, loss [-0.21842095, -0.256049, 0.03762805]\n",
      "Iter 1866, loss [-0.22236013, -0.25984246, 0.037482318]\n",
      "Iter 1867, loss [-0.22286585, -0.2598931, 0.03702724]\n",
      "Iter 1868, loss [-0.2254053, -0.2617376, 0.036332317]\n",
      "Iter 1869, loss [-0.16945112, -0.21926102, 0.0498099]\n",
      "Iter 1870, loss [-0.22949873, -0.26456398, 0.035065245]\n",
      "Iter 1871, loss [-0.22720996, -0.26460212, 0.037392177]\n",
      "Iter 1872, loss [-0.221661, -0.26069826, 0.039037265]\n",
      "Iter 1873, loss [-0.21309179, -0.25347778, 0.040385995]\n",
      "Iter 1874, loss [-0.21519202, -0.25501937, 0.03982735]\n",
      "Iter 1875, loss [-0.2228679, -0.26218238, 0.03931448]\n",
      "Iter 1876, loss [-0.22854319, -0.26537326, 0.036830068]\n",
      "Iter 1877, loss [-0.21487245, -0.25406834, 0.03919589]\n",
      "Iter 1878, loss [-0.22802705, -0.26468512, 0.036658082]\n",
      "Iter 1879, loss [-0.19992022, -0.2472034, 0.047283173]\n",
      "Iter 1880, loss [-0.2123394, -0.25374267, 0.04140327]\n",
      "Iter 1881, loss [-0.23180065, -0.26867476, 0.03687411]\n",
      "Iter 1882, loss [-0.22766042, -0.26430726, 0.03664684]\n",
      "Iter 1883, loss [-0.22138801, -0.2595597, 0.038171675]\n",
      "Iter 1884, loss [-0.22105329, -0.26036507, 0.039311778]\n",
      "Iter 1885, loss [-0.23003206, -0.26670355, 0.036671486]\n",
      "Iter 1886, loss [-0.2092705, -0.2492795, 0.040008985]\n",
      "Iter 1887, loss [-0.2290398, -0.26563263, 0.036592826]\n",
      "Iter 1888, loss [-0.21789367, -0.2572635, 0.039369836]\n",
      "Iter 1889, loss [-0.22043054, -0.26026967, 0.039839134]\n",
      "Iter 1890, loss [-0.22387996, -0.2613414, 0.037461422]\n",
      "Iter 1891, loss [-0.2229276, -0.26136085, 0.038433254]\n",
      "Iter 1892, loss [-0.220804, -0.26076448, 0.039960478]\n",
      "Iter 1893, loss [-0.2300948, -0.2670333, 0.0369385]\n",
      "Iter 1894, loss [-0.23030502, -0.2664222, 0.03611719]\n",
      "Iter 1895, loss [-0.22070163, -0.2602494, 0.039547767]\n",
      "Iter 1896, loss [-0.22321105, -0.26290053, 0.03968948]\n",
      "Iter 1897, loss [-0.21317576, -0.25198168, 0.038805913]\n",
      "Iter 1898, loss [-0.21764402, -0.25677878, 0.039134752]\n",
      "Iter 1899, loss [-0.21751058, -0.25667056, 0.039159976]\n",
      "Iter 1900, loss [-0.22051963, -0.25969076, 0.039171137]\n",
      "Iter 1901, loss [-0.23465317, -0.26982936, 0.035176188]\n",
      "Iter 1902, loss [-0.23007676, -0.26623562, 0.036158867]\n",
      "Iter 1903, loss [-0.2156649, -0.25481164, 0.03914676]\n",
      "Iter 1904, loss [-0.15396106, -0.21254231, 0.05858124]\n",
      "Iter 1905, loss [-0.22289462, -0.2607882, 0.037893575]\n",
      "Iter 1906, loss [-0.2232539, -0.26213816, 0.038884245]\n",
      "Iter 1907, loss [-0.21995854, -0.2590819, 0.03912335]\n",
      "Iter 1908, loss [-0.21951649, -0.25874597, 0.03922948]\n",
      "Iter 1909, loss [-0.21883534, -0.2573295, 0.03849416]\n",
      "Iter 1910, loss [-0.17592499, -0.22502002, 0.049095035]\n",
      "Iter 1911, loss [-0.21131164, -0.25365317, 0.042341538]\n",
      "Iter 1912, loss [-0.22777195, -0.26509166, 0.037319705]\n",
      "Iter 1913, loss [-0.22393848, -0.26289076, 0.038952276]\n",
      "Iter 1914, loss [-0.22502965, -0.2620302, 0.037000574]\n",
      "Iter 1915, loss [-0.2231498, -0.2607063, 0.037556496]\n",
      "Iter 1916, loss [-0.22607872, -0.26227373, 0.036195002]\n",
      "Iter 1917, loss [-0.22337452, -0.2607496, 0.037375093]\n",
      "Iter 1918, loss [-0.2220957, -0.25923085, 0.037135147]\n",
      "Iter 1919, loss [-0.2182815, -0.2567305, 0.038449004]\n",
      "Iter 1920, loss [-0.22101729, -0.25979447, 0.038777187]\n",
      "Iter 1921, loss [-0.23337066, -0.26863554, 0.035264872]\n",
      "Iter 1922, loss [-0.30892608, -0.31632864, 0.0074025616]\n",
      "Iter 1923, loss [-0.22768238, -0.26347092, 0.03578853]\n",
      "Iter 1924, loss [-0.22785658, -0.26299515, 0.03513857]\n",
      "Iter 1925, loss [-0.22430773, -0.26014444, 0.035836708]\n",
      "Iter 1926, loss [-0.21397915, -0.25291005, 0.03893089]\n",
      "Iter 1927, loss [-0.21983792, -0.25748396, 0.03764604]\n",
      "Iter 1928, loss [-0.21799645, -0.25715688, 0.03916043]\n",
      "Iter 1929, loss [-0.231256, -0.26713142, 0.035875425]\n",
      "Iter 1930, loss [-0.21693595, -0.2538469, 0.036910962]\n",
      "Iter 1931, loss [-0.22085239, -0.25990334, 0.03905095]\n",
      "Iter 1932, loss [-0.21851322, -0.2578401, 0.039326884]\n",
      "Iter 1933, loss [-0.22107098, -0.26191434, 0.040843368]\n",
      "Iter 1934, loss [-0.23028561, -0.26698, 0.03669437]\n",
      "Iter 1935, loss [-0.22632566, -0.26379597, 0.03747031]\n",
      "Iter 1936, loss [-0.2186298, -0.2560578, 0.03742799]\n",
      "Iter 1937, loss [-0.21545881, -0.25328207, 0.037823252]\n",
      "Iter 1938, loss [-0.22012827, -0.2585862, 0.038457938]\n",
      "Iter 1939, loss [-0.22277397, -0.2598516, 0.03707763]\n",
      "Iter 1940, loss [-0.22625871, -0.26282775, 0.036569044]\n",
      "Iter 1941, loss [-0.22057885, -0.26051292, 0.039934065]\n",
      "Iter 1942, loss [-0.22549953, -0.265375, 0.03987546]\n",
      "Iter 1943, loss [-0.21426582, -0.25398275, 0.039716937]\n",
      "Iter 1944, loss [-0.21454827, -0.25575697, 0.0412087]\n",
      "Iter 1945, loss [-0.22320977, -0.2590169, 0.035807136]\n",
      "Iter 1946, loss [-0.22390307, -0.2588689, 0.034965828]\n",
      "Iter 1947, loss [-0.22288403, -0.25991395, 0.037029922]\n",
      "Iter 1948, loss [-0.23183069, -0.26598775, 0.034157068]\n",
      "Iter 1949, loss [-0.21482578, -0.25417942, 0.039353635]\n",
      "Iter 1950, loss [-0.21811804, -0.25814185, 0.040023796]\n",
      "Iter 1951, loss [-0.22607431, -0.2633014, 0.03722709]\n",
      "Iter 1952, loss [-0.22870687, -0.26542002, 0.036713153]\n",
      "Iter 1953, loss [-0.22510919, -0.26396182, 0.038852625]\n",
      "Iter 1954, loss [-0.20941047, -0.25317296, 0.04376249]\n",
      "Iter 1955, loss [-0.22367907, -0.26091465, 0.037235584]\n",
      "Iter 1956, loss [-0.21574841, -0.2549296, 0.039181188]\n",
      "Iter 1957, loss [-0.21105406, -0.25197628, 0.040922217]\n",
      "Iter 1958, loss [-0.18429776, -0.23414743, 0.04984967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1959, loss [-0.19019657, -0.23746409, 0.047267508]\n",
      "Iter 1960, loss [-0.22482005, -0.2620224, 0.037202355]\n",
      "Iter 1961, loss [-0.225462, -0.26307312, 0.037611112]\n",
      "Iter 1962, loss [-0.20942068, -0.2490024, 0.039581724]\n",
      "Iter 1963, loss [-0.23277034, -0.26953667, 0.036766335]\n",
      "Iter 1964, loss [-0.22470245, -0.26287803, 0.03817559]\n",
      "Iter 1965, loss [-0.22184771, -0.26096976, 0.039122052]\n",
      "Iter 1966, loss [-0.2215656, -0.25730652, 0.03574091]\n",
      "Iter 1967, loss [-0.2293936, -0.26662424, 0.037230633]\n",
      "Iter 1968, loss [-0.22746491, -0.2606801, 0.033215195]\n",
      "Iter 1969, loss [-0.21429172, -0.25483197, 0.040540256]\n",
      "Iter 1970, loss [-0.22376388, -0.26293254, 0.039168663]\n",
      "Iter 1971, loss [-0.2247945, -0.26430333, 0.03950882]\n",
      "Iter 1972, loss [-0.21339378, -0.254398, 0.04100421]\n",
      "Iter 1973, loss [-0.22510444, -0.26094976, 0.035845324]\n",
      "Iter 1974, loss [-0.22194959, -0.26111215, 0.039162558]\n",
      "Iter 1975, loss [-0.22748618, -0.26732352, 0.039837345]\n",
      "Iter 1976, loss [-0.22266875, -0.26159313, 0.038924377]\n",
      "Iter 1977, loss [-0.22254723, -0.26098067, 0.038433425]\n",
      "Iter 1978, loss [-0.2298491, -0.26639354, 0.036544442]\n",
      "Iter 1979, loss [-0.2276985, -0.26405448, 0.036355965]\n",
      "Iter 1980, loss [-0.21694568, -0.25525385, 0.038308173]\n",
      "Iter 1981, loss [-0.22608757, -0.26117474, 0.035087176]\n",
      "Iter 1982, loss [-0.2298571, -0.26446995, 0.034612853]\n",
      "Iter 1983, loss [-0.2237668, -0.26096117, 0.037194364]\n",
      "Iter 1984, loss [-0.21883175, -0.25759417, 0.038762417]\n",
      "Iter 1985, loss [-0.22239499, -0.26019186, 0.03779687]\n",
      "Iter 1986, loss [-0.21402024, -0.2541231, 0.04010285]\n",
      "Iter 1987, loss [-0.21509607, -0.2538685, 0.03877242]\n",
      "Iter 1988, loss [-0.18715236, -0.24110694, 0.05395458]\n",
      "Iter 1989, loss [-0.22845072, -0.26600054, 0.037549816]\n",
      "Iter 1990, loss [-0.21882091, -0.25640383, 0.03758292]\n",
      "Iter 1991, loss [-0.21616057, -0.25502872, 0.038868155]\n",
      "Iter 1992, loss [-0.21855268, -0.2579882, 0.03943553]\n",
      "Iter 1993, loss [-0.22973336, -0.26714826, 0.037414894]\n",
      "Iter 1994, loss [-0.21889672, -0.25888896, 0.03999225]\n",
      "Iter 1995, loss [-0.21554022, -0.256304, 0.040763777]\n",
      "Iter 1996, loss [-0.22259489, -0.26156795, 0.038973056]\n",
      "Iter 1997, loss [-0.21971038, -0.25828832, 0.03857795]\n",
      "Iter 1998, loss [-0.16485643, -0.21944624, 0.054589808]\n",
      "Iter 1999, loss [-0.21883054, -0.25654262, 0.03771208]\n",
      "Iter 2000, loss [-0.22313306, -0.26078388, 0.037650816]\n",
      "Iter 2001, loss [-0.22669163, -0.2629767, 0.036285073]\n",
      "Iter 2002, loss [-0.22163409, -0.26005626, 0.03842216]\n",
      "Iter 2003, loss [-0.21903192, -0.25855425, 0.03952233]\n",
      "Iter 2004, loss [-0.23399958, -0.26964226, 0.035642676]\n",
      "Iter 2005, loss [-0.15908292, -0.21565273, 0.056569807]\n",
      "Iter 2006, loss [-0.20389712, -0.24394888, 0.04005176]\n",
      "Iter 2007, loss [-0.21643452, -0.25560316, 0.03916864]\n",
      "Iter 2008, loss [-0.21845463, -0.25744134, 0.038986705]\n",
      "Iter 2009, loss [-0.22680965, -0.26449543, 0.037685785]\n",
      "Iter 2010, loss [-0.22370757, -0.26037878, 0.036671206]\n",
      "Iter 2011, loss [-0.2321278, -0.26999247, 0.03786467]\n",
      "Iter 2012, loss [-0.21783821, -0.25823885, 0.04040064]\n",
      "Iter 2013, loss [-0.22302505, -0.26182717, 0.038802117]\n",
      "Iter 2014, loss [-0.22504747, -0.26253778, 0.03749031]\n",
      "Iter 2015, loss [-0.21945237, -0.2558626, 0.036410224]\n",
      "Iter 2016, loss [-0.2250537, -0.26301125, 0.03795754]\n",
      "Iter 2017, loss [-0.2314228, -0.26544723, 0.034024432]\n",
      "Iter 2018, loss [-0.21390696, -0.25214678, 0.038239818]\n",
      "Iter 2019, loss [-0.2222535, -0.2600454, 0.037791908]\n",
      "Iter 2020, loss [-0.2304034, -0.265718, 0.035314612]\n",
      "Iter 2021, loss [-0.22736618, -0.2642529, 0.03688672]\n",
      "Iter 2022, loss [-0.22691149, -0.265967, 0.039055526]\n",
      "Iter 2023, loss [-0.21865585, -0.25930327, 0.040647417]\n",
      "Iter 2024, loss [-0.22311135, -0.25969586, 0.036584508]\n",
      "Iter 2025, loss [-0.22108869, -0.2594275, 0.0383388]\n",
      "Iter 2026, loss [-0.23042803, -0.26736397, 0.036935944]\n",
      "Iter 2027, loss [-0.22698946, -0.2623186, 0.035329144]\n",
      "Iter 2028, loss [-0.22665048, -0.2635134, 0.03686291]\n",
      "Iter 2029, loss [-0.22965944, -0.2664504, 0.036790963]\n",
      "Iter 2030, loss [-0.21661408, -0.25680536, 0.040191278]\n",
      "Iter 2031, loss [-0.2081007, -0.24880981, 0.040709116]\n",
      "Iter 2032, loss [-0.22655919, -0.26359662, 0.037037432]\n",
      "Iter 2033, loss [-0.22732897, -0.26538786, 0.03805889]\n",
      "Iter 2034, loss [-0.21824984, -0.25762805, 0.03937821]\n",
      "Iter 2035, loss [-0.22157869, -0.25725594, 0.035677254]\n",
      "Iter 2036, loss [-0.23496446, -0.2710826, 0.036118157]\n",
      "Iter 2037, loss [-0.2206155, -0.26056954, 0.039954036]\n",
      "Iter 2038, loss [-0.21696231, -0.25606441, 0.03910211]\n",
      "Iter 2039, loss [-0.22384462, -0.2617407, 0.037896097]\n",
      "Iter 2040, loss [-0.22168733, -0.2595959, 0.037908565]\n",
      "Iter 2041, loss [-0.21467921, -0.25369534, 0.03901613]\n",
      "Iter 2042, loss [-0.22116387, -0.26060826, 0.039444394]\n",
      "Iter 2043, loss [-0.22622798, -0.26377216, 0.037544176]\n",
      "Iter 2044, loss [-0.22270212, -0.2607777, 0.03807559]\n",
      "Iter 2045, loss [-0.22517982, -0.26103863, 0.035858817]\n",
      "Iter 2046, loss [-0.20280953, -0.24425523, 0.0414457]\n",
      "Iter 2047, loss [-0.21999954, -0.26099825, 0.040998712]\n",
      "Iter 2048, loss [-0.20854732, -0.24532667, 0.036779337]\n",
      "Iter 2049, loss [-0.18326928, -0.2312263, 0.047957014]\n",
      "Iter 2050, loss [-0.22530597, -0.2608872, 0.035581227]\n",
      "Iter 2051, loss [-0.21360284, -0.25262505, 0.039022215]\n",
      "Iter 2052, loss [-0.1846441, -0.23603235, 0.05138825]\n",
      "Iter 2053, loss [-0.21861422, -0.26010045, 0.041486233]\n",
      "Iter 2054, loss [-0.21464184, -0.25581595, 0.041174106]\n",
      "Iter 2055, loss [-0.21425658, -0.25531965, 0.041063067]\n",
      "Iter 2056, loss [-0.21166065, -0.25187138, 0.04021072]\n",
      "Iter 2057, loss [-0.21942367, -0.25664958, 0.037225917]\n",
      "Iter 2058, loss [-0.23324215, -0.26757467, 0.03433251]\n",
      "Iter 2059, loss [-0.19333053, -0.23339804, 0.0400675]\n",
      "Iter 2060, loss [-0.21061608, -0.24936825, 0.038752176]\n",
      "Iter 2061, loss [-0.16528867, -0.22230196, 0.057013284]\n",
      "Iter 2062, loss [-0.22811168, -0.26420224, 0.036090545]\n",
      "Iter 2063, loss [-0.19378169, -0.24161173, 0.047830045]\n",
      "Iter 2064, loss [-0.21650305, -0.25681734, 0.040314283]\n",
      "Iter 2065, loss [-0.22998405, -0.2669623, 0.036978237]\n",
      "Iter 2066, loss [-0.22400601, -0.26198053, 0.037974518]\n",
      "Iter 2067, loss [-0.22736877, -0.26197657, 0.034607798]\n",
      "Iter 2068, loss [-0.21152404, -0.25236496, 0.04084092]\n",
      "Iter 2069, loss [-0.23015784, -0.2644031, 0.034245268]\n",
      "Iter 2070, loss [-0.21225926, -0.25237876, 0.040119506]\n",
      "Iter 2071, loss [-0.22503507, -0.26293293, 0.037897862]\n",
      "Iter 2072, loss [-0.2199558, -0.25700247, 0.037046667]\n",
      "Iter 2073, loss [-0.22946957, -0.26564977, 0.03618019]\n",
      "Iter 2074, loss [-0.2258017, -0.26210487, 0.03630316]\n",
      "Iter 2075, loss [-0.22696018, -0.2647503, 0.037790127]\n",
      "Iter 2076, loss [-0.2335848, -0.26773605, 0.03415124]\n",
      "Iter 2077, loss [-0.20836562, -0.2505104, 0.042144783]\n",
      "Iter 2078, loss [-0.22841902, -0.2627017, 0.03428267]\n",
      "Iter 2079, loss [-0.21344727, -0.25241464, 0.038967367]\n",
      "Iter 2080, loss [-0.22816417, -0.26446468, 0.036300503]\n",
      "Iter 2081, loss [-0.2126846, -0.25360572, 0.04092112]\n",
      "Iter 2082, loss [-0.22407216, -0.26468453, 0.040612374]\n",
      "Iter 2083, loss [-0.22209108, -0.26047406, 0.038382985]\n",
      "Iter 2084, loss [-0.22378883, -0.26252297, 0.03873413]\n",
      "Iter 2085, loss [-0.22784421, -0.26525462, 0.037410405]\n",
      "Iter 2086, loss [-0.20760944, -0.2508557, 0.04324626]\n",
      "Iter 2087, loss [-0.22078021, -0.2577794, 0.03699918]\n",
      "Iter 2088, loss [-0.21874991, -0.25607395, 0.03732404]\n",
      "Iter 2089, loss [-0.21908867, -0.2572811, 0.03819243]\n",
      "Iter 2090, loss [-0.2218583, -0.2611285, 0.0392702]\n",
      "Iter 2091, loss [-0.22536513, -0.26340994, 0.038044803]\n",
      "Iter 2092, loss [-0.21232724, -0.2532724, 0.040945165]\n",
      "Iter 2093, loss [-0.20644635, -0.24890807, 0.04246172]\n",
      "Iter 2094, loss [-0.22939911, -0.26480672, 0.03540761]\n",
      "Iter 2095, loss [-0.21655914, -0.2558439, 0.039284766]\n",
      "Iter 2096, loss [-0.21819231, -0.25771224, 0.039519936]\n",
      "Iter 2097, loss [-0.22489277, -0.2619384, 0.037045624]\n",
      "Iter 2098, loss [-0.19680224, -0.24147142, 0.04466918]\n",
      "Iter 2099, loss [-0.21683607, -0.2558761, 0.039040036]\n",
      "Iter 2100, loss [-0.22244352, -0.2619099, 0.03946638]\n",
      "Iter 2101, loss [-0.22348513, -0.2611998, 0.03771467]\n",
      "Iter 2102, loss [-0.2235989, -0.26011515, 0.03651625]\n",
      "Iter 2103, loss [-0.22019218, -0.25592303, 0.03573085]\n",
      "Iter 2104, loss [-0.2331469, -0.26850098, 0.035354078]\n",
      "Iter 2105, loss [-0.23200959, -0.26870733, 0.03669775]\n",
      "Iter 2106, loss [-0.19286986, -0.24142723, 0.04855737]\n",
      "Iter 2107, loss [-0.22408408, -0.2638243, 0.03974023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2108, loss [-0.2296327, -0.2681273, 0.038494587]\n",
      "Iter 2109, loss [-0.2213468, -0.26109162, 0.03974483]\n",
      "Iter 2110, loss [-0.15474051, -0.21371135, 0.058970846]\n",
      "Iter 2111, loss [-0.22401635, -0.26072925, 0.036712904]\n",
      "Iter 2112, loss [-0.20603147, -0.24810565, 0.042074174]\n",
      "Iter 2113, loss [-0.22119176, -0.25814906, 0.036957297]\n",
      "Iter 2114, loss [-0.22529875, -0.2604722, 0.035173457]\n",
      "Iter 2115, loss [-0.23018971, -0.26497537, 0.034785654]\n",
      "Iter 2116, loss [-0.15731326, -0.21139815, 0.05408489]\n",
      "Iter 2117, loss [-0.22085941, -0.2595724, 0.03871297]\n",
      "Iter 2118, loss [-0.22634242, -0.26520237, 0.038859945]\n",
      "Iter 2119, loss [-0.21776557, -0.25838566, 0.040620096]\n",
      "Iter 2120, loss [-0.19579913, -0.24294299, 0.047143858]\n",
      "Iter 2121, loss [-0.21921083, -0.25938064, 0.040169805]\n",
      "Iter 2122, loss [-0.22585276, -0.26230574, 0.036452975]\n",
      "Iter 2123, loss [-0.22338326, -0.25980332, 0.03642006]\n",
      "Iter 2124, loss [-0.2273112, -0.2622692, 0.034957998]\n",
      "Iter 2125, loss [-0.19366837, -0.23354623, 0.03987787]\n",
      "Iter 2126, loss [-0.2183901, -0.2556357, 0.037245594]\n",
      "Iter 2127, loss [-0.22496285, -0.26265022, 0.037687376]\n",
      "Iter 2128, loss [-0.21499775, -0.25395465, 0.038956895]\n",
      "Iter 2129, loss [-0.2263318, -0.2648344, 0.0385026]\n",
      "Iter 2130, loss [-0.21908559, -0.25778523, 0.038699638]\n",
      "Iter 2131, loss [-0.22933677, -0.2655678, 0.036231034]\n",
      "Iter 2132, loss [-0.19891746, -0.24286392, 0.043946456]\n",
      "Iter 2133, loss [-0.22196607, -0.26069307, 0.038726997]\n",
      "Iter 2134, loss [-0.21648641, -0.2554971, 0.03901069]\n",
      "Iter 2135, loss [-0.22161402, -0.2586549, 0.037040874]\n",
      "Iter 2136, loss [-0.20425707, -0.24659202, 0.042334944]\n",
      "Iter 2137, loss [-0.21726649, -0.25607675, 0.038810268]\n",
      "Iter 2138, loss [-0.22635198, -0.2621491, 0.035797127]\n",
      "Iter 2139, loss [-0.22541228, -0.2617714, 0.036359124]\n",
      "Iter 2140, loss [-0.1994208, -0.24150251, 0.042081714]\n",
      "Iter 2141, loss [-0.21329379, -0.25517684, 0.041883048]\n",
      "Iter 2142, loss [-0.2242422, -0.26266342, 0.038421225]\n",
      "Iter 2143, loss [-0.22883242, -0.26728138, 0.03844896]\n",
      "Iter 2144, loss [-0.22964424, -0.26728866, 0.03764441]\n",
      "Iter 2145, loss [-0.2255448, -0.26286063, 0.03731583]\n",
      "Iter 2146, loss [-0.22437593, -0.2626781, 0.03830216]\n",
      "Iter 2147, loss [-0.2249529, -0.2606058, 0.035652902]\n",
      "Iter 2148, loss [-0.22792232, -0.26523754, 0.03731522]\n",
      "Iter 2149, loss [-0.2164369, -0.2534233, 0.036986418]\n",
      "Iter 2150, loss [-0.21342476, -0.2548726, 0.041447837]\n",
      "Iter 2151, loss [-0.22262415, -0.26109585, 0.038471706]\n",
      "Iter 2152, loss [-0.2229424, -0.26142508, 0.03848268]\n",
      "Iter 2153, loss [-0.15477893, -0.21022797, 0.05544903]\n",
      "Iter 2154, loss [-0.22820891, -0.2660045, 0.037795585]\n",
      "Iter 2155, loss [-0.21041639, -0.25245705, 0.042040657]\n",
      "Iter 2156, loss [-0.22259402, -0.2613593, 0.038765274]\n",
      "Iter 2157, loss [-0.20938125, -0.24965052, 0.040269263]\n",
      "Iter 2158, loss [-0.22930947, -0.2654439, 0.03613442]\n",
      "Iter 2159, loss [-0.19290763, -0.23869015, 0.045782518]\n",
      "Iter 2160, loss [-0.21919394, -0.25769144, 0.038497504]\n",
      "Iter 2161, loss [-0.19204324, -0.24173373, 0.049690478]\n",
      "Iter 2162, loss [-0.22648917, -0.26320982, 0.036720645]\n",
      "Iter 2163, loss [-0.21645471, -0.25713524, 0.040680535]\n",
      "Iter 2164, loss [-0.21076985, -0.2513243, 0.04055445]\n",
      "Iter 2165, loss [-0.15942049, -0.2195365, 0.060116004]\n",
      "Iter 2166, loss [-0.22191307, -0.25963703, 0.037723962]\n",
      "Iter 2167, loss [-0.22020483, -0.2584436, 0.03823876]\n",
      "Iter 2168, loss [-0.20968571, -0.2487584, 0.039072685]\n",
      "Iter 2169, loss [-0.21810697, -0.2559136, 0.03780661]\n",
      "Iter 2170, loss [-0.22041208, -0.2572494, 0.036837306]\n",
      "Iter 2171, loss [-0.21818607, -0.25812766, 0.039941594]\n",
      "Iter 2172, loss [-0.14904112, -0.21124199, 0.06220087]\n",
      "Iter 2173, loss [-0.20875815, -0.25168547, 0.042927332]\n",
      "Iter 2174, loss [-0.22475007, -0.2638611, 0.03911102]\n",
      "Iter 2175, loss [-0.22328432, -0.2615798, 0.03829549]\n",
      "Iter 2176, loss [-0.2196348, -0.2584527, 0.03881792]\n",
      "Iter 2177, loss [-0.21703754, -0.25567788, 0.03864033]\n",
      "Iter 2178, loss [-0.19252631, -0.23900361, 0.046477303]\n",
      "Iter 2179, loss [-0.22205678, -0.26120162, 0.039144844]\n",
      "Iter 2180, loss [-0.21730424, -0.25656945, 0.039265204]\n",
      "Iter 2181, loss [-0.19690672, -0.24144909, 0.04454237]\n",
      "Iter 2182, loss [-0.22475591, -0.26176655, 0.03701064]\n",
      "Iter 2183, loss [-0.22934392, -0.2650783, 0.03573438]\n",
      "Iter 2184, loss [-0.22107589, -0.25880975, 0.037733845]\n",
      "Iter 2185, loss [-0.22819741, -0.26371732, 0.035519913]\n",
      "Iter 2186, loss [-0.20466647, -0.24631685, 0.041650392]\n",
      "Iter 2187, loss [-0.22145885, -0.2583484, 0.036889546]\n",
      "Iter 2188, loss [-0.21651848, -0.25195244, 0.03543396]\n",
      "Iter 2189, loss [-0.23132513, -0.26771596, 0.036390826]\n",
      "Iter 2190, loss [-0.21897584, -0.25878707, 0.039811224]\n",
      "Iter 2191, loss [-0.21772914, -0.2576322, 0.039903056]\n",
      "Iter 2192, loss [-0.22597542, -0.2640499, 0.03807447]\n",
      "Iter 2193, loss [-0.22528122, -0.2621282, 0.036846977]\n",
      "Iter 2194, loss [-0.16627195, -0.22112937, 0.054857425]\n",
      "Iter 2195, loss [-0.2164951, -0.25353205, 0.037036948]\n",
      "Iter 2196, loss [-0.22658071, -0.26275682, 0.036176115]\n",
      "Iter 2197, loss [-0.22020864, -0.25845945, 0.038250808]\n",
      "Iter 2198, loss [-0.20917544, -0.2495677, 0.04039226]\n",
      "Iter 2199, loss [-0.23163688, -0.26639622, 0.034759335]\n",
      "Iter 2200, loss [-0.22149393, -0.26003787, 0.038543932]\n",
      "Iter 2201, loss [-0.2153662, -0.25459146, 0.03922527]\n",
      "Iter 2202, loss [-0.22062282, -0.2586803, 0.038057487]\n",
      "Iter 2203, loss [-0.21688531, -0.25675258, 0.039867263]\n",
      "Iter 2204, loss [-0.22828591, -0.26609117, 0.03780526]\n",
      "Iter 2205, loss [-0.21357088, -0.2542412, 0.04067032]\n",
      "Iter 2206, loss [-0.21626872, -0.25612405, 0.03985533]\n",
      "Iter 2207, loss [-0.21615987, -0.25782433, 0.041664463]\n",
      "Iter 2208, loss [-0.22769636, -0.26540822, 0.03771186]\n",
      "Iter 2209, loss [-0.17754412, -0.21923424, 0.041690126]\n",
      "Iter 2210, loss [-0.2055342, -0.24764891, 0.042114705]\n",
      "Iter 2211, loss [-0.15779641, -0.20915076, 0.05135434]\n",
      "Iter 2212, loss [-0.22766384, -0.2622226, 0.03455875]\n",
      "Iter 2213, loss [-0.22617835, -0.26352093, 0.037342586]\n",
      "Iter 2214, loss [-0.18476799, -0.23272665, 0.047958657]\n",
      "Iter 2215, loss [-0.22963324, -0.26378754, 0.03415429]\n",
      "Iter 2216, loss [-0.23233448, -0.27005017, 0.03771569]\n",
      "Iter 2217, loss [-0.21456105, -0.25327888, 0.03871783]\n",
      "Iter 2218, loss [-0.2246407, -0.26406163, 0.039420933]\n",
      "Iter 2219, loss [-0.22586742, -0.26323542, 0.037368007]\n",
      "Iter 2220, loss [-0.219499, -0.25890717, 0.03940816]\n",
      "Iter 2221, loss [-0.23042245, -0.2668175, 0.036395054]\n",
      "Iter 2222, loss [-0.22172725, -0.26033357, 0.038606312]\n",
      "Iter 2223, loss [-0.21708071, -0.2550737, 0.03799298]\n",
      "Iter 2224, loss [-0.1879508, -0.24022555, 0.052274745]\n",
      "Iter 2225, loss [-0.21508688, -0.2528758, 0.037788935]\n",
      "Iter 2226, loss [-0.22733916, -0.26446056, 0.037121404]\n",
      "Iter 2227, loss [-0.22313711, -0.2615058, 0.0383687]\n",
      "Iter 2228, loss [-0.1721754, -0.22503784, 0.052862436]\n",
      "Iter 2229, loss [-0.21955271, -0.25772858, 0.03817587]\n",
      "Iter 2230, loss [-0.23468056, -0.2690105, 0.034329943]\n",
      "Iter 2231, loss [-0.23080394, -0.26745668, 0.036652736]\n",
      "Iter 2232, loss [-0.18572178, -0.23720217, 0.05148039]\n",
      "Iter 2233, loss [-0.17941593, -0.23119165, 0.051775724]\n",
      "Iter 2234, loss [-0.2170491, -0.25816405, 0.04111494]\n",
      "Iter 2235, loss [-0.21978314, -0.26208642, 0.04230328]\n",
      "Iter 2236, loss [-0.21323594, -0.2552474, 0.042011462]\n",
      "Iter 2237, loss [-0.21822569, -0.25893456, 0.040708862]\n",
      "Iter 2238, loss [-0.22140178, -0.25941962, 0.038017847]\n",
      "Iter 2239, loss [-0.22471076, -0.26106602, 0.03635525]\n",
      "Iter 2240, loss [-0.23062804, -0.26560926, 0.034981225]\n",
      "Iter 2241, loss [-0.22732262, -0.26334983, 0.036027204]\n",
      "Iter 2242, loss [-0.22499466, -0.2595682, 0.034573548]\n",
      "Iter 2243, loss [-0.22746441, -0.26435938, 0.036894985]\n",
      "Iter 2244, loss [-0.214749, -0.25773963, 0.042990636]\n",
      "Iter 2245, loss [-0.21641535, -0.2581547, 0.04173934]\n",
      "Iter 2246, loss [-0.21383893, -0.2566923, 0.042853348]\n",
      "Iter 2247, loss [-0.22074208, -0.25604403, 0.035301954]\n",
      "Iter 2248, loss [-0.2142114, -0.25353664, 0.039325234]\n",
      "Iter 2249, loss [-0.2252176, -0.25961798, 0.034400385]\n",
      "Iter 2250, loss [-0.19346419, -0.23332645, 0.039862256]\n",
      "Iter 2251, loss [-0.22754766, -0.2633975, 0.03584985]\n",
      "Iter 2252, loss [-0.22950144, -0.26652074, 0.0370193]\n",
      "Iter 2253, loss [-0.20482518, -0.24338365, 0.038558464]\n",
      "Iter 2254, loss [-0.22400156, -0.26349056, 0.039488997]\n",
      "Iter 2255, loss [-0.23031038, -0.26774362, 0.037433244]\n",
      "Iter 2256, loss [-0.2104309, -0.25421327, 0.043782365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2257, loss [-0.22243252, -0.2603709, 0.03793838]\n",
      "Iter 2258, loss [-0.22863185, -0.26508564, 0.03645379]\n",
      "Iter 2259, loss [-0.22550002, -0.2618133, 0.036313303]\n",
      "Iter 2260, loss [-0.23148957, -0.26562196, 0.0341324]\n",
      "Iter 2261, loss [-0.17452545, -0.22489695, 0.050371498]\n",
      "Iter 2262, loss [-0.20169309, -0.24244674, 0.040753648]\n",
      "Iter 2263, loss [-0.22232084, -0.26323265, 0.04091181]\n",
      "Iter 2264, loss [-0.21470556, -0.2531441, 0.038438533]\n",
      "Iter 2265, loss [-0.22520581, -0.26308984, 0.03788402]\n",
      "Iter 2266, loss [-0.20666769, -0.24907707, 0.04240937]\n",
      "Iter 2267, loss [-0.2195292, -0.25633243, 0.03680323]\n",
      "Iter 2268, loss [-0.22591712, -0.2626156, 0.03669847]\n",
      "Iter 2269, loss [-0.21150973, -0.24782546, 0.03631573]\n",
      "Iter 2270, loss [-0.21303406, -0.25419363, 0.041159566]\n",
      "Iter 2271, loss [-0.2337132, -0.27015364, 0.03644045]\n",
      "Iter 2272, loss [-0.21978015, -0.25803402, 0.03825388]\n",
      "Iter 2273, loss [-0.22860205, -0.26415843, 0.03555637]\n",
      "Iter 2274, loss [-0.21857178, -0.2561436, 0.03757181]\n",
      "Iter 2275, loss [-0.16767797, -0.21793805, 0.050260082]\n",
      "Iter 2276, loss [-0.22723922, -0.26233444, 0.035095215]\n",
      "Iter 2277, loss [-0.23058249, -0.2641205, 0.033538003]\n",
      "Iter 2278, loss [-0.21354625, -0.2531163, 0.03957007]\n",
      "Iter 2279, loss [-0.22220236, -0.25979787, 0.037595514]\n",
      "Iter 2280, loss [-0.21572204, -0.25568685, 0.039964806]\n",
      "Iter 2281, loss [-0.21332899, -0.2549438, 0.04161481]\n",
      "Iter 2282, loss [-0.2195351, -0.2597314, 0.040196314]\n",
      "Iter 2283, loss [-0.2248931, -0.26516137, 0.040268272]\n",
      "Iter 2284, loss [-0.2264153, -0.26461014, 0.03819483]\n",
      "Iter 2285, loss [-0.22263865, -0.26276568, 0.040127024]\n",
      "Iter 2286, loss [-0.2182903, -0.2591715, 0.040881183]\n",
      "Iter 2287, loss [-0.22188665, -0.26109135, 0.039204698]\n",
      "Iter 2288, loss [-0.16638818, -0.22056912, 0.054180942]\n",
      "Iter 2289, loss [-0.21797973, -0.258019, 0.040039267]\n",
      "Iter 2290, loss [-0.22971037, -0.26556173, 0.035851352]\n",
      "Iter 2291, loss [-0.19971928, -0.24195202, 0.042232733]\n",
      "Iter 2292, loss [-0.2222744, -0.26092237, 0.038647972]\n",
      "Iter 2293, loss [-0.2245599, -0.26285127, 0.03829136]\n",
      "Iter 2294, loss [-0.22790325, -0.26367524, 0.035772003]\n",
      "Iter 2295, loss [-0.22226964, -0.26013115, 0.03786151]\n",
      "Iter 2296, loss [-0.22573367, -0.26297057, 0.037236895]\n",
      "Iter 2297, loss [-0.22635321, -0.26242465, 0.03607143]\n",
      "Iter 2298, loss [-0.21588269, -0.2547636, 0.038880914]\n",
      "Iter 2299, loss [-0.23043689, -0.26606545, 0.035628557]\n",
      "Iter 2300, loss [-0.23183541, -0.2677412, 0.035905793]\n",
      "Iter 2301, loss [-0.2321816, -0.26765025, 0.035468657]\n",
      "Iter 2302, loss [-0.21797645, -0.25667486, 0.038698398]\n",
      "Iter 2303, loss [-0.21398816, -0.2550185, 0.041030355]\n",
      "Iter 2304, loss [-0.2211151, -0.25972643, 0.038611338]\n",
      "Iter 2305, loss [-0.23005196, -0.26691794, 0.036865972]\n",
      "Iter 2306, loss [-0.13573763, -0.19893305, 0.06319542]\n",
      "Iter 2307, loss [-0.22010782, -0.2582329, 0.038125075]\n",
      "Iter 2308, loss [-0.21808961, -0.2565069, 0.038417272]\n",
      "Iter 2309, loss [-0.23378903, -0.268914, 0.035124995]\n",
      "Iter 2310, loss [-0.21767786, -0.25796348, 0.04028561]\n",
      "Iter 2311, loss [-0.23152724, -0.2668786, 0.035351362]\n",
      "Iter 2312, loss [-0.22232834, -0.26025012, 0.03792178]\n",
      "Iter 2313, loss [-0.22383998, -0.26044574, 0.03660576]\n",
      "Iter 2314, loss [-0.22867294, -0.26455808, 0.035885137]\n",
      "Iter 2315, loss [-0.21964124, -0.25713703, 0.03749579]\n",
      "Iter 2316, loss [-0.23016544, -0.2655305, 0.035365056]\n",
      "Iter 2317, loss [-0.21631783, -0.2552068, 0.03888897]\n",
      "Iter 2318, loss [-0.16674192, -0.22514242, 0.058400493]\n",
      "Iter 2319, loss [-0.2240074, -0.26257327, 0.03856588]\n",
      "Iter 2320, loss [-0.18530689, -0.23231903, 0.047012135]\n",
      "Iter 2321, loss [-0.22380729, -0.26049933, 0.03669204]\n",
      "Iter 2322, loss [-0.2265059, -0.26189038, 0.03538447]\n",
      "Iter 2323, loss [-0.21498036, -0.25141388, 0.036433525]\n",
      "Iter 2324, loss [-0.21087258, -0.24839203, 0.03751945]\n",
      "Iter 2325, loss [-0.22080275, -0.26011643, 0.039313667]\n",
      "Iter 2326, loss [-0.21561933, -0.25492746, 0.03930813]\n",
      "Iter 2327, loss [-0.22037113, -0.26081422, 0.0404431]\n",
      "Iter 2328, loss [-0.2336916, -0.27058375, 0.036892153]\n",
      "Iter 2329, loss [-0.2185547, -0.2575836, 0.039028883]\n",
      "Iter 2330, loss [-0.19462809, -0.23635198, 0.041723892]\n",
      "Iter 2331, loss [-0.223556, -0.2614075, 0.037851498]\n",
      "Iter 2332, loss [-0.15815994, -0.20993863, 0.051778696]\n",
      "Iter 2333, loss [-0.21358463, -0.2548794, 0.041294754]\n",
      "Iter 2334, loss [-0.22622776, -0.26322922, 0.037001465]\n",
      "Iter 2335, loss [-0.22795081, -0.2647994, 0.03684857]\n",
      "Iter 2336, loss [-0.22579801, -0.26356432, 0.037766308]\n",
      "Iter 2337, loss [-0.2269878, -0.2624686, 0.035480812]\n",
      "Iter 2338, loss [-0.21715502, -0.25591308, 0.03875805]\n",
      "Iter 2339, loss [-0.22026065, -0.2592129, 0.038952265]\n",
      "Iter 2340, loss [-0.2137992, -0.2541655, 0.040366307]\n",
      "Iter 2341, loss [-0.22447793, -0.26564923, 0.041171297]\n",
      "Iter 2342, loss [-0.17285511, -0.2279474, 0.055092297]\n",
      "Iter 2343, loss [-0.21494263, -0.2523568, 0.037414156]\n",
      "Iter 2344, loss [-0.21431589, -0.25163588, 0.037319984]\n",
      "Iter 2345, loss [-0.2096476, -0.25125417, 0.041606575]\n",
      "Iter 2346, loss [-0.18048503, -0.23222066, 0.05173564]\n",
      "Iter 2347, loss [-0.22152825, -0.26233178, 0.040803533]\n",
      "Iter 2348, loss [-0.21961215, -0.25805488, 0.03844274]\n",
      "Iter 2349, loss [-0.21897785, -0.25773647, 0.038758617]\n",
      "Iter 2350, loss [-0.22069311, -0.2587519, 0.03805878]\n",
      "Iter 2351, loss [-0.19613582, -0.23879413, 0.04265832]\n",
      "Iter 2352, loss [-0.22052081, -0.25870478, 0.03818397]\n",
      "Iter 2353, loss [-0.2230208, -0.26282778, 0.039806973]\n",
      "Iter 2354, loss [-0.2298748, -0.26629603, 0.036421224]\n",
      "Iter 2355, loss [-0.22970724, -0.26556382, 0.035856582]\n",
      "Iter 2356, loss [-0.22495405, -0.26202092, 0.03706686]\n",
      "Iter 2357, loss [-0.22506952, -0.26258153, 0.03751201]\n",
      "Iter 2358, loss [-0.22610538, -0.26432106, 0.038215682]\n",
      "Iter 2359, loss [-0.22255906, -0.261726, 0.039166927]\n",
      "Iter 2360, loss [-0.22350116, -0.26284313, 0.039341968]\n",
      "Iter 2361, loss [-0.22243264, -0.2603489, 0.037916243]\n",
      "Iter 2362, loss [-0.20506799, -0.24838492, 0.043316927]\n",
      "Iter 2363, loss [-0.22831076, -0.26460898, 0.036298208]\n",
      "Iter 2364, loss [-0.23058027, -0.26735917, 0.036778897]\n",
      "Iter 2365, loss [-0.22150679, -0.25863138, 0.03712459]\n",
      "Iter 2366, loss [-0.19511537, -0.24170318, 0.04658781]\n",
      "Iter 2367, loss [-0.21696267, -0.25669628, 0.039733626]\n",
      "Iter 2368, loss [-0.20906112, -0.25022405, 0.04116293]\n",
      "Iter 2369, loss [-0.22264305, -0.25983447, 0.037191417]\n",
      "Iter 2370, loss [-0.21444175, -0.25595862, 0.041516878]\n",
      "Iter 2371, loss [-0.21440774, -0.2534757, 0.039067954]\n",
      "Iter 2372, loss [-0.22096972, -0.2586115, 0.03764178]\n",
      "Iter 2373, loss [-0.21758813, -0.25670874, 0.039120622]\n",
      "Iter 2374, loss [-0.21936058, -0.25854638, 0.039185803]\n",
      "Iter 2375, loss [-0.23042953, -0.2653886, 0.034959085]\n",
      "Iter 2376, loss [-0.22452155, -0.26258108, 0.03805954]\n",
      "Iter 2377, loss [-0.22572194, -0.2643346, 0.038612645]\n",
      "Iter 2378, loss [-0.21354088, -0.25288343, 0.03934256]\n",
      "Iter 2379, loss [-0.22106022, -0.26135275, 0.040292528]\n",
      "Iter 2380, loss [-0.21945623, -0.2594277, 0.03997148]\n",
      "Iter 2381, loss [-0.19731055, -0.24053808, 0.043227524]\n",
      "Iter 2382, loss [-0.21741442, -0.25549874, 0.038084313]\n",
      "Iter 2383, loss [-0.21860477, -0.25648108, 0.037876304]\n",
      "Iter 2384, loss [-0.23245321, -0.26612145, 0.03366823]\n",
      "Iter 2385, loss [-0.22280875, -0.2596845, 0.03687575]\n",
      "Iter 2386, loss [-0.22596267, -0.26182637, 0.035863694]\n",
      "Iter 2387, loss [-0.22689626, -0.26146218, 0.034565933]\n",
      "Iter 2388, loss [-0.22467037, -0.26075187, 0.03608151]\n",
      "Iter 2389, loss [-0.16975202, -0.2214863, 0.051734284]\n",
      "Iter 2390, loss [-0.20985751, -0.25055534, 0.040697824]\n",
      "Iter 2391, loss [-0.22285494, -0.25922695, 0.036372]\n",
      "Iter 2392, loss [-0.22524637, -0.26266366, 0.0374173]\n",
      "Iter 2393, loss [-0.17164609, -0.22285572, 0.05120962]\n",
      "Iter 2394, loss [-0.21402748, -0.25310534, 0.039077863]\n",
      "Iter 2395, loss [-0.21516976, -0.25545168, 0.04028192]\n",
      "Iter 2396, loss [-0.22492728, -0.26399735, 0.039070077]\n",
      "Iter 2397, loss [-0.22959915, -0.26611593, 0.036516786]\n",
      "Iter 2398, loss [-0.21661532, -0.25656354, 0.039948232]\n",
      "Iter 2399, loss [-0.22819471, -0.26448503, 0.036290318]\n",
      "Iter 2400, loss [-0.22591126, -0.260168, 0.034256727]\n",
      "Iter 2401, loss [-0.17367539, -0.22574848, 0.0520731]\n",
      "Iter 2402, loss [-0.19970693, -0.24667756, 0.046970636]\n",
      "Iter 2403, loss [-0.2292517, -0.26601815, 0.03676646]\n",
      "Iter 2404, loss [-0.21948557, -0.2598161, 0.04033054]\n",
      "Iter 2405, loss [-0.22325228, -0.26147452, 0.03822224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2406, loss [-0.22577128, -0.26332662, 0.037555344]\n",
      "Iter 2407, loss [-0.21833186, -0.25702175, 0.038689896]\n",
      "Iter 2408, loss [-0.22174837, -0.26003104, 0.038282674]\n",
      "Iter 2409, loss [-0.22764772, -0.2630793, 0.03543157]\n",
      "Iter 2410, loss [-0.22679918, -0.26343203, 0.03663285]\n",
      "Iter 2411, loss [-0.20175834, -0.24266826, 0.040909912]\n",
      "Iter 2412, loss [-0.21560296, -0.25528064, 0.039677687]\n",
      "Iter 2413, loss [-0.22217244, -0.260675, 0.03850258]\n",
      "Iter 2414, loss [-0.2227285, -0.26048836, 0.037759855]\n",
      "Iter 2415, loss [-0.23067138, -0.26657754, 0.035906162]\n",
      "Iter 2416, loss [-0.2054805, -0.24548146, 0.04000096]\n",
      "Iter 2417, loss [-0.21323147, -0.25382555, 0.040594067]\n",
      "Iter 2418, loss [-0.22693539, -0.2658648, 0.0389294]\n",
      "Iter 2419, loss [-0.22614756, -0.26235205, 0.036204483]\n",
      "Iter 2420, loss [-0.21854715, -0.2592581, 0.040710937]\n",
      "Iter 2421, loss [-0.23406565, -0.27023864, 0.036172982]\n",
      "Iter 2422, loss [-0.22964391, -0.2661563, 0.036512367]\n",
      "Iter 2423, loss [-0.21399243, -0.25579378, 0.04180135]\n",
      "Iter 2424, loss [-0.21851838, -0.25820893, 0.03969056]\n",
      "Iter 2425, loss [-0.22322696, -0.2620527, 0.038825758]\n",
      "Iter 2426, loss [-0.22825883, -0.2632126, 0.034953758]\n",
      "Iter 2427, loss [-0.23160172, -0.26588285, 0.03428113]\n",
      "Iter 2428, loss [-0.22499731, -0.26391754, 0.03892023]\n",
      "Iter 2429, loss [-0.22655296, -0.26344207, 0.036889102]\n",
      "Iter 2430, loss [-0.21624957, -0.2545597, 0.038310125]\n",
      "Iter 2431, loss [-0.22410573, -0.2629838, 0.03887807]\n",
      "Iter 2432, loss [-0.21962701, -0.2589352, 0.0393082]\n",
      "Iter 2433, loss [-0.22119492, -0.26006585, 0.038870938]\n",
      "Iter 2434, loss [-0.21202022, -0.25316995, 0.04114973]\n",
      "Iter 2435, loss [-0.22607175, -0.26355398, 0.037482228]\n",
      "Iter 2436, loss [-0.17589048, -0.22751921, 0.051628735]\n",
      "Iter 2437, loss [-0.21395883, -0.25563312, 0.041674294]\n",
      "Iter 2438, loss [-0.31002417, -0.31774393, 0.0077197514]\n",
      "Iter 2439, loss [-0.2307755, -0.26753435, 0.036758833]\n",
      "Iter 2440, loss [-0.21756275, -0.25629768, 0.038734924]\n",
      "Iter 2441, loss [-0.22184895, -0.25844234, 0.036593392]\n",
      "Iter 2442, loss [-0.22307763, -0.26076826, 0.037690632]\n",
      "Iter 2443, loss [-0.23019418, -0.26603058, 0.03583639]\n",
      "Iter 2444, loss [-0.21476987, -0.25272444, 0.03795457]\n",
      "Iter 2445, loss [-0.21778563, -0.2574008, 0.039615184]\n",
      "Iter 2446, loss [-0.21787694, -0.25701293, 0.039135985]\n",
      "Iter 2447, loss [-0.21672034, -0.25774163, 0.04102128]\n",
      "Iter 2448, loss [-0.21638298, -0.25668064, 0.04029765]\n",
      "Iter 2449, loss [-0.21762455, -0.2564103, 0.03878576]\n",
      "Iter 2450, loss [-0.2241484, -0.2619496, 0.037801202]\n",
      "Iter 2451, loss [-0.22740152, -0.2629673, 0.035565764]\n",
      "Iter 2452, loss [-0.22320601, -0.26058677, 0.03738075]\n",
      "Iter 2453, loss [-0.21547213, -0.25250807, 0.03703595]\n",
      "Iter 2454, loss [-0.20991749, -0.24892958, 0.039012097]\n",
      "Iter 2455, loss [-0.2088071, -0.2484719, 0.0396648]\n",
      "Iter 2456, loss [-0.22321233, -0.26057255, 0.037360214]\n",
      "Iter 2457, loss [-0.20226002, -0.2447993, 0.042539276]\n",
      "Iter 2458, loss [-0.22315541, -0.26041558, 0.03726017]\n",
      "Iter 2459, loss [-0.21736066, -0.25640032, 0.039039653]\n",
      "Iter 2460, loss [-0.21901348, -0.25944567, 0.040432185]\n",
      "Iter 2461, loss [-0.22141959, -0.26020706, 0.03878747]\n",
      "Iter 2462, loss [-0.21770214, -0.2578735, 0.04017137]\n",
      "Iter 2463, loss [-0.22805205, -0.2647535, 0.03670144]\n",
      "Iter 2464, loss [-0.22564359, -0.26196676, 0.036323175]\n",
      "Iter 2465, loss [-0.22711176, -0.26262394, 0.035512175]\n",
      "Iter 2466, loss [-0.22452581, -0.2606279, 0.036102086]\n",
      "Iter 2467, loss [-0.21750776, -0.25728315, 0.039775386]\n",
      "Iter 2468, loss [-0.22187887, -0.26002657, 0.0381477]\n",
      "Iter 2469, loss [-0.22183847, -0.25939825, 0.037559774]\n",
      "Iter 2470, loss [-0.21989119, -0.25663722, 0.036746025]\n",
      "Iter 2471, loss [-0.21813342, -0.25701785, 0.038884435]\n",
      "Iter 2472, loss [-0.22313012, -0.26177752, 0.038647395]\n",
      "Iter 2473, loss [-0.2147648, -0.25546095, 0.040696148]\n",
      "Iter 2474, loss [-0.22532259, -0.2623334, 0.037010804]\n",
      "Iter 2475, loss [-0.22925961, -0.26555178, 0.036292173]\n",
      "Iter 2476, loss [-0.22540727, -0.26235428, 0.036947016]\n",
      "Iter 2477, loss [-0.22941756, -0.26412204, 0.034704477]\n",
      "Iter 2478, loss [-0.21935885, -0.2579847, 0.03862585]\n",
      "Iter 2479, loss [-0.18034227, -0.22961542, 0.049273144]\n",
      "Iter 2480, loss [-0.22067949, -0.25965628, 0.038976785]\n",
      "Iter 2481, loss [-0.21772857, -0.25820264, 0.04047407]\n",
      "Iter 2482, loss [-0.22537918, -0.26162615, 0.03624697]\n",
      "Iter 2483, loss [-0.21587597, -0.25452238, 0.03864641]\n",
      "Iter 2484, loss [-0.2166028, -0.25498542, 0.038382616]\n",
      "Iter 2485, loss [-0.23327674, -0.26855865, 0.03528191]\n",
      "Iter 2486, loss [-0.22470364, -0.261863, 0.03715935]\n",
      "Iter 2487, loss [-0.22125953, -0.25903007, 0.037770532]\n",
      "Iter 2488, loss [-0.20830563, -0.24932088, 0.04101525]\n",
      "Iter 2489, loss [-0.16581462, -0.22305822, 0.0572436]\n",
      "Iter 2490, loss [-0.222969, -0.2611479, 0.0381789]\n",
      "Iter 2491, loss [-0.21458201, -0.25227052, 0.037688505]\n",
      "Iter 2492, loss [-0.22786771, -0.2637483, 0.03588058]\n",
      "Iter 2493, loss [-0.21275158, -0.25409022, 0.04133864]\n",
      "Iter 2494, loss [-0.1975071, -0.24773625, 0.050229143]\n",
      "Iter 2495, loss [-0.20890889, -0.25181416, 0.04290527]\n",
      "Iter 2496, loss [-0.22466248, -0.26430365, 0.03964118]\n",
      "Iter 2497, loss [-0.22792743, -0.26443532, 0.03650789]\n",
      "Iter 2498, loss [-0.2147936, -0.2540791, 0.039285503]\n",
      "Iter 2499, loss [-0.21231703, -0.25201046, 0.03969343]\n",
      "Iter 2500, loss [-0.22606036, -0.26219478, 0.036134418]\n",
      "Iter 2501, loss [-0.20800672, -0.24792048, 0.039913755]\n",
      "Iter 2502, loss [-0.23201571, -0.2668998, 0.034884077]\n",
      "Iter 2503, loss [-0.22469923, -0.2640636, 0.039364368]\n",
      "Iter 2504, loss [-0.23005679, -0.26634184, 0.03628505]\n",
      "Iter 2505, loss [-0.22822899, -0.26506165, 0.036832657]\n",
      "Iter 2506, loss [-0.22573885, -0.26524922, 0.039510377]\n",
      "Iter 2507, loss [-0.21265116, -0.2544416, 0.041790422]\n",
      "Iter 2508, loss [-0.2155558, -0.25402224, 0.03846644]\n",
      "Iter 2509, loss [-0.2261191, -0.26302168, 0.036902584]\n",
      "Iter 2510, loss [-0.23167884, -0.26665187, 0.034973025]\n",
      "Iter 2511, loss [-0.22606912, -0.26279157, 0.036722444]\n",
      "Iter 2512, loss [-0.21925966, -0.25998828, 0.04072861]\n",
      "Iter 2513, loss [-0.22361924, -0.25952253, 0.035903286]\n",
      "Iter 2514, loss [-0.21110585, -0.25386223, 0.042756375]\n",
      "Iter 2515, loss [-0.22296904, -0.26099327, 0.038024228]\n",
      "Iter 2516, loss [-0.21415856, -0.2541919, 0.040033333]\n",
      "Iter 2517, loss [-0.22148411, -0.25993046, 0.03844635]\n",
      "Iter 2518, loss [-0.227592, -0.26391196, 0.036319952]\n",
      "Iter 2519, loss [-0.21623588, -0.25485912, 0.03862325]\n",
      "Iter 2520, loss [-0.21246605, -0.25265744, 0.040191393]\n",
      "Iter 2521, loss [-0.22712423, -0.26515737, 0.038033143]\n",
      "Iter 2522, loss [-0.18454182, -0.2342813, 0.049739473]\n",
      "Iter 2523, loss [-0.22285326, -0.26007158, 0.037218317]\n",
      "Iter 2524, loss [-0.2241126, -0.2625873, 0.0384747]\n",
      "Iter 2525, loss [-0.21990824, -0.26007548, 0.040167235]\n",
      "Iter 2526, loss [-0.20682839, -0.249482, 0.042653617]\n",
      "Iter 2527, loss [-0.22723657, -0.26356956, 0.036333002]\n",
      "Iter 2528, loss [-0.22034897, -0.25874406, 0.038395092]\n",
      "Iter 2529, loss [-0.22419928, -0.26131463, 0.037115347]\n",
      "Iter 2530, loss [-0.21980837, -0.2578841, 0.038075708]\n",
      "Iter 2531, loss [-0.1845468, -0.23641253, 0.05186572]\n",
      "Iter 2532, loss [-0.22560677, -0.2654357, 0.039828926]\n",
      "Iter 2533, loss [-0.22578472, -0.2682655, 0.042480763]\n",
      "Iter 2534, loss [-0.21497223, -0.25668526, 0.04171302]\n",
      "Iter 2535, loss [-0.21990657, -0.2594996, 0.03959305]\n",
      "Iter 2536, loss [-0.22262254, -0.2602897, 0.037667163]\n",
      "Iter 2537, loss [-0.2317965, -0.26613507, 0.03433856]\n",
      "Iter 2538, loss [-0.2206005, -0.25592285, 0.035322357]\n",
      "Iter 2539, loss [-0.22125831, -0.25823855, 0.036980238]\n",
      "Iter 2540, loss [-0.21873257, -0.25595808, 0.037225507]\n",
      "Iter 2541, loss [-0.2260011, -0.26618695, 0.040185854]\n",
      "Iter 2542, loss [-0.21923876, -0.25985304, 0.040614285]\n",
      "Iter 2543, loss [-0.22738981, -0.26592132, 0.038531505]\n",
      "Iter 2544, loss [-0.2250197, -0.2634237, 0.03840401]\n",
      "Iter 2545, loss [-0.21847458, -0.25735876, 0.03888418]\n",
      "Iter 2546, loss [-0.22274134, -0.2599477, 0.03720636]\n",
      "Iter 2547, loss [-0.22521883, -0.26093918, 0.035720352]\n",
      "Iter 2548, loss [-0.2308614, -0.2656206, 0.034759194]\n",
      "Iter 2549, loss [-0.22246617, -0.25974518, 0.037279017]\n",
      "Iter 2550, loss [-0.19386055, -0.23912181, 0.04526126]\n",
      "Iter 2551, loss [-0.23275506, -0.26841578, 0.03566071]\n",
      "Iter 2552, loss [-0.2179182, -0.25609702, 0.038178813]\n",
      "Iter 2553, loss [-0.22113195, -0.25996554, 0.03883358]\n",
      "Iter 2554, loss [-0.23052055, -0.26639286, 0.035872318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2555, loss [-0.21640033, -0.25720376, 0.04080343]\n",
      "Iter 2556, loss [-0.2229634, -0.26102647, 0.038063075]\n",
      "Iter 2557, loss [-0.22000895, -0.2581993, 0.038190346]\n",
      "Iter 2558, loss [-0.2317833, -0.2655122, 0.03372889]\n",
      "Iter 2559, loss [-0.22134447, -0.2600191, 0.038674623]\n",
      "Iter 2560, loss [-0.22306249, -0.25863925, 0.03557677]\n",
      "Iter 2561, loss [-0.22711885, -0.26483345, 0.0377146]\n",
      "Iter 2562, loss [-0.22640303, -0.26510414, 0.038701117]\n",
      "Iter 2563, loss [-0.23388198, -0.27091646, 0.03703449]\n",
      "Iter 2564, loss [-0.22313808, -0.26315627, 0.040018186]\n",
      "Iter 2565, loss [-0.23031643, -0.26689252, 0.0365761]\n",
      "Iter 2566, loss [-0.22663832, -0.2642625, 0.03762418]\n",
      "Iter 2567, loss [-0.21681222, -0.2564569, 0.039644685]\n",
      "Iter 2568, loss [-0.23025435, -0.2655816, 0.03532725]\n",
      "Iter 2569, loss [-0.21511824, -0.2542789, 0.03916065]\n",
      "Iter 2570, loss [-0.22884631, -0.26607442, 0.037228115]\n",
      "Iter 2571, loss [-0.22387321, -0.26384884, 0.039975632]\n",
      "Iter 2572, loss [-0.22816479, -0.26749954, 0.03933475]\n",
      "Iter 2573, loss [-0.21335296, -0.25461048, 0.04125751]\n",
      "Iter 2574, loss [-0.21396032, -0.25668094, 0.042720612]\n",
      "Iter 2575, loss [-0.20899259, -0.24959308, 0.04060049]\n",
      "Iter 2576, loss [-0.22459362, -0.26116225, 0.036568623]\n",
      "Iter 2577, loss [-0.23421808, -0.2689338, 0.034715723]\n",
      "Iter 2578, loss [-0.19902135, -0.24343956, 0.044418197]\n",
      "Iter 2579, loss [-0.23001464, -0.26547125, 0.035456613]\n",
      "Iter 2580, loss [-0.22477621, -0.26039436, 0.035618156]\n",
      "Iter 2581, loss [-0.22076514, -0.2579581, 0.03719297]\n",
      "Iter 2582, loss [-0.2238951, -0.26203346, 0.038138356]\n",
      "Iter 2583, loss [-0.22128612, -0.26048014, 0.039194018]\n",
      "Iter 2584, loss [-0.22029845, -0.26041403, 0.040115576]\n",
      "Iter 2585, loss [-0.1745976, -0.22777432, 0.053176712]\n",
      "Iter 2586, loss [-0.22775634, -0.26431727, 0.036560934]\n",
      "Iter 2587, loss [-0.21128392, -0.25180134, 0.040517427]\n",
      "Iter 2588, loss [-0.23457456, -0.26959324, 0.035018675]\n",
      "Iter 2589, loss [-0.22956747, -0.26441553, 0.034848057]\n",
      "Iter 2590, loss [-0.22284053, -0.2603318, 0.037491273]\n",
      "Iter 2591, loss [-0.21902315, -0.25794438, 0.038921222]\n",
      "Iter 2592, loss [-0.22278619, -0.26152012, 0.03873393]\n",
      "Iter 2593, loss [-0.19848004, -0.24057378, 0.04209373]\n",
      "Iter 2594, loss [-0.15645258, -0.2093547, 0.052902117]\n",
      "Iter 2595, loss [-0.22378436, -0.26133925, 0.03755489]\n",
      "Iter 2596, loss [-0.22376117, -0.2621667, 0.038405538]\n",
      "Iter 2597, loss [-0.1289823, -0.18519992, 0.056217603]\n",
      "Iter 2598, loss [-0.19610891, -0.24015205, 0.04404314]\n",
      "Iter 2599, loss [-0.17373201, -0.22495173, 0.051219724]\n",
      "Iter 2600, loss [-0.22809926, -0.26422897, 0.036129717]\n",
      "Iter 2601, loss [-0.23375498, -0.26946527, 0.03571029]\n",
      "Iter 2602, loss [-0.22621132, -0.26534638, 0.039135054]\n",
      "Iter 2603, loss [-0.22585267, -0.26388615, 0.038033478]\n",
      "Iter 2604, loss [-0.21756056, -0.2580621, 0.040501542]\n",
      "Iter 2605, loss [-0.15693206, -0.21585298, 0.05892092]\n",
      "Iter 2606, loss [-0.22818545, -0.265494, 0.037308536]\n",
      "Iter 2607, loss [-0.22278343, -0.2612019, 0.03841846]\n",
      "Iter 2608, loss [-0.22381994, -0.26146254, 0.037642606]\n",
      "Iter 2609, loss [-0.22237182, -0.26095673, 0.038584925]\n",
      "Iter 2610, loss [-0.21831727, -0.25526094, 0.03694367]\n",
      "Iter 2611, loss [-0.22149694, -0.25818816, 0.03669121]\n",
      "Iter 2612, loss [-0.22293305, -0.2588771, 0.03594405]\n",
      "Iter 2613, loss [-0.21637592, -0.25347355, 0.03709764]\n",
      "Iter 2614, loss [-0.21501625, -0.2553888, 0.040372558]\n",
      "Iter 2615, loss [-0.23392743, -0.26982334, 0.035895906]\n",
      "Iter 2616, loss [-0.2274769, -0.26623246, 0.03875556]\n",
      "Iter 2617, loss [-0.23007677, -0.26708782, 0.037011046]\n",
      "Iter 2618, loss [-0.17364377, -0.22818038, 0.05453662]\n",
      "Iter 2619, loss [-0.22851479, -0.26556265, 0.037047856]\n",
      "Iter 2620, loss [-0.2242986, -0.26136106, 0.037062462]\n",
      "Iter 2621, loss [-0.20448825, -0.2467266, 0.042238347]\n",
      "Iter 2622, loss [-0.21039237, -0.25106147, 0.040669102]\n",
      "Iter 2623, loss [-0.2192756, -0.25881192, 0.039536335]\n",
      "Iter 2624, loss [-0.22634628, -0.26314312, 0.036796838]\n",
      "Iter 2625, loss [-0.22844669, -0.26372978, 0.03528309]\n",
      "Iter 2626, loss [-0.21991937, -0.25899306, 0.039073687]\n",
      "Iter 2627, loss [-0.22048756, -0.2556615, 0.03517392]\n",
      "Iter 2628, loss [-0.22230741, -0.25937134, 0.03706393]\n",
      "Iter 2629, loss [-0.22469366, -0.25937656, 0.034682896]\n",
      "Iter 2630, loss [-0.22946273, -0.26485482, 0.035392087]\n",
      "Iter 2631, loss [-0.2235992, -0.26123178, 0.037632585]\n",
      "Iter 2632, loss [-0.21358334, -0.25466082, 0.041077483]\n",
      "Iter 2633, loss [-0.23052229, -0.26548788, 0.034965586]\n",
      "Iter 2634, loss [-0.21947856, -0.2588375, 0.039358925]\n",
      "Iter 2635, loss [-0.21857966, -0.25833613, 0.039756462]\n",
      "Iter 2636, loss [-0.202636, -0.24341834, 0.040782325]\n",
      "Iter 2637, loss [-0.22610791, -0.26344317, 0.03733526]\n",
      "Iter 2638, loss [-0.2198778, -0.26036334, 0.040485546]\n",
      "Iter 2639, loss [-0.16580293, -0.2237477, 0.057944775]\n",
      "Iter 2640, loss [-0.21931887, -0.25690302, 0.037584156]\n",
      "Iter 2641, loss [-0.20165811, -0.24349917, 0.041841056]\n",
      "Iter 2642, loss [-0.21863793, -0.25834104, 0.039703112]\n",
      "Iter 2643, loss [-0.23361428, -0.26837808, 0.034763798]\n",
      "Iter 2644, loss [-0.22370882, -0.2615195, 0.03781067]\n",
      "Iter 2645, loss [-0.21705341, -0.2561228, 0.039069377]\n",
      "Iter 2646, loss [-0.22531983, -0.26359573, 0.038275898]\n",
      "Iter 2647, loss [-0.22939493, -0.26544252, 0.03604759]\n",
      "Iter 2648, loss [-0.212702, -0.25198996, 0.039287955]\n",
      "Iter 2649, loss [-0.21977451, -0.25735793, 0.037583403]\n",
      "Iter 2650, loss [-0.21396402, -0.25306594, 0.03910193]\n",
      "Iter 2651, loss [-0.21478665, -0.25361514, 0.038828485]\n",
      "Iter 2652, loss [-0.22217071, -0.2609504, 0.03877968]\n",
      "Iter 2653, loss [-0.21845159, -0.25953108, 0.041079495]\n",
      "Iter 2654, loss [-0.2164127, -0.25520828, 0.038795598]\n",
      "Iter 2655, loss [-0.15882134, -0.21557643, 0.056755073]\n",
      "Iter 2656, loss [-0.21954282, -0.25965273, 0.040109918]\n",
      "Iter 2657, loss [-0.21957073, -0.25921252, 0.039641798]\n",
      "Iter 2658, loss [-0.2194786, -0.2589406, 0.039462]\n",
      "Iter 2659, loss [-0.21143605, -0.25171462, 0.040278565]\n",
      "Iter 2660, loss [-0.2259853, -0.26227492, 0.03628962]\n",
      "Iter 2661, loss [-0.15676627, -0.21200356, 0.055237286]\n",
      "Iter 2662, loss [-0.2319607, -0.26719815, 0.035237446]\n",
      "Iter 2663, loss [-0.22060859, -0.26040205, 0.03979346]\n",
      "Iter 2664, loss [-0.23143756, -0.2677698, 0.036332242]\n",
      "Iter 2665, loss [-0.22211063, -0.25973424, 0.03762362]\n",
      "Iter 2666, loss [-0.21813276, -0.25742224, 0.039289474]\n",
      "Iter 2667, loss [-0.22686781, -0.26327398, 0.03640617]\n",
      "Iter 2668, loss [-0.17567167, -0.22503057, 0.049358904]\n",
      "Iter 2669, loss [-0.21962145, -0.25761068, 0.037989233]\n",
      "Iter 2670, loss [-0.22431263, -0.26235497, 0.03804233]\n",
      "Iter 2671, loss [-0.17162389, -0.2246334, 0.053009503]\n",
      "Iter 2672, loss [-0.22752607, -0.26380056, 0.03627449]\n",
      "Iter 2673, loss [-0.22865379, -0.26529324, 0.03663945]\n",
      "Iter 2674, loss [-0.21803866, -0.25815058, 0.04011191]\n",
      "Iter 2675, loss [-0.21975395, -0.2578508, 0.038096853]\n",
      "Iter 2676, loss [-0.22799337, -0.2642399, 0.03624653]\n",
      "Iter 2677, loss [-0.22290911, -0.26144978, 0.038540673]\n",
      "Iter 2678, loss [-0.22577186, -0.26312828, 0.03735642]\n",
      "Iter 2679, loss [-0.22202784, -0.25898728, 0.03695944]\n",
      "Iter 2680, loss [-0.22474548, -0.26203224, 0.03728675]\n",
      "Iter 2681, loss [-0.19313593, -0.24204953, 0.048913598]\n",
      "Iter 2682, loss [-0.3110319, -0.3184337, 0.007401808]\n",
      "Iter 2683, loss [-0.22618285, -0.2625548, 0.036371943]\n",
      "Iter 2684, loss [-0.21980308, -0.25841984, 0.03861676]\n",
      "Iter 2685, loss [-0.23132896, -0.26501617, 0.0336872]\n",
      "Iter 2686, loss [-0.22912687, -0.26449028, 0.035363413]\n",
      "Iter 2687, loss [-0.22156164, -0.25904098, 0.03747935]\n",
      "Iter 2688, loss [-0.21974596, -0.2598996, 0.040153626]\n",
      "Iter 2689, loss [-0.22204189, -0.26176816, 0.03972627]\n",
      "Iter 2690, loss [-0.22468019, -0.26155573, 0.03687555]\n",
      "Iter 2691, loss [-0.2215753, -0.26063615, 0.039060842]\n",
      "Iter 2692, loss [-0.22777122, -0.26435602, 0.036584802]\n",
      "Iter 2693, loss [-0.22039427, -0.26038128, 0.03998701]\n",
      "Iter 2694, loss [-0.21532422, -0.25503263, 0.039708402]\n",
      "Iter 2695, loss [-0.13594273, -0.19895948, 0.063016765]\n",
      "Iter 2696, loss [-0.22184108, -0.2590724, 0.03723131]\n",
      "Iter 2697, loss [-0.22548933, -0.26250154, 0.03701221]\n",
      "Iter 2698, loss [-0.21639644, -0.25562882, 0.03923239]\n",
      "Iter 2699, loss [-0.22548188, -0.26331708, 0.037835192]\n",
      "Iter 2700, loss [-0.23172837, -0.26563582, 0.033907447]\n",
      "Iter 2701, loss [-0.1496084, -0.20940693, 0.059798524]\n",
      "Iter 2702, loss [-0.22130668, -0.2602612, 0.038954534]\n",
      "Iter 2703, loss [-0.22021075, -0.25896415, 0.038753405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2704, loss [-0.22460389, -0.2623726, 0.03776873]\n",
      "Iter 2705, loss [-0.168329, -0.22003505, 0.051706046]\n",
      "Iter 2706, loss [-0.22377975, -0.26295722, 0.03917746]\n",
      "Iter 2707, loss [-0.22950083, -0.26511416, 0.035613336]\n",
      "Iter 2708, loss [-0.22370821, -0.26095036, 0.037242137]\n",
      "Iter 2709, loss [-0.19660814, -0.24006501, 0.043456864]\n",
      "Iter 2710, loss [-0.22477092, -0.26171073, 0.036939815]\n",
      "Iter 2711, loss [-0.21655169, -0.25507656, 0.038524866]\n",
      "Iter 2712, loss [-0.22584355, -0.26439744, 0.03855389]\n",
      "Iter 2713, loss [-0.22709021, -0.26235452, 0.035264313]\n",
      "Iter 2714, loss [-0.22373831, -0.26222354, 0.038485236]\n",
      "Iter 2715, loss [-0.23439465, -0.26942068, 0.03502603]\n",
      "Iter 2716, loss [-0.22972064, -0.26534337, 0.035622727]\n",
      "Iter 2717, loss [-0.22939777, -0.26304978, 0.033652004]\n",
      "Iter 2718, loss [-0.21816735, -0.25401467, 0.035847325]\n",
      "Iter 2719, loss [-0.22846787, -0.26542816, 0.03696029]\n",
      "Iter 2720, loss [-0.21573728, -0.25537512, 0.039637834]\n",
      "Iter 2721, loss [-0.21720125, -0.2572164, 0.040015146]\n",
      "Iter 2722, loss [-0.14599472, -0.20382549, 0.057830766]\n",
      "Iter 2723, loss [-0.22435139, -0.26197234, 0.037620947]\n",
      "Iter 2724, loss [-0.2305119, -0.26857457, 0.03806266]\n",
      "Iter 2725, loss [-0.2251617, -0.26245868, 0.037296977]\n",
      "Iter 2726, loss [-0.20965075, -0.24942097, 0.039770223]\n",
      "Iter 2727, loss [-0.15833142, -0.21294886, 0.054617442]\n",
      "Iter 2728, loss [-0.2266366, -0.26485017, 0.038213566]\n",
      "Iter 2729, loss [-0.21665868, -0.25621608, 0.039557405]\n",
      "Iter 2730, loss [-0.21682663, -0.2583412, 0.041514557]\n",
      "Iter 2731, loss [-0.21993098, -0.25701353, 0.03708256]\n",
      "Iter 2732, loss [-0.22942443, -0.26466492, 0.035240486]\n",
      "Iter 2733, loss [-0.22732203, -0.2644288, 0.03710677]\n",
      "Iter 2734, loss [-0.21678934, -0.25559634, 0.038806997]\n",
      "Iter 2735, loss [-0.2134487, -0.2525751, 0.03912639]\n",
      "Iter 2736, loss [-0.22161701, -0.2569646, 0.035347577]\n",
      "Iter 2737, loss [-0.22574057, -0.26309896, 0.037358392]\n",
      "Iter 2738, loss [-0.22216766, -0.26158446, 0.0394168]\n",
      "Iter 2739, loss [-0.21930173, -0.25666714, 0.037365407]\n",
      "Iter 2740, loss [-0.21500473, -0.2548906, 0.039885864]\n",
      "Iter 2741, loss [-0.21252269, -0.25304168, 0.040519003]\n",
      "Iter 2742, loss [-0.2207619, -0.25759742, 0.03683553]\n",
      "Iter 2743, loss [-0.21933365, -0.26065674, 0.041323096]\n",
      "Iter 2744, loss [-0.22809207, -0.2672807, 0.03918862]\n",
      "Iter 2745, loss [-0.22701901, -0.26440966, 0.03739065]\n",
      "Iter 2746, loss [-0.22558993, -0.2623294, 0.036739472]\n",
      "Iter 2747, loss [-0.22391275, -0.26320702, 0.039294273]\n",
      "Iter 2748, loss [-0.13341688, -0.19572145, 0.062304568]\n",
      "Iter 2749, loss [-0.22493607, -0.2614048, 0.03646875]\n",
      "Iter 2750, loss [-0.21111444, -0.25137174, 0.040257312]\n",
      "Iter 2751, loss [-0.2245245, -0.26182833, 0.037303843]\n",
      "Iter 2752, loss [-0.22853564, -0.26471925, 0.036183607]\n",
      "Iter 2753, loss [-0.2299818, -0.2671716, 0.037189793]\n",
      "Iter 2754, loss [-0.22634736, -0.26435277, 0.03800541]\n",
      "Iter 2755, loss [-0.20073128, -0.2434372, 0.04270592]\n",
      "Iter 2756, loss [-0.22858907, -0.26579556, 0.037206482]\n",
      "Iter 2757, loss [-0.22716713, -0.26264697, 0.03547984]\n",
      "Iter 2758, loss [-0.21830362, -0.25625193, 0.037948307]\n",
      "Iter 2759, loss [-0.17710748, -0.21917674, 0.042069253]\n",
      "Iter 2760, loss [-0.21563141, -0.2533433, 0.037711907]\n",
      "Iter 2761, loss [-0.21482798, -0.25312987, 0.038301878]\n",
      "Iter 2762, loss [-0.21946463, -0.2585904, 0.039125763]\n",
      "Iter 2763, loss [-0.23070294, -0.26606056, 0.03535763]\n",
      "Iter 2764, loss [-0.22530141, -0.26383907, 0.038537648]\n",
      "Iter 2765, loss [-0.22233549, -0.25997007, 0.037634578]\n",
      "Iter 2766, loss [-0.22975953, -0.26590067, 0.036141142]\n",
      "Iter 2767, loss [-0.2182196, -0.25659823, 0.03837864]\n",
      "Iter 2768, loss [-0.18690391, -0.23271348, 0.045809567]\n",
      "Iter 2769, loss [-0.21394312, -0.25371492, 0.039771803]\n",
      "Iter 2770, loss [-0.22856742, -0.26428592, 0.0357185]\n",
      "Iter 2771, loss [-0.2269887, -0.2636492, 0.036660496]\n",
      "Iter 2772, loss [-0.23155841, -0.2680353, 0.03647688]\n",
      "Iter 2773, loss [-0.22723225, -0.26484007, 0.03760781]\n",
      "Iter 2774, loss [-0.23063, -0.26721346, 0.03658347]\n",
      "Iter 2775, loss [-0.22914013, -0.2669281, 0.037787966]\n",
      "Iter 2776, loss [-0.20872244, -0.25047114, 0.041748695]\n",
      "Iter 2777, loss [-0.21530116, -0.25479993, 0.039498776]\n",
      "Iter 2778, loss [-0.21265875, -0.2525698, 0.039911043]\n",
      "Iter 2779, loss [-0.2191677, -0.2569347, 0.037767004]\n",
      "Iter 2780, loss [-0.22347532, -0.26143074, 0.03795542]\n",
      "Iter 2781, loss [-0.22217175, -0.25823927, 0.036067516]\n",
      "Iter 2782, loss [-0.21835735, -0.2571565, 0.038799144]\n",
      "Iter 2783, loss [-0.2227535, -0.2612195, 0.038466007]\n",
      "Iter 2784, loss [-0.22205001, -0.2625836, 0.040533602]\n",
      "Iter 2785, loss [-0.22550702, -0.26460797, 0.03910094]\n",
      "Iter 2786, loss [-0.22823639, -0.26600793, 0.037771538]\n",
      "Iter 2787, loss [-0.22482936, -0.26234, 0.03751065]\n",
      "Iter 2788, loss [-0.21698985, -0.25693035, 0.039940502]\n",
      "Iter 2789, loss [-0.21766466, -0.25602117, 0.038356517]\n",
      "Iter 2790, loss [-0.18800648, -0.23565984, 0.047653362]\n",
      "Iter 2791, loss [-0.22461267, -0.2609855, 0.036372826]\n",
      "Iter 2792, loss [-0.23035975, -0.26674762, 0.036387876]\n",
      "Iter 2793, loss [-0.21423793, -0.25222552, 0.037987582]\n",
      "Iter 2794, loss [-0.22695218, -0.2650657, 0.03811352]\n",
      "Iter 2795, loss [-0.22385369, -0.26254117, 0.038687486]\n",
      "Iter 2796, loss [-0.22292355, -0.26044762, 0.03752408]\n",
      "Iter 2797, loss [-0.21697128, -0.25597695, 0.039005674]\n",
      "Iter 2798, loss [-0.22863905, -0.2629613, 0.034322243]\n",
      "Iter 2799, loss [-0.21451092, -0.25606686, 0.04155594]\n",
      "Iter 2800, loss [-0.218546, -0.25583777, 0.037291765]\n",
      "Iter 2801, loss [-0.2141223, -0.25489652, 0.040774226]\n",
      "Iter 2802, loss [-0.22332135, -0.26161852, 0.038297173]\n",
      "Iter 2803, loss [-0.2276693, -0.2632281, 0.035558797]\n",
      "Iter 2804, loss [-0.22707835, -0.26505423, 0.03797587]\n",
      "Iter 2805, loss [-0.21924987, -0.25968343, 0.040433552]\n",
      "Iter 2806, loss [-0.22507747, -0.261468, 0.036390528]\n",
      "Iter 2807, loss [-0.22532365, -0.26492497, 0.039601333]\n",
      "Iter 2808, loss [-0.21724, -0.2569214, 0.039681412]\n",
      "Iter 2809, loss [-0.21447924, -0.2539276, 0.039448343]\n",
      "Iter 2810, loss [-0.22853038, -0.26515108, 0.03662071]\n",
      "Iter 2811, loss [-0.21640289, -0.25546077, 0.039057888]\n",
      "Iter 2812, loss [-0.21057461, -0.25244427, 0.041869655]\n",
      "Iter 2813, loss [-0.2059579, -0.24664156, 0.04068366]\n",
      "Iter 2814, loss [-0.21770199, -0.25636348, 0.0386615]\n",
      "Iter 2815, loss [-0.22443247, -0.2620795, 0.03764703]\n",
      "Iter 2816, loss [-0.22553991, -0.26157936, 0.03603946]\n",
      "Iter 2817, loss [-0.22675577, -0.26471028, 0.03795451]\n",
      "Iter 2818, loss [-0.22218114, -0.25973395, 0.037552796]\n",
      "Iter 2819, loss [-0.22478381, -0.26443088, 0.039647065]\n",
      "Iter 2820, loss [-0.21868207, -0.25754476, 0.038862694]\n",
      "Iter 2821, loss [-0.21960747, -0.25787917, 0.038271703]\n",
      "Iter 2822, loss [-0.2181423, -0.2585789, 0.04043659]\n",
      "Iter 2823, loss [-0.22315307, -0.26017278, 0.03701971]\n",
      "Iter 2824, loss [-0.1879973, -0.23400246, 0.04600516]\n",
      "Iter 2825, loss [-0.21863651, -0.25843883, 0.03980232]\n",
      "Iter 2826, loss [-0.22014585, -0.25943783, 0.03929197]\n",
      "Iter 2827, loss [-0.21027112, -0.2516768, 0.04140568]\n",
      "Iter 2828, loss [-0.22041005, -0.259793, 0.039382964]\n",
      "Iter 2829, loss [-0.21493894, -0.2550292, 0.04009027]\n",
      "Iter 2830, loss [-0.20432493, -0.24751748, 0.043192547]\n",
      "Iter 2831, loss [-0.22347502, -0.26022202, 0.036746994]\n",
      "Iter 2832, loss [-0.2202776, -0.25799242, 0.037714805]\n",
      "Iter 2833, loss [-0.2285625, -0.26638523, 0.03782273]\n",
      "Iter 2834, loss [-0.22316027, -0.26136062, 0.038200345]\n",
      "Iter 2835, loss [-0.22024491, -0.26084292, 0.040598]\n",
      "Iter 2836, loss [-0.17190103, -0.22581613, 0.053915095]\n",
      "Iter 2837, loss [-0.21938272, -0.26165932, 0.042276606]\n",
      "Iter 2838, loss [-0.2194457, -0.25921845, 0.039772756]\n",
      "Iter 2839, loss [-0.21785451, -0.25806147, 0.040206958]\n",
      "Iter 2840, loss [-0.21923488, -0.25807905, 0.038844176]\n",
      "Iter 2841, loss [-0.20781668, -0.24907333, 0.04125665]\n",
      "Iter 2842, loss [-0.22183417, -0.25925887, 0.037424695]\n",
      "Iter 2843, loss [-0.22841476, -0.26667824, 0.03826348]\n",
      "Iter 2844, loss [-0.20866185, -0.24853314, 0.039871294]\n",
      "Iter 2845, loss [-0.22444257, -0.2617256, 0.03728304]\n",
      "Iter 2846, loss [-0.2209316, -0.2584396, 0.037507996]\n",
      "Iter 2847, loss [-0.22419664, -0.26147857, 0.03728193]\n",
      "Iter 2848, loss [-0.2191248, -0.25767982, 0.038555026]\n",
      "Iter 2849, loss [-0.21666315, -0.25832677, 0.041663613]\n",
      "Iter 2850, loss [-0.22497466, -0.26324224, 0.038267575]\n",
      "Iter 2851, loss [-0.18497738, -0.23308165, 0.04810428]\n",
      "Iter 2852, loss [-0.2124472, -0.25386524, 0.041418053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2853, loss [-0.21667382, -0.25722855, 0.040554725]\n",
      "Iter 2854, loss [-0.218294, -0.25679424, 0.03850025]\n",
      "Iter 2855, loss [-0.21791539, -0.25535992, 0.03744454]\n",
      "Iter 2856, loss [-0.22787449, -0.263157, 0.03528252]\n",
      "Iter 2857, loss [-0.22962832, -0.26607618, 0.03644785]\n",
      "Iter 2858, loss [-0.2173039, -0.25636113, 0.039057225]\n",
      "Iter 2859, loss [-0.22718734, -0.2636988, 0.03651146]\n",
      "Iter 2860, loss [-0.2283606, -0.26424778, 0.035887178]\n",
      "Iter 2861, loss [-0.2230826, -0.26104993, 0.03796733]\n",
      "Iter 2862, loss [-0.2253355, -0.26293564, 0.03760014]\n",
      "Iter 2863, loss [-0.22038017, -0.25956845, 0.03918828]\n",
      "Iter 2864, loss [-0.22132671, -0.25977513, 0.038448416]\n",
      "Iter 2865, loss [-0.2234591, -0.2616607, 0.038201593]\n",
      "Iter 2866, loss [-0.21389723, -0.25412744, 0.040230222]\n",
      "Iter 2867, loss [-0.22108617, -0.2588493, 0.03776311]\n",
      "Iter 2868, loss [-0.19107977, -0.23907496, 0.04799519]\n",
      "Iter 2869, loss [-0.2251455, -0.2624157, 0.037270203]\n",
      "Iter 2870, loss [-0.21973571, -0.25848377, 0.038748052]\n",
      "Iter 2871, loss [-0.2240395, -0.26147732, 0.037437823]\n",
      "Iter 2872, loss [-0.21710879, -0.2567795, 0.039670713]\n",
      "Iter 2873, loss [-0.21837284, -0.2568197, 0.038446855]\n",
      "Iter 2874, loss [-0.22973007, -0.26577845, 0.03604839]\n",
      "Iter 2875, loss [-0.2207677, -0.25865957, 0.037891865]\n",
      "Iter 2876, loss [-0.22587149, -0.26140505, 0.03553356]\n",
      "Iter 2877, loss [-0.22353745, -0.26108107, 0.03754363]\n",
      "Iter 2878, loss [-0.22397664, -0.26193935, 0.037962712]\n",
      "Iter 2879, loss [-0.2276926, -0.26377267, 0.036080062]\n",
      "Iter 2880, loss [-0.21263963, -0.2547481, 0.042108484]\n",
      "Iter 2881, loss [-0.18079594, -0.230143, 0.04934705]\n",
      "Iter 2882, loss [-0.22407843, -0.26298007, 0.038901642]\n",
      "Iter 2883, loss [-0.22984396, -0.26573303, 0.035889074]\n",
      "Iter 2884, loss [-0.22535896, -0.2632135, 0.037854526]\n",
      "Iter 2885, loss [-0.22295955, -0.26094058, 0.03798104]\n",
      "Iter 2886, loss [-0.22771023, -0.2654619, 0.037751656]\n",
      "Iter 2887, loss [-0.21936755, -0.26072565, 0.041358102]\n",
      "Iter 2888, loss [-0.22122884, -0.25933948, 0.03811064]\n",
      "Iter 2889, loss [-0.21327588, -0.25313002, 0.039854135]\n",
      "Iter 2890, loss [-0.2210764, -0.2587761, 0.0376997]\n",
      "Iter 2891, loss [-0.22484696, -0.26263657, 0.037789613]\n",
      "Iter 2892, loss [-0.22086199, -0.25674382, 0.03588183]\n",
      "Iter 2893, loss [-0.22814684, -0.26306793, 0.03492109]\n",
      "Iter 2894, loss [-0.2291151, -0.26516524, 0.03605015]\n",
      "Iter 2895, loss [-0.22287291, -0.26030862, 0.037435703]\n",
      "Iter 2896, loss [-0.22055379, -0.25984186, 0.03928808]\n",
      "Iter 2897, loss [-0.22370696, -0.263566, 0.039859034]\n",
      "Iter 2898, loss [-0.22627103, -0.26545057, 0.039179526]\n",
      "Iter 2899, loss [-0.22384849, -0.2621929, 0.038344406]\n",
      "Iter 2900, loss [-0.21618801, -0.2570741, 0.040886074]\n",
      "Iter 2901, loss [-0.22390632, -0.26227733, 0.03837101]\n",
      "Iter 2902, loss [-0.21725044, -0.25616702, 0.03891659]\n",
      "Iter 2903, loss [-0.22474104, -0.26255354, 0.037812494]\n",
      "Iter 2904, loss [-0.22107485, -0.26061642, 0.039541565]\n",
      "Iter 2905, loss [-0.22209245, -0.25901863, 0.036926188]\n",
      "Iter 2906, loss [-0.22553475, -0.26306066, 0.037525903]\n",
      "Iter 2907, loss [-0.22277464, -0.26122785, 0.038453203]\n",
      "Iter 2908, loss [-0.22565708, -0.26304808, 0.037391]\n",
      "Iter 2909, loss [-0.220756, -0.2581396, 0.03738362]\n",
      "Iter 2910, loss [-0.21414274, -0.2544854, 0.040342666]\n",
      "Iter 2911, loss [-0.22993049, -0.26756358, 0.0376331]\n",
      "Iter 2912, loss [-0.2315796, -0.26686552, 0.035285912]\n",
      "Iter 2913, loss [-0.22492363, -0.26262277, 0.037699144]\n",
      "Iter 2914, loss [-0.21890345, -0.25823507, 0.039331608]\n",
      "Iter 2915, loss [-0.21176922, -0.25291908, 0.041149855]\n",
      "Iter 2916, loss [-0.2250351, -0.2616399, 0.036604792]\n",
      "Iter 2917, loss [-0.21810949, -0.25637096, 0.038261466]\n",
      "Iter 2918, loss [-0.22578155, -0.26245645, 0.0366749]\n",
      "Iter 2919, loss [-0.22554316, -0.26275572, 0.037212566]\n",
      "Iter 2920, loss [-0.21568976, -0.25536385, 0.039674085]\n",
      "Iter 2921, loss [-0.15019119, -0.20076261, 0.050571427]\n",
      "Iter 2922, loss [-0.22430423, -0.2610971, 0.036792874]\n",
      "Iter 2923, loss [-0.1833499, -0.23238711, 0.049037203]\n",
      "Iter 2924, loss [-0.20468691, -0.24588251, 0.04119561]\n",
      "Iter 2925, loss [-0.22392543, -0.2641718, 0.04024638]\n",
      "Iter 2926, loss [-0.22415559, -0.26052728, 0.03637169]\n",
      "Iter 2927, loss [-0.21635118, -0.2575768, 0.041225605]\n",
      "Iter 2928, loss [-0.22329053, -0.2627132, 0.039422665]\n",
      "Iter 2929, loss [-0.23037286, -0.26600543, 0.03563257]\n",
      "Iter 2930, loss [-0.22933292, -0.26430923, 0.0349763]\n",
      "Iter 2931, loss [-0.2260068, -0.26433146, 0.038324647]\n",
      "Iter 2932, loss [-0.22025706, -0.2570971, 0.036840033]\n",
      "Iter 2933, loss [-0.22665834, -0.2608533, 0.03419494]\n",
      "Iter 2934, loss [-0.22300428, -0.26386362, 0.04085934]\n",
      "Iter 2935, loss [-0.23043698, -0.26775846, 0.037321474]\n",
      "Iter 2936, loss [-0.21937865, -0.26022398, 0.040845342]\n",
      "Iter 2937, loss [-0.18135637, -0.23639679, 0.05504042]\n",
      "Iter 2938, loss [-0.22409643, -0.2626013, 0.038504854]\n",
      "Iter 2939, loss [-0.21817312, -0.2541524, 0.035979263]\n",
      "Iter 2940, loss [-0.21468541, -0.2534279, 0.03874248]\n",
      "Iter 2941, loss [-0.22745264, -0.26303592, 0.035583295]\n",
      "Iter 2942, loss [-0.20923084, -0.24987392, 0.04064308]\n",
      "Iter 2943, loss [-0.22391158, -0.2621529, 0.038241334]\n",
      "Iter 2944, loss [-0.22812532, -0.2656662, 0.037540868]\n",
      "Iter 2945, loss [-0.208973, -0.24951224, 0.040539235]\n",
      "Iter 2946, loss [-0.21110964, -0.25321695, 0.042107306]\n",
      "Iter 2947, loss [-0.21607292, -0.2560388, 0.03996589]\n",
      "Iter 2948, loss [-0.2293121, -0.26380572, 0.034493607]\n",
      "Iter 2949, loss [-0.21749236, -0.2562875, 0.038795132]\n",
      "Iter 2950, loss [-0.2151089, -0.25564918, 0.040540274]\n",
      "Iter 2951, loss [-0.22865905, -0.26497495, 0.0363159]\n",
      "Iter 2952, loss [-0.22648175, -0.26391894, 0.037437186]\n",
      "Iter 2953, loss [-0.22079387, -0.25992927, 0.039135396]\n",
      "Iter 2954, loss [-0.21962982, -0.2588279, 0.039198063]\n",
      "Iter 2955, loss [-0.22144161, -0.26075974, 0.039318126]\n",
      "Iter 2956, loss [-0.2203693, -0.25894842, 0.038579125]\n",
      "Iter 2957, loss [-0.22011271, -0.25904173, 0.03892901]\n",
      "Iter 2958, loss [-0.2253973, -0.26181912, 0.036421817]\n",
      "Iter 2959, loss [-0.22897124, -0.26739454, 0.038423292]\n",
      "Iter 2960, loss [-0.23070079, -0.26712394, 0.036423154]\n",
      "Iter 2961, loss [-0.21497434, -0.2567124, 0.04173807]\n",
      "Iter 2962, loss [-0.22824743, -0.26470172, 0.03645429]\n",
      "Iter 2963, loss [-0.21383128, -0.25328615, 0.039454885]\n",
      "Iter 2964, loss [-0.224895, -0.26211074, 0.037215732]\n",
      "Iter 2965, loss [-0.2269615, -0.2627674, 0.03580591]\n",
      "Iter 2966, loss [-0.22845362, -0.26394683, 0.035493206]\n",
      "Iter 2967, loss [-0.22618446, -0.26233447, 0.03615001]\n",
      "Iter 2968, loss [-0.23060247, -0.26583692, 0.035234448]\n",
      "Iter 2969, loss [-0.22266328, -0.2622605, 0.03959721]\n",
      "Iter 2970, loss [-0.22459565, -0.26163784, 0.037042186]\n",
      "Iter 2971, loss [-0.22251752, -0.2615106, 0.038993098]\n",
      "Iter 2972, loss [-0.19120862, -0.23850763, 0.04729901]\n",
      "Iter 2973, loss [-0.16515648, -0.22087745, 0.055720966]\n",
      "Iter 2974, loss [-0.21947816, -0.2575341, 0.038055923]\n",
      "Iter 2975, loss [-0.22508922, -0.26114023, 0.036051]\n",
      "Iter 2976, loss [-0.21249278, -0.25198877, 0.039495986]\n",
      "Iter 2977, loss [-0.22425438, -0.26158163, 0.037327245]\n",
      "Iter 2978, loss [-0.2207163, -0.25966632, 0.038950033]\n",
      "Iter 2979, loss [-0.22628123, -0.2635135, 0.037232276]\n",
      "Iter 2980, loss [-0.21171093, -0.25080034, 0.03908942]\n",
      "Iter 2981, loss [-0.22944233, -0.26707247, 0.037630137]\n",
      "Iter 2982, loss [-0.2163524, -0.2557969, 0.039444514]\n",
      "Iter 2983, loss [-0.22005425, -0.25713316, 0.0370789]\n",
      "Iter 2984, loss [-0.2275705, -0.26327306, 0.035702553]\n",
      "Iter 2985, loss [-0.22494659, -0.25931156, 0.03436497]\n",
      "Iter 2986, loss [-0.21346673, -0.25335488, 0.039888144]\n",
      "Iter 2987, loss [-0.18742485, -0.23878111, 0.051356256]\n",
      "Iter 2988, loss [-0.21360435, -0.2547989, 0.041194543]\n",
      "Iter 2989, loss [-0.2217147, -0.26021993, 0.038505223]\n",
      "Iter 2990, loss [-0.22639313, -0.2623285, 0.035935365]\n",
      "Iter 2991, loss [-0.22653794, -0.26289245, 0.03635452]\n",
      "Iter 2992, loss [-0.22383487, -0.26118356, 0.037348688]\n",
      "Iter 2993, loss [-0.21978828, -0.2565343, 0.036746025]\n",
      "Iter 2994, loss [-0.2260234, -0.2618926, 0.03586919]\n",
      "Iter 2995, loss [-0.21682371, -0.2555304, 0.038706675]\n",
      "Iter 2996, loss [-0.22985175, -0.26607224, 0.03622049]\n",
      "Iter 2997, loss [-0.21691377, -0.25729465, 0.04038088]\n",
      "Iter 2998, loss [-0.22993064, -0.2668702, 0.036939558]\n",
      "Iter 2999, loss [-0.22500679, -0.26421106, 0.039204266]\n",
      "Iter 3000, loss [-0.21831916, -0.25868496, 0.040365797]\n",
      "Iter 3001, loss [-0.21751934, -0.25445932, 0.03693997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3002, loss [-0.21937418, -0.2566062, 0.037232004]\n",
      "Iter 3003, loss [-0.21058334, -0.24919064, 0.0386073]\n",
      "Iter 3004, loss [-0.2206968, -0.26097536, 0.04027856]\n",
      "Iter 3005, loss [-0.22187822, -0.26080647, 0.03892825]\n",
      "Iter 3006, loss [-0.22942397, -0.2667037, 0.037279718]\n",
      "Iter 3007, loss [-0.22706138, -0.26475435, 0.03769298]\n",
      "Iter 3008, loss [-0.22283082, -0.26198226, 0.039151445]\n",
      "Iter 3009, loss [-0.22318786, -0.2612923, 0.038104445]\n",
      "Iter 3010, loss [-0.20520234, -0.24855292, 0.043350574]\n",
      "Iter 3011, loss [-0.21321715, -0.25184602, 0.038628858]\n",
      "Iter 3012, loss [-0.22469129, -0.26441377, 0.039722487]\n",
      "Iter 3013, loss [-0.22103843, -0.26133278, 0.040294357]\n",
      "Iter 3014, loss [-0.22322844, -0.26178652, 0.038558077]\n",
      "Iter 3015, loss [-0.22181962, -0.2603061, 0.038486466]\n",
      "Iter 3016, loss [-0.2098721, -0.25324687, 0.04337477]\n",
      "Iter 3017, loss [-0.22304967, -0.26052317, 0.037473492]\n",
      "Iter 3018, loss [-0.20773399, -0.24820203, 0.040468045]\n",
      "Iter 3019, loss [-0.22652042, -0.26166284, 0.03514242]\n",
      "Iter 3020, loss [-0.23058344, -0.26596263, 0.035379186]\n",
      "Iter 3021, loss [-0.22278684, -0.25988278, 0.03709593]\n",
      "Iter 3022, loss [-0.21973541, -0.25842372, 0.03868831]\n",
      "Iter 3023, loss [-0.21613994, -0.256257, 0.040117055]\n",
      "Iter 3024, loss [-0.22681719, -0.26099548, 0.03417828]\n",
      "Iter 3025, loss [-0.22633927, -0.26374847, 0.0374092]\n",
      "Iter 3026, loss [-0.23180804, -0.26741886, 0.03561082]\n",
      "Iter 3027, loss [-0.22410703, -0.26156396, 0.03745693]\n",
      "Iter 3028, loss [-0.2243542, -0.26290533, 0.038551137]\n",
      "Iter 3029, loss [-0.20547584, -0.24739188, 0.04191604]\n",
      "Iter 3030, loss [-0.22685984, -0.26433766, 0.037477814]\n",
      "Iter 3031, loss [-0.21681291, -0.25666392, 0.039851017]\n",
      "Iter 3032, loss [-0.22407044, -0.26218054, 0.03811009]\n",
      "Iter 3033, loss [-0.22161207, -0.2614064, 0.039794326]\n",
      "Iter 3034, loss [-0.21903308, -0.2585826, 0.03954951]\n",
      "Iter 3035, loss [-0.17419712, -0.22760929, 0.053412165]\n",
      "Iter 3036, loss [-0.22598892, -0.26575395, 0.039765023]\n",
      "Iter 3037, loss [-0.22794056, -0.26598158, 0.03804102]\n",
      "Iter 3038, loss [-0.21691065, -0.258399, 0.04148836]\n",
      "Iter 3039, loss [-0.22069186, -0.25744915, 0.03675729]\n",
      "Iter 3040, loss [-0.2240408, -0.25901353, 0.034972724]\n",
      "Iter 3041, loss [-0.21881641, -0.2577191, 0.03890268]\n",
      "Iter 3042, loss [-0.21540155, -0.25242347, 0.037021924]\n",
      "Iter 3043, loss [-0.22394593, -0.25991103, 0.0359651]\n",
      "Iter 3044, loss [-0.22572672, -0.26360306, 0.037876334]\n",
      "Iter 3045, loss [-0.1884778, -0.23797062, 0.04949282]\n",
      "Iter 3046, loss [-0.22429739, -0.2640594, 0.039762005]\n",
      "Iter 3047, loss [-0.2257143, -0.26347664, 0.037762336]\n",
      "Iter 3048, loss [-0.22943388, -0.2652917, 0.035857808]\n",
      "Iter 3049, loss [-0.21745753, -0.25718597, 0.039728425]\n",
      "Iter 3050, loss [-0.22081408, -0.25944254, 0.03862846]\n",
      "Iter 3051, loss [-0.21538273, -0.25479195, 0.039409228]\n",
      "Iter 3052, loss [-0.1491018, -0.20983985, 0.06073805]\n",
      "Iter 3053, loss [-0.18159863, -0.2354927, 0.05389408]\n",
      "Iter 3054, loss [-0.21653698, -0.2575326, 0.04099561]\n",
      "Iter 3055, loss [-0.22234854, -0.26247808, 0.040129535]\n",
      "Iter 3056, loss [-0.20889518, -0.2501837, 0.041288525]\n",
      "Iter 3057, loss [-0.21894333, -0.25569636, 0.03675302]\n",
      "Iter 3058, loss [-0.15503895, -0.20787026, 0.052831303]\n",
      "Iter 3059, loss [-0.22676839, -0.26131392, 0.034545526]\n",
      "Iter 3060, loss [-0.21112077, -0.2506008, 0.03948005]\n",
      "Iter 3061, loss [-0.22132406, -0.26048896, 0.039164897]\n",
      "Iter 3062, loss [-0.2305183, -0.26898015, 0.038461845]\n",
      "Iter 3063, loss [-0.21334669, -0.2549484, 0.041601725]\n",
      "Iter 3064, loss [-0.22433682, -0.26458195, 0.040245127]\n",
      "Iter 3065, loss [-0.2057763, -0.24827486, 0.042498566]\n",
      "Iter 3066, loss [-0.22667357, -0.26424658, 0.037573017]\n",
      "Iter 3067, loss [-0.20579675, -0.24645546, 0.04065871]\n",
      "Iter 3068, loss [-0.21822923, -0.25626382, 0.038034596]\n",
      "Iter 3069, loss [-0.227786, -0.26433867, 0.036552664]\n",
      "Iter 3070, loss [-0.22925451, -0.26315725, 0.033902727]\n",
      "Iter 3071, loss [-0.22865725, -0.26539072, 0.03673348]\n",
      "Iter 3072, loss [-0.23142876, -0.26812008, 0.036691323]\n",
      "Iter 3073, loss [-0.22464961, -0.26410016, 0.039450563]\n",
      "Iter 3074, loss [-0.22261328, -0.2608484, 0.038235135]\n",
      "Iter 3075, loss [-0.22997655, -0.26578805, 0.0358115]\n",
      "Iter 3076, loss [-0.22409955, -0.26347944, 0.03937989]\n",
      "Iter 3077, loss [-0.22111621, -0.26003134, 0.038915135]\n",
      "Iter 3078, loss [-0.23191732, -0.2660689, 0.03415158]\n",
      "Iter 3079, loss [-0.22323416, -0.26139054, 0.038156375]\n",
      "Iter 3080, loss [-0.19438516, -0.24188398, 0.047498822]\n",
      "Iter 3081, loss [-0.2230508, -0.26175675, 0.038705952]\n",
      "Iter 3082, loss [-0.22344714, -0.2610865, 0.037639357]\n",
      "Iter 3083, loss [-0.23420614, -0.2702772, 0.03607107]\n",
      "Iter 3084, loss [-0.22899261, -0.26764667, 0.03865406]\n",
      "Iter 3085, loss [-0.21781206, -0.25690514, 0.039093077]\n",
      "Iter 3086, loss [-0.21762142, -0.257177, 0.03955558]\n",
      "Iter 3087, loss [-0.22365458, -0.26213747, 0.038482886]\n",
      "Iter 3088, loss [-0.2247785, -0.2601775, 0.035398994]\n",
      "Iter 3089, loss [-0.22663417, -0.26304394, 0.036409758]\n",
      "Iter 3090, loss [-0.15018104, -0.21314223, 0.06296119]\n",
      "Iter 3091, loss [-0.23019236, -0.26530948, 0.03511712]\n",
      "Iter 3092, loss [-0.20933856, -0.2515419, 0.042203348]\n",
      "Iter 3093, loss [-0.21860424, -0.25751954, 0.038915314]\n",
      "Iter 3094, loss [-0.21101414, -0.2532256, 0.042211454]\n",
      "Iter 3095, loss [-0.22665673, -0.26343748, 0.036780752]\n",
      "Iter 3096, loss [-0.21622592, -0.25323862, 0.037012693]\n",
      "Iter 3097, loss [-0.14803487, -0.20518412, 0.057149254]\n",
      "Iter 3098, loss [-0.23027472, -0.2649858, 0.034711078]\n",
      "Iter 3099, loss [-0.208652, -0.24627577, 0.037623763]\n",
      "Iter 3100, loss [-0.21818385, -0.2567933, 0.038609453]\n",
      "Iter 3101, loss [-0.22479585, -0.26243502, 0.03763918]\n",
      "Iter 3102, loss [-0.22713605, -0.26497713, 0.037841078]\n",
      "Iter 3103, loss [-0.2054095, -0.24917984, 0.043770343]\n",
      "Iter 3104, loss [-0.22572586, -0.26381764, 0.038091786]\n",
      "Iter 3105, loss [-0.22293788, -0.26188502, 0.038947143]\n",
      "Iter 3106, loss [-0.20311762, -0.24427444, 0.041156814]\n",
      "Iter 3107, loss [-0.21388754, -0.2535544, 0.03966687]\n",
      "Iter 3108, loss [-0.22696646, -0.2634423, 0.03647585]\n",
      "Iter 3109, loss [-0.22382757, -0.2602556, 0.036428034]\n",
      "Iter 3110, loss [-0.21927968, -0.25523356, 0.035953876]\n",
      "Iter 3111, loss [-0.2263545, -0.26287958, 0.03652509]\n",
      "Iter 3112, loss [-0.21601132, -0.25606832, 0.04005701]\n",
      "Iter 3113, loss [-0.22552761, -0.26401025, 0.038482636]\n",
      "Iter 3114, loss [-0.2244393, -0.2630992, 0.038659904]\n",
      "Iter 3115, loss [-0.23074284, -0.26618698, 0.03544414]\n",
      "Iter 3116, loss [-0.21932665, -0.2585452, 0.039218552]\n",
      "Iter 3117, loss [-0.22061062, -0.25847745, 0.03786683]\n",
      "Iter 3118, loss [-0.22611997, -0.26365054, 0.03753058]\n",
      "Iter 3119, loss [-0.21796726, -0.2562978, 0.03833054]\n",
      "Iter 3120, loss [-0.21493748, -0.2525913, 0.03765383]\n",
      "Iter 3121, loss [-0.23071101, -0.26737443, 0.03666341]\n",
      "Iter 3122, loss [-0.22568634, -0.26211718, 0.036430843]\n",
      "Iter 3123, loss [-0.21962103, -0.25820535, 0.03858432]\n",
      "Iter 3124, loss [-0.22213924, -0.26012027, 0.03798104]\n",
      "Iter 3125, loss [-0.22452107, -0.2641445, 0.039623447]\n",
      "Iter 3126, loss [-0.2233111, -0.26210558, 0.03879448]\n",
      "Iter 3127, loss [-0.21543582, -0.2551353, 0.039699484]\n",
      "Iter 3128, loss [-0.2191399, -0.25811797, 0.03897807]\n",
      "Iter 3129, loss [-0.2036989, -0.24445026, 0.04075135]\n",
      "Iter 3130, loss [-0.22040793, -0.25975895, 0.039351016]\n",
      "Iter 3131, loss [-0.21750087, -0.25698602, 0.039485164]\n",
      "Iter 3132, loss [-0.22719128, -0.26441774, 0.037226457]\n",
      "Iter 3133, loss [-0.21438965, -0.25447252, 0.04008287]\n",
      "Iter 3134, loss [-0.21492249, -0.25516716, 0.04024467]\n",
      "Iter 3135, loss [-0.2257838, -0.2619743, 0.036190502]\n",
      "Iter 3136, loss [-0.22232968, -0.25999263, 0.03766295]\n",
      "Iter 3137, loss [-0.22424668, -0.26185992, 0.037613243]\n",
      "Iter 3138, loss [-0.22895142, -0.26631537, 0.037363954]\n",
      "Iter 3139, loss [-0.22752053, -0.26556486, 0.03804433]\n",
      "Iter 3140, loss [-0.20288913, -0.24658363, 0.043694496]\n",
      "Iter 3141, loss [-0.22369596, -0.26074708, 0.037051108]\n",
      "Iter 3142, loss [-0.21732053, -0.25593948, 0.038618945]\n",
      "Iter 3143, loss [-0.23083103, -0.26689142, 0.03606039]\n",
      "Iter 3144, loss [-0.22673306, -0.26423863, 0.037505567]\n",
      "Iter 3145, loss [-0.22608665, -0.2640912, 0.038004547]\n",
      "Iter 3146, loss [-0.21280672, -0.25370815, 0.040901434]\n",
      "Iter 3147, loss [-0.2269647, -0.2628552, 0.035890505]\n",
      "Iter 3148, loss [-0.22629155, -0.26459315, 0.038301602]\n",
      "Iter 3149, loss [-0.22416824, -0.26152483, 0.037356593]\n",
      "Iter 3150, loss [-0.21532464, -0.2553061, 0.03998145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3151, loss [-0.20738232, -0.24762328, 0.040240955]\n",
      "Iter 3152, loss [-0.14113142, -0.19922961, 0.058098197]\n",
      "Iter 3153, loss [-0.22685933, -0.26251572, 0.0356564]\n",
      "Iter 3154, loss [-0.22288203, -0.26189134, 0.0390093]\n",
      "Iter 3155, loss [-0.16554716, -0.22689295, 0.061345786]\n",
      "Iter 3156, loss [-0.23357572, -0.2680386, 0.034462888]\n",
      "Iter 3157, loss [-0.22448403, -0.26233146, 0.037847422]\n",
      "Iter 3158, loss [-0.18074094, -0.23223256, 0.05149162]\n",
      "Iter 3159, loss [-0.23372933, -0.2679431, 0.03421379]\n",
      "Iter 3160, loss [-0.22907409, -0.26717365, 0.038099565]\n",
      "Iter 3161, loss [-0.19678745, -0.24174857, 0.044961117]\n",
      "Iter 3162, loss [-0.22482309, -0.2606012, 0.035778113]\n",
      "Iter 3163, loss [-0.17135656, -0.22351845, 0.052161895]\n",
      "Iter 3164, loss [-0.2113, -0.2521132, 0.04081319]\n",
      "Iter 3165, loss [-0.2282063, -0.26284, 0.034633696]\n",
      "Iter 3166, loss [-0.22949934, -0.26546815, 0.035968807]\n",
      "Iter 3167, loss [-0.2228633, -0.26066253, 0.03779922]\n",
      "Iter 3168, loss [-0.2197882, -0.25698036, 0.037192173]\n",
      "Iter 3169, loss [-0.22333546, -0.2600597, 0.036724254]\n",
      "Iter 3170, loss [-0.23344712, -0.27091116, 0.037464038]\n",
      "Iter 3171, loss [-0.2288905, -0.26518658, 0.03629608]\n",
      "Iter 3172, loss [-0.21778041, -0.25705957, 0.03927916]\n",
      "Iter 3173, loss [-0.22448497, -0.26496908, 0.040484115]\n",
      "Iter 3174, loss [-0.21904671, -0.25929874, 0.040252037]\n",
      "Iter 3175, loss [-0.22309878, -0.2624647, 0.039365925]\n",
      "Iter 3176, loss [-0.22135946, -0.262356, 0.040996544]\n",
      "Iter 3177, loss [-0.22701971, -0.2653613, 0.038341597]\n",
      "Iter 3178, loss [-0.13597378, -0.19569433, 0.059720546]\n",
      "Iter 3179, loss [-0.21680284, -0.25611997, 0.039317124]\n",
      "Iter 3180, loss [-0.22989932, -0.26697803, 0.0370787]\n",
      "Iter 3181, loss [-0.21525908, -0.2540286, 0.03876951]\n",
      "Iter 3182, loss [-0.21991193, -0.25932905, 0.03941712]\n",
      "Iter 3183, loss [-0.22967374, -0.2657851, 0.036111347]\n",
      "Iter 3184, loss [-0.22581798, -0.26152635, 0.03570836]\n",
      "Iter 3185, loss [-0.21255411, -0.2528261, 0.040271986]\n",
      "Iter 3186, loss [-0.2194714, -0.25715822, 0.03768682]\n",
      "Iter 3187, loss [-0.2253646, -0.26348472, 0.038120117]\n",
      "Iter 3188, loss [-0.2282714, -0.26576295, 0.037491556]\n",
      "Iter 3189, loss [-0.22758667, -0.26388097, 0.036294296]\n",
      "Iter 3190, loss [-0.22860451, -0.26535383, 0.036749315]\n",
      "Iter 3191, loss [-0.21517408, -0.25167274, 0.036498673]\n",
      "Iter 3192, loss [-0.22588629, -0.2617242, 0.03583791]\n",
      "Iter 3193, loss [-0.2198939, -0.25925052, 0.039356627]\n",
      "Iter 3194, loss [-0.21894526, -0.25902945, 0.040084187]\n",
      "Iter 3195, loss [-0.22617534, -0.2643749, 0.03819957]\n",
      "Iter 3196, loss [-0.17153898, -0.22382846, 0.052289493]\n",
      "Iter 3197, loss [-0.22916202, -0.2652682, 0.036106184]\n",
      "Iter 3198, loss [-0.21823165, -0.25669557, 0.03846392]\n",
      "Iter 3199, loss [-0.21510217, -0.25492308, 0.03982091]\n",
      "Iter 3200, loss [-0.22857764, -0.2671097, 0.038532056]\n",
      "Iter 3201, loss [-0.22908418, -0.26665834, 0.037574157]\n",
      "Iter 3202, loss [-0.21250221, -0.25460663, 0.04210442]\n",
      "Iter 3203, loss [-0.22406456, -0.26101747, 0.03695291]\n",
      "Iter 3204, loss [-0.22801045, -0.26464725, 0.0366368]\n",
      "Iter 3205, loss [-0.2262659, -0.26244888, 0.036182966]\n",
      "Iter 3206, loss [-0.2204751, -0.25836328, 0.03788817]\n",
      "Iter 3207, loss [-0.21868512, -0.2569971, 0.038311988]\n",
      "Iter 3208, loss [-0.22494942, -0.26314682, 0.038197402]\n",
      "Iter 3209, loss [-0.18517731, -0.2331811, 0.04800379]\n",
      "Iter 3210, loss [-0.22129625, -0.26057795, 0.039281696]\n",
      "Iter 3211, loss [-0.22345318, -0.26393342, 0.04048024]\n",
      "Iter 3212, loss [-0.2292197, -0.2643595, 0.035139807]\n",
      "Iter 3213, loss [-0.2187674, -0.25866002, 0.039892614]\n",
      "Iter 3214, loss [-0.21932642, -0.2572438, 0.037917387]\n",
      "Iter 3215, loss [-0.19104978, -0.23739003, 0.04634025]\n",
      "Iter 3216, loss [-0.22672895, -0.262151, 0.035422053]\n",
      "Iter 3217, loss [-0.22578755, -0.26412165, 0.03833411]\n",
      "Iter 3218, loss [-0.23146775, -0.26721394, 0.03574618]\n",
      "Iter 3219, loss [-0.22860165, -0.26646444, 0.03786279]\n",
      "Iter 3220, loss [-0.22901863, -0.26759166, 0.038573034]\n",
      "Iter 3221, loss [-0.2138635, -0.25434044, 0.040476933]\n",
      "Iter 3222, loss [-0.21105695, -0.25333002, 0.04227308]\n",
      "Iter 3223, loss [-0.21450433, -0.2542472, 0.039742865]\n",
      "Iter 3224, loss [-0.22884962, -0.26510707, 0.036257446]\n",
      "Iter 3225, loss [-0.22483796, -0.26197812, 0.03714017]\n",
      "Iter 3226, loss [-0.22987506, -0.26536876, 0.03549371]\n",
      "Iter 3227, loss [-0.22767502, -0.26381987, 0.036144845]\n",
      "Iter 3228, loss [-0.2260548, -0.26704, 0.04098521]\n",
      "Iter 3229, loss [-0.21470317, -0.25514928, 0.04044611]\n",
      "Iter 3230, loss [-0.22323483, -0.26127037, 0.038035534]\n",
      "Iter 3231, loss [-0.21931446, -0.258006, 0.038691558]\n",
      "Iter 3232, loss [-0.22986391, -0.26642546, 0.036561552]\n",
      "Iter 3233, loss [-0.21923417, -0.25745818, 0.038224004]\n",
      "Iter 3234, loss [-0.21658431, -0.25619036, 0.03960605]\n",
      "Iter 3235, loss [-0.14634906, -0.20381042, 0.057461362]\n",
      "Iter 3236, loss [-0.16991164, -0.2203121, 0.050400462]\n",
      "Iter 3237, loss [-0.21014604, -0.25158674, 0.041440703]\n",
      "Iter 3238, loss [-0.2197579, -0.26198307, 0.042225167]\n",
      "Iter 3239, loss [-0.22666308, -0.26402783, 0.037364744]\n",
      "Iter 3240, loss [-0.20958307, -0.24998532, 0.04040225]\n",
      "Iter 3241, loss [-0.18694848, -0.23803733, 0.051088847]\n",
      "Iter 3242, loss [-0.22510499, -0.26141277, 0.036307782]\n",
      "Iter 3243, loss [-0.21968552, -0.25684097, 0.03715545]\n",
      "Iter 3244, loss [-0.2085128, -0.24968311, 0.04117031]\n",
      "Iter 3245, loss [-0.22492304, -0.26248565, 0.03756261]\n",
      "Iter 3246, loss [-0.22436795, -0.26112807, 0.03676012]\n",
      "Iter 3247, loss [-0.22996423, -0.26696962, 0.037005387]\n",
      "Iter 3248, loss [-0.22128469, -0.26166773, 0.04038304]\n",
      "Iter 3249, loss [-0.21537417, -0.2564082, 0.04103405]\n",
      "Iter 3250, loss [-0.21981074, -0.2585749, 0.038764168]\n",
      "Iter 3251, loss [-0.22454685, -0.26181838, 0.037271526]\n",
      "Iter 3252, loss [-0.21908912, -0.25870016, 0.039611038]\n",
      "Iter 3253, loss [-0.21121323, -0.24977976, 0.038566526]\n",
      "Iter 3254, loss [-0.22928928, -0.26558864, 0.03629936]\n",
      "Iter 3255, loss [-0.21997783, -0.25774315, 0.03776532]\n",
      "Iter 3256, loss [-0.22989136, -0.2649821, 0.035090752]\n",
      "Iter 3257, loss [-0.21407008, -0.25386408, 0.039794005]\n",
      "Iter 3258, loss [-0.22576085, -0.26590496, 0.040144123]\n",
      "Iter 3259, loss [-0.22242443, -0.26082954, 0.0384051]\n",
      "Iter 3260, loss [-0.21584079, -0.25678632, 0.040945526]\n",
      "Iter 3261, loss [-0.22741649, -0.2635291, 0.036112614]\n",
      "Iter 3262, loss [-0.21904005, -0.2584526, 0.03941254]\n",
      "Iter 3263, loss [-0.18664938, -0.23357898, 0.04692959]\n",
      "Iter 3264, loss [-0.20819362, -0.24919035, 0.04099673]\n",
      "Iter 3265, loss [-0.1871306, -0.23680711, 0.049676508]\n",
      "Iter 3266, loss [-0.2247012, -0.2628702, 0.038169004]\n",
      "Iter 3267, loss [-0.2270981, -0.26492926, 0.037831154]\n",
      "Iter 3268, loss [-0.21063256, -0.25256926, 0.041936703]\n",
      "Iter 3269, loss [-0.22535563, -0.26355213, 0.038196497]\n",
      "Iter 3270, loss [-0.22749963, -0.26391464, 0.03641502]\n",
      "Iter 3271, loss [-0.2194069, -0.25818992, 0.038783014]\n",
      "Iter 3272, loss [-0.21443234, -0.25425592, 0.039823573]\n",
      "Iter 3273, loss [-0.22798005, -0.26437965, 0.03639961]\n",
      "Iter 3274, loss [-0.22664842, -0.26405257, 0.03740415]\n",
      "Iter 3275, loss [-0.21436086, -0.25341427, 0.039053403]\n",
      "Iter 3276, loss [-0.22358358, -0.26129818, 0.037714593]\n",
      "Iter 3277, loss [-0.2295451, -0.263833, 0.03428788]\n",
      "Iter 3278, loss [-0.2126672, -0.2522139, 0.039546706]\n",
      "Iter 3279, loss [-0.22297211, -0.26062346, 0.03765135]\n",
      "Iter 3280, loss [-0.23461339, -0.2697655, 0.035152104]\n",
      "Iter 3281, loss [-0.14735287, -0.20537682, 0.05802394]\n",
      "Iter 3282, loss [-0.22462353, -0.2638073, 0.03918377]\n",
      "Iter 3283, loss [-0.22129235, -0.26065037, 0.039358016]\n",
      "Iter 3284, loss [-0.2094572, -0.25116727, 0.041710064]\n",
      "Iter 3285, loss [-0.21398091, -0.2527098, 0.038728893]\n",
      "Iter 3286, loss [-0.22667736, -0.26416585, 0.037488498]\n",
      "Iter 3287, loss [-0.2180707, -0.25585, 0.037779287]\n",
      "Iter 3288, loss [-0.22799155, -0.26278263, 0.034791075]\n",
      "Iter 3289, loss [-0.21856797, -0.25845498, 0.03988702]\n",
      "Iter 3290, loss [-0.21894306, -0.2589889, 0.04004582]\n",
      "Iter 3291, loss [-0.21192339, -0.25263932, 0.040715925]\n",
      "Iter 3292, loss [-0.22779569, -0.26453102, 0.036735326]\n",
      "Iter 3293, loss [-0.22375906, -0.26106256, 0.0373035]\n",
      "Iter 3294, loss [-0.20832893, -0.24941196, 0.041083016]\n",
      "Iter 3295, loss [-0.22402014, -0.26095498, 0.036934834]\n",
      "Iter 3296, loss [-0.22335184, -0.2597587, 0.036406882]\n",
      "Iter 3297, loss [-0.22598776, -0.2618143, 0.03582654]\n",
      "Iter 3298, loss [-0.21648347, -0.25744155, 0.040958073]\n",
      "Iter 3299, loss [-0.22284146, -0.26210055, 0.039259095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3300, loss [-0.19043687, -0.2392016, 0.048764728]\n",
      "Iter 3301, loss [-0.22488815, -0.26265803, 0.03776989]\n",
      "Iter 3302, loss [-0.22169062, -0.26144034, 0.039749704]\n",
      "Iter 3303, loss [-0.22436431, -0.26119292, 0.036828607]\n",
      "Iter 3304, loss [-0.22578219, -0.26164547, 0.03586328]\n",
      "Iter 3305, loss [-0.22568956, -0.26314318, 0.03745362]\n",
      "Iter 3306, loss [-0.23382267, -0.2691398, 0.035317123]\n",
      "Iter 3307, loss [-0.2240791, -0.2623836, 0.038304515]\n",
      "Iter 3308, loss [-0.22792915, -0.26405835, 0.0361292]\n",
      "Iter 3309, loss [-0.22814518, -0.26447046, 0.036325283]\n",
      "Iter 3310, loss [-0.21757357, -0.25735506, 0.039781496]\n",
      "Iter 3311, loss [-0.22917005, -0.26636666, 0.037196614]\n",
      "Iter 3312, loss [-0.2101563, -0.2482979, 0.03814159]\n",
      "Iter 3313, loss [-0.21780926, -0.25746915, 0.03965988]\n",
      "Iter 3314, loss [-0.21384019, -0.2540043, 0.04016412]\n",
      "Iter 3315, loss [-0.22638598, -0.26379266, 0.03740668]\n",
      "Iter 3316, loss [-0.22132921, -0.260261, 0.038931794]\n",
      "Iter 3317, loss [-0.21451524, -0.25520647, 0.040691234]\n",
      "Iter 3318, loss [-0.2161235, -0.2573305, 0.041207]\n",
      "Iter 3319, loss [-0.21404561, -0.25275227, 0.03870666]\n",
      "Iter 3320, loss [-0.22107878, -0.25817037, 0.03709159]\n",
      "Iter 3321, loss [-0.22388801, -0.258147, 0.03425899]\n",
      "Iter 3322, loss [-0.21360025, -0.25111637, 0.037516117]\n",
      "Iter 3323, loss [-0.22663653, -0.26335615, 0.03671962]\n",
      "Iter 3324, loss [-0.23027891, -0.2667785, 0.036499597]\n",
      "Iter 3325, loss [-0.22324328, -0.26231512, 0.039071843]\n",
      "Iter 3326, loss [-0.22880208, -0.2661912, 0.037389137]\n",
      "Iter 3327, loss [-0.22418226, -0.26033568, 0.036153417]\n",
      "Iter 3328, loss [-0.22679256, -0.26337638, 0.036583826]\n",
      "Iter 3329, loss [-0.2196403, -0.25729665, 0.037656352]\n",
      "Iter 3330, loss [-0.22892305, -0.26423028, 0.035307236]\n",
      "Iter 3331, loss [-0.22966692, -0.26545593, 0.035789005]\n",
      "Iter 3332, loss [-0.18887886, -0.23370086, 0.04482199]\n",
      "Iter 3333, loss [-0.22016302, -0.2566825, 0.036519475]\n",
      "Iter 3334, loss [-0.22129047, -0.2602041, 0.038913634]\n",
      "Iter 3335, loss [-0.19146873, -0.2383399, 0.046871167]\n",
      "Iter 3336, loss [-0.22773916, -0.26432815, 0.036588993]\n",
      "Iter 3337, loss [-0.22806966, -0.26437888, 0.036309212]\n",
      "Iter 3338, loss [-0.2267289, -0.2633156, 0.036586687]\n",
      "Iter 3339, loss [-0.19790578, -0.24318597, 0.045280185]\n",
      "Iter 3340, loss [-0.2106202, -0.2514394, 0.040819205]\n",
      "Iter 3341, loss [-0.22858433, -0.26599488, 0.037410542]\n",
      "Iter 3342, loss [-0.21065643, -0.24789354, 0.0372371]\n",
      "Iter 3343, loss [-0.22499463, -0.2630781, 0.038083464]\n",
      "Iter 3344, loss [-0.1701466, -0.2243421, 0.054195493]\n",
      "Iter 3345, loss [-0.22181384, -0.25688738, 0.035073534]\n",
      "Iter 3346, loss [-0.22357209, -0.2588946, 0.035322506]\n",
      "Iter 3347, loss [-0.21379638, -0.25241542, 0.03861905]\n",
      "Iter 3348, loss [-0.20938167, -0.2511292, 0.041747533]\n",
      "Iter 3349, loss [-0.21672411, -0.25672358, 0.039999466]\n",
      "Iter 3350, loss [-0.22512147, -0.26318797, 0.0380665]\n",
      "Iter 3351, loss [-0.20710564, -0.24697427, 0.039868638]\n",
      "Iter 3352, loss [-0.22132936, -0.25862885, 0.03729948]\n",
      "Iter 3353, loss [-0.22213069, -0.25933877, 0.03720808]\n",
      "Iter 3354, loss [-0.22088236, -0.25770456, 0.036822207]\n",
      "Iter 3355, loss [-0.21716112, -0.2521892, 0.035028066]\n",
      "Iter 3356, loss [-0.13253613, -0.18849376, 0.055957627]\n",
      "Iter 3357, loss [-0.23381212, -0.26855227, 0.034740157]\n",
      "Iter 3358, loss [-0.23005286, -0.26489368, 0.03484082]\n",
      "Iter 3359, loss [-0.225004, -0.26291114, 0.037907142]\n",
      "Iter 3360, loss [-0.22038318, -0.260469, 0.040085804]\n",
      "Iter 3361, loss [-0.22201309, -0.26070604, 0.03869296]\n",
      "Iter 3362, loss [-0.22630247, -0.26306185, 0.036759377]\n",
      "Iter 3363, loss [-0.20308435, -0.24386014, 0.040775795]\n",
      "Iter 3364, loss [-0.22669731, -0.26174936, 0.035052042]\n",
      "Iter 3365, loss [-0.21745206, -0.2535399, 0.036087826]\n",
      "Iter 3366, loss [-0.22551973, -0.26262826, 0.037108526]\n",
      "Iter 3367, loss [-0.22182497, -0.25953382, 0.037708856]\n",
      "Iter 3368, loss [-0.21510787, -0.25477296, 0.039665084]\n",
      "Iter 3369, loss [-0.21291688, -0.25547805, 0.04256117]\n",
      "Iter 3370, loss [-0.22281355, -0.26174194, 0.03892839]\n",
      "Iter 3371, loss [-0.21568382, -0.25461167, 0.038927853]\n",
      "Iter 3372, loss [-0.22402859, -0.26044425, 0.036415666]\n",
      "Iter 3373, loss [-0.22862324, -0.26399, 0.035366766]\n",
      "Iter 3374, loss [-0.23343384, -0.2679798, 0.034545954]\n",
      "Iter 3375, loss [-0.21659854, -0.25562623, 0.039027695]\n",
      "Iter 3376, loss [-0.2175405, -0.25420555, 0.03666505]\n",
      "Iter 3377, loss [-0.18936738, -0.23546454, 0.046097152]\n",
      "Iter 3378, loss [-0.22888151, -0.26401517, 0.035133656]\n",
      "Iter 3379, loss [-0.22012822, -0.258031, 0.037902784]\n",
      "Iter 3380, loss [-0.22344366, -0.26083162, 0.03738796]\n",
      "Iter 3381, loss [-0.22884896, -0.2640338, 0.035184827]\n",
      "Iter 3382, loss [-0.21982607, -0.25916705, 0.039340977]\n",
      "Iter 3383, loss [-0.22401823, -0.26177022, 0.037751988]\n",
      "Iter 3384, loss [-0.21933383, -0.25716397, 0.037830144]\n",
      "Iter 3385, loss [-0.21862736, -0.25657532, 0.037947953]\n",
      "Iter 3386, loss [-0.22199398, -0.2622763, 0.040282317]\n",
      "Iter 3387, loss [-0.2259027, -0.26397577, 0.03807307]\n",
      "Iter 3388, loss [-0.18532664, -0.23432018, 0.04899354]\n",
      "Iter 3389, loss [-0.20926112, -0.24693169, 0.037670575]\n",
      "Iter 3390, loss [-0.20808184, -0.25293547, 0.04485362]\n",
      "Iter 3391, loss [-0.22080885, -0.26112086, 0.040312003]\n",
      "Iter 3392, loss [-0.2132846, -0.25199896, 0.03871436]\n",
      "Iter 3393, loss [-0.22285238, -0.26110303, 0.038250647]\n",
      "Iter 3394, loss [-0.22015378, -0.25904584, 0.038892057]\n",
      "Iter 3395, loss [-0.2232521, -0.26117882, 0.037926715]\n",
      "Iter 3396, loss [-0.22134341, -0.2594455, 0.03810207]\n",
      "Iter 3397, loss [-0.215342, -0.2548496, 0.039507613]\n",
      "Iter 3398, loss [-0.22193792, -0.259166, 0.03722808]\n",
      "Iter 3399, loss [-0.23012942, -0.26684284, 0.03671342]\n",
      "Iter 3400, loss [-0.22527097, -0.26159525, 0.036324274]\n",
      "Iter 3401, loss [-0.21924862, -0.25712857, 0.03787995]\n",
      "Iter 3402, loss [-0.21563794, -0.25488502, 0.039247084]\n",
      "Iter 3403, loss [-0.22181332, -0.25947782, 0.037664503]\n",
      "Iter 3404, loss [-0.22166574, -0.26004875, 0.038383003]\n",
      "Iter 3405, loss [-0.22464876, -0.26306972, 0.038420957]\n",
      "Iter 3406, loss [-0.2262541, -0.26184115, 0.035587046]\n",
      "Iter 3407, loss [-0.22162488, -0.26197392, 0.04034903]\n",
      "Iter 3408, loss [-0.13115461, -0.19594559, 0.06479098]\n",
      "Iter 3409, loss [-0.21673712, -0.2563602, 0.03962308]\n",
      "Iter 3410, loss [-0.22811997, -0.26402622, 0.035906248]\n",
      "Iter 3411, loss [-0.22974023, -0.26410598, 0.03436575]\n",
      "Iter 3412, loss [-0.22000161, -0.257513, 0.037511386]\n",
      "Iter 3413, loss [-0.20939237, -0.24958032, 0.04018795]\n",
      "Iter 3414, loss [-0.22382633, -0.26129124, 0.0374649]\n",
      "Iter 3415, loss [-0.21765459, -0.25612625, 0.03847166]\n",
      "Iter 3416, loss [-0.21712147, -0.25866422, 0.041542754]\n",
      "Iter 3417, loss [-0.22132099, -0.25934216, 0.03802117]\n",
      "Iter 3418, loss [-0.22442722, -0.2612287, 0.036801495]\n",
      "Iter 3419, loss [-0.22267804, -0.26041386, 0.037735812]\n",
      "Iter 3420, loss [-0.22533336, -0.26202852, 0.036695145]\n",
      "Iter 3421, loss [-0.21384035, -0.25348127, 0.039640915]\n",
      "Iter 3422, loss [-0.22105192, -0.26002795, 0.038976025]\n",
      "Iter 3423, loss [-0.2240462, -0.2613564, 0.03731022]\n",
      "Iter 3424, loss [-0.22608027, -0.2627045, 0.03662423]\n",
      "Iter 3425, loss [-0.22240588, -0.25980845, 0.03740257]\n",
      "Iter 3426, loss [-0.22536434, -0.26087108, 0.035506736]\n",
      "Iter 3427, loss [-0.22964644, -0.2659777, 0.03633127]\n",
      "Iter 3428, loss [-0.22517559, -0.26294878, 0.0377732]\n",
      "Iter 3429, loss [-0.22383142, -0.26190007, 0.038068652]\n",
      "Iter 3430, loss [-0.21509981, -0.25533363, 0.040233828]\n",
      "Iter 3431, loss [-0.2248573, -0.26158497, 0.036727674]\n",
      "Iter 3432, loss [-0.223378, -0.26261756, 0.039239556]\n",
      "Iter 3433, loss [-0.22260508, -0.2615593, 0.038954232]\n",
      "Iter 3434, loss [-0.22300774, -0.2607419, 0.03773416]\n",
      "Iter 3435, loss [-0.22198504, -0.25899723, 0.037012197]\n",
      "Iter 3436, loss [-0.2268686, -0.26407418, 0.03720557]\n",
      "Iter 3437, loss [-0.22471882, -0.2626619, 0.03794308]\n",
      "Iter 3438, loss [-0.22486727, -0.26266643, 0.03779917]\n",
      "Iter 3439, loss [-0.2229373, -0.260702, 0.03776471]\n",
      "Iter 3440, loss [-0.23044679, -0.26654935, 0.03610257]\n",
      "Iter 3441, loss [-0.19722654, -0.24240047, 0.045173924]\n",
      "Iter 3442, loss [-0.229482, -0.26695976, 0.037477758]\n",
      "Iter 3443, loss [-0.21437009, -0.2553418, 0.040971715]\n",
      "Iter 3444, loss [-0.22275978, -0.26190254, 0.039142754]\n",
      "Iter 3445, loss [-0.22908895, -0.26559994, 0.036510993]\n",
      "Iter 3446, loss [-0.2295317, -0.26638493, 0.03685323]\n",
      "Iter 3447, loss [-0.19396532, -0.23444754, 0.04048223]\n",
      "Iter 3448, loss [-0.22347167, -0.26068527, 0.037213594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3449, loss [-0.22438355, -0.2613288, 0.03694524]\n",
      "Iter 3450, loss [-0.22658765, -0.26269525, 0.036107592]\n",
      "Iter 3451, loss [-0.22404405, -0.26156735, 0.037523307]\n",
      "Iter 3452, loss [-0.21900256, -0.2594349, 0.04043235]\n",
      "Iter 3453, loss [-0.22001074, -0.2593166, 0.03930585]\n",
      "Iter 3454, loss [-0.22132406, -0.26046216, 0.039138105]\n",
      "Iter 3455, loss [-0.22829469, -0.2656173, 0.03732262]\n",
      "Iter 3456, loss [-0.21953523, -0.2591047, 0.03956946]\n",
      "Iter 3457, loss [-0.2268663, -0.26428497, 0.037418656]\n",
      "Iter 3458, loss [-0.21583037, -0.25724292, 0.041412544]\n",
      "Iter 3459, loss [-0.2318598, -0.26734382, 0.035484012]\n",
      "Iter 3460, loss [-0.20925635, -0.25434795, 0.04509159]\n",
      "Iter 3461, loss [-0.20358902, -0.24820654, 0.044617515]\n",
      "Iter 3462, loss [-0.21519533, -0.2555304, 0.04033505]\n",
      "Iter 3463, loss [-0.22774921, -0.26349264, 0.035743427]\n",
      "Iter 3464, loss [-0.22602305, -0.26145178, 0.03542873]\n",
      "Iter 3465, loss [-0.23048896, -0.26589555, 0.035406597]\n",
      "Iter 3466, loss [-0.21847254, -0.2585828, 0.040110253]\n",
      "Iter 3467, loss [-0.22086006, -0.25938427, 0.03852421]\n",
      "Iter 3468, loss [-0.21580157, -0.2569553, 0.04115372]\n",
      "Iter 3469, loss [-0.16634125, -0.22123761, 0.05489637]\n",
      "Iter 3470, loss [-0.22192496, -0.2630435, 0.04111854]\n",
      "Iter 3471, loss [-0.21784437, -0.25778985, 0.039945476]\n",
      "Iter 3472, loss [-0.21822007, -0.25803226, 0.039812192]\n",
      "Iter 3473, loss [-0.21540831, -0.2553843, 0.039975986]\n",
      "Iter 3474, loss [-0.19895619, -0.24193653, 0.042980336]\n",
      "Iter 3475, loss [-0.22209227, -0.25969508, 0.037602812]\n",
      "Iter 3476, loss [-0.21599194, -0.2558057, 0.039813757]\n",
      "Iter 3477, loss [-0.22427422, -0.26104993, 0.03677571]\n",
      "Iter 3478, loss [-0.23042378, -0.26574504, 0.035321258]\n",
      "Iter 3479, loss [-0.22423813, -0.26222786, 0.037989743]\n",
      "Iter 3480, loss [-0.2247122, -0.26149565, 0.036783464]\n",
      "Iter 3481, loss [-0.23044959, -0.2662081, 0.035758533]\n",
      "Iter 3482, loss [-0.22567491, -0.26278216, 0.037107244]\n",
      "Iter 3483, loss [-0.16503677, -0.2193983, 0.054361533]\n",
      "Iter 3484, loss [-0.21821022, -0.25668362, 0.038473405]\n",
      "Iter 3485, loss [-0.2269898, -0.26488283, 0.037893027]\n",
      "Iter 3486, loss [-0.23259635, -0.26901516, 0.03641881]\n",
      "Iter 3487, loss [-0.22395273, -0.2630589, 0.039106175]\n",
      "Iter 3488, loss [-0.21432017, -0.25576684, 0.04144667]\n",
      "Iter 3489, loss [-0.22739096, -0.2644998, 0.037108857]\n",
      "Iter 3490, loss [-0.22679956, -0.26394242, 0.037142854]\n",
      "Iter 3491, loss [-0.22026405, -0.25823525, 0.037971195]\n",
      "Iter 3492, loss [-0.21626799, -0.2562146, 0.0399466]\n",
      "Iter 3493, loss [-0.21579182, -0.25468317, 0.038891345]\n",
      "Iter 3494, loss [-0.21367313, -0.25199038, 0.03831725]\n",
      "Iter 3495, loss [-0.22302571, -0.26084682, 0.037821107]\n",
      "Iter 3496, loss [-0.22460064, -0.26422122, 0.03962057]\n",
      "Iter 3497, loss [-0.22624744, -0.26365304, 0.03740559]\n",
      "Iter 3498, loss [-0.22470033, -0.26237026, 0.03766992]\n",
      "Iter 3499, loss [-0.22234792, -0.259481, 0.037133094]\n",
      "Iter 3500, loss [-0.22694036, -0.26375553, 0.03681517]\n",
      "Iter 3501, loss [-0.21917951, -0.25969404, 0.04051452]\n",
      "Iter 3502, loss [-0.22185719, -0.26273987, 0.04088267]\n",
      "Iter 3503, loss [-0.2244243, -0.26272836, 0.03830406]\n",
      "Iter 3504, loss [-0.22108872, -0.2589217, 0.037832994]\n",
      "Iter 3505, loss [-0.2307381, -0.26737425, 0.03663614]\n",
      "Iter 3506, loss [-0.22711599, -0.26511452, 0.03799853]\n",
      "Iter 3507, loss [-0.21773551, -0.25758663, 0.039851114]\n",
      "Iter 3508, loss [-0.21666893, -0.25476164, 0.038092695]\n",
      "Iter 3509, loss [-0.23069565, -0.2662626, 0.03556694]\n",
      "Iter 3510, loss [-0.21263093, -0.24919865, 0.036567718]\n",
      "Iter 3511, loss [-0.22604083, -0.2625584, 0.036517575]\n",
      "Iter 3512, loss [-0.22658709, -0.26433834, 0.037751254]\n",
      "Iter 3513, loss [-0.21736372, -0.2565313, 0.03916758]\n",
      "Iter 3514, loss [-0.22708191, -0.2643733, 0.037291393]\n",
      "Iter 3515, loss [-0.22586092, -0.26202536, 0.036164425]\n",
      "Iter 3516, loss [-0.18801393, -0.23714635, 0.049132418]\n",
      "Iter 3517, loss [-0.22303769, -0.26075044, 0.037712745]\n",
      "Iter 3518, loss [-0.22766687, -0.26419246, 0.03652559]\n",
      "Iter 3519, loss [-0.195838, -0.2395643, 0.043726303]\n",
      "Iter 3520, loss [-0.22948873, -0.26506004, 0.0355713]\n",
      "Iter 3521, loss [-0.22333406, -0.26255423, 0.039220165]\n",
      "Iter 3522, loss [-0.22910704, -0.26467344, 0.0355664]\n",
      "Iter 3523, loss [-0.22206892, -0.26008672, 0.038017794]\n",
      "Iter 3524, loss [-0.22296242, -0.26053402, 0.037571594]\n",
      "Iter 3525, loss [-0.15819594, -0.21298538, 0.054789446]\n",
      "Iter 3526, loss [-0.19361296, -0.23516297, 0.041550018]\n",
      "Iter 3527, loss [-0.21179196, -0.24856861, 0.036776647]\n",
      "Iter 3528, loss [-0.22931787, -0.26317596, 0.03385809]\n",
      "Iter 3529, loss [-0.21911189, -0.25793275, 0.03882086]\n",
      "Iter 3530, loss [-0.22459163, -0.26253167, 0.03794004]\n",
      "Iter 3531, loss [-0.22646257, -0.26499647, 0.03853389]\n",
      "Iter 3532, loss [-0.22273202, -0.26275635, 0.04002433]\n",
      "Iter 3533, loss [-0.22989447, -0.26767868, 0.037784208]\n",
      "Iter 3534, loss [-0.21867093, -0.25675687, 0.03808594]\n",
      "Iter 3535, loss [-0.15926506, -0.21326678, 0.05400172]\n",
      "Iter 3536, loss [-0.22204195, -0.26065725, 0.0386153]\n",
      "Iter 3537, loss [-0.22584829, -0.26187965, 0.03603137]\n",
      "Iter 3538, loss [-0.21447471, -0.25324088, 0.03876617]\n",
      "Iter 3539, loss [-0.22822401, -0.26319268, 0.034968667]\n",
      "Iter 3540, loss [-0.22968152, -0.26661035, 0.03692884]\n",
      "Iter 3541, loss [-0.21535055, -0.2533422, 0.037991658]\n",
      "Iter 3542, loss [-0.2129539, -0.25467604, 0.04172214]\n",
      "Iter 3543, loss [-0.22513977, -0.2619989, 0.036859132]\n",
      "Iter 3544, loss [-0.22326641, -0.2603717, 0.03710531]\n",
      "Iter 3545, loss [-0.22700551, -0.26367086, 0.036665346]\n",
      "Iter 3546, loss [-0.2276702, -0.2654062, 0.037736006]\n",
      "Iter 3547, loss [-0.2143349, -0.25238922, 0.038054317]\n",
      "Iter 3548, loss [-0.1996189, -0.24243578, 0.042816877]\n",
      "Iter 3549, loss [-0.23208849, -0.26686436, 0.034775864]\n",
      "Iter 3550, loss [-0.21466236, -0.25425303, 0.039590668]\n",
      "Iter 3551, loss [-0.21476766, -0.2547992, 0.040031515]\n",
      "Iter 3552, loss [-0.22428718, -0.26180044, 0.037513252]\n",
      "Iter 3553, loss [-0.21956767, -0.2604885, 0.040920835]\n",
      "Iter 3554, loss [-0.22544205, -0.26339686, 0.037954807]\n",
      "Iter 3555, loss [-0.2124134, -0.25333557, 0.040922172]\n",
      "Iter 3556, loss [-0.22280338, -0.26008052, 0.037277132]\n",
      "Iter 3557, loss [-0.21800932, -0.25587535, 0.037866026]\n",
      "Iter 3558, loss [-0.2266794, -0.26174685, 0.035067454]\n",
      "Iter 3559, loss [-0.22252771, -0.25983876, 0.03731104]\n",
      "Iter 3560, loss [-0.2282364, -0.26457393, 0.036337525]\n",
      "Iter 3561, loss [-0.21943378, -0.25743955, 0.03800576]\n",
      "Iter 3562, loss [-0.22674233, -0.26267293, 0.03593061]\n",
      "Iter 3563, loss [-0.21498036, -0.25504598, 0.040065613]\n",
      "Iter 3564, loss [-0.22582258, -0.26291606, 0.037093475]\n",
      "Iter 3565, loss [-0.2279238, -0.26549184, 0.037568044]\n",
      "Iter 3566, loss [-0.22086315, -0.2612787, 0.040415544]\n",
      "Iter 3567, loss [-0.18136632, -0.23452334, 0.053157017]\n",
      "Iter 3568, loss [-0.21224983, -0.2534766, 0.04122676]\n",
      "Iter 3569, loss [-0.21270105, -0.25317538, 0.04047432]\n",
      "Iter 3570, loss [-0.21815947, -0.25643757, 0.038278107]\n",
      "Iter 3571, loss [-0.22369455, -0.260915, 0.03722046]\n",
      "Iter 3572, loss [-0.2241407, -0.26144648, 0.03730577]\n",
      "Iter 3573, loss [-0.21538389, -0.25607035, 0.040686466]\n",
      "Iter 3574, loss [-0.21342057, -0.25569567, 0.042275093]\n",
      "Iter 3575, loss [-0.22759667, -0.2643619, 0.036765218]\n",
      "Iter 3576, loss [-0.22178677, -0.25949284, 0.037706085]\n",
      "Iter 3577, loss [-0.23064938, -0.26804933, 0.037399948]\n",
      "Iter 3578, loss [-0.21925908, -0.25805736, 0.038798273]\n",
      "Iter 3579, loss [-0.23193496, -0.2673208, 0.035385843]\n",
      "Iter 3580, loss [-0.21920015, -0.25852862, 0.039328467]\n",
      "Iter 3581, loss [-0.2306977, -0.26683918, 0.036141474]\n",
      "Iter 3582, loss [-0.21341339, -0.2495829, 0.036169514]\n",
      "Iter 3583, loss [-0.22080308, -0.25703856, 0.036235478]\n",
      "Iter 3584, loss [-0.21440226, -0.25321957, 0.03881731]\n",
      "Iter 3585, loss [-0.2079003, -0.25153726, 0.04363696]\n",
      "Iter 3586, loss [-0.21986839, -0.25928536, 0.03941697]\n",
      "Iter 3587, loss [-0.22136953, -0.26044342, 0.039073884]\n",
      "Iter 3588, loss [-0.22428516, -0.26443923, 0.040154077]\n",
      "Iter 3589, loss [-0.17650573, -0.23071204, 0.05420631]\n",
      "Iter 3590, loss [-0.19426489, -0.24212176, 0.04785686]\n",
      "Iter 3591, loss [-0.22350724, -0.26266226, 0.039155018]\n",
      "Iter 3592, loss [-0.2105242, -0.24922144, 0.03869725]\n",
      "Iter 3593, loss [-0.16322175, -0.2155196, 0.05229786]\n",
      "Iter 3594, loss [-0.15974665, -0.21778603, 0.05803938]\n",
      "Iter 3595, loss [-0.144962, -0.20458826, 0.059626266]\n",
      "Iter 3596, loss [-0.22690561, -0.26509133, 0.038185716]\n",
      "Iter 3597, loss [-0.21426816, -0.25706965, 0.04280148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3598, loss [-0.21875367, -0.25673357, 0.0379799]\n",
      "Iter 3599, loss [-0.21925232, -0.25778005, 0.038527735]\n",
      "Iter 3600, loss [-0.2243111, -0.26194862, 0.037637517]\n",
      "Iter 3601, loss [-0.22257826, -0.2572601, 0.034681853]\n",
      "Iter 3602, loss [-0.22606578, -0.26225066, 0.03618488]\n",
      "Iter 3603, loss [-0.19298029, -0.23435386, 0.041373562]\n",
      "Iter 3604, loss [-0.22515658, -0.2636058, 0.03844923]\n",
      "Iter 3605, loss [-0.22199255, -0.26018623, 0.03819367]\n",
      "Iter 3606, loss [-0.20989293, -0.2485319, 0.038638968]\n",
      "Iter 3607, loss [-0.22570795, -0.26170093, 0.035992987]\n",
      "Iter 3608, loss [-0.22827232, -0.2648387, 0.03656637]\n",
      "Iter 3609, loss [-0.22853382, -0.26537672, 0.036842898]\n",
      "Iter 3610, loss [-0.22780728, -0.26560083, 0.03779355]\n",
      "Iter 3611, loss [-0.21212107, -0.25421163, 0.042090565]\n",
      "Iter 3612, loss [-0.22027865, -0.26058373, 0.040305085]\n",
      "Iter 3613, loss [-0.21517608, -0.25604033, 0.04086425]\n",
      "Iter 3614, loss [-0.22222918, -0.26001635, 0.03778717]\n",
      "Iter 3615, loss [-0.2193099, -0.25764778, 0.038337883]\n",
      "Iter 3616, loss [-0.23318087, -0.26775232, 0.034571454]\n",
      "Iter 3617, loss [-0.23064768, -0.26493225, 0.034284566]\n",
      "Iter 3618, loss [-0.22157589, -0.25893608, 0.037360184]\n",
      "Iter 3619, loss [-0.18456437, -0.23247108, 0.04790671]\n",
      "Iter 3620, loss [-0.22573282, -0.26382384, 0.03809102]\n",
      "Iter 3621, loss [-0.14097376, -0.20089583, 0.05992207]\n",
      "Iter 3622, loss [-0.22725922, -0.2633111, 0.036051877]\n",
      "Iter 3623, loss [-0.22377057, -0.26031485, 0.036544282]\n",
      "Iter 3624, loss [-0.21417923, -0.25384766, 0.039668422]\n",
      "Iter 3625, loss [-0.22342888, -0.26085773, 0.037428863]\n",
      "Iter 3626, loss [-0.23121342, -0.26513943, 0.03392601]\n",
      "Iter 3627, loss [-0.21498504, -0.25412765, 0.039142605]\n",
      "Iter 3628, loss [-0.22668953, -0.26465634, 0.0379668]\n",
      "Iter 3629, loss [-0.23080741, -0.26677427, 0.03596686]\n",
      "Iter 3630, loss [-0.23194616, -0.26709327, 0.035147116]\n",
      "Iter 3631, loss [-0.23008926, -0.2685175, 0.038428232]\n",
      "Iter 3632, loss [-0.22290036, -0.26139626, 0.03849589]\n",
      "Iter 3633, loss [-0.22769856, -0.2652691, 0.03757054]\n",
      "Iter 3634, loss [-0.22347854, -0.26212543, 0.038646888]\n",
      "Iter 3635, loss [-0.18492433, -0.23680383, 0.051879495]\n",
      "Iter 3636, loss [-0.22310147, -0.25840545, 0.035303976]\n",
      "Iter 3637, loss [-0.22102356, -0.25944075, 0.038417187]\n",
      "Iter 3638, loss [-0.21158734, -0.25200185, 0.04041451]\n",
      "Iter 3639, loss [-0.21517548, -0.25301158, 0.0378361]\n",
      "Iter 3640, loss [-0.21690105, -0.25589332, 0.03899227]\n",
      "Iter 3641, loss [-0.17108987, -0.22762927, 0.056539398]\n",
      "Iter 3642, loss [-0.23044038, -0.26800585, 0.03756547]\n",
      "Iter 3643, loss [-0.22564985, -0.26495904, 0.039309192]\n",
      "Iter 3644, loss [-0.21487185, -0.25385156, 0.038979717]\n",
      "Iter 3645, loss [-0.21719174, -0.2571306, 0.039938852]\n",
      "Iter 3646, loss [-0.22253375, -0.26238486, 0.039851114]\n",
      "Iter 3647, loss [-0.20521033, -0.24927025, 0.044059925]\n",
      "Iter 3648, loss [-0.22330102, -0.26277152, 0.039470494]\n",
      "Iter 3649, loss [-0.22777197, -0.2646748, 0.036902837]\n",
      "Iter 3650, loss [-0.22689393, -0.26267952, 0.035785593]\n",
      "Iter 3651, loss [-0.22745648, -0.2635278, 0.036071327]\n",
      "Iter 3652, loss [-0.22345856, -0.25888237, 0.03542381]\n",
      "Iter 3653, loss [-0.2185333, -0.25656578, 0.03803248]\n",
      "Iter 3654, loss [-0.22619504, -0.26237264, 0.0361776]\n",
      "Iter 3655, loss [-0.13605848, -0.19496697, 0.0589085]\n",
      "Iter 3656, loss [-0.2197454, -0.25880554, 0.039060146]\n",
      "Iter 3657, loss [-0.22580677, -0.26461753, 0.038810752]\n",
      "Iter 3658, loss [-0.22902535, -0.264729, 0.035703644]\n",
      "Iter 3659, loss [-0.22423497, -0.26246747, 0.038232498]\n",
      "Iter 3660, loss [-0.22847462, -0.26520905, 0.036734425]\n",
      "Iter 3661, loss [-0.19423875, -0.23892595, 0.044687193]\n",
      "Iter 3662, loss [-0.22452357, -0.2611187, 0.036595136]\n",
      "Iter 3663, loss [-0.22434191, -0.2612299, 0.03688799]\n",
      "Iter 3664, loss [-0.21731329, -0.25665593, 0.039342646]\n",
      "Iter 3665, loss [-0.2249127, -0.26251844, 0.03760573]\n",
      "Iter 3666, loss [-0.18877421, -0.23614827, 0.04737405]\n",
      "Iter 3667, loss [-0.2236054, -0.26257613, 0.038970735]\n",
      "Iter 3668, loss [-0.22834209, -0.26596045, 0.03761837]\n",
      "Iter 3669, loss [-0.2086206, -0.25051254, 0.041891944]\n",
      "Iter 3670, loss [-0.22445601, -0.26389185, 0.039435834]\n",
      "Iter 3671, loss [-0.2213617, -0.258535, 0.0371733]\n",
      "Iter 3672, loss [-0.22864226, -0.26580873, 0.03716647]\n",
      "Iter 3673, loss [-0.22519258, -0.26032877, 0.035136186]\n",
      "Iter 3674, loss [-0.22241363, -0.2598596, 0.037445966]\n",
      "Iter 3675, loss [-0.22113332, -0.25972632, 0.03859299]\n",
      "Iter 3676, loss [-0.18604207, -0.23629057, 0.0502485]\n",
      "Iter 3677, loss [-0.22914979, -0.26549846, 0.03634867]\n",
      "Iter 3678, loss [-0.22505787, -0.26296544, 0.037907563]\n",
      "Iter 3679, loss [-0.13419785, -0.19552599, 0.06132814]\n",
      "Iter 3680, loss [-0.20187464, -0.24500152, 0.04312688]\n",
      "Iter 3681, loss [-0.22017387, -0.25777897, 0.037605107]\n",
      "Iter 3682, loss [-0.2290782, -0.26437283, 0.035294615]\n",
      "Iter 3683, loss [-0.21655968, -0.2551457, 0.03858602]\n",
      "Iter 3684, loss [-0.14622006, -0.20514522, 0.058925174]\n",
      "Iter 3685, loss [-0.22430043, -0.26387355, 0.039573114]\n",
      "Iter 3686, loss [-0.22282398, -0.2603017, 0.03747773]\n",
      "Iter 3687, loss [-0.21697052, -0.25628135, 0.039310824]\n",
      "Iter 3688, loss [-0.21824132, -0.2579208, 0.039679483]\n",
      "Iter 3689, loss [-0.22317931, -0.26112595, 0.037946634]\n",
      "Iter 3690, loss [-0.22608191, -0.26252583, 0.036443923]\n",
      "Iter 3691, loss [-0.2263914, -0.26271147, 0.036320053]\n",
      "Iter 3692, loss [-0.21427576, -0.25472668, 0.040450916]\n",
      "Iter 3693, loss [-0.23044144, -0.26600718, 0.035565745]\n",
      "Iter 3694, loss [-0.22097285, -0.25858453, 0.037611675]\n",
      "Iter 3695, loss [-0.22153078, -0.26119262, 0.03966184]\n",
      "Iter 3696, loss [-0.22591841, -0.26236582, 0.0364474]\n",
      "Iter 3697, loss [-0.22497952, -0.26350388, 0.038524352]\n",
      "Iter 3698, loss [-0.23033363, -0.26706475, 0.03673112]\n",
      "Iter 3699, loss [-0.21769026, -0.25775185, 0.040061593]\n",
      "Iter 3700, loss [-0.20626903, -0.24819192, 0.041922897]\n",
      "Iter 3701, loss [-0.21714103, -0.25209603, 0.034955002]\n",
      "Iter 3702, loss [-0.223027, -0.26134282, 0.038315814]\n",
      "Iter 3703, loss [-0.1813767, -0.23153059, 0.05015389]\n",
      "Iter 3704, loss [-0.23052211, -0.26834792, 0.037825808]\n",
      "Iter 3705, loss [-0.19609995, -0.24120364, 0.04510368]\n",
      "Iter 3706, loss [-0.23400669, -0.27053076, 0.03652407]\n",
      "Iter 3707, loss [-0.1794227, -0.23090385, 0.051481143]\n",
      "Iter 3708, loss [-0.21777672, -0.25546014, 0.03768342]\n",
      "Iter 3709, loss [-0.20255463, -0.24578081, 0.043226182]\n",
      "Iter 3710, loss [-0.21786022, -0.25700364, 0.039143417]\n",
      "Iter 3711, loss [-0.22856383, -0.2650162, 0.036452364]\n",
      "Iter 3712, loss [-0.2199885, -0.25838482, 0.03839632]\n",
      "Iter 3713, loss [-0.20305976, -0.24646261, 0.04340285]\n",
      "Iter 3714, loss [-0.21920212, -0.25866336, 0.039461236]\n",
      "Iter 3715, loss [-0.21975806, -0.25943387, 0.039675802]\n",
      "Iter 3716, loss [-0.22793622, -0.26508287, 0.03714664]\n",
      "Iter 3717, loss [-0.189017, -0.2386974, 0.049680404]\n",
      "Iter 3718, loss [-0.23458397, -0.27030012, 0.035716154]\n",
      "Iter 3719, loss [-0.21476501, -0.25612515, 0.04136014]\n",
      "Iter 3720, loss [-0.21415247, -0.255571, 0.041418537]\n",
      "Iter 3721, loss [-0.2256552, -0.2651453, 0.039490096]\n",
      "Iter 3722, loss [-0.22122753, -0.25972158, 0.03849405]\n",
      "Iter 3723, loss [-0.21601975, -0.25634053, 0.04032078]\n",
      "Iter 3724, loss [-0.22002092, -0.25923106, 0.039210133]\n",
      "Iter 3725, loss [-0.22561052, -0.26361337, 0.03800284]\n",
      "Iter 3726, loss [-0.23153552, -0.26622224, 0.03468671]\n",
      "Iter 3727, loss [-0.18932357, -0.23714502, 0.047821444]\n",
      "Iter 3728, loss [-0.22315957, -0.26174352, 0.038583953]\n",
      "Iter 3729, loss [-0.22752589, -0.263994, 0.03646812]\n",
      "Iter 3730, loss [-0.223816, -0.26176116, 0.037945144]\n",
      "Iter 3731, loss [-0.21991111, -0.25852135, 0.038610235]\n",
      "Iter 3732, loss [-0.23057453, -0.26557642, 0.03500189]\n",
      "Iter 3733, loss [-0.22673851, -0.2638596, 0.037121087]\n",
      "Iter 3734, loss [-0.15233739, -0.2107432, 0.058405813]\n",
      "Iter 3735, loss [-0.22894235, -0.26651195, 0.037569594]\n",
      "Iter 3736, loss [-0.22508246, -0.26019576, 0.035113305]\n",
      "Iter 3737, loss [-0.21668118, -0.25632268, 0.039641492]\n",
      "Iter 3738, loss [-0.23424329, -0.2695426, 0.035299316]\n",
      "Iter 3739, loss [-0.22444698, -0.26363873, 0.039191745]\n",
      "Iter 3740, loss [-0.22557975, -0.2609458, 0.03536604]\n",
      "Iter 3741, loss [-0.21942896, -0.2589941, 0.039565153]\n",
      "Iter 3742, loss [-0.219453, -0.25822064, 0.03876764]\n",
      "Iter 3743, loss [-0.23373213, -0.2675219, 0.033789754]\n",
      "Iter 3744, loss [-0.22258693, -0.2621278, 0.039540865]\n",
      "Iter 3745, loss [-0.22069317, -0.26030213, 0.039608963]\n",
      "Iter 3746, loss [-0.21845758, -0.2583287, 0.03987112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3747, loss [-0.2182482, -0.25873885, 0.040490642]\n",
      "Iter 3748, loss [-0.2324724, -0.26766902, 0.035196617]\n",
      "Iter 3749, loss [-0.22935183, -0.26714662, 0.037794784]\n",
      "Iter 3750, loss [-0.22314826, -0.26034826, 0.0372]\n",
      "Iter 3751, loss [-0.2010982, -0.23901571, 0.037917502]\n",
      "Iter 3752, loss [-0.22467816, -0.26173365, 0.037055496]\n",
      "Iter 3753, loss [-0.18843512, -0.23724866, 0.048813533]\n",
      "Iter 3754, loss [-0.2247358, -0.2616325, 0.0368967]\n",
      "Iter 3755, loss [-0.23283361, -0.26719412, 0.03436051]\n",
      "Iter 3756, loss [-0.21441804, -0.25372148, 0.039303437]\n",
      "Iter 3757, loss [-0.2193387, -0.25969937, 0.040360674]\n",
      "Iter 3758, loss [-0.22600858, -0.26279387, 0.03678529]\n",
      "Iter 3759, loss [-0.227238, -0.26551002, 0.03827202]\n",
      "Iter 3760, loss [-0.22796735, -0.26397547, 0.036008112]\n",
      "Iter 3761, loss [-0.23272987, -0.2685936, 0.03586374]\n",
      "Iter 3762, loss [-0.22218522, -0.25910848, 0.03692326]\n",
      "Iter 3763, loss [-0.20873491, -0.24806501, 0.039330095]\n",
      "Iter 3764, loss [-0.19160686, -0.23883304, 0.047226176]\n",
      "Iter 3765, loss [-0.21977672, -0.2587552, 0.038978495]\n",
      "Iter 3766, loss [-0.22082287, -0.25865427, 0.037831403]\n",
      "Iter 3767, loss [-0.21257494, -0.25423872, 0.04166378]\n",
      "Iter 3768, loss [-0.16044426, -0.21726479, 0.05682052]\n",
      "Iter 3769, loss [-0.21906641, -0.258098, 0.039031595]\n",
      "Iter 3770, loss [-0.2230628, -0.26103106, 0.03796826]\n",
      "Iter 3771, loss [-0.22265145, -0.2573443, 0.034692846]\n",
      "Iter 3772, loss [-0.2181665, -0.25640333, 0.038236827]\n",
      "Iter 3773, loss [-0.21067089, -0.24844168, 0.03777079]\n",
      "Iter 3774, loss [-0.22170913, -0.2613841, 0.039674964]\n",
      "Iter 3775, loss [-0.22993132, -0.26749787, 0.037566543]\n",
      "Iter 3776, loss [-0.22727314, -0.2659002, 0.03862706]\n",
      "Iter 3777, loss [-0.22394201, -0.2631643, 0.0392223]\n",
      "Iter 3778, loss [-0.2274409, -0.26521727, 0.037776373]\n",
      "Iter 3779, loss [-0.21435882, -0.2547224, 0.040363565]\n",
      "Iter 3780, loss [-0.21623686, -0.2538876, 0.037650727]\n",
      "Iter 3781, loss [-0.22129214, -0.2582207, 0.036928557]\n",
      "Iter 3782, loss [-0.18172896, -0.23182736, 0.05009841]\n",
      "Iter 3783, loss [-0.2212113, -0.25917813, 0.03796683]\n",
      "Iter 3784, loss [-0.22184935, -0.262261, 0.040411644]\n",
      "Iter 3785, loss [-0.22602117, -0.26397708, 0.037955903]\n",
      "Iter 3786, loss [-0.23301253, -0.26879823, 0.035785712]\n",
      "Iter 3787, loss [-0.22766265, -0.26442915, 0.0367665]\n",
      "Iter 3788, loss [-0.22114262, -0.25860783, 0.037465207]\n",
      "Iter 3789, loss [-0.22939584, -0.26570585, 0.03631001]\n",
      "Iter 3790, loss [-0.22553267, -0.26469183, 0.039159164]\n",
      "Iter 3791, loss [-0.22104853, -0.26034403, 0.039295487]\n",
      "Iter 3792, loss [-0.22016604, -0.2598067, 0.03964065]\n",
      "Iter 3793, loss [-0.2302839, -0.2673923, 0.037108403]\n",
      "Iter 3794, loss [-0.22223738, -0.26166886, 0.039431486]\n",
      "Iter 3795, loss [-0.22674818, -0.26477537, 0.03802718]\n",
      "Iter 3796, loss [-0.23046482, -0.2661261, 0.035661276]\n",
      "Iter 3797, loss [-0.20825472, -0.24919005, 0.04093532]\n",
      "Iter 3798, loss [-0.22799328, -0.26491618, 0.03692291]\n",
      "Iter 3799, loss [-0.22385523, -0.26114124, 0.03728601]\n",
      "Iter 3800, loss [-0.23073755, -0.26667464, 0.035937082]\n",
      "Iter 3801, loss [-0.2178632, -0.25831196, 0.040448748]\n",
      "Iter 3802, loss [-0.21376495, -0.25430807, 0.040543124]\n",
      "Iter 3803, loss [-0.22055799, -0.26037216, 0.03981417]\n",
      "Iter 3804, loss [-0.22642428, -0.26365432, 0.037230037]\n",
      "Iter 3805, loss [-0.21839866, -0.2573878, 0.03898913]\n",
      "Iter 3806, loss [-0.22400704, -0.26137, 0.037362963]\n",
      "Iter 3807, loss [-0.22756083, -0.26190206, 0.03434123]\n",
      "Iter 3808, loss [-0.22530544, -0.26041198, 0.035106543]\n",
      "Iter 3809, loss [-0.23079203, -0.268132, 0.037339967]\n",
      "Iter 3810, loss [-0.2266384, -0.26284286, 0.036204457]\n",
      "Iter 3811, loss [-0.22288887, -0.25962898, 0.03674011]\n",
      "Iter 3812, loss [-0.16381577, -0.22090338, 0.057087623]\n",
      "Iter 3813, loss [-0.23099947, -0.26749605, 0.03649658]\n",
      "Iter 3814, loss [-0.22922426, -0.26654238, 0.037318103]\n",
      "Iter 3815, loss [-0.22508597, -0.2639947, 0.038908727]\n",
      "Iter 3816, loss [-0.22089638, -0.26050082, 0.03960444]\n",
      "Iter 3817, loss [-0.18853617, -0.23414321, 0.045607045]\n",
      "Iter 3818, loss [-0.22427419, -0.26089442, 0.03662023]\n",
      "Iter 3819, loss [-0.22070779, -0.25791326, 0.037205473]\n",
      "Iter 3820, loss [-0.22750187, -0.26425904, 0.03675717]\n",
      "Iter 3821, loss [-0.22797078, -0.26592866, 0.037957884]\n",
      "Iter 3822, loss [-0.22041273, -0.25947016, 0.03905743]\n",
      "Iter 3823, loss [-0.22097988, -0.25996667, 0.03898679]\n",
      "Iter 3824, loss [-0.21531488, -0.25259966, 0.037284777]\n",
      "Iter 3825, loss [-0.22294098, -0.25779772, 0.034856737]\n",
      "Iter 3826, loss [-0.13531949, -0.19544488, 0.060125392]\n",
      "Iter 3827, loss [-0.21640946, -0.2547448, 0.03833534]\n",
      "Iter 3828, loss [-0.22772509, -0.26169676, 0.033971675]\n",
      "Iter 3829, loss [-0.21771352, -0.25552914, 0.037815616]\n",
      "Iter 3830, loss [-0.22876263, -0.2659616, 0.037198957]\n",
      "Iter 3831, loss [-0.21473427, -0.25524566, 0.040511385]\n",
      "Iter 3832, loss [-0.22796059, -0.26595524, 0.03799465]\n",
      "Iter 3833, loss [-0.18472044, -0.23550093, 0.050780486]\n",
      "Iter 3834, loss [-0.2192074, -0.25808695, 0.03887954]\n",
      "Iter 3835, loss [-0.13734052, -0.19328192, 0.055941403]\n",
      "Iter 3836, loss [-0.22774944, -0.26402617, 0.036276735]\n",
      "Iter 3837, loss [-0.22287935, -0.2611011, 0.038221754]\n",
      "Iter 3838, loss [-0.23017308, -0.26509404, 0.034920953]\n",
      "Iter 3839, loss [-0.2207722, -0.25905472, 0.03828251]\n",
      "Iter 3840, loss [-0.18115234, -0.23096448, 0.04981213]\n",
      "Iter 3841, loss [-0.223876, -0.261661, 0.03778499]\n",
      "Iter 3842, loss [-0.22511157, -0.26177785, 0.03666627]\n",
      "Iter 3843, loss [-0.2109493, -0.25039554, 0.039446227]\n",
      "Iter 3844, loss [-0.21976958, -0.2590501, 0.03928052]\n",
      "Iter 3845, loss [-0.15080377, -0.20176631, 0.050962538]\n",
      "Iter 3846, loss [-0.2243313, -0.25969717, 0.035365865]\n",
      "Iter 3847, loss [-0.23254068, -0.2670802, 0.034539506]\n",
      "Iter 3848, loss [-0.18494526, -0.23067927, 0.045734018]\n",
      "Iter 3849, loss [-0.22029212, -0.2601868, 0.03989467]\n",
      "Iter 3850, loss [-0.22705236, -0.2660806, 0.03902823]\n",
      "Iter 3851, loss [-0.22532251, -0.2621376, 0.036815085]\n",
      "Iter 3852, loss [-0.18557893, -0.2338665, 0.04828757]\n",
      "Iter 3853, loss [-0.214411, -0.2556051, 0.041194092]\n",
      "Iter 3854, loss [-0.2215201, -0.26204976, 0.04052967]\n",
      "Iter 3855, loss [-0.2283868, -0.26537508, 0.036988273]\n",
      "Iter 3856, loss [-0.22827002, -0.26165146, 0.03338143]\n",
      "Iter 3857, loss [-0.22263996, -0.25665933, 0.034019366]\n",
      "Iter 3858, loss [-0.20930757, -0.24494854, 0.035640966]\n",
      "Iter 3859, loss [-0.22093046, -0.259439, 0.038508534]\n",
      "Iter 3860, loss [-0.22102034, -0.26002276, 0.03900241]\n",
      "Iter 3861, loss [-0.23032911, -0.26812705, 0.03779794]\n",
      "Iter 3862, loss [-0.21542746, -0.25620282, 0.040775355]\n",
      "Iter 3863, loss [-0.22704484, -0.2640186, 0.03697376]\n",
      "Iter 3864, loss [-0.21974175, -0.2595475, 0.039805755]\n",
      "Iter 3865, loss [-0.22309807, -0.25869513, 0.035597052]\n",
      "Iter 3866, loss [-0.21417508, -0.24935524, 0.035180166]\n",
      "Iter 3867, loss [-0.20811842, -0.24761264, 0.039494213]\n",
      "Iter 3868, loss [-0.22121838, -0.25967318, 0.03845481]\n",
      "Iter 3869, loss [-0.22265291, -0.26017052, 0.037517603]\n",
      "Iter 3870, loss [-0.22712886, -0.26450104, 0.037372164]\n",
      "Iter 3871, loss [-0.20893885, -0.25242758, 0.043488722]\n",
      "Iter 3872, loss [-0.19675374, -0.242183, 0.045429252]\n",
      "Iter 3873, loss [-0.197202, -0.24204494, 0.044842944]\n",
      "Iter 3874, loss [-0.21959166, -0.25836363, 0.03877197]\n",
      "Iter 3875, loss [-0.2317978, -0.2671537, 0.035355907]\n",
      "Iter 3876, loss [-0.21584277, -0.25375372, 0.037910953]\n",
      "Iter 3877, loss [-0.1886484, -0.23779356, 0.049145162]\n",
      "Iter 3878, loss [-0.15785873, -0.2158181, 0.057959374]\n",
      "Iter 3879, loss [-0.21682303, -0.25799057, 0.041167542]\n",
      "Iter 3880, loss [-0.20793043, -0.251971, 0.044040576]\n",
      "Iter 3881, loss [-0.23442388, -0.2704425, 0.03601861]\n",
      "Iter 3882, loss [-0.22346893, -0.26385635, 0.04038742]\n",
      "Iter 3883, loss [-0.22206633, -0.26216435, 0.040098023]\n",
      "Iter 3884, loss [-0.22997588, -0.26503575, 0.03505986]\n",
      "Iter 3885, loss [-0.22432366, -0.26063773, 0.03631407]\n",
      "Iter 3886, loss [-0.22719361, -0.262684, 0.03549038]\n",
      "Iter 3887, loss [-0.22293267, -0.25923634, 0.036303677]\n",
      "Iter 3888, loss [-0.22203362, -0.2599048, 0.037871175]\n",
      "Iter 3889, loss [-0.2050905, -0.24738707, 0.04229658]\n",
      "Iter 3890, loss [-0.21605176, -0.2566867, 0.04063493]\n",
      "Iter 3891, loss [-0.2197627, -0.2585132, 0.038750514]\n",
      "Iter 3892, loss [-0.22165199, -0.25928873, 0.037636742]\n",
      "Iter 3893, loss [-0.23103908, -0.26609764, 0.035058565]\n",
      "Iter 3894, loss [-0.21734376, -0.25681525, 0.039471492]\n",
      "Iter 3895, loss [-0.22848442, -0.26538977, 0.03690535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3896, loss [-0.21700574, -0.2558318, 0.03882606]\n",
      "Iter 3897, loss [-0.22771968, -0.26509959, 0.0373799]\n",
      "Iter 3898, loss [-0.2285797, -0.2658372, 0.03725749]\n",
      "Iter 3899, loss [-0.22790095, -0.2642779, 0.036376946]\n",
      "Iter 3900, loss [-0.22617011, -0.26218304, 0.036012933]\n",
      "Iter 3901, loss [-0.21730797, -0.25469345, 0.03738548]\n",
      "Iter 3902, loss [-0.21108547, -0.25249347, 0.041407995]\n",
      "Iter 3903, loss [-0.22757475, -0.26325387, 0.035679113]\n",
      "Iter 3904, loss [-0.16551507, -0.21877721, 0.05326214]\n",
      "Iter 3905, loss [-0.2244412, -0.26145738, 0.03701618]\n",
      "Iter 3906, loss [-0.21832584, -0.2577372, 0.039411347]\n",
      "Iter 3907, loss [-0.2252428, -0.26454684, 0.039304044]\n",
      "Iter 3908, loss [-0.21987972, -0.25648388, 0.036604173]\n",
      "Iter 3909, loss [-0.22009814, -0.256751, 0.036652867]\n",
      "Iter 3910, loss [-0.18949692, -0.23517004, 0.045673113]\n",
      "Iter 3911, loss [-0.23068887, -0.2664793, 0.035790443]\n",
      "Iter 3912, loss [-0.22234297, -0.25966564, 0.037322663]\n",
      "Iter 3913, loss [-0.21803814, -0.25741, 0.039371844]\n",
      "Iter 3914, loss [-0.18906972, -0.23738198, 0.04831227]\n",
      "Iter 3915, loss [-0.22007453, -0.2586764, 0.03860187]\n",
      "Iter 3916, loss [-0.22622761, -0.26552245, 0.039294835]\n",
      "Iter 3917, loss [-0.22422296, -0.26036933, 0.036146365]\n",
      "Iter 3918, loss [-0.21792364, -0.25508016, 0.03715652]\n",
      "Iter 3919, loss [-0.22254632, -0.25999072, 0.037444398]\n",
      "Iter 3920, loss [-0.21939641, -0.2571831, 0.03778669]\n",
      "Iter 3921, loss [-0.22364113, -0.26220033, 0.038559206]\n",
      "Iter 3922, loss [-0.21464367, -0.25349212, 0.03884844]\n",
      "Iter 3923, loss [-0.2230818, -0.2593958, 0.03631401]\n",
      "Iter 3924, loss [-0.19697043, -0.24008644, 0.043116003]\n",
      "Iter 3925, loss [-0.23364648, -0.26835677, 0.034710288]\n",
      "Iter 3926, loss [-0.22127448, -0.25998324, 0.038708758]\n",
      "Iter 3927, loss [-0.23075144, -0.2670439, 0.03629245]\n",
      "Iter 3928, loss [-0.22255358, -0.26039857, 0.037844982]\n",
      "Iter 3929, loss [-0.22667116, -0.261843, 0.03517183]\n",
      "Iter 3930, loss [-0.20590481, -0.24919322, 0.04328841]\n",
      "Iter 3931, loss [-0.2271017, -0.2645063, 0.037404608]\n",
      "Iter 3932, loss [-0.1723556, -0.22577503, 0.053419422]\n",
      "Iter 3933, loss [-0.21655297, -0.25709173, 0.040538754]\n",
      "Iter 3934, loss [-0.21751216, -0.25644612, 0.03893397]\n",
      "Iter 3935, loss [-0.21657263, -0.25662634, 0.040053707]\n",
      "Iter 3936, loss [-0.20404881, -0.25202394, 0.04797512]\n",
      "Iter 3937, loss [-0.23025882, -0.2668819, 0.036623098]\n",
      "Iter 3938, loss [-0.21249536, -0.2537737, 0.041278325]\n",
      "Iter 3939, loss [-0.2248222, -0.26411346, 0.03929126]\n",
      "Iter 3940, loss [-0.19704576, -0.24164025, 0.044594496]\n",
      "Iter 3941, loss [-0.22761612, -0.2649712, 0.037355077]\n",
      "Iter 3942, loss [-0.21839392, -0.2559518, 0.037557863]\n",
      "Iter 3943, loss [-0.21278176, -0.25164026, 0.0388585]\n",
      "Iter 3944, loss [-0.22486681, -0.26445135, 0.039584544]\n",
      "Iter 3945, loss [-0.22279924, -0.2617612, 0.038961954]\n",
      "Iter 3946, loss [-0.17824854, -0.2242699, 0.046021357]\n",
      "Iter 3947, loss [-0.22206713, -0.2605251, 0.038457975]\n",
      "Iter 3948, loss [-0.22849922, -0.26530236, 0.03680314]\n",
      "Iter 3949, loss [-0.21595493, -0.2548016, 0.03884667]\n",
      "Iter 3950, loss [-0.20942691, -0.24859323, 0.03916631]\n",
      "Iter 3951, loss [-0.21922076, -0.258264, 0.039043248]\n",
      "Iter 3952, loss [-0.22173746, -0.2611358, 0.039398327]\n",
      "Iter 3953, loss [-0.22452715, -0.26413077, 0.03960363]\n",
      "Iter 3954, loss [-0.22361498, -0.26306364, 0.03944866]\n",
      "Iter 3955, loss [-0.2212342, -0.25878468, 0.03755048]\n",
      "Iter 3956, loss [-0.23172179, -0.2668194, 0.03509759]\n",
      "Iter 3957, loss [-0.22075182, -0.25880864, 0.038056828]\n",
      "Iter 3958, loss [-0.22633755, -0.26346326, 0.037125707]\n",
      "Iter 3959, loss [-0.22475623, -0.2602947, 0.03553848]\n",
      "Iter 3960, loss [-0.22443756, -0.26077586, 0.036338292]\n",
      "Iter 3961, loss [-0.21867254, -0.25877237, 0.040099822]\n",
      "Iter 3962, loss [-0.23321515, -0.26941103, 0.036195878]\n",
      "Iter 3963, loss [-0.21861884, -0.25753295, 0.03891412]\n",
      "Iter 3964, loss [-0.18235025, -0.23159768, 0.049247436]\n",
      "Iter 3965, loss [-0.22360283, -0.26145092, 0.037848093]\n",
      "Iter 3966, loss [-0.18507066, -0.23654807, 0.051477395]\n",
      "Iter 3967, loss [-0.23106073, -0.26693317, 0.035872445]\n",
      "Iter 3968, loss [-0.22608747, -0.265971, 0.03988354]\n",
      "Iter 3969, loss [-0.23334241, -0.26819116, 0.034848742]\n",
      "Iter 3970, loss [-0.22298364, -0.26057646, 0.03759281]\n",
      "Iter 3971, loss [-0.2149426, -0.25628403, 0.04134143]\n",
      "Iter 3972, loss [-0.22535548, -0.262877, 0.037521508]\n",
      "Iter 3973, loss [-0.21632831, -0.25429067, 0.03796236]\n",
      "Iter 3974, loss [-0.13661101, -0.19700123, 0.060390227]\n",
      "Iter 3975, loss [-0.2215164, -0.2592675, 0.037751116]\n",
      "Iter 3976, loss [-0.21257414, -0.2517563, 0.03918217]\n",
      "Iter 3977, loss [-0.18122192, -0.23416196, 0.05294004]\n",
      "Iter 3978, loss [-0.21580617, -0.25645962, 0.040653452]\n",
      "Iter 3979, loss [-0.2248202, -0.26258314, 0.037762932]\n",
      "Iter 3980, loss [-0.2225923, -0.263622, 0.04102969]\n",
      "Iter 3981, loss [-0.22815709, -0.26615867, 0.03800158]\n",
      "Iter 3982, loss [-0.21940258, -0.25679895, 0.03739637]\n",
      "Iter 3983, loss [-0.21901049, -0.25986332, 0.040852826]\n",
      "Iter 3984, loss [-0.21742252, -0.25635266, 0.03893014]\n",
      "Iter 3985, loss [-0.22462413, -0.26038098, 0.035756856]\n",
      "Iter 3986, loss [-0.2262801, -0.26115373, 0.034873635]\n",
      "Iter 3987, loss [-0.16438407, -0.22123078, 0.0568467]\n",
      "Iter 3988, loss [-0.2148158, -0.2553936, 0.0405778]\n",
      "Iter 3989, loss [-0.22277649, -0.25984976, 0.037073266]\n",
      "Iter 3990, loss [-0.17716826, -0.21959223, 0.042423964]\n",
      "Iter 3991, loss [-0.21348566, -0.252978, 0.03949234]\n",
      "Iter 3992, loss [-0.22329205, -0.26045763, 0.03716558]\n",
      "Iter 3993, loss [-0.22537327, -0.25984704, 0.034473784]\n",
      "Iter 3994, loss [-0.21524616, -0.25363535, 0.038389195]\n",
      "Iter 3995, loss [-0.21986507, -0.255841, 0.03597592]\n",
      "Iter 3996, loss [-0.22219118, -0.25850508, 0.036313895]\n",
      "Iter 3997, loss [-0.21041611, -0.25156376, 0.041147646]\n",
      "Iter 3998, loss [-0.2140379, -0.25213546, 0.038097557]\n",
      "Iter 3999, loss [-0.16316627, -0.21958584, 0.056419566]\n",
      "Iter 4000, loss [-0.18918063, -0.23521811, 0.046037477]\n",
      "Iter 4001, loss [-0.23209941, -0.26776594, 0.035666518]\n",
      "Iter 4002, loss [-0.22681883, -0.26537424, 0.03855542]\n",
      "Iter 4003, loss [-0.22387357, -0.26385102, 0.039977442]\n",
      "Iter 4004, loss [-0.21929553, -0.25881502, 0.039519496]\n",
      "Iter 4005, loss [-0.15980235, -0.210607, 0.050804656]\n",
      "Iter 4006, loss [-0.22243705, -0.26105535, 0.038618296]\n",
      "Iter 4007, loss [-0.21824268, -0.25778425, 0.03954157]\n",
      "Iter 4008, loss [-0.22383723, -0.26306677, 0.03922955]\n",
      "Iter 4009, loss [-0.216337, -0.2549779, 0.038640913]\n",
      "Iter 4010, loss [-0.22363402, -0.26041853, 0.03678452]\n",
      "Iter 4011, loss [-0.20819819, -0.24595118, 0.03775298]\n",
      "Iter 4012, loss [-0.22511241, -0.25983107, 0.034718655]\n",
      "Iter 4013, loss [-0.19385146, -0.23457934, 0.040727887]\n",
      "Iter 4014, loss [-0.22480908, -0.2604306, 0.03562153]\n",
      "Iter 4015, loss [-0.23318894, -0.26825312, 0.035064176]\n",
      "Iter 4016, loss [-0.2077333, -0.24981558, 0.042082287]\n",
      "Iter 4017, loss [-0.2236984, -0.26203963, 0.038341228]\n",
      "Iter 4018, loss [-0.21963088, -0.25693753, 0.03730665]\n",
      "Iter 4019, loss [-0.2255609, -0.26469347, 0.039132573]\n",
      "Iter 4020, loss [-0.22250135, -0.25975466, 0.0372533]\n",
      "Iter 4021, loss [-0.22425635, -0.26175275, 0.037496403]\n",
      "Iter 4022, loss [-0.22039728, -0.2592637, 0.038866416]\n",
      "Iter 4023, loss [-0.22857665, -0.26654425, 0.03796761]\n",
      "Iter 4024, loss [-0.23430352, -0.2694552, 0.035151675]\n",
      "Iter 4025, loss [-0.22009127, -0.2597641, 0.039672833]\n",
      "Iter 4026, loss [-0.2191127, -0.25995287, 0.040840186]\n",
      "Iter 4027, loss [-0.22092868, -0.25866976, 0.03774108]\n",
      "Iter 4028, loss [-0.24065721, -0.27535444, 0.034697242]\n",
      "Iter 4029, loss [-0.22129104, -0.26088792, 0.03959688]\n",
      "Iter 4030, loss [-0.21694621, -0.25662312, 0.0396769]\n",
      "Iter 4031, loss [-0.22092131, -0.260334, 0.039412715]\n",
      "Iter 4032, loss [-0.13023962, -0.18772537, 0.05748574]\n",
      "Iter 4033, loss [-0.20271516, -0.24622215, 0.043506987]\n",
      "Iter 4034, loss [-0.21462567, -0.25399458, 0.03936891]\n",
      "Iter 4035, loss [-0.23184808, -0.26704904, 0.03520097]\n",
      "Iter 4036, loss [-0.22051418, -0.2575739, 0.037059724]\n",
      "Iter 4037, loss [-0.20753843, -0.24986447, 0.042326055]\n",
      "Iter 4038, loss [-0.23092219, -0.26739997, 0.036477774]\n",
      "Iter 4039, loss [-0.22558153, -0.26301596, 0.03743442]\n",
      "Iter 4040, loss [-0.21724656, -0.2569628, 0.03971625]\n",
      "Iter 4041, loss [-0.22861026, -0.26629105, 0.03768079]\n",
      "Iter 4042, loss [-0.22435561, -0.26216894, 0.03781333]\n",
      "Iter 4043, loss [-0.23007718, -0.26654398, 0.0364668]\n",
      "Iter 4044, loss [-0.22515246, -0.26229495, 0.037142478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4045, loss [-0.22459029, -0.2617125, 0.0371222]\n",
      "Iter 4046, loss [-0.22663262, -0.26290157, 0.036268942]\n",
      "Iter 4047, loss [-0.22252455, -0.2599568, 0.03743226]\n",
      "Iter 4048, loss [-0.22028959, -0.2579952, 0.037705608]\n",
      "Iter 4049, loss [-0.22221395, -0.26135814, 0.03914419]\n",
      "Iter 4050, loss [-0.22488005, -0.2639494, 0.03906934]\n",
      "Iter 4051, loss [-0.22669294, -0.26620468, 0.039511736]\n",
      "Iter 4052, loss [-0.1704088, -0.2256847, 0.055275902]\n",
      "Iter 4053, loss [-0.2172356, -0.25840765, 0.041172057]\n",
      "Iter 4054, loss [-0.22887546, -0.26526928, 0.036393818]\n",
      "Iter 4055, loss [-0.2152485, -0.2538396, 0.038591117]\n",
      "Iter 4056, loss [-0.22889619, -0.2649218, 0.03602563]\n",
      "Iter 4057, loss [-0.22108243, -0.25937247, 0.038290042]\n",
      "Iter 4058, loss [-0.23045084, -0.2659515, 0.035500683]\n",
      "Iter 4059, loss [-0.2202476, -0.25833243, 0.038084835]\n",
      "Iter 4060, loss [-0.21657845, -0.25546154, 0.038883086]\n",
      "Iter 4061, loss [-0.22133484, -0.2600998, 0.038764946]\n",
      "Iter 4062, loss [-0.21809337, -0.2568239, 0.03873053]\n",
      "Iter 4063, loss [-0.21812639, -0.25793144, 0.039805047]\n",
      "Iter 4064, loss [-0.230474, -0.26652178, 0.036047783]\n",
      "Iter 4065, loss [-0.21943156, -0.25942978, 0.039998215]\n",
      "Iter 4066, loss [-0.22777581, -0.26481882, 0.037042998]\n",
      "Iter 4067, loss [-0.21344703, -0.25386894, 0.040421896]\n",
      "Iter 4068, loss [-0.22199626, -0.26124805, 0.03925179]\n",
      "Iter 4069, loss [-0.22536033, -0.2628403, 0.037479974]\n",
      "Iter 4070, loss [-0.23143445, -0.26795083, 0.036516383]\n",
      "Iter 4071, loss [-0.21512966, -0.2535889, 0.03845926]\n",
      "Iter 4072, loss [-0.22800376, -0.2653233, 0.037319556]\n",
      "Iter 4073, loss [-0.18699227, -0.23548038, 0.04848811]\n",
      "Iter 4074, loss [-0.17465222, -0.2259912, 0.05133898]\n",
      "Iter 4075, loss [-0.21941926, -0.25743374, 0.038014486]\n",
      "Iter 4076, loss [-0.22971813, -0.2641417, 0.03442357]\n",
      "Iter 4077, loss [-0.22922215, -0.26593813, 0.036715977]\n",
      "Iter 4078, loss [-0.22276515, -0.2612765, 0.038511373]\n",
      "Iter 4079, loss [-0.22477147, -0.26109183, 0.036320355]\n",
      "Iter 4080, loss [-0.13409558, -0.19623633, 0.062140744]\n",
      "Iter 4081, loss [-0.22190662, -0.26105723, 0.03915061]\n",
      "Iter 4082, loss [-0.23168124, -0.26694748, 0.03526624]\n",
      "Iter 4083, loss [-0.20671833, -0.24736303, 0.0406447]\n",
      "Iter 4084, loss [-0.2222392, -0.25907218, 0.03683298]\n",
      "Iter 4085, loss [-0.16687708, -0.22016959, 0.05329251]\n",
      "Iter 4086, loss [-0.22296086, -0.2599909, 0.037030037]\n",
      "Iter 4087, loss [-0.22593431, -0.26356447, 0.037630156]\n",
      "Iter 4088, loss [-0.22992958, -0.26653945, 0.03660987]\n",
      "Iter 4089, loss [-0.2299594, -0.26613295, 0.036173552]\n",
      "Iter 4090, loss [-0.21411972, -0.25277713, 0.038657416]\n",
      "Iter 4091, loss [-0.21984963, -0.25793946, 0.038089823]\n",
      "Iter 4092, loss [-0.21408115, -0.25323734, 0.039156184]\n",
      "Iter 4093, loss [-0.22651437, -0.2616633, 0.035148926]\n",
      "Iter 4094, loss [-0.22975445, -0.26552054, 0.035766087]\n",
      "Iter 4095, loss [-0.21210524, -0.25229293, 0.040187687]\n",
      "Iter 4096, loss [-0.21165976, -0.25118476, 0.039525002]\n",
      "Iter 4097, loss [-0.23083192, -0.2673657, 0.036533773]\n",
      "Iter 4098, loss [-0.22490105, -0.26252568, 0.037624635]\n",
      "Iter 4099, loss [-0.2182207, -0.25657204, 0.038351342]\n",
      "Iter 4100, loss [-0.21414207, -0.2554457, 0.041303616]\n",
      "Iter 4101, loss [-0.22331695, -0.26134238, 0.03802542]\n",
      "Iter 4102, loss [-0.23030666, -0.2663994, 0.03609276]\n",
      "Iter 4103, loss [-0.23216283, -0.26777261, 0.03560979]\n",
      "Iter 4104, loss [-0.2156754, -0.25562182, 0.03994642]\n",
      "Iter 4105, loss [-0.20319423, -0.24361785, 0.040423624]\n",
      "Iter 4106, loss [-0.21187106, -0.25132394, 0.03945288]\n",
      "Iter 4107, loss [-0.22310537, -0.25967556, 0.0365702]\n",
      "Iter 4108, loss [-0.1412094, -0.19784203, 0.056632638]\n",
      "Iter 4109, loss [-0.22452605, -0.26218352, 0.037657477]\n",
      "Iter 4110, loss [-0.20839064, -0.25002605, 0.04163541]\n",
      "Iter 4111, loss [-0.22496521, -0.26099458, 0.03602936]\n",
      "Iter 4112, loss [-0.22426003, -0.26426592, 0.040005896]\n",
      "Iter 4113, loss [-0.2161041, -0.25707814, 0.040974036]\n",
      "Iter 4114, loss [-0.22272542, -0.26105338, 0.038327962]\n",
      "Iter 4115, loss [-0.22320746, -0.26102692, 0.03781946]\n",
      "Iter 4116, loss [-0.21752986, -0.25663945, 0.039109595]\n",
      "Iter 4117, loss [-0.21840455, -0.2563361, 0.037931543]\n",
      "Iter 4118, loss [-0.2231789, -0.25952393, 0.036345035]\n",
      "Iter 4119, loss [-0.23369019, -0.26981628, 0.036126092]\n",
      "Iter 4120, loss [-0.17012167, -0.22652687, 0.05640521]\n",
      "Iter 4121, loss [-0.2176759, -0.2568091, 0.039133184]\n",
      "Iter 4122, loss [-0.2134622, -0.25379625, 0.040334053]\n",
      "Iter 4123, loss [-0.21450669, -0.2532227, 0.03871602]\n",
      "Iter 4124, loss [-0.21686485, -0.25642708, 0.03956223]\n",
      "Iter 4125, loss [-0.2252967, -0.2641424, 0.03884568]\n",
      "Iter 4126, loss [-0.21741903, -0.25683028, 0.03941124]\n",
      "Iter 4127, loss [-0.22870854, -0.266946, 0.03823746]\n",
      "Iter 4128, loss [-0.22185126, -0.25990143, 0.038050175]\n",
      "Iter 4129, loss [-0.22698087, -0.26406226, 0.037081383]\n",
      "Iter 4130, loss [-0.22509618, -0.26299313, 0.037896946]\n",
      "Iter 4131, loss [-0.22112188, -0.26024252, 0.03912064]\n",
      "Iter 4132, loss [-0.20474204, -0.24604027, 0.041298218]\n",
      "Iter 4133, loss [-0.23267956, -0.26606393, 0.033384368]\n",
      "Iter 4134, loss [-0.22293647, -0.2592962, 0.036359746]\n",
      "Iter 4135, loss [-0.22677815, -0.2621107, 0.03533256]\n",
      "Iter 4136, loss [-0.22777213, -0.26329884, 0.03552671]\n",
      "Iter 4137, loss [-0.22654527, -0.26320967, 0.036664393]\n",
      "Iter 4138, loss [-0.22780706, -0.26335084, 0.03554378]\n",
      "Iter 4139, loss [-0.2249899, -0.26319268, 0.038202778]\n",
      "Iter 4140, loss [-0.22478111, -0.26158553, 0.03680442]\n",
      "Iter 4141, loss [-0.2241976, -0.26345852, 0.039260916]\n",
      "Iter 4142, loss [-0.22384727, -0.26156414, 0.03771686]\n",
      "Iter 4143, loss [-0.21678382, -0.25655106, 0.03976723]\n",
      "Iter 4144, loss [-0.2167379, -0.25601503, 0.039277133]\n",
      "Iter 4145, loss [-0.22320682, -0.2618344, 0.038627595]\n",
      "Iter 4146, loss [-0.18795976, -0.23887579, 0.05091603]\n",
      "Iter 4147, loss [-0.22660181, -0.26516327, 0.038561456]\n",
      "Iter 4148, loss [-0.21165714, -0.2549028, 0.043245673]\n",
      "Iter 4149, loss [-0.20321108, -0.24793307, 0.04472199]\n",
      "Iter 4150, loss [-0.23060448, -0.26657334, 0.03596885]\n",
      "Iter 4151, loss [-0.17442614, -0.225593, 0.051166862]\n",
      "Iter 4152, loss [-0.22716355, -0.26467997, 0.03751641]\n",
      "Iter 4153, loss [-0.23182473, -0.26820228, 0.036377545]\n",
      "Iter 4154, loss [-0.20496991, -0.24586733, 0.04089741]\n",
      "Iter 4155, loss [-0.22863446, -0.26379493, 0.035160467]\n",
      "Iter 4156, loss [-0.2280031, -0.26391256, 0.03590946]\n",
      "Iter 4157, loss [-0.23219225, -0.2694578, 0.03726553]\n",
      "Iter 4158, loss [-0.1720983, -0.22655626, 0.054457963]\n",
      "Iter 4159, loss [-0.22610573, -0.26210696, 0.03600122]\n",
      "Iter 4160, loss [-0.22663268, -0.2621781, 0.035545405]\n",
      "Iter 4161, loss [-0.21986976, -0.259656, 0.039786242]\n",
      "Iter 4162, loss [-0.22873512, -0.26405707, 0.03532195]\n",
      "Iter 4163, loss [-0.22519043, -0.2642969, 0.03910646]\n",
      "Iter 4164, loss [-0.23025133, -0.2674357, 0.037184373]\n",
      "Iter 4165, loss [-0.21741754, -0.25644115, 0.03902361]\n",
      "Iter 4166, loss [-0.20813398, -0.24934761, 0.041213635]\n",
      "Iter 4167, loss [-0.22489843, -0.26524305, 0.04034462]\n",
      "Iter 4168, loss [-0.20919275, -0.25093752, 0.04174476]\n",
      "Iter 4169, loss [-0.20216571, -0.24344596, 0.041280255]\n",
      "Iter 4170, loss [-0.22340961, -0.26173308, 0.038323477]\n",
      "Iter 4171, loss [-0.2271406, -0.2646545, 0.03751389]\n",
      "Iter 4172, loss [-0.22531787, -0.26296452, 0.03764665]\n",
      "Iter 4173, loss [-0.22485726, -0.26363865, 0.038781386]\n",
      "Iter 4174, loss [-0.22687848, -0.26304096, 0.03616248]\n",
      "Iter 4175, loss [-0.2268329, -0.26370606, 0.036873158]\n",
      "Iter 4176, loss [-0.22143365, -0.26054424, 0.039110582]\n",
      "Iter 4177, loss [-0.2275936, -0.26572597, 0.038132362]\n",
      "Iter 4178, loss [-0.22293429, -0.26193807, 0.03900377]\n",
      "Iter 4179, loss [-0.23162463, -0.2673012, 0.035676576]\n",
      "Iter 4180, loss [-0.20633088, -0.24839877, 0.042067885]\n",
      "Iter 4181, loss [-0.23084651, -0.2651763, 0.034329787]\n",
      "Iter 4182, loss [-0.22518837, -0.26385134, 0.038662978]\n",
      "Iter 4183, loss [-0.21406987, -0.25337872, 0.03930884]\n",
      "Iter 4184, loss [-0.22668493, -0.26580837, 0.039123446]\n",
      "Iter 4185, loss [-0.22801256, -0.26456797, 0.036555417]\n",
      "Iter 4186, loss [-0.21769261, -0.2590094, 0.041316785]\n",
      "Iter 4187, loss [-0.22096498, -0.26093292, 0.039967936]\n",
      "Iter 4188, loss [-0.22024101, -0.2575048, 0.03726379]\n",
      "Iter 4189, loss [-0.21074778, -0.25028542, 0.03953764]\n",
      "Iter 4190, loss [-0.21559155, -0.25387275, 0.0382812]\n",
      "Iter 4191, loss [-0.22447202, -0.26153788, 0.037065856]\n",
      "Iter 4192, loss [-0.22524379, -0.2627518, 0.037507992]\n",
      "Iter 4193, loss [-0.15880293, -0.21248657, 0.053683646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4194, loss [-0.2277706, -0.26488283, 0.037112232]\n",
      "Iter 4195, loss [-0.2239534, -0.26290116, 0.038947754]\n",
      "Iter 4196, loss [-0.22743613, -0.26655185, 0.03911572]\n",
      "Iter 4197, loss [-0.1624453, -0.21663332, 0.054188006]\n",
      "Iter 4198, loss [-0.23250726, -0.26939133, 0.03688407]\n",
      "Iter 4199, loss [-0.22754186, -0.26438558, 0.036843725]\n",
      "Iter 4200, loss [-0.22324027, -0.26024365, 0.03700338]\n",
      "Iter 4201, loss [-0.21638852, -0.25530702, 0.038918503]\n",
      "Iter 4202, loss [-0.22118881, -0.25987563, 0.038686804]\n",
      "Iter 4203, loss [-0.226969, -0.26460135, 0.037632354]\n",
      "Iter 4204, loss [-0.22689459, -0.26392522, 0.037030637]\n",
      "Iter 4205, loss [-0.22642675, -0.26316518, 0.036738418]\n",
      "Iter 4206, loss [-0.16061324, -0.21907665, 0.058463406]\n",
      "Iter 4207, loss [-0.21400727, -0.25556484, 0.041557565]\n",
      "Iter 4208, loss [-0.21595767, -0.25596654, 0.040008873]\n",
      "Iter 4209, loss [-0.21584632, -0.25623968, 0.040393364]\n",
      "Iter 4210, loss [-0.22006932, -0.25898147, 0.03891214]\n",
      "Iter 4211, loss [-0.2018456, -0.24272239, 0.04087679]\n",
      "Iter 4212, loss [-0.2342824, -0.26971972, 0.035437323]\n",
      "Iter 4213, loss [-0.21639213, -0.25614583, 0.039753705]\n",
      "Iter 4214, loss [-0.20844959, -0.25105736, 0.04260777]\n",
      "Iter 4215, loss [-0.22122554, -0.25918466, 0.037959114]\n",
      "Iter 4216, loss [-0.22207195, -0.26170203, 0.039630093]\n",
      "Iter 4217, loss [-0.21999091, -0.258419, 0.03842809]\n",
      "Iter 4218, loss [-0.214512, -0.25217324, 0.037661236]\n",
      "Iter 4219, loss [-0.2219094, -0.2606677, 0.038758308]\n",
      "Iter 4220, loss [-0.226372, -0.2641724, 0.037800398]\n",
      "Iter 4221, loss [-0.19026913, -0.23706052, 0.046791386]\n",
      "Iter 4222, loss [-0.22219718, -0.2594195, 0.037222326]\n",
      "Iter 4223, loss [-0.21064952, -0.249301, 0.03865149]\n",
      "Iter 4224, loss [-0.20172793, -0.24548872, 0.043760784]\n",
      "Iter 4225, loss [-0.22345026, -0.26149702, 0.03804676]\n",
      "Iter 4226, loss [-0.23091939, -0.26638252, 0.035463125]\n",
      "Iter 4227, loss [-0.22321588, -0.26200247, 0.038786598]\n",
      "Iter 4228, loss [-0.22446422, -0.26308125, 0.03861703]\n",
      "Iter 4229, loss [-0.22212572, -0.25955626, 0.03743054]\n",
      "Iter 4230, loss [-0.20003708, -0.2415367, 0.04149963]\n",
      "Iter 4231, loss [-0.21993466, -0.2615405, 0.041605845]\n",
      "Iter 4232, loss [-0.21645443, -0.25263673, 0.036182296]\n",
      "Iter 4233, loss [-0.22286256, -0.26364735, 0.040784787]\n",
      "Iter 4234, loss [-0.23338614, -0.26983956, 0.036453407]\n",
      "Iter 4235, loss [-0.21240515, -0.25360176, 0.041196622]\n",
      "Iter 4236, loss [-0.22725457, -0.26494294, 0.037688367]\n",
      "Iter 4237, loss [-0.23041138, -0.26534382, 0.034932435]\n",
      "Iter 4238, loss [-0.22935276, -0.26468486, 0.0353321]\n",
      "Iter 4239, loss [-0.22780322, -0.26289785, 0.035094634]\n",
      "Iter 4240, loss [-0.18227033, -0.23523985, 0.052969515]\n",
      "Iter 4241, loss [-0.21296322, -0.25362143, 0.040658202]\n",
      "Iter 4242, loss [-0.20102149, -0.24410056, 0.04307907]\n",
      "Iter 4243, loss [-0.20342286, -0.24154615, 0.0381233]\n",
      "Iter 4244, loss [-0.2247256, -0.26058456, 0.03585896]\n",
      "Iter 4245, loss [-0.22595523, -0.26362383, 0.037668597]\n",
      "Iter 4246, loss [-0.21695828, -0.25595647, 0.03899818]\n",
      "Iter 4247, loss [-0.22837244, -0.26652837, 0.038155925]\n",
      "Iter 4248, loss [-0.20285624, -0.24809417, 0.045237925]\n",
      "Iter 4249, loss [-0.22068034, -0.25927463, 0.038594287]\n",
      "Iter 4250, loss [-0.23044838, -0.26739687, 0.036948483]\n",
      "Iter 4251, loss [-0.2260082, -0.26037842, 0.034370217]\n",
      "Iter 4252, loss [-0.21003431, -0.24802344, 0.037989132]\n",
      "Iter 4253, loss [-0.18809742, -0.23506391, 0.046966486]\n",
      "Iter 4254, loss [-0.22470316, -0.2620804, 0.03737724]\n",
      "Iter 4255, loss [-0.2317428, -0.26791823, 0.03617543]\n",
      "Iter 4256, loss [-0.23319647, -0.26790696, 0.034710504]\n",
      "Iter 4257, loss [-0.23233353, -0.26821467, 0.03588115]\n",
      "Iter 4258, loss [-0.23205361, -0.26853833, 0.03648471]\n",
      "Iter 4259, loss [-0.22749949, -0.2650852, 0.0375857]\n",
      "Iter 4260, loss [-0.2232121, -0.26037142, 0.037159316]\n",
      "Iter 4261, loss [-0.17202789, -0.22592078, 0.05389289]\n",
      "Iter 4262, loss [-0.21846355, -0.25728056, 0.038817003]\n",
      "Iter 4263, loss [-0.22211243, -0.2586412, 0.03652878]\n",
      "Iter 4264, loss [-0.20096108, -0.24242388, 0.0414628]\n",
      "Iter 4265, loss [-0.19790462, -0.24793261, 0.050028004]\n",
      "Iter 4266, loss [-0.23093681, -0.2675866, 0.036649775]\n",
      "Iter 4267, loss [-0.22880067, -0.2674183, 0.038617626]\n",
      "Iter 4268, loss [-0.21983968, -0.25961906, 0.039779376]\n",
      "Iter 4269, loss [-0.22048521, -0.2596732, 0.039187998]\n",
      "Iter 4270, loss [-0.23094913, -0.26624924, 0.035300102]\n",
      "Iter 4271, loss [-0.22721778, -0.2641584, 0.03694062]\n",
      "Iter 4272, loss [-0.23445338, -0.2693183, 0.034864932]\n",
      "Iter 4273, loss [-0.20517176, -0.24701966, 0.041847896]\n",
      "Iter 4274, loss [-0.23368417, -0.26803425, 0.03435008]\n",
      "Iter 4275, loss [-0.22345796, -0.2613609, 0.037902948]\n",
      "Iter 4276, loss [-0.22263291, -0.26069114, 0.03805823]\n",
      "Iter 4277, loss [-0.21883935, -0.2561595, 0.037320167]\n",
      "Iter 4278, loss [-0.22993267, -0.26422244, 0.03428977]\n",
      "Iter 4279, loss [-0.21870805, -0.2555165, 0.036808442]\n",
      "Iter 4280, loss [-0.22692087, -0.26367965, 0.03675878]\n",
      "Iter 4281, loss [-0.22063166, -0.25870335, 0.0380717]\n",
      "Iter 4282, loss [-0.22312643, -0.26165423, 0.0385278]\n",
      "Iter 4283, loss [-0.22239327, -0.26069796, 0.038304694]\n",
      "Iter 4284, loss [-0.22975689, -0.26620007, 0.036443174]\n",
      "Iter 4285, loss [-0.22856078, -0.2652885, 0.036727723]\n",
      "Iter 4286, loss [-0.2188651, -0.25878072, 0.039915618]\n",
      "Iter 4287, loss [-0.20510745, -0.24581553, 0.040708087]\n",
      "Iter 4288, loss [-0.22285955, -0.26120973, 0.03835018]\n",
      "Iter 4289, loss [-0.21954705, -0.25971255, 0.0401655]\n",
      "Iter 4290, loss [-0.21785216, -0.25515583, 0.03730367]\n",
      "Iter 4291, loss [-0.19662863, -0.24441828, 0.047789656]\n",
      "Iter 4292, loss [-0.23176321, -0.26634496, 0.034581743]\n",
      "Iter 4293, loss [-0.23090895, -0.26715383, 0.036244888]\n",
      "Iter 4294, loss [-0.22624819, -0.26410308, 0.037854895]\n",
      "Iter 4295, loss [-0.22626036, -0.26272112, 0.036460765]\n",
      "Iter 4296, loss [-0.20461488, -0.25225848, 0.047643602]\n",
      "Iter 4297, loss [-0.2173951, -0.25250566, 0.035110563]\n",
      "Iter 4298, loss [-0.22956873, -0.26476327, 0.03519453]\n",
      "Iter 4299, loss [-0.23330049, -0.26901466, 0.035714164]\n",
      "Iter 4300, loss [-0.21798515, -0.2578381, 0.039852954]\n",
      "Iter 4301, loss [-0.21207179, -0.25333878, 0.04126699]\n",
      "Iter 4302, loss [-0.2125499, -0.25452885, 0.041978948]\n",
      "Iter 4303, loss [-0.23055929, -0.26663765, 0.036078364]\n",
      "Iter 4304, loss [-0.2149717, -0.25334594, 0.038374227]\n",
      "Iter 4305, loss [-0.22879675, -0.26583382, 0.037037082]\n",
      "Iter 4306, loss [-0.16517079, -0.21963938, 0.054468587]\n",
      "Iter 4307, loss [-0.22468469, -0.2623382, 0.0376535]\n",
      "Iter 4308, loss [-0.21497239, -0.25525692, 0.04028453]\n",
      "Iter 4309, loss [-0.22756363, -0.26308298, 0.035519343]\n",
      "Iter 4310, loss [-0.21696788, -0.25693142, 0.039963536]\n",
      "Iter 4311, loss [-0.22372729, -0.26240396, 0.038676675]\n",
      "Iter 4312, loss [-0.20911333, -0.24961822, 0.040504895]\n",
      "Iter 4313, loss [-0.22588167, -0.26597342, 0.04009176]\n",
      "Iter 4314, loss [-0.22919211, -0.2659906, 0.03679851]\n",
      "Iter 4315, loss [-0.22708103, -0.26379675, 0.036715716]\n",
      "Iter 4316, loss [-0.22832465, -0.26526383, 0.036939174]\n",
      "Iter 4317, loss [-0.21026853, -0.24965787, 0.039389335]\n",
      "Iter 4318, loss [-0.22226715, -0.2622788, 0.04001165]\n",
      "Iter 4319, loss [-0.2267219, -0.26699525, 0.040273353]\n",
      "Iter 4320, loss [-0.21590967, -0.2556897, 0.03978004]\n",
      "Iter 4321, loss [-0.1571691, -0.21427186, 0.05710275]\n",
      "Iter 4322, loss [-0.2262362, -0.26202935, 0.035793163]\n",
      "Iter 4323, loss [-0.21982121, -0.26014143, 0.04032021]\n",
      "Iter 4324, loss [-0.22189322, -0.25857598, 0.03668276]\n",
      "Iter 4325, loss [-0.22322494, -0.25919548, 0.03597053]\n",
      "Iter 4326, loss [-0.22219856, -0.2583969, 0.03619833]\n",
      "Iter 4327, loss [-0.22082515, -0.2606716, 0.039846435]\n",
      "Iter 4328, loss [-0.208778, -0.25086823, 0.042090245]\n",
      "Iter 4329, loss [-0.23099506, -0.26760462, 0.036609564]\n",
      "Iter 4330, loss [-0.22525033, -0.26441032, 0.03915998]\n",
      "Iter 4331, loss [-0.22653928, -0.2641052, 0.037565924]\n",
      "Iter 4332, loss [-0.21048245, -0.25156525, 0.041082807]\n",
      "Iter 4333, loss [-0.22562212, -0.26437077, 0.03874866]\n",
      "Iter 4334, loss [-0.2217584, -0.26083472, 0.03907632]\n",
      "Iter 4335, loss [-0.22614609, -0.26472485, 0.038578767]\n",
      "Iter 4336, loss [-0.21679263, -0.2585383, 0.041745674]\n",
      "Iter 4337, loss [-0.22692661, -0.26606947, 0.039142862]\n",
      "Iter 4338, loss [-0.215967, -0.25737184, 0.041404836]\n",
      "Iter 4339, loss [-0.19524202, -0.24301472, 0.047772713]\n",
      "Iter 4340, loss [-0.23112822, -0.26784977, 0.03672156]\n",
      "Iter 4341, loss [-0.2088752, -0.25095132, 0.042076122]\n",
      "Iter 4342, loss [-0.22881141, -0.265267, 0.03645561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4343, loss [-0.21678397, -0.25515845, 0.03837448]\n",
      "Iter 4344, loss [-0.22579041, -0.26182967, 0.03603927]\n",
      "Iter 4345, loss [-0.22137368, -0.2594045, 0.038030826]\n",
      "Iter 4346, loss [-0.22123525, -0.26005635, 0.03882111]\n",
      "Iter 4347, loss [-0.15714684, -0.21205857, 0.054911733]\n",
      "Iter 4348, loss [-0.22692469, -0.2637871, 0.036862396]\n",
      "Iter 4349, loss [-0.21959077, -0.25907266, 0.039481893]\n",
      "Iter 4350, loss [-0.22130054, -0.26061934, 0.0393188]\n",
      "Iter 4351, loss [-0.21722654, -0.25732544, 0.040098898]\n",
      "Iter 4352, loss [-0.22868092, -0.26516473, 0.036483806]\n",
      "Iter 4353, loss [-0.2194635, -0.25878602, 0.03932252]\n",
      "Iter 4354, loss [-0.23069327, -0.2669225, 0.036229234]\n",
      "Iter 4355, loss [-0.21431826, -0.25577918, 0.041460916]\n",
      "Iter 4356, loss [-0.23382805, -0.26924896, 0.03542091]\n",
      "Iter 4357, loss [-0.22972484, -0.2642121, 0.034487262]\n",
      "Iter 4358, loss [-0.22639793, -0.26364797, 0.037250035]\n",
      "Iter 4359, loss [-0.21814525, -0.25658303, 0.038437787]\n",
      "Iter 4360, loss [-0.21734801, -0.25529414, 0.037946142]\n",
      "Iter 4361, loss [-0.2295043, -0.26636022, 0.036855917]\n",
      "Iter 4362, loss [-0.22024031, -0.25984317, 0.03960286]\n",
      "Iter 4363, loss [-0.22587249, -0.26456034, 0.038687848]\n",
      "Iter 4364, loss [-0.21142364, -0.25261626, 0.04119263]\n",
      "Iter 4365, loss [-0.21675746, -0.25583732, 0.03907986]\n",
      "Iter 4366, loss [-0.16671884, -0.2227875, 0.05606865]\n",
      "Iter 4367, loss [-0.22084624, -0.25826386, 0.037417628]\n",
      "Iter 4368, loss [-0.22385384, -0.26166415, 0.03781031]\n",
      "Iter 4369, loss [-0.21615171, -0.25527146, 0.03911975]\n",
      "Iter 4370, loss [-0.22607416, -0.26423755, 0.038163394]\n",
      "Iter 4371, loss [-0.20467499, -0.2509386, 0.0462636]\n",
      "Iter 4372, loss [-0.22853248, -0.2669958, 0.03846331]\n",
      "Iter 4373, loss [-0.21813421, -0.25765136, 0.03951715]\n",
      "Iter 4374, loss [-0.22658521, -0.26554063, 0.038955413]\n",
      "Iter 4375, loss [-0.22529495, -0.26364887, 0.03835392]\n",
      "Iter 4376, loss [-0.22394994, -0.26401314, 0.040063206]\n",
      "Iter 4377, loss [-0.20021215, -0.24462342, 0.044411264]\n",
      "Iter 4378, loss [-0.22621238, -0.26438552, 0.038173147]\n",
      "Iter 4379, loss [-0.22843269, -0.26472083, 0.03628815]\n",
      "Iter 4380, loss [-0.22736192, -0.26315203, 0.035790123]\n",
      "Iter 4381, loss [-0.22597158, -0.26401186, 0.038040277]\n",
      "Iter 4382, loss [-0.22628532, -0.2641851, 0.037899774]\n",
      "Iter 4383, loss [-0.2256582, -0.26231387, 0.036655683]\n",
      "Iter 4384, loss [-0.21706168, -0.2563674, 0.0393057]\n",
      "Iter 4385, loss [-0.2259967, -0.26361355, 0.03761684]\n",
      "Iter 4386, loss [-0.21376908, -0.2532198, 0.03945073]\n",
      "Iter 4387, loss [-0.23382205, -0.26835918, 0.03453713]\n",
      "Iter 4388, loss [-0.20827961, -0.25138137, 0.043101758]\n",
      "Iter 4389, loss [-0.22588977, -0.26146743, 0.035577662]\n",
      "Iter 4390, loss [-0.21275473, -0.25303656, 0.040281832]\n",
      "Iter 4391, loss [-0.22648296, -0.2634616, 0.03697864]\n",
      "Iter 4392, loss [-0.2227552, -0.26077354, 0.038018342]\n",
      "Iter 4393, loss [-0.22387472, -0.26115155, 0.037276827]\n",
      "Iter 4394, loss [-0.22202142, -0.25865743, 0.036636014]\n",
      "Iter 4395, loss [-0.22504823, -0.26353356, 0.03848533]\n",
      "Iter 4396, loss [-0.22817841, -0.26273927, 0.03456085]\n",
      "Iter 4397, loss [-0.2282688, -0.26522863, 0.03695982]\n",
      "Iter 4398, loss [-0.22303692, -0.26019493, 0.037158016]\n",
      "Iter 4399, loss [-0.23284736, -0.2684506, 0.035603218]\n",
      "Iter 4400, loss [-0.22156017, -0.25996163, 0.038401466]\n",
      "Iter 4401, loss [-0.230735, -0.26601207, 0.03527707]\n",
      "Iter 4402, loss [-0.21737303, -0.25297046, 0.03559743]\n",
      "Iter 4403, loss [-0.22351673, -0.260752, 0.037235256]\n",
      "Iter 4404, loss [-0.21848348, -0.25625, 0.03776651]\n",
      "Iter 4405, loss [-0.21650718, -0.2556051, 0.03909792]\n",
      "Iter 4406, loss [-0.22335356, -0.2623449, 0.03899133]\n",
      "Iter 4407, loss [-0.17913662, -0.22423628, 0.04509966]\n",
      "Iter 4408, loss [-0.2260735, -0.26270813, 0.03663463]\n",
      "Iter 4409, loss [-0.2147083, -0.25372458, 0.039016277]\n",
      "Iter 4410, loss [-0.23349357, -0.2675626, 0.03406903]\n",
      "Iter 4411, loss [-0.22296904, -0.26108032, 0.038111284]\n",
      "Iter 4412, loss [-0.21437192, -0.25372034, 0.03934842]\n",
      "Iter 4413, loss [-0.22566207, -0.26415598, 0.038493913]\n",
      "Iter 4414, loss [-0.22289777, -0.2625594, 0.039661646]\n",
      "Iter 4415, loss [-0.22472017, -0.26420385, 0.03948368]\n",
      "Iter 4416, loss [-0.2306875, -0.26828906, 0.037601568]\n",
      "Iter 4417, loss [-0.21483105, -0.25517565, 0.04034459]\n",
      "Iter 4418, loss [-0.22980757, -0.26493925, 0.035131674]\n",
      "Iter 4419, loss [-0.22203572, -0.2589597, 0.03692399]\n",
      "Iter 4420, loss [-0.22310445, -0.25971416, 0.0366097]\n",
      "Iter 4421, loss [-0.225833, -0.26205325, 0.03622026]\n",
      "Iter 4422, loss [-0.22607622, -0.26254332, 0.036467098]\n",
      "Iter 4423, loss [-0.20779368, -0.2471626, 0.039368916]\n",
      "Iter 4424, loss [-0.22261906, -0.26112702, 0.03850796]\n",
      "Iter 4425, loss [-0.22575895, -0.26395518, 0.03819622]\n",
      "Iter 4426, loss [-0.22949877, -0.26677278, 0.037274003]\n",
      "Iter 4427, loss [-0.22455347, -0.26198962, 0.03743615]\n",
      "Iter 4428, loss [-0.22974727, -0.2656313, 0.03588403]\n",
      "Iter 4429, loss [-0.2224393, -0.25938362, 0.03694432]\n",
      "Iter 4430, loss [-0.22212148, -0.2584575, 0.036336027]\n",
      "Iter 4431, loss [-0.20860946, -0.24836335, 0.03975388]\n",
      "Iter 4432, loss [-0.2209664, -0.26023403, 0.039267633]\n",
      "Iter 4433, loss [-0.14115429, -0.19959041, 0.058436118]\n",
      "Iter 4434, loss [-0.22403783, -0.26283556, 0.038797736]\n",
      "Iter 4435, loss [-0.22846313, -0.26570752, 0.037244394]\n",
      "Iter 4436, loss [-0.2227216, -0.26079836, 0.03807676]\n",
      "Iter 4437, loss [-0.22645682, -0.26166406, 0.03520724]\n",
      "Iter 4438, loss [-0.21297793, -0.25111815, 0.038140222]\n",
      "Iter 4439, loss [-0.21086249, -0.25147367, 0.040611174]\n",
      "Iter 4440, loss [-0.21894534, -0.2568308, 0.037885472]\n",
      "Iter 4441, loss [-0.23115236, -0.26563627, 0.034483902]\n",
      "Iter 4442, loss [-0.22660258, -0.26395848, 0.037355907]\n",
      "Iter 4443, loss [-0.21914867, -0.2586336, 0.039484955]\n",
      "Iter 4444, loss [-0.22757949, -0.26458082, 0.03700133]\n",
      "Iter 4445, loss [-0.23377159, -0.2717082, 0.03793659]\n",
      "Iter 4446, loss [-0.22767062, -0.2658519, 0.038181286]\n",
      "Iter 4447, loss [-0.22603571, -0.26240176, 0.036366053]\n",
      "Iter 4448, loss [-0.23085354, -0.26645878, 0.035605237]\n",
      "Iter 4449, loss [-0.22252229, -0.2588246, 0.0363023]\n",
      "Iter 4450, loss [-0.22161709, -0.25835952, 0.036742434]\n",
      "Iter 4451, loss [-0.22881436, -0.2642235, 0.03540913]\n",
      "Iter 4452, loss [-0.2274198, -0.26399714, 0.036577344]\n",
      "Iter 4453, loss [-0.22207415, -0.25976142, 0.037687268]\n",
      "Iter 4454, loss [-0.21201709, -0.2550089, 0.042991813]\n",
      "Iter 4455, loss [-0.21717103, -0.25637347, 0.039202437]\n",
      "Iter 4456, loss [-0.21210608, -0.25248674, 0.04038065]\n",
      "Iter 4457, loss [-0.22627264, -0.26488474, 0.038612094]\n",
      "Iter 4458, loss [-0.22731598, -0.26525736, 0.037941385]\n",
      "Iter 4459, loss [-0.23073341, -0.26624078, 0.035507362]\n",
      "Iter 4460, loss [-0.21125177, -0.25212848, 0.04087672]\n",
      "Iter 4461, loss [-0.21610592, -0.2533374, 0.03723149]\n",
      "Iter 4462, loss [-0.16006422, -0.22196852, 0.061904304]\n",
      "Iter 4463, loss [-0.22556415, -0.26417845, 0.038614307]\n",
      "Iter 4464, loss [-0.22393885, -0.26380342, 0.039864566]\n",
      "Iter 4465, loss [-0.2230591, -0.26157814, 0.03851904]\n",
      "Iter 4466, loss [-0.22654934, -0.2639497, 0.037400354]\n",
      "Iter 4467, loss [-0.22595638, -0.26413065, 0.038174268]\n",
      "Iter 4468, loss [-0.23078522, -0.26673684, 0.03595161]\n",
      "Iter 4469, loss [-0.21464956, -0.25301632, 0.03836676]\n",
      "Iter 4470, loss [-0.22139834, -0.259166, 0.03776766]\n",
      "Iter 4471, loss [-0.22265676, -0.26260936, 0.03995261]\n",
      "Iter 4472, loss [-0.22320598, -0.26206127, 0.038855284]\n",
      "Iter 4473, loss [-0.21777844, -0.25730556, 0.039527126]\n",
      "Iter 4474, loss [-0.21930243, -0.2567268, 0.037424367]\n",
      "Iter 4475, loss [-0.23070946, -0.2666772, 0.035967737]\n",
      "Iter 4476, loss [-0.22647622, -0.26192927, 0.03545305]\n",
      "Iter 4477, loss [-0.2239235, -0.261964, 0.03804048]\n",
      "Iter 4478, loss [-0.22839072, -0.26472595, 0.03633523]\n",
      "Iter 4479, loss [-0.22406358, -0.25970343, 0.035639845]\n",
      "Iter 4480, loss [-0.22346549, -0.2632203, 0.039754823]\n",
      "Iter 4481, loss [-0.2209919, -0.2604878, 0.0394959]\n",
      "Iter 4482, loss [-0.22664374, -0.26431087, 0.037667118]\n",
      "Iter 4483, loss [-0.22496486, -0.26345357, 0.03848871]\n",
      "Iter 4484, loss [-0.21302195, -0.25483167, 0.04180972]\n",
      "Iter 4485, loss [-0.22478268, -0.2636774, 0.03889472]\n",
      "Iter 4486, loss [-0.22885945, -0.2661208, 0.037261337]\n",
      "Iter 4487, loss [-0.23091441, -0.2672811, 0.036366664]\n",
      "Iter 4488, loss [-0.21880084, -0.25936338, 0.040562548]\n",
      "Iter 4489, loss [-0.22499476, -0.2629805, 0.037985723]\n",
      "Iter 4490, loss [-0.22261201, -0.26049364, 0.037881628]\n",
      "Iter 4491, loss [-0.21303685, -0.25414407, 0.04110722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4492, loss [-0.22575518, -0.2650146, 0.039259404]\n",
      "Iter 4493, loss [-0.22468519, -0.26073015, 0.03604495]\n",
      "Iter 4494, loss [-0.22738811, -0.26268283, 0.03529471]\n",
      "Iter 4495, loss [-0.22772, -0.2630439, 0.0353239]\n",
      "Iter 4496, loss [-0.22730157, -0.26449534, 0.037193768]\n",
      "Iter 4497, loss [-0.2157518, -0.25642294, 0.04067114]\n",
      "Iter 4498, loss [-0.2104371, -0.25372067, 0.043283567]\n",
      "Iter 4499, loss [-0.21959397, -0.25840756, 0.03881359]\n",
      "Iter 4500, loss [-0.22310366, -0.2614886, 0.038384926]\n",
      "Iter 4501, loss [-0.21614031, -0.25437164, 0.038231324]\n",
      "Iter 4502, loss [-0.22776732, -0.2636697, 0.035902377]\n",
      "Iter 4503, loss [-0.23037842, -0.26633787, 0.035959452]\n",
      "Iter 4504, loss [-0.204746, -0.2452186, 0.040472608]\n",
      "Iter 4505, loss [-0.2299658, -0.26844084, 0.038475044]\n",
      "Iter 4506, loss [-0.22258209, -0.2600809, 0.037498813]\n",
      "Iter 4507, loss [-0.22496328, -0.26443127, 0.03946799]\n",
      "Iter 4508, loss [-0.22666074, -0.26221502, 0.03555427]\n",
      "Iter 4509, loss [-0.2180955, -0.25881994, 0.040724438]\n",
      "Iter 4510, loss [-0.23243538, -0.26812133, 0.03568595]\n",
      "Iter 4511, loss [-0.2250689, -0.26289046, 0.037821554]\n",
      "Iter 4512, loss [-0.22561541, -0.26271793, 0.037102528]\n",
      "Iter 4513, loss [-0.13701412, -0.1939071, 0.056892984]\n",
      "Iter 4514, loss [-0.22331667, -0.26143283, 0.038116165]\n",
      "Iter 4515, loss [-0.23024428, -0.26665732, 0.03641304]\n",
      "Iter 4516, loss [-0.228228, -0.26596707, 0.03773907]\n",
      "Iter 4517, loss [-0.23153237, -0.26713738, 0.035605006]\n",
      "Iter 4518, loss [-0.22725275, -0.26403883, 0.036786072]\n",
      "Iter 4519, loss [-0.2228422, -0.2623282, 0.039486006]\n",
      "Iter 4520, loss [-0.23053047, -0.26805267, 0.037522193]\n",
      "Iter 4521, loss [-0.22779652, -0.26370078, 0.035904266]\n",
      "Iter 4522, loss [-0.2215043, -0.25987768, 0.03837339]\n",
      "Iter 4523, loss [-0.2263402, -0.26259956, 0.03625936]\n",
      "Iter 4524, loss [-0.22343734, -0.26144132, 0.03800399]\n",
      "Iter 4525, loss [-0.22038272, -0.26004177, 0.03965906]\n",
      "Iter 4526, loss [-0.21632439, -0.25629723, 0.039972834]\n",
      "Iter 4527, loss [-0.22443712, -0.26373914, 0.039302018]\n",
      "Iter 4528, loss [-0.22317278, -0.2605548, 0.037382014]\n",
      "Iter 4529, loss [-0.20891964, -0.24952416, 0.040604517]\n",
      "Iter 4530, loss [-0.20985404, -0.25136456, 0.041510526]\n",
      "Iter 4531, loss [-0.2293832, -0.2654766, 0.03609342]\n",
      "Iter 4532, loss [-0.22677496, -0.26267952, 0.035904553]\n",
      "Iter 4533, loss [-0.22966984, -0.266092, 0.036422163]\n",
      "Iter 4534, loss [-0.22680731, -0.26379183, 0.03698452]\n",
      "Iter 4535, loss [-0.20359743, -0.24759698, 0.043999545]\n",
      "Iter 4536, loss [-0.2202262, -0.25833234, 0.03810615]\n",
      "Iter 4537, loss [-0.1828728, -0.23409238, 0.051219575]\n",
      "Iter 4538, loss [-0.21781299, -0.25754055, 0.03972756]\n",
      "Iter 4539, loss [-0.22721055, -0.26425698, 0.037046425]\n",
      "Iter 4540, loss [-0.20860803, -0.24841693, 0.0398089]\n",
      "Iter 4541, loss [-0.21875513, -0.25638255, 0.037627436]\n",
      "Iter 4542, loss [-0.2135892, -0.25447333, 0.04088412]\n",
      "Iter 4543, loss [-0.22415619, -0.26378006, 0.039623868]\n",
      "Iter 4544, loss [-0.22481361, -0.2650044, 0.04019078]\n",
      "Iter 4545, loss [-0.22412136, -0.2631065, 0.038985126]\n",
      "Iter 4546, loss [-0.22816041, -0.26366875, 0.035508335]\n",
      "Iter 4547, loss [-0.22572786, -0.26267093, 0.036943078]\n",
      "Iter 4548, loss [-0.22673509, -0.2635496, 0.03681452]\n",
      "Iter 4549, loss [-0.23347796, -0.2684074, 0.034929436]\n",
      "Iter 4550, loss [-0.21702406, -0.25634283, 0.039318766]\n",
      "Iter 4551, loss [-0.18657179, -0.23314793, 0.046576142]\n",
      "Iter 4552, loss [-0.2265858, -0.2629634, 0.036377616]\n",
      "Iter 4553, loss [-0.22311655, -0.25989127, 0.03677472]\n",
      "Iter 4554, loss [-0.21970181, -0.25760844, 0.03790663]\n",
      "Iter 4555, loss [-0.22255129, -0.25789514, 0.035343856]\n",
      "Iter 4556, loss [-0.22696348, -0.26473913, 0.03777565]\n",
      "Iter 4557, loss [-0.21671906, -0.25614128, 0.039422214]\n",
      "Iter 4558, loss [-0.15084371, -0.2071757, 0.056331992]\n",
      "Iter 4559, loss [-0.21493183, -0.25479692, 0.039865088]\n",
      "Iter 4560, loss [-0.22558233, -0.26372236, 0.038140036]\n",
      "Iter 4561, loss [-0.22421055, -0.2626952, 0.038484648]\n",
      "Iter 4562, loss [-0.23079853, -0.26667747, 0.03587894]\n",
      "Iter 4563, loss [-0.21861152, -0.25827318, 0.039661657]\n",
      "Iter 4564, loss [-0.22448054, -0.26345176, 0.038971223]\n",
      "Iter 4565, loss [-0.22177052, -0.26026398, 0.038493462]\n",
      "Iter 4566, loss [-0.22984992, -0.264619, 0.034769073]\n",
      "Iter 4567, loss [-0.20588148, -0.24813543, 0.042253964]\n",
      "Iter 4568, loss [-0.21490398, -0.252961, 0.038057026]\n",
      "Iter 4569, loss [-0.22707115, -0.26414692, 0.037075773]\n",
      "Iter 4570, loss [-0.22166423, -0.25943404, 0.037769806]\n",
      "Iter 4571, loss [-0.23181754, -0.26846606, 0.03664852]\n",
      "Iter 4572, loss [-0.2270382, -0.26505557, 0.03801736]\n",
      "Iter 4573, loss [-0.22837366, -0.26466987, 0.0362962]\n",
      "Iter 4574, loss [-0.21941222, -0.25806788, 0.038655654]\n",
      "Iter 4575, loss [-0.23419383, -0.26903388, 0.03484004]\n",
      "Iter 4576, loss [-0.21622917, -0.25618067, 0.03995151]\n",
      "Iter 4577, loss [-0.21899416, -0.25867066, 0.039676502]\n",
      "Iter 4578, loss [-0.21457894, -0.25295708, 0.03837813]\n",
      "Iter 4579, loss [-0.20850694, -0.25164047, 0.04313352]\n",
      "Iter 4580, loss [-0.22490227, -0.2625104, 0.03760811]\n",
      "Iter 4581, loss [-0.2278246, -0.26495284, 0.037128247]\n",
      "Iter 4582, loss [-0.22098842, -0.25782147, 0.03683304]\n",
      "Iter 4583, loss [-0.2231884, -0.261677, 0.0384886]\n",
      "Iter 4584, loss [-0.22481555, -0.26187244, 0.0370569]\n",
      "Iter 4585, loss [-0.21963096, -0.2584539, 0.038822945]\n",
      "Iter 4586, loss [-0.23080552, -0.26628873, 0.03548322]\n",
      "Iter 4587, loss [-0.23018785, -0.26572293, 0.035535082]\n",
      "Iter 4588, loss [-0.21728721, -0.25664255, 0.03935533]\n",
      "Iter 4589, loss [-0.22500843, -0.26275533, 0.0377469]\n",
      "Iter 4590, loss [-0.21731845, -0.25766346, 0.04034502]\n",
      "Iter 4591, loss [-0.2005279, -0.24625775, 0.04572984]\n",
      "Iter 4592, loss [-0.22598611, -0.2647081, 0.038721994]\n",
      "Iter 4593, loss [-0.18553245, -0.23586495, 0.050332498]\n",
      "Iter 4594, loss [-0.22186384, -0.25916997, 0.037306122]\n",
      "Iter 4595, loss [-0.23125234, -0.26527593, 0.03402359]\n",
      "Iter 4596, loss [-0.20967068, -0.25211656, 0.042445883]\n",
      "Iter 4597, loss [-0.21481632, -0.25359657, 0.038780257]\n",
      "Iter 4598, loss [-0.22254968, -0.26010182, 0.03755214]\n",
      "Iter 4599, loss [-0.21874745, -0.25694472, 0.038197264]\n",
      "Iter 4600, loss [-0.23111707, -0.26809058, 0.03697351]\n",
      "Iter 4601, loss [-0.21554519, -0.2566517, 0.041106507]\n",
      "Iter 4602, loss [-0.22217646, -0.2612718, 0.039095342]\n",
      "Iter 4603, loss [-0.22054318, -0.25916913, 0.03862595]\n",
      "Iter 4604, loss [-0.21996242, -0.25913346, 0.039171048]\n",
      "Iter 4605, loss [-0.18934873, -0.23481955, 0.045470826]\n",
      "Iter 4606, loss [-0.21901725, -0.2579095, 0.038892254]\n",
      "Iter 4607, loss [-0.21770066, -0.25534558, 0.037644915]\n",
      "Iter 4608, loss [-0.21604776, -0.25354567, 0.037497908]\n",
      "Iter 4609, loss [-0.22632869, -0.26562878, 0.0393001]\n",
      "Iter 4610, loss [-0.21083236, -0.25028569, 0.039453335]\n",
      "Iter 4611, loss [-0.23400341, -0.27115512, 0.03715171]\n",
      "Iter 4612, loss [-0.20255493, -0.24755129, 0.044996362]\n",
      "Iter 4613, loss [-0.2260139, -0.2645895, 0.038575582]\n",
      "Iter 4614, loss [-0.21237746, -0.25269324, 0.040315777]\n",
      "Iter 4615, loss [-0.21402025, -0.25362864, 0.039608385]\n",
      "Iter 4616, loss [-0.22878592, -0.26509967, 0.036313754]\n",
      "Iter 4617, loss [-0.22719792, -0.2640483, 0.036850385]\n",
      "Iter 4618, loss [-0.21727833, -0.25710514, 0.039826818]\n",
      "Iter 4619, loss [-0.23224358, -0.26780513, 0.035561543]\n",
      "Iter 4620, loss [-0.23269616, -0.2675511, 0.034854934]\n",
      "Iter 4621, loss [-0.217092, -0.25616223, 0.03907022]\n",
      "Iter 4622, loss [-0.22630607, -0.2619572, 0.03565113]\n",
      "Iter 4623, loss [-0.1379264, -0.19549936, 0.057572957]\n",
      "Iter 4624, loss [-0.22596306, -0.26072523, 0.034762174]\n",
      "Iter 4625, loss [-0.2237501, -0.25985587, 0.036105767]\n",
      "Iter 4626, loss [-0.21727464, -0.25746816, 0.040193524]\n",
      "Iter 4627, loss [-0.22635195, -0.26304486, 0.036692914]\n",
      "Iter 4628, loss [-0.21946968, -0.2600024, 0.04053272]\n",
      "Iter 4629, loss [-0.22204818, -0.2602123, 0.038164124]\n",
      "Iter 4630, loss [-0.22551021, -0.2634556, 0.037945382]\n",
      "Iter 4631, loss [-0.22858338, -0.26532793, 0.036744546]\n",
      "Iter 4632, loss [-0.22145845, -0.26043946, 0.038981]\n",
      "Iter 4633, loss [-0.21552551, -0.25474393, 0.03921842]\n",
      "Iter 4634, loss [-0.22619267, -0.26319972, 0.037007045]\n",
      "Iter 4635, loss [-0.13005611, -0.18706505, 0.057008933]\n",
      "Iter 4636, loss [-0.22005224, -0.2583888, 0.038336545]\n",
      "Iter 4637, loss [-0.22452706, -0.26065233, 0.03612528]\n",
      "Iter 4638, loss [-0.22800262, -0.26229954, 0.034296915]\n",
      "Iter 4639, loss [-0.22242838, -0.25999087, 0.037562486]\n",
      "Iter 4640, loss [-0.21761769, -0.25595376, 0.038336076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4641, loss [-0.20155285, -0.24578431, 0.044231456]\n",
      "Iter 4642, loss [-0.22925788, -0.26564083, 0.036382936]\n",
      "Iter 4643, loss [-0.2154148, -0.25224438, 0.036829576]\n",
      "Iter 4644, loss [-0.21206409, -0.25233984, 0.040275745]\n",
      "Iter 4645, loss [-0.20566055, -0.24579206, 0.040131517]\n",
      "Iter 4646, loss [-0.21608225, -0.252412, 0.03632974]\n",
      "Iter 4647, loss [-0.21866712, -0.25549734, 0.036830217]\n",
      "Iter 4648, loss [-0.22207612, -0.26186895, 0.03979283]\n",
      "Iter 4649, loss [-0.22273836, -0.2625092, 0.039770838]\n",
      "Iter 4650, loss [-0.22348212, -0.26316682, 0.039684694]\n",
      "Iter 4651, loss [-0.2178413, -0.2576863, 0.03984499]\n",
      "Iter 4652, loss [-0.22160687, -0.2611576, 0.039550737]\n",
      "Iter 4653, loss [-0.22549713, -0.26148832, 0.035991192]\n",
      "Iter 4654, loss [-0.2273489, -0.26199752, 0.034648623]\n",
      "Iter 4655, loss [-0.22489803, -0.25901926, 0.03412123]\n",
      "Iter 4656, loss [-0.22625738, -0.2625978, 0.036340423]\n",
      "Iter 4657, loss [-0.23156938, -0.26635146, 0.034782074]\n",
      "Iter 4658, loss [-0.21720691, -0.25795108, 0.04074417]\n",
      "Iter 4659, loss [-0.20478901, -0.24692826, 0.042139255]\n",
      "Iter 4660, loss [-0.22407773, -0.26356256, 0.03948483]\n",
      "Iter 4661, loss [-0.2206473, -0.2597231, 0.039075788]\n",
      "Iter 4662, loss [-0.22326605, -0.26075566, 0.037489608]\n",
      "Iter 4663, loss [-0.22285417, -0.25997493, 0.037120752]\n",
      "Iter 4664, loss [-0.22824794, -0.26242507, 0.03417712]\n",
      "Iter 4665, loss [-0.22066236, -0.2578355, 0.037173145]\n",
      "Iter 4666, loss [-0.21156764, -0.25385746, 0.04228982]\n",
      "Iter 4667, loss [-0.20255876, -0.24478199, 0.042223223]\n",
      "Iter 4668, loss [-0.2216081, -0.25868198, 0.037073877]\n",
      "Iter 4669, loss [-0.21655324, -0.25722998, 0.040676743]\n",
      "Iter 4670, loss [-0.13593262, -0.19605885, 0.060126238]\n",
      "Iter 4671, loss [-0.21824904, -0.2568393, 0.038590264]\n",
      "Iter 4672, loss [-0.18114981, -0.2287459, 0.04759608]\n",
      "Iter 4673, loss [-0.22644997, -0.26049745, 0.034047477]\n",
      "Iter 4674, loss [-0.22319442, -0.257573, 0.03437859]\n",
      "Iter 4675, loss [-0.22468852, -0.2601932, 0.03550468]\n",
      "Iter 4676, loss [-0.21820827, -0.2575719, 0.03936364]\n",
      "Iter 4677, loss [-0.22655256, -0.26432166, 0.03776909]\n",
      "Iter 4678, loss [-0.19543248, -0.24188954, 0.046457045]\n",
      "Iter 4679, loss [-0.22112456, -0.25961483, 0.03849026]\n",
      "Iter 4680, loss [-0.22364484, -0.26061535, 0.03697051]\n",
      "Iter 4681, loss [-0.22326972, -0.26013836, 0.036868647]\n",
      "Iter 4682, loss [-0.22438726, -0.2597018, 0.035314523]\n",
      "Iter 4683, loss [-0.21392952, -0.2543969, 0.04046737]\n",
      "Iter 4684, loss [-0.22668684, -0.26339555, 0.036708705]\n",
      "Iter 4685, loss [-0.21191216, -0.2534272, 0.04151505]\n",
      "Iter 4686, loss [-0.21971314, -0.25986543, 0.040152293]\n",
      "Iter 4687, loss [-0.22569454, -0.2642978, 0.038603283]\n",
      "Iter 4688, loss [-0.17879038, -0.2323951, 0.05360472]\n",
      "Iter 4689, loss [-0.22399306, -0.26201892, 0.038025852]\n",
      "Iter 4690, loss [-0.22824852, -0.26564258, 0.037394058]\n",
      "Iter 4691, loss [-0.21616766, -0.25455415, 0.038386494]\n",
      "Iter 4692, loss [-0.2093926, -0.24825443, 0.038861822]\n",
      "Iter 4693, loss [-0.22584143, -0.2627656, 0.036924154]\n",
      "Iter 4694, loss [-0.22621253, -0.2653406, 0.039128065]\n",
      "Iter 4695, loss [-0.23463163, -0.2711898, 0.03655818]\n",
      "Iter 4696, loss [-0.21967594, -0.25777507, 0.03809913]\n",
      "Iter 4697, loss [-0.22525989, -0.26382738, 0.0385675]\n",
      "Iter 4698, loss [-0.16912842, -0.21895748, 0.049829066]\n",
      "Iter 4699, loss [-0.21515691, -0.25218114, 0.037024237]\n",
      "Iter 4700, loss [-0.23135367, -0.26532167, 0.033967998]\n",
      "Iter 4701, loss [-0.22825399, -0.2650878, 0.036833823]\n",
      "Iter 4702, loss [-0.21504767, -0.25409076, 0.039043084]\n",
      "Iter 4703, loss [-0.23065966, -0.2659883, 0.03532862]\n",
      "Iter 4704, loss [-0.23135567, -0.26750422, 0.03614854]\n",
      "Iter 4705, loss [-0.22408468, -0.26468244, 0.040597774]\n",
      "Iter 4706, loss [-0.23227756, -0.26858467, 0.036307108]\n",
      "Iter 4707, loss [-0.20861472, -0.25051054, 0.041895818]\n",
      "Iter 4708, loss [-0.22403961, -0.25973353, 0.03569392]\n",
      "Iter 4709, loss [-0.22515675, -0.26217487, 0.037018128]\n",
      "Iter 4710, loss [-0.22034995, -0.25842416, 0.03807421]\n",
      "Iter 4711, loss [-0.22874989, -0.26453397, 0.035784077]\n",
      "Iter 4712, loss [-0.20417547, -0.25098535, 0.04680989]\n",
      "Iter 4713, loss [-0.22124913, -0.26037946, 0.039130323]\n",
      "Iter 4714, loss [-0.22874713, -0.26731506, 0.038567934]\n",
      "Iter 4715, loss [-0.22140743, -0.2629256, 0.041518163]\n",
      "Iter 4716, loss [-0.22669959, -0.265604, 0.038904395]\n",
      "Iter 4717, loss [-0.23349273, -0.27032417, 0.036831446]\n",
      "Iter 4718, loss [-0.22140487, -0.25978974, 0.038384873]\n",
      "Iter 4719, loss [-0.22905418, -0.26276943, 0.03371524]\n",
      "Iter 4720, loss [-0.21568197, -0.25448966, 0.038807683]\n",
      "Iter 4721, loss [-0.22520694, -0.26122737, 0.03602042]\n",
      "Iter 4722, loss [-0.22178645, -0.2583851, 0.036598634]\n",
      "Iter 4723, loss [-0.20754673, -0.24963343, 0.0420867]\n",
      "Iter 4724, loss [-0.2262539, -0.26572418, 0.03947028]\n",
      "Iter 4725, loss [-0.2193853, -0.25950676, 0.040121462]\n",
      "Iter 4726, loss [-0.21589255, -0.25803792, 0.042145368]\n",
      "Iter 4727, loss [-0.19997802, -0.24631278, 0.046334755]\n",
      "Iter 4728, loss [-0.22581366, -0.26303637, 0.037222713]\n",
      "Iter 4729, loss [-0.2179747, -0.2557283, 0.03775362]\n",
      "Iter 4730, loss [-0.22291303, -0.2594228, 0.036509775]\n",
      "Iter 4731, loss [-0.2267271, -0.26203537, 0.035308275]\n",
      "Iter 4732, loss [-0.21473196, -0.25419316, 0.039461188]\n",
      "Iter 4733, loss [-0.22617209, -0.26325634, 0.037084248]\n",
      "Iter 4734, loss [-0.22885506, -0.26615462, 0.037299562]\n",
      "Iter 4735, loss [-0.22141907, -0.259763, 0.038343944]\n",
      "Iter 4736, loss [-0.15647562, -0.20962282, 0.053147197]\n",
      "Iter 4737, loss [-0.23055758, -0.267952, 0.037394416]\n",
      "Iter 4738, loss [-0.22295636, -0.2625187, 0.039562345]\n",
      "Iter 4739, loss [-0.21988738, -0.2599901, 0.040102713]\n",
      "Iter 4740, loss [-0.21082115, -0.25220412, 0.04138297]\n",
      "Iter 4741, loss [-0.1302684, -0.18771084, 0.05744244]\n",
      "Iter 4742, loss [-0.22237915, -0.25955302, 0.037173875]\n",
      "Iter 4743, loss [-0.21861987, -0.25620994, 0.037590068]\n",
      "Iter 4744, loss [-0.21450916, -0.25146765, 0.03695849]\n",
      "Iter 4745, loss [-0.22797717, -0.26280382, 0.034826647]\n",
      "Iter 4746, loss [-0.22230837, -0.2601431, 0.03783474]\n",
      "Iter 4747, loss [-0.21589282, -0.25573894, 0.039846122]\n",
      "Iter 4748, loss [-0.22544527, -0.2651941, 0.03974881]\n",
      "Iter 4749, loss [-0.22411984, -0.26440006, 0.04028023]\n",
      "Iter 4750, loss [-0.23388717, -0.27087218, 0.036985017]\n",
      "Iter 4751, loss [-0.2107596, -0.2517293, 0.04096971]\n",
      "Iter 4752, loss [-0.21831548, -0.25701836, 0.038702883]\n",
      "Iter 4753, loss [-0.22786926, -0.26292554, 0.035056278]\n",
      "Iter 4754, loss [-0.23349927, -0.267634, 0.034134727]\n",
      "Iter 4755, loss [-0.21438643, -0.25289103, 0.038504604]\n",
      "Iter 4756, loss [-0.22209302, -0.2589682, 0.036875192]\n",
      "Iter 4757, loss [-0.22038274, -0.25908569, 0.038702954]\n",
      "Iter 4758, loss [-0.22594519, -0.26209942, 0.03615422]\n",
      "Iter 4759, loss [-0.21272972, -0.25380194, 0.04107222]\n",
      "Iter 4760, loss [-0.22531593, -0.26192242, 0.036606483]\n",
      "Iter 4761, loss [-0.22325604, -0.26243293, 0.039176896]\n",
      "Iter 4762, loss [-0.13357991, -0.1899273, 0.05634738]\n",
      "Iter 4763, loss [-0.22343001, -0.26093, 0.037499994]\n",
      "Iter 4764, loss [-0.21742493, -0.2556751, 0.038250174]\n",
      "Iter 4765, loss [-0.21778256, -0.2565149, 0.038732346]\n",
      "Iter 4766, loss [-0.22046366, -0.2626135, 0.04214985]\n",
      "Iter 4767, loss [-0.22684659, -0.26494688, 0.038100287]\n",
      "Iter 4768, loss [-0.22864142, -0.26568547, 0.037044056]\n",
      "Iter 4769, loss [-0.21511242, -0.2517877, 0.036675267]\n",
      "Iter 4770, loss [-0.22445002, -0.2605958, 0.036145777]\n",
      "Iter 4771, loss [-0.21536702, -0.25237492, 0.037007906]\n",
      "Iter 4772, loss [-0.22356915, -0.26121283, 0.037643664]\n",
      "Iter 4773, loss [-0.22273314, -0.2611515, 0.038418345]\n",
      "Iter 4774, loss [-0.23020142, -0.2675246, 0.037323184]\n",
      "Iter 4775, loss [-0.15716767, -0.21453851, 0.05737084]\n",
      "Iter 4776, loss [-0.2199244, -0.25997657, 0.04005216]\n",
      "Iter 4777, loss [-0.2166829, -0.25659415, 0.03991126]\n",
      "Iter 4778, loss [-0.22348183, -0.26089433, 0.037412494]\n",
      "Iter 4779, loss [-0.23071086, -0.2673411, 0.036630243]\n",
      "Iter 4780, loss [-0.2148487, -0.25453848, 0.039689787]\n",
      "Iter 4781, loss [-0.22976846, -0.26423705, 0.034468587]\n",
      "Iter 4782, loss [-0.21028173, -0.24929468, 0.039012946]\n",
      "Iter 4783, loss [-0.23370516, -0.26784956, 0.034144394]\n",
      "Iter 4784, loss [-0.21830289, -0.2563954, 0.03809251]\n",
      "Iter 4785, loss [-0.22621188, -0.26229054, 0.03607867]\n",
      "Iter 4786, loss [-0.2221677, -0.26040566, 0.038237955]\n",
      "Iter 4787, loss [-0.23024374, -0.26771593, 0.037472192]\n",
      "Iter 4788, loss [-0.15139589, -0.20245293, 0.051057037]\n",
      "Iter 4789, loss [-0.23413016, -0.26956114, 0.03543098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4790, loss [-0.22559151, -0.2643257, 0.03873419]\n",
      "Iter 4791, loss [-0.23080145, -0.26667494, 0.035873484]\n",
      "Iter 4792, loss [-0.2301685, -0.26578078, 0.035612267]\n",
      "Iter 4793, loss [-0.219637, -0.25902057, 0.039383553]\n",
      "Iter 4794, loss [-0.22533816, -0.26326928, 0.037931114]\n",
      "Iter 4795, loss [-0.22341624, -0.26200268, 0.038586438]\n",
      "Iter 4796, loss [-0.22986469, -0.2658308, 0.035966128]\n",
      "Iter 4797, loss [-0.21834582, -0.25760362, 0.039257795]\n",
      "Iter 4798, loss [-0.22575605, -0.26480615, 0.03905011]\n",
      "Iter 4799, loss [-0.22002353, -0.26012686, 0.040103327]\n",
      "Iter 4800, loss [-0.22966345, -0.2657767, 0.036113244]\n",
      "Iter 4801, loss [-0.22524704, -0.26284245, 0.03759541]\n",
      "Iter 4802, loss [-0.21929695, -0.2587856, 0.03948866]\n",
      "Iter 4803, loss [-0.22355992, -0.2597996, 0.036239687]\n",
      "Iter 4804, loss [-0.21547224, -0.25402611, 0.038553875]\n",
      "Iter 4805, loss [-0.22630462, -0.26222542, 0.03592079]\n",
      "Iter 4806, loss [-0.22567143, -0.26234788, 0.03667645]\n",
      "Iter 4807, loss [-0.21972765, -0.257056, 0.03732835]\n",
      "Iter 4808, loss [-0.23273328, -0.266822, 0.03408873]\n",
      "Iter 4809, loss [-0.2243289, -0.26253158, 0.03820268]\n",
      "Iter 4810, loss [-0.22506765, -0.26367283, 0.03860519]\n",
      "Iter 4811, loss [-0.21854797, -0.2553108, 0.036762826]\n",
      "Iter 4812, loss [-0.22349864, -0.2622492, 0.03875055]\n",
      "Iter 4813, loss [-0.22117993, -0.26187637, 0.040696442]\n",
      "Iter 4814, loss [-0.23165572, -0.26752213, 0.035866402]\n",
      "Iter 4815, loss [-0.14932999, -0.20473115, 0.05540116]\n",
      "Iter 4816, loss [-0.2267082, -0.26286834, 0.036160138]\n",
      "Iter 4817, loss [-0.21571374, -0.2540705, 0.038356747]\n",
      "Iter 4818, loss [-0.23228782, -0.26933593, 0.03704811]\n",
      "Iter 4819, loss [-0.22654508, -0.2654688, 0.038923725]\n",
      "Iter 4820, loss [-0.21459222, -0.25348604, 0.03889382]\n",
      "Iter 4821, loss [-0.2307316, -0.26692495, 0.03619335]\n",
      "Iter 4822, loss [-0.22777744, -0.26533365, 0.037556212]\n",
      "Iter 4823, loss [-0.22770852, -0.26550743, 0.03779892]\n",
      "Iter 4824, loss [-0.23201299, -0.26808438, 0.036071386]\n",
      "Iter 4825, loss [-0.2247893, -0.2642296, 0.03944029]\n",
      "Iter 4826, loss [-0.23063092, -0.26740426, 0.036773335]\n",
      "Iter 4827, loss [-0.2265116, -0.26583815, 0.03932655]\n",
      "Iter 4828, loss [-0.2293653, -0.26618224, 0.03681694]\n",
      "Iter 4829, loss [-0.23085861, -0.26838872, 0.037530106]\n",
      "Iter 4830, loss [-0.19142266, -0.24031703, 0.04889437]\n",
      "Iter 4831, loss [-0.22418657, -0.26183513, 0.037648566]\n",
      "Iter 4832, loss [-0.23358694, -0.2698179, 0.03623096]\n",
      "Iter 4833, loss [-0.21060196, -0.2492266, 0.03862465]\n",
      "Iter 4834, loss [-0.21731591, -0.2587336, 0.04141769]\n",
      "Iter 4835, loss [-0.2224706, -0.2614765, 0.039005887]\n",
      "Iter 4836, loss [-0.22985451, -0.26623535, 0.036380842]\n",
      "Iter 4837, loss [-0.19441728, -0.24131666, 0.046899375]\n",
      "Iter 4838, loss [-0.161051, -0.21903251, 0.0579815]\n",
      "Iter 4839, loss [-0.22486338, -0.26108056, 0.03621718]\n",
      "Iter 4840, loss [-0.21424611, -0.25341526, 0.039169144]\n",
      "Iter 4841, loss [-0.22190642, -0.25720805, 0.035301622]\n",
      "Iter 4842, loss [-0.21658611, -0.25794598, 0.041359868]\n",
      "Iter 4843, loss [-0.18204652, -0.23201527, 0.04996875]\n",
      "Iter 4844, loss [-0.22644828, -0.26422438, 0.0377761]\n",
      "Iter 4845, loss [-0.22074896, -0.2609943, 0.040245324]\n",
      "Iter 4846, loss [-0.22498797, -0.26260114, 0.037613165]\n",
      "Iter 4847, loss [-0.22664535, -0.26320988, 0.036564525]\n",
      "Iter 4848, loss [-0.22103253, -0.25924975, 0.038217224]\n",
      "Iter 4849, loss [-0.22611403, -0.261524, 0.03540995]\n",
      "Iter 4850, loss [-0.22394763, -0.2608466, 0.036898986]\n",
      "Iter 4851, loss [-0.22326128, -0.26020184, 0.03694056]\n",
      "Iter 4852, loss [-0.22605503, -0.2623409, 0.036285874]\n",
      "Iter 4853, loss [-0.22383994, -0.26179054, 0.037950613]\n",
      "Iter 4854, loss [-0.22169042, -0.26016325, 0.038472824]\n",
      "Iter 4855, loss [-0.20832598, -0.24962924, 0.041303255]\n",
      "Iter 4856, loss [-0.22211841, -0.26157507, 0.039456666]\n",
      "Iter 4857, loss [-0.21333688, -0.2535797, 0.04024283]\n",
      "Iter 4858, loss [-0.22151338, -0.25835955, 0.036846176]\n",
      "Iter 4859, loss [-0.19977051, -0.24331552, 0.043545015]\n",
      "Iter 4860, loss [-0.13418508, -0.19243774, 0.058252655]\n",
      "Iter 4861, loss [-0.21480526, -0.25362402, 0.03881876]\n",
      "Iter 4862, loss [-0.22836375, -0.26414177, 0.03577801]\n",
      "Iter 4863, loss [-0.22159627, -0.26063827, 0.03904199]\n",
      "Iter 4864, loss [-0.21646416, -0.25157055, 0.035106383]\n",
      "Iter 4865, loss [-0.20607173, -0.24874778, 0.042676043]\n",
      "Iter 4866, loss [-0.224838, -0.26136902, 0.036531016]\n",
      "Iter 4867, loss [-0.22743459, -0.26527628, 0.037841693]\n",
      "Iter 4868, loss [-0.22045772, -0.25935858, 0.038900863]\n",
      "Iter 4869, loss [-0.22727045, -0.26447955, 0.037209094]\n",
      "Iter 4870, loss [-0.22446598, -0.26323545, 0.038769465]\n",
      "Iter 4871, loss [-0.20577376, -0.2496751, 0.043901335]\n",
      "Iter 4872, loss [-0.21610439, -0.25602698, 0.039922602]\n",
      "Iter 4873, loss [-0.22879577, -0.26446474, 0.035668977]\n",
      "Iter 4874, loss [-0.22515893, -0.26200762, 0.036848687]\n",
      "Iter 4875, loss [-0.22549985, -0.26286277, 0.037362922]\n",
      "Iter 4876, loss [-0.21598244, -0.2560126, 0.04003016]\n",
      "Iter 4877, loss [-0.21279195, -0.25129402, 0.03850206]\n",
      "Iter 4878, loss [-0.21853179, -0.25730994, 0.038778163]\n",
      "Iter 4879, loss [-0.22592847, -0.26200324, 0.03607477]\n",
      "Iter 4880, loss [-0.22439915, -0.2619967, 0.03759753]\n",
      "Iter 4881, loss [-0.21155947, -0.25181997, 0.040260494]\n",
      "Iter 4882, loss [-0.22595297, -0.26448238, 0.03852941]\n",
      "Iter 4883, loss [-0.23179555, -0.2666768, 0.03488126]\n",
      "Iter 4884, loss [-0.21769696, -0.2571215, 0.03942453]\n",
      "Iter 4885, loss [-0.21733123, -0.2560496, 0.03871838]\n",
      "Iter 4886, loss [-0.22356278, -0.25941387, 0.035851095]\n",
      "Iter 4887, loss [-0.21860796, -0.2567986, 0.038190626]\n",
      "Iter 4888, loss [-0.22824605, -0.26359546, 0.035349414]\n",
      "Iter 4889, loss [-0.21959358, -0.25847936, 0.038885772]\n",
      "Iter 4890, loss [-0.22364697, -0.26076728, 0.03712032]\n",
      "Iter 4891, loss [-0.22079018, -0.25955844, 0.038768254]\n",
      "Iter 4892, loss [-0.22328433, -0.26196975, 0.03868542]\n",
      "Iter 4893, loss [-0.22196004, -0.2589428, 0.036982782]\n",
      "Iter 4894, loss [-0.22825965, -0.26706254, 0.038802885]\n",
      "Iter 4895, loss [-0.22885238, -0.2666414, 0.037789032]\n",
      "Iter 4896, loss [-0.22121893, -0.26035166, 0.039132733]\n",
      "Iter 4897, loss [-0.1717765, -0.22464368, 0.052867174]\n",
      "Iter 4898, loss [-0.2171216, -0.2566183, 0.039496686]\n",
      "Iter 4899, loss [-0.22636542, -0.26258034, 0.036214925]\n",
      "Iter 4900, loss [-0.22803418, -0.2646331, 0.036598906]\n",
      "Iter 4901, loss [-0.22425641, -0.26094332, 0.036686912]\n",
      "Iter 4902, loss [-0.16930133, -0.21952726, 0.050225925]\n",
      "Iter 4903, loss [-0.2287359, -0.2654048, 0.03666889]\n",
      "Iter 4904, loss [-0.23120949, -0.2686989, 0.037489418]\n",
      "Iter 4905, loss [-0.23083751, -0.26576284, 0.034925327]\n",
      "Iter 4906, loss [-0.13075684, -0.1882869, 0.057530057]\n",
      "Iter 4907, loss [-0.22515449, -0.2624599, 0.037305407]\n",
      "Iter 4908, loss [-0.21176518, -0.25144076, 0.03967558]\n",
      "Iter 4909, loss [-0.2216666, -0.25992474, 0.038258135]\n",
      "Iter 4910, loss [-0.22821537, -0.2645716, 0.036356233]\n",
      "Iter 4911, loss [-0.22142781, -0.26203954, 0.04061173]\n",
      "Iter 4912, loss [-0.21720402, -0.25579906, 0.038595036]\n",
      "Iter 4913, loss [-0.15082732, -0.20516379, 0.05433647]\n",
      "Iter 4914, loss [-0.20060194, -0.24251463, 0.041912697]\n",
      "Iter 4915, loss [-0.21698508, -0.25631762, 0.03933253]\n",
      "Iter 4916, loss [-0.21490817, -0.25620756, 0.041299384]\n",
      "Iter 4917, loss [-0.22660777, -0.2631337, 0.036525927]\n",
      "Iter 4918, loss [-0.17058277, -0.22427982, 0.05369705]\n",
      "Iter 4919, loss [-0.22597052, -0.26347768, 0.037507158]\n",
      "Iter 4920, loss [-0.22110161, -0.25927344, 0.03817182]\n",
      "Iter 4921, loss [-0.21623662, -0.2549807, 0.03874409]\n",
      "Iter 4922, loss [-0.22005755, -0.2600739, 0.040016353]\n",
      "Iter 4923, loss [-0.2221959, -0.26096842, 0.038772516]\n",
      "Iter 4924, loss [-0.2283482, -0.26468405, 0.036335863]\n",
      "Iter 4925, loss [-0.22143851, -0.25766554, 0.036227033]\n",
      "Iter 4926, loss [-0.21828642, -0.25884703, 0.040560603]\n",
      "Iter 4927, loss [-0.22012681, -0.25618008, 0.036053266]\n",
      "Iter 4928, loss [-0.21946564, -0.2574833, 0.03801766]\n",
      "Iter 4929, loss [-0.22309929, -0.25895146, 0.035852157]\n",
      "Iter 4930, loss [-0.22164026, -0.26025924, 0.03861899]\n",
      "Iter 4931, loss [-0.21622711, -0.2566174, 0.040390283]\n",
      "Iter 4932, loss [-0.21570572, -0.25640473, 0.04069901]\n",
      "Iter 4933, loss [-0.23015429, -0.26653686, 0.03638257]\n",
      "Iter 4934, loss [-0.22314149, -0.25925386, 0.036112376]\n",
      "Iter 4935, loss [-0.22937891, -0.26373523, 0.03435632]\n",
      "Iter 4936, loss [-0.21200727, -0.25284365, 0.040836375]\n",
      "Iter 4937, loss [-0.23269497, -0.2666399, 0.03394492]\n",
      "Iter 4938, loss [-0.21586007, -0.255473, 0.039612927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4939, loss [-0.23146392, -0.2658879, 0.034423962]\n",
      "Iter 4940, loss [-0.22221594, -0.26026896, 0.038053017]\n",
      "Iter 4941, loss [-0.21954769, -0.25869805, 0.039150357]\n",
      "Iter 4942, loss [-0.20637102, -0.24938469, 0.043013662]\n",
      "Iter 4943, loss [-0.21280701, -0.25404647, 0.04123945]\n",
      "Iter 4944, loss [-0.21572246, -0.25622416, 0.0405017]\n",
      "Iter 4945, loss [-0.22515792, -0.2612509, 0.036092997]\n",
      "Iter 4946, loss [-0.22901508, -0.26527318, 0.036258098]\n",
      "Iter 4947, loss [-0.22493994, -0.26246804, 0.037528105]\n",
      "Iter 4948, loss [-0.22470605, -0.26275334, 0.03804728]\n",
      "Iter 4949, loss [-0.22539338, -0.26496676, 0.03957338]\n",
      "Iter 4950, loss [-0.22216403, -0.25836498, 0.03620094]\n",
      "Iter 4951, loss [-0.20960395, -0.24986178, 0.040257823]\n",
      "Iter 4952, loss [-0.21432374, -0.25392434, 0.039600592]\n",
      "Iter 4953, loss [-0.21882361, -0.25644147, 0.037617855]\n",
      "Iter 4954, loss [-0.2207517, -0.25932878, 0.038577072]\n",
      "Iter 4955, loss [-0.23067656, -0.2661065, 0.03542992]\n",
      "Iter 4956, loss [-0.2108996, -0.25402266, 0.043123048]\n",
      "Iter 4957, loss [-0.23402417, -0.2692354, 0.035211243]\n",
      "Iter 4958, loss [-0.21963562, -0.25881696, 0.039181337]\n",
      "Iter 4959, loss [-0.22297731, -0.26105413, 0.038076818]\n",
      "Iter 4960, loss [-0.23206224, -0.26660177, 0.034539536]\n",
      "Iter 4961, loss [-0.23022886, -0.26606753, 0.03583868]\n",
      "Iter 4962, loss [-0.22356601, -0.26218706, 0.038621053]\n",
      "Iter 4963, loss [-0.21904624, -0.2578729, 0.03882667]\n",
      "Iter 4964, loss [-0.22839564, -0.26386645, 0.03547081]\n",
      "Iter 4965, loss [-0.21857603, -0.257657, 0.039080963]\n",
      "Iter 4966, loss [-0.23097956, -0.26695344, 0.035973873]\n",
      "Iter 4967, loss [-0.22164105, -0.260435, 0.038793936]\n",
      "Iter 4968, loss [-0.22884876, -0.26626655, 0.037417807]\n",
      "Iter 4969, loss [-0.20827788, -0.25011745, 0.041839562]\n",
      "Iter 4970, loss [-0.21839684, -0.25758526, 0.039188407]\n",
      "Iter 4971, loss [-0.2214467, -0.25945833, 0.038011637]\n",
      "Iter 4972, loss [-0.20148392, -0.24364191, 0.04215799]\n",
      "Iter 4973, loss [-0.2263836, -0.26187328, 0.035489682]\n",
      "Iter 4974, loss [-0.21531184, -0.24994305, 0.03463121]\n",
      "Iter 4975, loss [-0.17860138, -0.23020929, 0.0516079]\n",
      "Iter 4976, loss [-0.22660807, -0.26362747, 0.0370194]\n",
      "Iter 4977, loss [-0.21892884, -0.25836024, 0.039431393]\n",
      "Iter 4978, loss [-0.21656007, -0.25746733, 0.040907264]\n",
      "Iter 4979, loss [-0.21848598, -0.25616223, 0.037676245]\n",
      "Iter 4980, loss [-0.2229216, -0.26157865, 0.03865705]\n",
      "Iter 4981, loss [-0.22417551, -0.26219216, 0.038016647]\n",
      "Iter 4982, loss [-0.21248825, -0.255837, 0.043348745]\n",
      "Iter 4983, loss [-0.22835952, -0.26515016, 0.03679063]\n",
      "Iter 4984, loss [-0.23011047, -0.26709586, 0.036985394]\n",
      "Iter 4985, loss [-0.20904966, -0.2545899, 0.04554023]\n",
      "Iter 4986, loss [-0.22073501, -0.260048, 0.039312996]\n",
      "Iter 4987, loss [-0.2223723, -0.26187676, 0.03950446]\n",
      "Iter 4988, loss [-0.22383595, -0.26094478, 0.037108835]\n",
      "Iter 4989, loss [-0.2249475, -0.26352718, 0.038579687]\n",
      "Iter 4990, loss [-0.22403732, -0.26094532, 0.036907993]\n",
      "Iter 4991, loss [-0.22654933, -0.2633903, 0.036840968]\n",
      "Iter 4992, loss [-0.22375974, -0.26081115, 0.037051402]\n",
      "Iter 4993, loss [-0.22893944, -0.26495308, 0.036013626]\n",
      "Iter 4994, loss [-0.22744313, -0.2654623, 0.038019177]\n",
      "Iter 4995, loss [-0.2194241, -0.25752917, 0.038105067]\n",
      "Iter 4996, loss [-0.23074001, -0.26749852, 0.03675852]\n",
      "Iter 4997, loss [-0.2220175, -0.2610597, 0.039042212]\n",
      "Iter 4998, loss [-0.22725584, -0.26409122, 0.036835387]\n",
      "Iter 4999, loss [-0.2279219, -0.26340276, 0.035480853]\n",
      "Iter 5000, loss [-0.2258215, -0.26431543, 0.03849394]\n",
      "Iter 5001, loss [-0.22043654, -0.25886756, 0.03843102]\n",
      "Iter 5002, loss [-0.23105243, -0.26666167, 0.035609245]\n",
      "Iter 5003, loss [-0.22235185, -0.26179248, 0.03944063]\n",
      "Iter 5004, loss [-0.22686157, -0.26513022, 0.038268656]\n",
      "Iter 5005, loss [-0.19345236, -0.23714153, 0.043689176]\n",
      "Iter 5006, loss [-0.224145, -0.2631691, 0.039024115]\n",
      "Iter 5007, loss [-0.22270408, -0.26017216, 0.03746808]\n",
      "Iter 5008, loss [-0.22413912, -0.2607799, 0.03664076]\n",
      "Iter 5009, loss [-0.22889689, -0.26462445, 0.03572756]\n",
      "Iter 5010, loss [-0.22518046, -0.26221752, 0.03703706]\n",
      "Iter 5011, loss [-0.20559606, -0.24867882, 0.043082755]\n",
      "Iter 5012, loss [-0.22725734, -0.26476258, 0.03750523]\n",
      "Iter 5013, loss [-0.2233018, -0.26222086, 0.038919065]\n",
      "Iter 5014, loss [-0.22394802, -0.26297048, 0.039022464]\n",
      "Iter 5015, loss [-0.21898496, -0.25796306, 0.0389781]\n",
      "Iter 5016, loss [-0.22601011, -0.26231486, 0.036304742]\n",
      "Iter 5017, loss [-0.22561044, -0.26278278, 0.037172344]\n",
      "Iter 5018, loss [-0.22084808, -0.2603371, 0.03948904]\n",
      "Iter 5019, loss [-0.21827656, -0.25707093, 0.038794365]\n",
      "Iter 5020, loss [-0.21785142, -0.2562242, 0.038372766]\n",
      "Iter 5021, loss [-0.22860064, -0.26369947, 0.035098832]\n",
      "Iter 5022, loss [-0.22356763, -0.26177529, 0.03820765]\n",
      "Iter 5023, loss [-0.17163981, -0.22771928, 0.056079462]\n",
      "Iter 5024, loss [-0.22335052, -0.26310208, 0.03975156]\n",
      "Iter 5025, loss [-0.21554837, -0.2556962, 0.040147834]\n",
      "Iter 5026, loss [-0.22201964, -0.25932306, 0.037303418]\n",
      "Iter 5027, loss [-0.2264364, -0.26250803, 0.03607163]\n",
      "Iter 5028, loss [-0.22261441, -0.26172376, 0.039109346]\n",
      "Iter 5029, loss [-0.22496903, -0.26408792, 0.03911888]\n",
      "Iter 5030, loss [-0.21967107, -0.25814095, 0.038469873]\n",
      "Iter 5031, loss [-0.2112703, -0.2527645, 0.041494183]\n",
      "Iter 5032, loss [-0.22464399, -0.26305252, 0.03840853]\n",
      "Iter 5033, loss [-0.21662351, -0.25676593, 0.04014241]\n",
      "Iter 5034, loss [-0.23066665, -0.2664364, 0.035769746]\n",
      "Iter 5035, loss [-0.21628821, -0.25489914, 0.038610943]\n",
      "Iter 5036, loss [-0.22845764, -0.2647423, 0.03628467]\n",
      "Iter 5037, loss [-0.21180066, -0.25091124, 0.039110564]\n",
      "Iter 5038, loss [-0.18676539, -0.23459786, 0.047832474]\n",
      "Iter 5039, loss [-0.23148933, -0.2667992, 0.03530988]\n",
      "Iter 5040, loss [-0.22421427, -0.26101673, 0.036802452]\n",
      "Iter 5041, loss [-0.21804118, -0.25466353, 0.036622338]\n",
      "Iter 5042, loss [-0.2231274, -0.26268134, 0.039553937]\n",
      "Iter 5043, loss [-0.22442383, -0.26337123, 0.03894741]\n",
      "Iter 5044, loss [-0.21798794, -0.2574208, 0.03943287]\n",
      "Iter 5045, loss [-0.22351424, -0.26287493, 0.039360683]\n",
      "Iter 5046, loss [-0.22901966, -0.26596794, 0.03694828]\n",
      "Iter 5047, loss [-0.2239993, -0.2616325, 0.0376332]\n",
      "Iter 5048, loss [-0.22567812, -0.26383305, 0.038154926]\n",
      "Iter 5049, loss [-0.17886166, -0.21858515, 0.039723482]\n",
      "Iter 5050, loss [-0.22815165, -0.2643417, 0.036190063]\n",
      "Iter 5051, loss [-0.22985749, -0.26432538, 0.034467887]\n",
      "Iter 5052, loss [-0.22799817, -0.26503587, 0.037037693]\n",
      "Iter 5053, loss [-0.22323172, -0.26251864, 0.039286926]\n",
      "Iter 5054, loss [-0.23376243, -0.26917684, 0.035414416]\n",
      "Iter 5055, loss [-0.22272687, -0.26124993, 0.038523063]\n",
      "Iter 5056, loss [-0.21535969, -0.25346935, 0.03810966]\n",
      "Iter 5057, loss [-0.22474837, -0.26271152, 0.037963152]\n",
      "Iter 5058, loss [-0.22032261, -0.25761938, 0.037296772]\n",
      "Iter 5059, loss [-0.2151672, -0.25442177, 0.039254572]\n",
      "Iter 5060, loss [-0.13408172, -0.1927613, 0.05867959]\n",
      "Iter 5061, loss [-0.22676486, -0.26520696, 0.038442098]\n",
      "Iter 5062, loss [-0.22659963, -0.26361328, 0.037013657]\n",
      "Iter 5063, loss [-0.21089348, -0.24957663, 0.03868314]\n",
      "Iter 5064, loss [-0.2260913, -0.26246622, 0.036374927]\n",
      "Iter 5065, loss [-0.20848599, -0.24867487, 0.040188886]\n",
      "Iter 5066, loss [-0.21231806, -0.25106147, 0.038743414]\n",
      "Iter 5067, loss [-0.22934449, -0.26649705, 0.037152555]\n",
      "Iter 5068, loss [-0.2162062, -0.25570938, 0.03950318]\n",
      "Iter 5069, loss [-0.20635079, -0.2472989, 0.040948108]\n",
      "Iter 5070, loss [-0.22585084, -0.2616012, 0.03575037]\n",
      "Iter 5071, loss [-0.21877947, -0.25759196, 0.03881248]\n",
      "Iter 5072, loss [-0.22393449, -0.26388407, 0.03994958]\n",
      "Iter 5073, loss [-0.21599782, -0.25420833, 0.038210507]\n",
      "Iter 5074, loss [-0.21123268, -0.2532494, 0.042016726]\n",
      "Iter 5075, loss [-0.19961885, -0.24386397, 0.04424512]\n",
      "Iter 5076, loss [-0.20793658, -0.25055444, 0.04261785]\n",
      "Iter 5077, loss [-0.21872783, -0.25964963, 0.0409218]\n",
      "Iter 5078, loss [-0.1680341, -0.22183594, 0.053801835]\n",
      "Iter 5079, loss [-0.22641177, -0.26463735, 0.038225576]\n",
      "Iter 5080, loss [-0.22564735, -0.2646005, 0.038953144]\n",
      "Iter 5081, loss [-0.1994195, -0.24482818, 0.04540869]\n",
      "Iter 5082, loss [-0.21738686, -0.25533137, 0.03794451]\n",
      "Iter 5083, loss [-0.20826605, -0.24960981, 0.041343763]\n",
      "Iter 5084, loss [-0.20670263, -0.25008395, 0.043381315]\n",
      "Iter 5085, loss [-0.22949325, -0.26562324, 0.036129992]\n",
      "Iter 5086, loss [-0.22543924, -0.26196986, 0.036530625]\n",
      "Iter 5087, loss [-0.22275284, -0.260517, 0.037764154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5088, loss [-0.2204803, -0.25939262, 0.038912334]\n",
      "Iter 5089, loss [-0.21874255, -0.2589728, 0.040230248]\n",
      "Iter 5090, loss [-0.22701022, -0.26498052, 0.037970297]\n",
      "Iter 5091, loss [-0.22405034, -0.2614535, 0.037403163]\n",
      "Iter 5092, loss [-0.22388336, -0.26081926, 0.036935892]\n",
      "Iter 5093, loss [-0.23328573, -0.26778087, 0.034495138]\n",
      "Iter 5094, loss [-0.21877906, -0.25656226, 0.0377832]\n",
      "Iter 5095, loss [-0.22374997, -0.26148552, 0.037735548]\n",
      "Iter 5096, loss [-0.23135616, -0.26706448, 0.03570832]\n",
      "Iter 5097, loss [-0.20481941, -0.24615295, 0.04133355]\n",
      "Iter 5098, loss [-0.22417645, -0.26074642, 0.036569968]\n",
      "Iter 5099, loss [-0.22062932, -0.25778642, 0.0371571]\n",
      "Iter 5100, loss [-0.22709358, -0.26146975, 0.03437618]\n",
      "Iter 5101, loss [-0.21593368, -0.25570157, 0.039767895]\n",
      "Iter 5102, loss [-0.21498394, -0.25523627, 0.04025232]\n",
      "Iter 5103, loss [-0.22417814, -0.26266408, 0.03848594]\n",
      "Iter 5104, loss [-0.2263095, -0.26396775, 0.037658256]\n",
      "Iter 5105, loss [-0.22650829, -0.26544458, 0.038936287]\n",
      "Iter 5106, loss [-0.21487619, -0.2510118, 0.036135603]\n",
      "Iter 5107, loss [-0.21867298, -0.2584218, 0.039748833]\n",
      "Iter 5108, loss [-0.22822428, -0.26453817, 0.03631389]\n",
      "Iter 5109, loss [-0.22626267, -0.26259488, 0.036332205]\n",
      "Iter 5110, loss [-0.22258025, -0.26327148, 0.04069123]\n",
      "Iter 5111, loss [-0.21715307, -0.258238, 0.041084915]\n",
      "Iter 5112, loss [-0.22611494, -0.26614332, 0.040028382]\n",
      "Iter 5113, loss [-0.23032391, -0.2664398, 0.036115877]\n",
      "Iter 5114, loss [-0.22771513, -0.26551625, 0.037801113]\n",
      "Iter 5115, loss [-0.19151929, -0.23908153, 0.04756224]\n",
      "Iter 5116, loss [-0.22980109, -0.2646518, 0.034850724]\n",
      "Iter 5117, loss [-0.21535918, -0.25250864, 0.037149467]\n",
      "Iter 5118, loss [-0.22729148, -0.26523393, 0.037942454]\n",
      "Iter 5119, loss [-0.22040404, -0.2590384, 0.038634345]\n",
      "Iter 5120, loss [-0.17731225, -0.21753095, 0.040218692]\n",
      "Iter 5121, loss [-0.2257858, -0.2610872, 0.035301402]\n",
      "Iter 5122, loss [-0.22610682, -0.2649155, 0.038808666]\n",
      "Iter 5123, loss [-0.22680424, -0.26331332, 0.036509078]\n",
      "Iter 5124, loss [-0.22703677, -0.2646824, 0.037645638]\n",
      "Iter 5125, loss [-0.22263466, -0.2618397, 0.039205033]\n",
      "Iter 5126, loss [-0.22768539, -0.26516303, 0.037477642]\n",
      "Iter 5127, loss [-0.19385095, -0.23645177, 0.042600825]\n",
      "Iter 5128, loss [-0.22659901, -0.26301888, 0.036419876]\n",
      "Iter 5129, loss [-0.22844917, -0.26423907, 0.035789903]\n",
      "Iter 5130, loss [-0.23270397, -0.26835278, 0.035648808]\n",
      "Iter 5131, loss [-0.23102136, -0.26688674, 0.035865378]\n",
      "Iter 5132, loss [-0.22489364, -0.26402617, 0.03913252]\n",
      "Iter 5133, loss [-0.18947889, -0.2355563, 0.04607741]\n",
      "Iter 5134, loss [-0.22716093, -0.26503843, 0.037877496]\n",
      "Iter 5135, loss [-0.22734845, -0.265529, 0.038180564]\n",
      "Iter 5136, loss [-0.2247887, -0.26343042, 0.03864172]\n",
      "Iter 5137, loss [-0.23059146, -0.26766613, 0.037074666]\n",
      "Iter 5138, loss [-0.21806487, -0.25765836, 0.03959348]\n",
      "Iter 5139, loss [-0.22340834, -0.26165843, 0.03825009]\n",
      "Iter 5140, loss [-0.22696315, -0.26384845, 0.036885306]\n",
      "Iter 5141, loss [-0.22575055, -0.26310444, 0.03735389]\n",
      "Iter 5142, loss [-0.2139938, -0.25156087, 0.03756706]\n",
      "Iter 5143, loss [-0.195465, -0.23631032, 0.040845327]\n",
      "Iter 5144, loss [-0.22388765, -0.26074156, 0.036853906]\n",
      "Iter 5145, loss [-0.22053188, -0.25603083, 0.035498943]\n",
      "Iter 5146, loss [-0.22726056, -0.2637238, 0.03646323]\n",
      "Iter 5147, loss [-0.22133863, -0.25989467, 0.038556043]\n",
      "Iter 5148, loss [-0.22620207, -0.2639039, 0.037701815]\n",
      "Iter 5149, loss [-0.21775979, -0.25762337, 0.039863586]\n",
      "Iter 5150, loss [-0.21657524, -0.25677758, 0.040202357]\n",
      "Iter 5151, loss [-0.20704992, -0.24824457, 0.041194644]\n",
      "Iter 5152, loss [-0.22684455, -0.263991, 0.03714644]\n",
      "Iter 5153, loss [-0.20552996, -0.24609414, 0.040564172]\n",
      "Iter 5154, loss [-0.2273466, -0.26390398, 0.036557384]\n",
      "Iter 5155, loss [-0.2318582, -0.26610187, 0.03424367]\n",
      "Iter 5156, loss [-0.21269476, -0.25316176, 0.040466987]\n",
      "Iter 5157, loss [-0.21671818, -0.25580734, 0.039089154]\n",
      "Iter 5158, loss [-0.22417292, -0.2612255, 0.037052568]\n",
      "Iter 5159, loss [-0.2205825, -0.25757068, 0.03698818]\n",
      "Iter 5160, loss [-0.2206801, -0.26023728, 0.039557174]\n",
      "Iter 5161, loss [-0.23441401, -0.26883915, 0.034425147]\n",
      "Iter 5162, loss [-0.22202773, -0.2569245, 0.034896772]\n",
      "Iter 5163, loss [-0.22758302, -0.26454633, 0.03696332]\n",
      "Iter 5164, loss [-0.2353918, -0.27182394, 0.036432143]\n",
      "Iter 5165, loss [-0.22259967, -0.2612605, 0.038660835]\n",
      "Iter 5166, loss [-0.21509707, -0.25443017, 0.039333105]\n",
      "Iter 5167, loss [-0.22124493, -0.2603722, 0.039127257]\n",
      "Iter 5168, loss [-0.2250658, -0.26222625, 0.037160464]\n",
      "Iter 5169, loss [-0.21727262, -0.2564531, 0.039180476]\n",
      "Iter 5170, loss [-0.2284448, -0.26420704, 0.035762236]\n",
      "Iter 5171, loss [-0.21908887, -0.25640792, 0.03731905]\n",
      "Iter 5172, loss [-0.22454323, -0.26376578, 0.039222553]\n",
      "Iter 5173, loss [-0.22611581, -0.2633932, 0.037277386]\n",
      "Iter 5174, loss [-0.23122337, -0.2697243, 0.038500927]\n",
      "Iter 5175, loss [-0.23111562, -0.26684502, 0.035729397]\n",
      "Iter 5176, loss [-0.23492205, -0.2701833, 0.035261236]\n",
      "Iter 5177, loss [-0.23098801, -0.26649725, 0.03550924]\n",
      "Iter 5178, loss [-0.17203149, -0.22576497, 0.05373349]\n",
      "Iter 5179, loss [-0.18079099, -0.22943746, 0.048646465]\n",
      "Iter 5180, loss [-0.22611268, -0.2624693, 0.03635661]\n",
      "Iter 5181, loss [-0.20825073, -0.2495182, 0.041267477]\n",
      "Iter 5182, loss [-0.20870033, -0.25018626, 0.041485928]\n",
      "Iter 5183, loss [-0.23053446, -0.26688284, 0.036348365]\n",
      "Iter 5184, loss [-0.22308213, -0.26341784, 0.04033571]\n",
      "Iter 5185, loss [-0.22886424, -0.2675691, 0.038704857]\n",
      "Iter 5186, loss [-0.20816423, -0.24989305, 0.04172882]\n",
      "Iter 5187, loss [-0.18748131, -0.23461168, 0.04713036]\n",
      "Iter 5188, loss [-0.23067611, -0.26839843, 0.03772232]\n",
      "Iter 5189, loss [-0.21398738, -0.2555174, 0.04153001]\n",
      "Iter 5190, loss [-0.22707167, -0.26592445, 0.038852785]\n",
      "Iter 5191, loss [-0.2227216, -0.26171076, 0.038989153]\n",
      "Iter 5192, loss [-0.21648696, -0.25742802, 0.04094106]\n",
      "Iter 5193, loss [-0.21736595, -0.25647953, 0.039113574]\n",
      "Iter 5194, loss [-0.22050855, -0.25892144, 0.038412906]\n",
      "Iter 5195, loss [-0.2267594, -0.26192304, 0.035163637]\n",
      "Iter 5196, loss [-0.2282426, -0.2628929, 0.034650303]\n",
      "Iter 5197, loss [-0.23183101, -0.26777554, 0.035944525]\n",
      "Iter 5198, loss [-0.20728526, -0.25120595, 0.043920696]\n",
      "Iter 5199, loss [-0.2187896, -0.26116383, 0.042374216]\n",
      "Iter 5200, loss [-0.19322433, -0.23702815, 0.043803826]\n",
      "Iter 5201, loss [-0.22749178, -0.26241526, 0.03492348]\n",
      "Iter 5202, loss [-0.22979179, -0.26479712, 0.03500533]\n",
      "Iter 5203, loss [-0.21988313, -0.25907677, 0.03919364]\n",
      "Iter 5204, loss [-0.22060168, -0.26154423, 0.040942542]\n",
      "Iter 5205, loss [-0.22240205, -0.26132017, 0.03891812]\n",
      "Iter 5206, loss [-0.22281353, -0.26083332, 0.03801979]\n",
      "Iter 5207, loss [-0.22752881, -0.2640408, 0.03651198]\n",
      "Iter 5208, loss [-0.23324189, -0.2687698, 0.035527915]\n",
      "Iter 5209, loss [-0.22258124, -0.26190612, 0.03932488]\n",
      "Iter 5210, loss [-0.23330352, -0.26928398, 0.035980463]\n",
      "Iter 5211, loss [-0.23227277, -0.26745805, 0.035185285]\n",
      "Iter 5212, loss [-0.21423475, -0.25414586, 0.039911106]\n",
      "Iter 5213, loss [-0.21152839, -0.24974932, 0.038220927]\n",
      "Iter 5214, loss [-0.2211953, -0.26046127, 0.03926598]\n",
      "Iter 5215, loss [-0.22227585, -0.26186156, 0.039585706]\n",
      "Iter 5216, loss [-0.21874374, -0.2579724, 0.03922865]\n",
      "Iter 5217, loss [-0.23307994, -0.2691383, 0.036058366]\n",
      "Iter 5218, loss [-0.22786796, -0.2638478, 0.035979845]\n",
      "Iter 5219, loss [-0.23037258, -0.26789278, 0.037520196]\n",
      "Iter 5220, loss [-0.22774412, -0.26282132, 0.0350772]\n",
      "Iter 5221, loss [-0.18591437, -0.23228021, 0.046365835]\n",
      "Iter 5222, loss [-0.22722489, -0.2647642, 0.037539296]\n",
      "Iter 5223, loss [-0.22604837, -0.26338273, 0.037334364]\n",
      "Iter 5224, loss [-0.21964563, -0.2574071, 0.03776146]\n",
      "Iter 5225, loss [-0.22646724, -0.2630877, 0.036620453]\n",
      "Iter 5226, loss [-0.2212917, -0.26027724, 0.038985536]\n",
      "Iter 5227, loss [-0.21492302, -0.25550988, 0.04058685]\n",
      "Iter 5228, loss [-0.1818865, -0.23521467, 0.05332817]\n",
      "Iter 5229, loss [-0.22437255, -0.26319408, 0.038821537]\n",
      "Iter 5230, loss [-0.21801859, -0.25799897, 0.039980378]\n",
      "Iter 5231, loss [-0.23041683, -0.26737893, 0.036962084]\n",
      "Iter 5232, loss [-0.2278048, -0.2638756, 0.03607081]\n",
      "Iter 5233, loss [-0.22606175, -0.26349115, 0.037429407]\n",
      "Iter 5234, loss [-0.22210139, -0.26014373, 0.038042337]\n",
      "Iter 5235, loss [-0.2238578, -0.26340792, 0.039550107]\n",
      "Iter 5236, loss [-0.23098485, -0.2681853, 0.037200436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5237, loss [-0.22746974, -0.26401174, 0.036542006]\n",
      "Iter 5238, loss [-0.22165641, -0.26099184, 0.039335426]\n",
      "Iter 5239, loss [-0.22627613, -0.26375097, 0.037474837]\n",
      "Iter 5240, loss [-0.2165641, -0.2549988, 0.0384347]\n",
      "Iter 5241, loss [-0.19750264, -0.241779, 0.044276353]\n",
      "Iter 5242, loss [-0.22450148, -0.26325646, 0.038754985]\n",
      "Iter 5243, loss [-0.21895117, -0.25871813, 0.039766967]\n",
      "Iter 5244, loss [-0.19797117, -0.24189094, 0.04391977]\n",
      "Iter 5245, loss [-0.23446293, -0.26984146, 0.035378527]\n",
      "Iter 5246, loss [-0.20403683, -0.24488707, 0.040850237]\n",
      "Iter 5247, loss [-0.21280026, -0.25307798, 0.040277712]\n",
      "Iter 5248, loss [-0.21963668, -0.25844222, 0.038805537]\n",
      "Iter 5249, loss [-0.2064893, -0.24800342, 0.041514132]\n",
      "Iter 5250, loss [-0.22783843, -0.26493543, 0.037097007]\n",
      "Iter 5251, loss [-0.22628632, -0.26261574, 0.036329426]\n",
      "Iter 5252, loss [-0.22768512, -0.2648291, 0.037143983]\n",
      "Iter 5253, loss [-0.22519474, -0.2631167, 0.03792195]\n",
      "Iter 5254, loss [-0.23020008, -0.266438, 0.036237918]\n",
      "Iter 5255, loss [-0.23240362, -0.2689784, 0.036574766]\n",
      "Iter 5256, loss [-0.22419763, -0.2594443, 0.035246667]\n",
      "Iter 5257, loss [-0.21348944, -0.25307965, 0.039590217]\n",
      "Iter 5258, loss [-0.20568632, -0.2487593, 0.043072984]\n",
      "Iter 5259, loss [-0.21857539, -0.25624385, 0.03766846]\n",
      "Iter 5260, loss [-0.18663394, -0.23896176, 0.052327804]\n",
      "Iter 5261, loss [-0.22451504, -0.2628034, 0.03828837]\n",
      "Iter 5262, loss [-0.14681894, -0.2061978, 0.059378855]\n",
      "Iter 5263, loss [-0.22731872, -0.26497844, 0.037659716]\n",
      "Iter 5264, loss [-0.21345167, -0.25424105, 0.040789377]\n",
      "Iter 5265, loss [-0.22987701, -0.2659186, 0.036041602]\n",
      "Iter 5266, loss [-0.229842, -0.26529583, 0.035453826]\n",
      "Iter 5267, loss [-0.22421218, -0.26067173, 0.036459547]\n",
      "Iter 5268, loss [-0.23073964, -0.26638666, 0.03564702]\n",
      "Iter 5269, loss [-0.22572228, -0.26615924, 0.040436946]\n",
      "Iter 5270, loss [-0.22169006, -0.26001823, 0.03832817]\n",
      "Iter 5271, loss [-0.22373556, -0.26173654, 0.038000986]\n",
      "Iter 5272, loss [-0.218499, -0.25801554, 0.03951654]\n",
      "Iter 5273, loss [-0.22877729, -0.2659005, 0.037123196]\n",
      "Iter 5274, loss [-0.21918887, -0.25686383, 0.037674956]\n",
      "Iter 5275, loss [-0.19860175, -0.2431415, 0.044539742]\n",
      "Iter 5276, loss [-0.16584171, -0.22002386, 0.05418214]\n",
      "Iter 5277, loss [-0.2041241, -0.24508543, 0.04096134]\n",
      "Iter 5278, loss [-0.2127401, -0.25274813, 0.04000804]\n",
      "Iter 5279, loss [-0.21325052, -0.25284168, 0.039591163]\n",
      "Iter 5280, loss [-0.21866544, -0.2556639, 0.036998466]\n",
      "Iter 5281, loss [-0.22654265, -0.2638887, 0.037346043]\n",
      "Iter 5282, loss [-0.21849851, -0.25843874, 0.03994022]\n",
      "Iter 5283, loss [-0.17590623, -0.21859652, 0.04269029]\n",
      "Iter 5284, loss [-0.2060978, -0.24860767, 0.042509865]\n",
      "Iter 5285, loss [-0.22126889, -0.26035988, 0.03909099]\n",
      "Iter 5286, loss [-0.22374235, -0.2616781, 0.037935752]\n",
      "Iter 5287, loss [-0.22663352, -0.26400226, 0.037368745]\n",
      "Iter 5288, loss [-0.21603009, -0.25614303, 0.040112942]\n",
      "Iter 5289, loss [-0.22010869, -0.25802138, 0.037912704]\n",
      "Iter 5290, loss [-0.21535814, -0.2535193, 0.03816116]\n",
      "Iter 5291, loss [-0.22180387, -0.25949958, 0.037695713]\n",
      "Iter 5292, loss [-0.22209138, -0.25626025, 0.03416886]\n",
      "Iter 5293, loss [-0.22928554, -0.2648051, 0.03551957]\n",
      "Iter 5294, loss [-0.22315502, -0.26026818, 0.037113152]\n",
      "Iter 5295, loss [-0.21830422, -0.26001263, 0.041708417]\n",
      "Iter 5296, loss [-0.22652791, -0.26387703, 0.03734912]\n",
      "Iter 5297, loss [-0.2264477, -0.2640375, 0.03758978]\n",
      "Iter 5298, loss [-0.19928072, -0.24494688, 0.04566616]\n",
      "Iter 5299, loss [-0.22823066, -0.26374415, 0.035513483]\n",
      "Iter 5300, loss [-0.20938429, -0.24920654, 0.039822258]\n",
      "Iter 5301, loss [-0.19858225, -0.24077016, 0.04218791]\n",
      "Iter 5302, loss [-0.223454, -0.26148024, 0.038026236]\n",
      "Iter 5303, loss [-0.20367506, -0.25133273, 0.04765767]\n",
      "Iter 5304, loss [-0.21782783, -0.25819182, 0.04036399]\n",
      "Iter 5305, loss [-0.22306313, -0.26261294, 0.039549813]\n",
      "Iter 5306, loss [-0.22603479, -0.2633566, 0.0373218]\n",
      "Iter 5307, loss [-0.1576223, -0.2095633, 0.051941004]\n",
      "Iter 5308, loss [-0.2249336, -0.26351002, 0.03857643]\n",
      "Iter 5309, loss [-0.22174838, -0.2582516, 0.03650322]\n",
      "Iter 5310, loss [-0.22584566, -0.26125264, 0.035406984]\n",
      "Iter 5311, loss [-0.20884573, -0.25201222, 0.04316648]\n",
      "Iter 5312, loss [-0.22012284, -0.25853524, 0.038412396]\n",
      "Iter 5313, loss [-0.21513422, -0.25780234, 0.042668115]\n",
      "Iter 5314, loss [-0.21765238, -0.2570942, 0.039441824]\n",
      "Iter 5315, loss [-0.22505212, -0.2629136, 0.037861504]\n",
      "Iter 5316, loss [-0.21721727, -0.25423154, 0.037014272]\n",
      "Iter 5317, loss [-0.21560685, -0.25531387, 0.03970702]\n",
      "Iter 5318, loss [-0.22940746, -0.2636215, 0.034214046]\n",
      "Iter 5319, loss [-0.22281754, -0.25891986, 0.036102325]\n",
      "Iter 5320, loss [-0.22035873, -0.25870752, 0.038348794]\n",
      "Iter 5321, loss [-0.21300882, -0.25329787, 0.040289044]\n",
      "Iter 5322, loss [-0.22819404, -0.2662476, 0.03805356]\n",
      "Iter 5323, loss [-0.20898321, -0.2505525, 0.04156929]\n",
      "Iter 5324, loss [-0.22152816, -0.2606396, 0.03911145]\n",
      "Iter 5325, loss [-0.15016133, -0.20245998, 0.052298646]\n",
      "Iter 5326, loss [-0.22396743, -0.26169705, 0.037729625]\n",
      "Iter 5327, loss [-0.22067828, -0.25863013, 0.03795184]\n",
      "Iter 5328, loss [-0.22931369, -0.264983, 0.03566931]\n",
      "Iter 5329, loss [-0.22629833, -0.26419884, 0.037900515]\n",
      "Iter 5330, loss [-0.22514026, -0.26287955, 0.037739288]\n",
      "Iter 5331, loss [-0.22569078, -0.26303145, 0.03734067]\n",
      "Iter 5332, loss [-0.23105714, -0.26834297, 0.03728583]\n",
      "Iter 5333, loss [-0.22366734, -0.26332736, 0.039660018]\n",
      "Iter 5334, loss [-0.16174999, -0.21455084, 0.052800845]\n",
      "Iter 5335, loss [-0.16099676, -0.21536125, 0.054364484]\n",
      "Iter 5336, loss [-0.21331757, -0.25277653, 0.039458957]\n",
      "Iter 5337, loss [-0.19672923, -0.23950511, 0.042775884]\n",
      "Iter 5338, loss [-0.2137048, -0.2557196, 0.042014804]\n",
      "Iter 5339, loss [-0.215744, -0.25483486, 0.039090857]\n",
      "Iter 5340, loss [-0.23271915, -0.26874083, 0.03602168]\n",
      "Iter 5341, loss [-0.22315826, -0.2621836, 0.039025355]\n",
      "Iter 5342, loss [-0.222303, -0.26220962, 0.03990662]\n",
      "Iter 5343, loss [-0.16056111, -0.21994312, 0.059382003]\n",
      "Iter 5344, loss [-0.22942486, -0.26639354, 0.036968682]\n",
      "Iter 5345, loss [-0.22698489, -0.26359615, 0.036611266]\n",
      "Iter 5346, loss [-0.23007801, -0.2653474, 0.035269387]\n",
      "Iter 5347, loss [-0.14672114, -0.20264411, 0.055922966]\n",
      "Iter 5348, loss [-0.22039005, -0.2598376, 0.03944754]\n",
      "Iter 5349, loss [-0.22802709, -0.26348227, 0.035455182]\n",
      "Iter 5350, loss [-0.22959314, -0.26405546, 0.034462314]\n",
      "Iter 5351, loss [-0.21427777, -0.25419822, 0.03992045]\n",
      "Iter 5352, loss [-0.21166404, -0.25187778, 0.04021375]\n",
      "Iter 5353, loss [-0.2223171, -0.2603671, 0.038049996]\n",
      "Iter 5354, loss [-0.22972962, -0.26590982, 0.036180206]\n",
      "Iter 5355, loss [-0.3100579, -0.31758747, 0.007529553]\n",
      "Iter 5356, loss [-0.19109108, -0.23735566, 0.046264585]\n",
      "Iter 5357, loss [-0.23202467, -0.26641822, 0.034393556]\n",
      "Iter 5358, loss [-0.22718057, -0.26424146, 0.037060883]\n",
      "Iter 5359, loss [-0.20488751, -0.24441794, 0.039530426]\n",
      "Iter 5360, loss [-0.22303894, -0.25976068, 0.036721744]\n",
      "Iter 5361, loss [-0.18742344, -0.23585601, 0.04843257]\n",
      "Iter 5362, loss [-0.23316169, -0.2695654, 0.036403723]\n",
      "Iter 5363, loss [-0.19279364, -0.23527618, 0.042482547]\n",
      "Iter 5364, loss [-0.22590753, -0.26315778, 0.037250243]\n",
      "Iter 5365, loss [-0.2219872, -0.25960022, 0.037613016]\n",
      "Iter 5366, loss [-0.22483374, -0.26211917, 0.037285436]\n",
      "Iter 5367, loss [-0.22986959, -0.26528078, 0.035411194]\n",
      "Iter 5368, loss [-0.22971699, -0.26538453, 0.035667542]\n",
      "Iter 5369, loss [-0.22692508, -0.2636138, 0.03668871]\n",
      "Iter 5370, loss [-0.22241813, -0.26265085, 0.04023271]\n",
      "Iter 5371, loss [-0.22338462, -0.26156646, 0.03818184]\n",
      "Iter 5372, loss [-0.22196157, -0.2604889, 0.038527325]\n",
      "Iter 5373, loss [-0.21875924, -0.25795195, 0.0391927]\n",
      "Iter 5374, loss [-0.20092177, -0.24231382, 0.041392036]\n",
      "Iter 5375, loss [-0.21800493, -0.25535214, 0.037347216]\n",
      "Iter 5376, loss [-0.2146409, -0.2522965, 0.037655603]\n",
      "Iter 5377, loss [-0.22347361, -0.25925034, 0.035776734]\n",
      "Iter 5378, loss [-0.22124693, -0.26049444, 0.039247505]\n",
      "Iter 5379, loss [-0.20522867, -0.24778527, 0.042556595]\n",
      "Iter 5380, loss [-0.22677127, -0.2647762, 0.038004942]\n",
      "Iter 5381, loss [-0.21515305, -0.25479868, 0.039645623]\n",
      "Iter 5382, loss [-0.22932413, -0.26406226, 0.03473813]\n",
      "Iter 5383, loss [-0.21682394, -0.2554114, 0.03858745]\n",
      "Iter 5384, loss [-0.23420544, -0.26778856, 0.033583116]\n",
      "Iter 5385, loss [-0.22237949, -0.25884178, 0.036462292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5386, loss [-0.22226027, -0.25929067, 0.0370304]\n",
      "Iter 5387, loss [-0.15155022, -0.20321482, 0.051664602]\n",
      "Iter 5388, loss [-0.23388569, -0.27019954, 0.036313843]\n",
      "Iter 5389, loss [-0.23083955, -0.2684744, 0.03763485]\n",
      "Iter 5390, loss [-0.22804454, -0.26591983, 0.037875287]\n",
      "Iter 5391, loss [-0.23234937, -0.26934496, 0.036995586]\n",
      "Iter 5392, loss [-0.23356277, -0.26921642, 0.03565366]\n",
      "Iter 5393, loss [-0.22419846, -0.26136318, 0.03716471]\n",
      "Iter 5394, loss [-0.18562135, -0.23575944, 0.05013808]\n",
      "Iter 5395, loss [-0.16616793, -0.2221626, 0.05599467]\n",
      "Iter 5396, loss [-0.21748628, -0.25491834, 0.03743206]\n",
      "Iter 5397, loss [-0.21689221, -0.25869507, 0.041802846]\n",
      "Iter 5398, loss [-0.20837572, -0.24830617, 0.039930455]\n",
      "Iter 5399, loss [-0.2180783, -0.25759572, 0.039517414]\n",
      "Iter 5400, loss [-0.22747351, -0.2620154, 0.034541886]\n",
      "Iter 5401, loss [-0.22013488, -0.258016, 0.037881106]\n",
      "Iter 5402, loss [-0.2217215, -0.25889784, 0.03717634]\n",
      "Iter 5403, loss [-0.21536161, -0.2529927, 0.037631076]\n",
      "Iter 5404, loss [-0.22043863, -0.25966808, 0.039229453]\n",
      "Iter 5405, loss [-0.22570492, -0.26130065, 0.035595726]\n",
      "Iter 5406, loss [-0.2285783, -0.26531607, 0.03673777]\n",
      "Iter 5407, loss [-0.22580588, -0.26087892, 0.03507304]\n",
      "Iter 5408, loss [-0.22066508, -0.26071298, 0.040047895]\n",
      "Iter 5409, loss [-0.21945834, -0.26097733, 0.04151898]\n",
      "Iter 5410, loss [-0.21710749, -0.25777167, 0.04066418]\n",
      "Iter 5411, loss [-0.22268547, -0.26043046, 0.037744984]\n",
      "Iter 5412, loss [-0.22367848, -0.26153916, 0.037860673]\n",
      "Iter 5413, loss [-0.22000799, -0.25807253, 0.038064532]\n",
      "Iter 5414, loss [-0.22489506, -0.26173902, 0.03684395]\n",
      "Iter 5415, loss [-0.22980691, -0.2646895, 0.034882586]\n",
      "Iter 5416, loss [-0.23264718, -0.26689807, 0.034250885]\n",
      "Iter 5417, loss [-0.21834117, -0.25811455, 0.039773367]\n",
      "Iter 5418, loss [-0.2340429, -0.2685573, 0.03451441]\n",
      "Iter 5419, loss [-0.17428258, -0.22680542, 0.052522838]\n",
      "Iter 5420, loss [-0.21894567, -0.2583428, 0.03939713]\n",
      "Iter 5421, loss [-0.2226118, -0.26045272, 0.037840914]\n",
      "Iter 5422, loss [-0.22803819, -0.26510224, 0.037064046]\n",
      "Iter 5423, loss [-0.2268681, -0.26275522, 0.03588713]\n",
      "Iter 5424, loss [-0.2142987, -0.25357506, 0.039276354]\n",
      "Iter 5425, loss [-0.19680601, -0.23991016, 0.043104142]\n",
      "Iter 5426, loss [-0.22177017, -0.2596965, 0.037926354]\n",
      "Iter 5427, loss [-0.20370314, -0.24494825, 0.041245114]\n",
      "Iter 5428, loss [-0.22038805, -0.26063234, 0.04024429]\n",
      "Iter 5429, loss [-0.23365498, -0.2711575, 0.03750252]\n",
      "Iter 5430, loss [-0.21510488, -0.2558093, 0.040704433]\n",
      "Iter 5431, loss [-0.20155314, -0.247959, 0.046405863]\n",
      "Iter 5432, loss [-0.22147924, -0.26137716, 0.039897926]\n",
      "Iter 5433, loss [-0.22122891, -0.25978732, 0.03855841]\n",
      "Iter 5434, loss [-0.22302106, -0.2610221, 0.03800103]\n",
      "Iter 5435, loss [-0.22168458, -0.25918722, 0.037502643]\n",
      "Iter 5436, loss [-0.22346634, -0.26110956, 0.037643224]\n",
      "Iter 5437, loss [-0.21727121, -0.25732213, 0.040050924]\n",
      "Iter 5438, loss [-0.22871025, -0.26669538, 0.037985127]\n",
      "Iter 5439, loss [-0.22692981, -0.26594126, 0.03901145]\n",
      "Iter 5440, loss [-0.2320485, -0.26834467, 0.036296174]\n",
      "Iter 5441, loss [-0.23042573, -0.2673127, 0.03688697]\n",
      "Iter 5442, loss [-0.23277621, -0.27016518, 0.03738897]\n",
      "Iter 5443, loss [-0.22550747, -0.26403576, 0.0385283]\n",
      "Iter 5444, loss [-0.22170725, -0.25664592, 0.034938656]\n",
      "Iter 5445, loss [-0.21696159, -0.25479722, 0.03783562]\n",
      "Iter 5446, loss [-0.22977582, -0.26591563, 0.036139823]\n",
      "Iter 5447, loss [-0.22696131, -0.26430765, 0.037346326]\n",
      "Iter 5448, loss [-0.23402235, -0.26940933, 0.03538698]\n",
      "Iter 5449, loss [-0.2086781, -0.25198436, 0.04330627]\n",
      "Iter 5450, loss [-0.2059258, -0.2502484, 0.04432259]\n",
      "Iter 5451, loss [-0.22544049, -0.2653228, 0.039882313]\n",
      "Iter 5452, loss [-0.22004396, -0.2593618, 0.039317846]\n",
      "Iter 5453, loss [-0.18723285, -0.23599938, 0.048766516]\n",
      "Iter 5454, loss [-0.22786868, -0.2639588, 0.036090128]\n",
      "Iter 5455, loss [-0.20109229, -0.24239908, 0.041306794]\n",
      "Iter 5456, loss [-0.2012788, -0.24584313, 0.04456433]\n",
      "Iter 5457, loss [-0.22876465, -0.26524672, 0.03648206]\n",
      "Iter 5458, loss [-0.22519155, -0.2640128, 0.03882127]\n",
      "Iter 5459, loss [-0.22422417, -0.26343605, 0.039211888]\n",
      "Iter 5460, loss [-0.22506756, -0.26478606, 0.039718512]\n",
      "Iter 5461, loss [-0.1938085, -0.24222986, 0.048421375]\n",
      "Iter 5462, loss [-0.21406946, -0.25553453, 0.041465074]\n",
      "Iter 5463, loss [-0.23080707, -0.26682636, 0.036019303]\n",
      "Iter 5464, loss [-0.2186352, -0.25807998, 0.039444767]\n",
      "Iter 5465, loss [-0.22781368, -0.2629652, 0.035151526]\n",
      "Iter 5466, loss [-0.23045021, -0.26588106, 0.035430856]\n",
      "Iter 5467, loss [-0.22839844, -0.26522505, 0.036826618]\n",
      "Iter 5468, loss [-0.22268203, -0.2574357, 0.034753673]\n",
      "Iter 5469, loss [-0.22961515, -0.26569107, 0.036075912]\n",
      "Iter 5470, loss [-0.22453517, -0.26304793, 0.038512774]\n",
      "Iter 5471, loss [-0.2042764, -0.24632643, 0.04205003]\n",
      "Iter 5472, loss [-0.22053209, -0.2598248, 0.03929273]\n",
      "Iter 5473, loss [-0.22960404, -0.26550946, 0.035905425]\n",
      "Iter 5474, loss [-0.21799079, -0.25735295, 0.03936217]\n",
      "Iter 5475, loss [-0.23480734, -0.27019474, 0.035387404]\n",
      "Iter 5476, loss [-0.21315342, -0.25060552, 0.0374521]\n",
      "Iter 5477, loss [-0.21336032, -0.25664392, 0.043283593]\n",
      "Iter 5478, loss [-0.22489369, -0.26112583, 0.03623215]\n",
      "Iter 5479, loss [-0.22747895, -0.2645652, 0.037086245]\n",
      "Iter 5480, loss [-0.22254631, -0.26217645, 0.039630145]\n",
      "Iter 5481, loss [-0.22940105, -0.26600152, 0.036600467]\n",
      "Iter 5482, loss [-0.23021425, -0.2642971, 0.03408284]\n",
      "Iter 5483, loss [-0.22873163, -0.26493764, 0.036206014]\n",
      "Iter 5484, loss [-0.21590912, -0.25286075, 0.03695164]\n",
      "Iter 5485, loss [-0.22186609, -0.25941104, 0.03754495]\n",
      "Iter 5486, loss [-0.22725084, -0.26466, 0.03740915]\n",
      "Iter 5487, loss [-0.21453667, -0.25482094, 0.040284283]\n",
      "Iter 5488, loss [-0.22354823, -0.26176605, 0.038217813]\n",
      "Iter 5489, loss [-0.22578435, -0.2624443, 0.03665994]\n",
      "Iter 5490, loss [-0.21287107, -0.25447717, 0.041606102]\n",
      "Iter 5491, loss [-0.22804618, -0.26557058, 0.03752441]\n",
      "Iter 5492, loss [-0.22679307, -0.26467478, 0.037881717]\n",
      "Iter 5493, loss [-0.22042277, -0.25967214, 0.039249368]\n",
      "Iter 5494, loss [-0.17205454, -0.22503391, 0.052979365]\n",
      "Iter 5495, loss [-0.21666571, -0.25728974, 0.040624026]\n",
      "Iter 5496, loss [-0.23127726, -0.26718876, 0.035911508]\n",
      "Iter 5497, loss [-0.21698084, -0.2593382, 0.042357355]\n",
      "Iter 5498, loss [-0.2222262, -0.26045275, 0.038226537]\n",
      "Iter 5499, loss [-0.20867309, -0.24953431, 0.040861227]\n",
      "Iter 5500, loss [-0.21110779, -0.2530422, 0.0419344]\n",
      "Iter 5501, loss [-0.22134128, -0.25876614, 0.03742486]\n",
      "Iter 5502, loss [-0.21728203, -0.25661704, 0.039335005]\n",
      "Iter 5503, loss [-0.2237068, -0.2618279, 0.03812109]\n",
      "Iter 5504, loss [-0.15054315, -0.20667641, 0.056133263]\n",
      "Iter 5505, loss [-0.22888958, -0.26551417, 0.036624588]\n",
      "Iter 5506, loss [-0.22732048, -0.26388413, 0.03656365]\n",
      "Iter 5507, loss [-0.22602089, -0.2640247, 0.038003817]\n",
      "Iter 5508, loss [-0.22534434, -0.2639886, 0.038644265]\n",
      "Iter 5509, loss [-0.2260701, -0.26503655, 0.038966447]\n",
      "Iter 5510, loss [-0.21852285, -0.2571446, 0.038621746]\n",
      "Iter 5511, loss [-0.23039103, -0.26665258, 0.036261562]\n",
      "Iter 5512, loss [-0.23273015, -0.26844046, 0.03571031]\n",
      "Iter 5513, loss [-0.22152089, -0.2607952, 0.03927432]\n",
      "Iter 5514, loss [-0.2153877, -0.25654542, 0.04115772]\n",
      "Iter 5515, loss [-0.2177271, -0.25697523, 0.03924813]\n",
      "Iter 5516, loss [-0.23111519, -0.26786622, 0.03675104]\n",
      "Iter 5517, loss [-0.22319692, -0.2609494, 0.037752472]\n",
      "Iter 5518, loss [-0.22626615, -0.2628765, 0.036610357]\n",
      "Iter 5519, loss [-0.22499609, -0.26437128, 0.039375193]\n",
      "Iter 5520, loss [-0.22892508, -0.2649374, 0.036012314]\n",
      "Iter 5521, loss [-0.22343326, -0.26137993, 0.037946668]\n",
      "Iter 5522, loss [-0.21943316, -0.25902826, 0.039595105]\n",
      "Iter 5523, loss [-0.22546329, -0.26343477, 0.03797148]\n",
      "Iter 5524, loss [-0.22403824, -0.26105663, 0.03701838]\n",
      "Iter 5525, loss [-0.2285839, -0.26264185, 0.034057945]\n",
      "Iter 5526, loss [-0.22380167, -0.2591975, 0.035395827]\n",
      "Iter 5527, loss [-0.21986316, -0.2563812, 0.036518056]\n",
      "Iter 5528, loss [-0.22006243, -0.2559523, 0.035889857]\n",
      "Iter 5529, loss [-0.22441368, -0.25972196, 0.035308283]\n",
      "Iter 5530, loss [-0.22310504, -0.26106468, 0.03795963]\n",
      "Iter 5531, loss [-0.20045283, -0.24588054, 0.045427702]\n",
      "Iter 5532, loss [-0.22454675, -0.26179186, 0.03724511]\n",
      "Iter 5533, loss [-0.2226935, -0.2606098, 0.03791631]\n",
      "Iter 5534, loss [-0.22163993, -0.26075336, 0.039113432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5535, loss [-0.22269125, -0.26205778, 0.03936653]\n",
      "Iter 5536, loss [-0.22882561, -0.2667467, 0.037921082]\n",
      "Iter 5537, loss [-0.22157267, -0.26056427, 0.038991608]\n",
      "Iter 5538, loss [-0.22773957, -0.26589984, 0.038160264]\n",
      "Iter 5539, loss [-0.22289628, -0.2633404, 0.040444132]\n",
      "Iter 5540, loss [-0.22919238, -0.2669364, 0.037744015]\n",
      "Iter 5541, loss [-0.22142486, -0.26162806, 0.040203195]\n",
      "Iter 5542, loss [-0.21421435, -0.25466755, 0.040453203]\n",
      "Iter 5543, loss [-0.21156886, -0.25124544, 0.039676577]\n",
      "Iter 5544, loss [-0.21232238, -0.25512892, 0.042806543]\n",
      "Iter 5545, loss [-0.226505, -0.26470178, 0.038196787]\n",
      "Iter 5546, loss [-0.21882416, -0.25739118, 0.03856702]\n",
      "Iter 5547, loss [-0.22434503, -0.26045796, 0.036112934]\n",
      "Iter 5548, loss [-0.22423738, -0.26408485, 0.039847463]\n",
      "Iter 5549, loss [-0.21770474, -0.25569162, 0.037986867]\n",
      "Iter 5550, loss [-0.21628901, -0.25508323, 0.038794212]\n",
      "Iter 5551, loss [-0.23086286, -0.26877385, 0.037911005]\n",
      "Iter 5552, loss [-0.21840537, -0.2554931, 0.037087735]\n",
      "Iter 5553, loss [-0.22915412, -0.2672487, 0.03809456]\n",
      "Iter 5554, loss [-0.22888987, -0.2634955, 0.034605637]\n",
      "Iter 5555, loss [-0.22854649, -0.26658708, 0.03804059]\n",
      "Iter 5556, loss [-0.22562271, -0.26529515, 0.039672434]\n",
      "Iter 5557, loss [-0.22487733, -0.26341337, 0.038536035]\n",
      "Iter 5558, loss [-0.23238164, -0.26938486, 0.037003227]\n",
      "Iter 5559, loss [-0.21532694, -0.25424787, 0.03892093]\n",
      "Iter 5560, loss [-0.22206101, -0.26004198, 0.03798098]\n",
      "Iter 5561, loss [-0.22164154, -0.2600331, 0.038391564]\n",
      "Iter 5562, loss [-0.22361484, -0.26344582, 0.03983098]\n",
      "Iter 5563, loss [-0.2219142, -0.2600716, 0.038157403]\n",
      "Iter 5564, loss [-0.21116477, -0.2521315, 0.040966716]\n",
      "Iter 5565, loss [-0.223683, -0.2608181, 0.037135087]\n",
      "Iter 5566, loss [-0.21831584, -0.2568794, 0.038563542]\n",
      "Iter 5567, loss [-0.22559899, -0.26277372, 0.03717474]\n",
      "Iter 5568, loss [-0.22789669, -0.26372856, 0.03583187]\n",
      "Iter 5569, loss [-0.21925227, -0.25886732, 0.03961505]\n",
      "Iter 5570, loss [-0.22468981, -0.2611314, 0.036441594]\n",
      "Iter 5571, loss [-0.21288146, -0.25343645, 0.04055499]\n",
      "Iter 5572, loss [-0.22615632, -0.26453808, 0.038381748]\n",
      "Iter 5573, loss [-0.1852157, -0.23253508, 0.047319382]\n",
      "Iter 5574, loss [-0.21089017, -0.24965811, 0.038767926]\n",
      "Iter 5575, loss [-0.19515114, -0.243135, 0.047983866]\n",
      "Iter 5576, loss [-0.2234059, -0.26232088, 0.038914975]\n",
      "Iter 5577, loss [-0.22391309, -0.2620684, 0.038155306]\n",
      "Iter 5578, loss [-0.22761095, -0.2638349, 0.03622394]\n",
      "Iter 5579, loss [-0.21937466, -0.2575428, 0.038168132]\n",
      "Iter 5580, loss [-0.175476, -0.22542156, 0.049945563]\n",
      "Iter 5581, loss [-0.22627479, -0.2635099, 0.03723512]\n",
      "Iter 5582, loss [-0.22448799, -0.26159754, 0.03710955]\n",
      "Iter 5583, loss [-0.13641334, -0.19914268, 0.062729344]\n",
      "Iter 5584, loss [-0.2235217, -0.25795466, 0.034432963]\n",
      "Iter 5585, loss [-0.22414488, -0.26203492, 0.03789004]\n",
      "Iter 5586, loss [-0.23154674, -0.26698542, 0.03543867]\n",
      "Iter 5587, loss [-0.224473, -0.2609121, 0.0364391]\n",
      "Iter 5588, loss [-0.21744952, -0.2567652, 0.039315667]\n",
      "Iter 5589, loss [-0.22199969, -0.26134846, 0.039348762]\n",
      "Iter 5590, loss [-0.22334103, -0.26065847, 0.037317444]\n",
      "Iter 5591, loss [-0.21800143, -0.25728688, 0.039285444]\n",
      "Iter 5592, loss [-0.22332765, -0.26187763, 0.03854997]\n",
      "Iter 5593, loss [-0.17940062, -0.22942106, 0.050020438]\n",
      "Iter 5594, loss [-0.23179632, -0.26698497, 0.03518864]\n",
      "Iter 5595, loss [-0.21729127, -0.25627083, 0.038979568]\n",
      "Iter 5596, loss [-0.22014284, -0.2596751, 0.039532237]\n",
      "Iter 5597, loss [-0.23143153, -0.2672336, 0.035802085]\n",
      "Iter 5598, loss [-0.2291314, -0.2663665, 0.037235104]\n",
      "Iter 5599, loss [-0.21680526, -0.25715318, 0.040347915]\n",
      "Iter 5600, loss [-0.22824572, -0.26316765, 0.03492193]\n",
      "Iter 5601, loss [-0.17915565, -0.23133895, 0.0521833]\n",
      "Iter 5602, loss [-0.22834568, -0.26518434, 0.03683867]\n",
      "Iter 5603, loss [-0.22675389, -0.26336336, 0.03660947]\n",
      "Iter 5604, loss [-0.21301234, -0.25289568, 0.039883353]\n",
      "Iter 5605, loss [-0.22914997, -0.26282373, 0.033673756]\n",
      "Iter 5606, loss [-0.22644936, -0.2627544, 0.036305055]\n",
      "Iter 5607, loss [-0.22575915, -0.26509064, 0.039331492]\n",
      "Iter 5608, loss [-0.22111766, -0.26161033, 0.04049267]\n",
      "Iter 5609, loss [-0.2275434, -0.26619625, 0.03865285]\n",
      "Iter 5610, loss [-0.21465519, -0.2564306, 0.041775398]\n",
      "Iter 5611, loss [-0.23366994, -0.2687391, 0.03506916]\n",
      "Iter 5612, loss [-0.2253128, -0.26319623, 0.03788344]\n",
      "Iter 5613, loss [-0.22250324, -0.2583789, 0.03587565]\n",
      "Iter 5614, loss [-0.23216024, -0.26616403, 0.034003787]\n",
      "Iter 5615, loss [-0.18694839, -0.23884742, 0.051899027]\n",
      "Iter 5616, loss [-0.21149018, -0.25210708, 0.0406169]\n",
      "Iter 5617, loss [-0.22657207, -0.26495725, 0.03838518]\n",
      "Iter 5618, loss [-0.22757874, -0.26381284, 0.036234092]\n",
      "Iter 5619, loss [-0.2228345, -0.26108152, 0.03824701]\n",
      "Iter 5620, loss [-0.21948114, -0.25855848, 0.039077338]\n",
      "Iter 5621, loss [-0.23089527, -0.2672791, 0.036383823]\n",
      "Iter 5622, loss [-0.22194734, -0.26039433, 0.03844699]\n",
      "Iter 5623, loss [-0.21985301, -0.25608677, 0.03623375]\n",
      "Iter 5624, loss [-0.2237535, -0.25987247, 0.03611897]\n",
      "Iter 5625, loss [-0.22299857, -0.25915223, 0.03615366]\n",
      "Iter 5626, loss [-0.2297989, -0.26468486, 0.03488596]\n",
      "Iter 5627, loss [-0.24081936, -0.27647275, 0.03565338]\n",
      "Iter 5628, loss [-0.23022696, -0.2674395, 0.03721255]\n",
      "Iter 5629, loss [-0.20055778, -0.24032675, 0.03976896]\n",
      "Iter 5630, loss [-0.15527749, -0.21215442, 0.056876928]\n",
      "Iter 5631, loss [-0.21845388, -0.25445306, 0.035999183]\n",
      "Iter 5632, loss [-0.15866902, -0.21332207, 0.05465304]\n",
      "Iter 5633, loss [-0.22977287, -0.26479915, 0.035026275]\n",
      "Iter 5634, loss [-0.22018357, -0.25991154, 0.039727967]\n",
      "Iter 5635, loss [-0.16373627, -0.22344339, 0.059707116]\n",
      "Iter 5636, loss [-0.21618691, -0.25631508, 0.04012818]\n",
      "Iter 5637, loss [-0.21869498, -0.25942698, 0.04073199]\n",
      "Iter 5638, loss [-0.22360921, -0.26123464, 0.037625432]\n",
      "Iter 5639, loss [-0.227014, -0.26496816, 0.037954148]\n",
      "Iter 5640, loss [-0.22151184, -0.25869563, 0.03718379]\n",
      "Iter 5641, loss [-0.23074915, -0.26798055, 0.0372314]\n",
      "Iter 5642, loss [-0.21764532, -0.25689253, 0.039247215]\n",
      "Iter 5643, loss [-0.22877003, -0.2654031, 0.03663306]\n",
      "Iter 5644, loss [-0.21108203, -0.25319853, 0.042116504]\n",
      "Iter 5645, loss [-0.22057429, -0.25802255, 0.037448257]\n",
      "Iter 5646, loss [-0.22140855, -0.26070532, 0.03929677]\n",
      "Iter 5647, loss [-0.22932431, -0.26586416, 0.036539853]\n",
      "Iter 5648, loss [-0.22477467, -0.26193544, 0.03716077]\n",
      "Iter 5649, loss [-0.13028912, -0.18394037, 0.053651243]\n",
      "Iter 5650, loss [-0.23340844, -0.26777875, 0.034370314]\n",
      "Iter 5651, loss [-0.2105341, -0.24866098, 0.038126886]\n",
      "Iter 5652, loss [-0.22056296, -0.25945237, 0.0388894]\n",
      "Iter 5653, loss [-0.23140305, -0.26849055, 0.037087508]\n",
      "Iter 5654, loss [-0.22747569, -0.26537046, 0.03789477]\n",
      "Iter 5655, loss [-0.22830237, -0.2657665, 0.037464123]\n",
      "Iter 5656, loss [-0.21520053, -0.2574103, 0.042209756]\n",
      "Iter 5657, loss [-0.21812855, -0.2573414, 0.039212864]\n",
      "Iter 5658, loss [-0.21566021, -0.25477555, 0.039115336]\n",
      "Iter 5659, loss [-0.22638494, -0.26351425, 0.037129305]\n",
      "Iter 5660, loss [-0.21609049, -0.25446144, 0.03837095]\n",
      "Iter 5661, loss [-0.22247672, -0.2593288, 0.036852084]\n",
      "Iter 5662, loss [-0.23072432, -0.26727876, 0.03655444]\n",
      "Iter 5663, loss [-0.23035106, -0.26667008, 0.036319017]\n",
      "Iter 5664, loss [-0.225941, -0.26375526, 0.037814252]\n",
      "Iter 5665, loss [-0.2346623, -0.26923773, 0.03457543]\n",
      "Iter 5666, loss [-0.23058885, -0.2661492, 0.035560347]\n",
      "Iter 5667, loss [-0.21550953, -0.255178, 0.039668478]\n",
      "Iter 5668, loss [-0.22827333, -0.26418597, 0.03591263]\n",
      "Iter 5669, loss [-0.21410471, -0.25466985, 0.040565126]\n",
      "Iter 5670, loss [-0.22352, -0.26358002, 0.04006003]\n",
      "Iter 5671, loss [-0.22118619, -0.25850752, 0.03732133]\n",
      "Iter 5672, loss [-0.22179994, -0.2602121, 0.03841216]\n",
      "Iter 5673, loss [-0.22423759, -0.26394087, 0.03970328]\n",
      "Iter 5674, loss [-0.22282818, -0.26045164, 0.037623458]\n",
      "Iter 5675, loss [-0.21880803, -0.25684083, 0.0380328]\n",
      "Iter 5676, loss [-0.22860238, -0.26411548, 0.035513096]\n",
      "Iter 5677, loss [-0.19232252, -0.23660068, 0.044278152]\n",
      "Iter 5678, loss [-0.1571779, -0.21406871, 0.056890808]\n",
      "Iter 5679, loss [-0.18553115, -0.23734261, 0.051811453]\n",
      "Iter 5680, loss [-0.21982151, -0.2583202, 0.038498692]\n",
      "Iter 5681, loss [-0.22145191, -0.25965932, 0.03820742]\n",
      "Iter 5682, loss [-0.22966716, -0.26746216, 0.037795007]\n",
      "Iter 5683, loss [-0.22562411, -0.26246274, 0.03683863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5684, loss [-0.21688032, -0.2573136, 0.040433295]\n",
      "Iter 5685, loss [-0.23114088, -0.2698144, 0.03867352]\n",
      "Iter 5686, loss [-0.22746977, -0.2648836, 0.037413843]\n",
      "Iter 5687, loss [-0.22085483, -0.25730196, 0.03644712]\n",
      "Iter 5688, loss [-0.23079082, -0.26555464, 0.034763806]\n",
      "Iter 5689, loss [-0.22660992, -0.26451275, 0.037902825]\n",
      "Iter 5690, loss [-0.2223862, -0.2618197, 0.03943349]\n",
      "Iter 5691, loss [-0.22316557, -0.26160374, 0.03843818]\n",
      "Iter 5692, loss [-0.2316806, -0.268589, 0.036908396]\n",
      "Iter 5693, loss [-0.14965743, -0.21010958, 0.06045215]\n",
      "Iter 5694, loss [-0.21942249, -0.25686234, 0.037439846]\n",
      "Iter 5695, loss [-0.22417417, -0.26179278, 0.037618607]\n",
      "Iter 5696, loss [-0.22437698, -0.26100376, 0.036626793]\n",
      "Iter 5697, loss [-0.22201893, -0.2603585, 0.03833959]\n",
      "Iter 5698, loss [-0.18864487, -0.24003604, 0.051391166]\n",
      "Iter 5699, loss [-0.2305198, -0.26851797, 0.037998177]\n",
      "Iter 5700, loss [-0.21801037, -0.2581706, 0.04016023]\n",
      "Iter 5701, loss [-0.22324768, -0.26350862, 0.04026095]\n",
      "Iter 5702, loss [-0.223236, -0.2613734, 0.038137402]\n",
      "Iter 5703, loss [-0.22852942, -0.265031, 0.036501586]\n",
      "Iter 5704, loss [-0.22402015, -0.25880122, 0.034781076]\n",
      "Iter 5705, loss [-0.23285697, -0.26673275, 0.033875775]\n",
      "Iter 5706, loss [-0.15294637, -0.20830226, 0.055355888]\n",
      "Iter 5707, loss [-0.21469912, -0.25388882, 0.039189704]\n",
      "Iter 5708, loss [-0.22864188, -0.26448703, 0.03584514]\n",
      "Iter 5709, loss [-0.22248355, -0.2609759, 0.03849235]\n",
      "Iter 5710, loss [-0.22349702, -0.26386932, 0.040372297]\n",
      "Iter 5711, loss [-0.2275998, -0.2654096, 0.03780978]\n",
      "Iter 5712, loss [-0.22519937, -0.26294446, 0.037745096]\n",
      "Iter 5713, loss [-0.22259866, -0.2623334, 0.039734736]\n",
      "Iter 5714, loss [-0.2163298, -0.25527006, 0.038940262]\n",
      "Iter 5715, loss [-0.21428512, -0.25156766, 0.03728254]\n",
      "Iter 5716, loss [-0.23066233, -0.26656976, 0.035907432]\n",
      "Iter 5717, loss [-0.22392416, -0.26285145, 0.038927287]\n",
      "Iter 5718, loss [-0.22203073, -0.26028976, 0.03825903]\n",
      "Iter 5719, loss [-0.22375585, -0.26394853, 0.04019268]\n",
      "Iter 5720, loss [-0.22376847, -0.26277876, 0.039010286]\n",
      "Iter 5721, loss [-0.21770018, -0.2577798, 0.04007962]\n",
      "Iter 5722, loss [-0.2277215, -0.26414892, 0.036427423]\n",
      "Iter 5723, loss [-0.23497416, -0.27047464, 0.035500478]\n",
      "Iter 5724, loss [-0.22193286, -0.26064485, 0.038712002]\n",
      "Iter 5725, loss [-0.21744838, -0.25748095, 0.040032562]\n",
      "Iter 5726, loss [-0.23051003, -0.26677167, 0.036261648]\n",
      "Iter 5727, loss [-0.14735723, -0.20766813, 0.060310893]\n",
      "Iter 5728, loss [-0.20514259, -0.24562387, 0.040481284]\n",
      "Iter 5729, loss [-0.211231, -0.24901214, 0.03778114]\n",
      "Iter 5730, loss [-0.22794822, -0.26375794, 0.035809718]\n",
      "Iter 5731, loss [-0.22151238, -0.25932723, 0.037814856]\n",
      "Iter 5732, loss [-0.22489072, -0.26026088, 0.035370156]\n",
      "Iter 5733, loss [-0.22901064, -0.26807228, 0.039061643]\n",
      "Iter 5734, loss [-0.21849646, -0.25898555, 0.040489092]\n",
      "Iter 5735, loss [-0.22903216, -0.26629263, 0.037260465]\n",
      "Iter 5736, loss [-0.21646553, -0.25584707, 0.03938154]\n",
      "Iter 5737, loss [-0.23239335, -0.2670838, 0.034690436]\n",
      "Iter 5738, loss [-0.22048774, -0.2594399, 0.03895215]\n",
      "Iter 5739, loss [-0.21536826, -0.25234753, 0.03697927]\n",
      "Iter 5740, loss [-0.22605482, -0.26090965, 0.034854826]\n",
      "Iter 5741, loss [-0.22273403, -0.2592183, 0.036484268]\n",
      "Iter 5742, loss [-0.22402635, -0.26145127, 0.037424915]\n",
      "Iter 5743, loss [-0.22699559, -0.26350316, 0.036507577]\n",
      "Iter 5744, loss [-0.22183913, -0.25997573, 0.0381366]\n",
      "Iter 5745, loss [-0.21589538, -0.2566512, 0.040755816]\n",
      "Iter 5746, loss [-0.2282685, -0.26609543, 0.037826933]\n",
      "Iter 5747, loss [-0.22427778, -0.2625408, 0.03826301]\n",
      "Iter 5748, loss [-0.22346918, -0.2611701, 0.037700906]\n",
      "Iter 5749, loss [-0.22479895, -0.26329583, 0.03849688]\n",
      "Iter 5750, loss [-0.2091431, -0.24883354, 0.039690442]\n",
      "Iter 5751, loss [-0.22604758, -0.2653613, 0.039313734]\n",
      "Iter 5752, loss [-0.22552904, -0.26346296, 0.037933912]\n",
      "Iter 5753, loss [-0.22742534, -0.264769, 0.03734366]\n",
      "Iter 5754, loss [-0.22012304, -0.2599978, 0.039874773]\n",
      "Iter 5755, loss [-0.22470087, -0.2636913, 0.03899043]\n",
      "Iter 5756, loss [-0.22339073, -0.2619703, 0.038579583]\n",
      "Iter 5757, loss [-0.2284598, -0.2660217, 0.037561886]\n",
      "Iter 5758, loss [-0.23211175, -0.26869786, 0.036586102]\n",
      "Iter 5759, loss [-0.22547653, -0.26151317, 0.036036633]\n",
      "Iter 5760, loss [-0.21573567, -0.25584358, 0.0401079]\n",
      "Iter 5761, loss [-0.22315054, -0.2606514, 0.037500873]\n",
      "Iter 5762, loss [-0.21009101, -0.2512692, 0.04117818]\n",
      "Iter 5763, loss [-0.21797107, -0.25444597, 0.036474895]\n",
      "Iter 5764, loss [-0.21956816, -0.25775906, 0.038190894]\n",
      "Iter 5765, loss [-0.21510765, -0.25567737, 0.04056972]\n",
      "Iter 5766, loss [-0.22953147, -0.2651279, 0.03559643]\n",
      "Iter 5767, loss [-0.21359296, -0.2544444, 0.04085143]\n",
      "Iter 5768, loss [-0.21993269, -0.25819492, 0.03826223]\n",
      "Iter 5769, loss [-0.21526743, -0.25462073, 0.039353296]\n",
      "Iter 5770, loss [-0.21183807, -0.24924302, 0.037404954]\n",
      "Iter 5771, loss [-0.22048092, -0.2585249, 0.038043976]\n",
      "Iter 5772, loss [-0.22038849, -0.2597248, 0.039336305]\n",
      "Iter 5773, loss [-0.22367272, -0.26033077, 0.036658045]\n",
      "Iter 5774, loss [-0.21155402, -0.25224784, 0.040693816]\n",
      "Iter 5775, loss [-0.21150482, -0.25285572, 0.041350905]\n",
      "Iter 5776, loss [-0.21670692, -0.2566348, 0.03992788]\n",
      "Iter 5777, loss [-0.2244299, -0.259992, 0.03556209]\n",
      "Iter 5778, loss [-0.22799201, -0.26326162, 0.035269603]\n",
      "Iter 5779, loss [-0.22237626, -0.26043606, 0.03805981]\n",
      "Iter 5780, loss [-0.22540888, -0.26208135, 0.03667247]\n",
      "Iter 5781, loss [-0.22291377, -0.26112977, 0.038215987]\n",
      "Iter 5782, loss [-0.22216907, -0.26053435, 0.038365267]\n",
      "Iter 5783, loss [-0.22638124, -0.2621407, 0.035759453]\n",
      "Iter 5784, loss [-0.21767575, -0.25855196, 0.040876202]\n",
      "Iter 5785, loss [-0.2194497, -0.25965324, 0.04020354]\n",
      "Iter 5786, loss [-0.23278998, -0.26955757, 0.036767583]\n",
      "Iter 5787, loss [-0.22751056, -0.26347792, 0.03596736]\n",
      "Iter 5788, loss [-0.2346797, -0.26897302, 0.034293324]\n",
      "Iter 5789, loss [-0.23149633, -0.26726502, 0.03576868]\n",
      "Iter 5790, loss [-0.22440806, -0.2611042, 0.036696143]\n",
      "Iter 5791, loss [-0.21044001, -0.25177684, 0.04133683]\n",
      "Iter 5792, loss [-0.19731674, -0.24233, 0.045013256]\n",
      "Iter 5793, loss [-0.22420925, -0.26216906, 0.037959807]\n",
      "Iter 5794, loss [-0.18748409, -0.23298761, 0.045503523]\n",
      "Iter 5795, loss [-0.21806978, -0.25967172, 0.04160194]\n",
      "Iter 5796, loss [-0.22413374, -0.26196593, 0.037832182]\n",
      "Iter 5797, loss [-0.22407949, -0.26209396, 0.03801447]\n",
      "Iter 5798, loss [-0.21729505, -0.2596967, 0.04240164]\n",
      "Iter 5799, loss [-0.20482513, -0.2458341, 0.041008957]\n",
      "Iter 5800, loss [-0.22391586, -0.2602109, 0.03629504]\n",
      "Iter 5801, loss [-0.21880268, -0.25929755, 0.04049487]\n",
      "Iter 5802, loss [-0.21605006, -0.25523138, 0.039181326]\n",
      "Iter 5803, loss [-0.16227318, -0.21375898, 0.05148579]\n",
      "Iter 5804, loss [-0.22326338, -0.26263902, 0.039375626]\n",
      "Iter 5805, loss [-0.2208125, -0.2592279, 0.0384154]\n",
      "Iter 5806, loss [-0.22379637, -0.263521, 0.03972461]\n",
      "Iter 5807, loss [-0.22346479, -0.2616792, 0.03821441]\n",
      "Iter 5808, loss [-0.1470635, -0.2053652, 0.058301702]\n",
      "Iter 5809, loss [-0.21246965, -0.25216213, 0.039692476]\n",
      "Iter 5810, loss [-0.22999129, -0.26562396, 0.03563267]\n",
      "Iter 5811, loss [-0.21307404, -0.25264713, 0.039573085]\n",
      "Iter 5812, loss [-0.22897446, -0.26384464, 0.034870178]\n",
      "Iter 5813, loss [-0.21807113, -0.25670984, 0.03863872]\n",
      "Iter 5814, loss [-0.21695071, -0.25583485, 0.03888414]\n",
      "Iter 5815, loss [-0.22925994, -0.26811272, 0.038852774]\n",
      "Iter 5816, loss [-0.18955874, -0.23456143, 0.04500268]\n",
      "Iter 5817, loss [-0.22641073, -0.26405084, 0.037640106]\n",
      "Iter 5818, loss [-0.21890374, -0.25876746, 0.03986372]\n",
      "Iter 5819, loss [-0.22128882, -0.26206288, 0.040774062]\n",
      "Iter 5820, loss [-0.14772901, -0.20413604, 0.05640703]\n",
      "Iter 5821, loss [-0.17021339, -0.22595234, 0.055738956]\n",
      "Iter 5822, loss [-0.22668163, -0.2618508, 0.035169173]\n",
      "Iter 5823, loss [-0.19245301, -0.23974852, 0.047295507]\n",
      "Iter 5824, loss [-0.21925516, -0.25922045, 0.039965283]\n",
      "Iter 5825, loss [-0.2322756, -0.26828307, 0.036007468]\n",
      "Iter 5826, loss [-0.15256876, -0.21402973, 0.06146097]\n",
      "Iter 5827, loss [-0.20815036, -0.25111875, 0.042968385]\n",
      "Iter 5828, loss [-0.21994305, -0.2587644, 0.03882134]\n",
      "Iter 5829, loss [-0.22289404, -0.26082855, 0.03793451]\n",
      "Iter 5830, loss [-0.22032736, -0.25757405, 0.03724669]\n",
      "Iter 5831, loss [-0.22677796, -0.26400772, 0.03722976]\n",
      "Iter 5832, loss [-0.21887077, -0.25766435, 0.03879358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5833, loss [-0.14941874, -0.2091601, 0.05974137]\n",
      "Iter 5834, loss [-0.16442607, -0.2208061, 0.056380033]\n",
      "Iter 5835, loss [-0.19419158, -0.23660243, 0.042410847]\n",
      "Iter 5836, loss [-0.1958426, -0.24212018, 0.046277583]\n",
      "Iter 5837, loss [-0.22267336, -0.25883242, 0.03615907]\n",
      "Iter 5838, loss [-0.21393594, -0.25263354, 0.038697593]\n",
      "Iter 5839, loss [-0.22713447, -0.26403576, 0.036901303]\n",
      "Iter 5840, loss [-0.22581583, -0.2638877, 0.03807187]\n",
      "Iter 5841, loss [-0.22043625, -0.25966686, 0.039230615]\n",
      "Iter 5842, loss [-0.2287807, -0.26469028, 0.035909574]\n",
      "Iter 5843, loss [-0.22750734, -0.26317358, 0.035666246]\n",
      "Iter 5844, loss [-0.22107357, -0.26066428, 0.039590716]\n",
      "Iter 5845, loss [-0.23038289, -0.26487574, 0.034492847]\n",
      "Iter 5846, loss [-0.23074009, -0.26590326, 0.035163175]\n",
      "Iter 5847, loss [-0.20786801, -0.249624, 0.04175599]\n",
      "Iter 5848, loss [-0.21253575, -0.25304332, 0.04050757]\n",
      "Iter 5849, loss [-0.22928388, -0.26449338, 0.035209488]\n",
      "Iter 5850, loss [-0.22010894, -0.25930363, 0.03919469]\n",
      "Iter 5851, loss [-0.22515509, -0.26200956, 0.036854483]\n",
      "Iter 5852, loss [-0.22577055, -0.26375437, 0.037983816]\n",
      "Iter 5853, loss [-0.22044629, -0.25836146, 0.037915163]\n",
      "Iter 5854, loss [-0.2298767, -0.2647387, 0.034862004]\n",
      "Iter 5855, loss [-0.22255439, -0.26041386, 0.03785947]\n",
      "Iter 5856, loss [-0.2224402, -0.26060525, 0.038165044]\n",
      "Iter 5857, loss [-0.216994, -0.25607336, 0.039079357]\n",
      "Iter 5858, loss [-0.22363853, -0.26211834, 0.038479812]\n",
      "Iter 5859, loss [-0.22591762, -0.26311624, 0.037198618]\n",
      "Iter 5860, loss [-0.21582574, -0.25147218, 0.035646446]\n",
      "Iter 5861, loss [-0.22029114, -0.26003692, 0.03974577]\n",
      "Iter 5862, loss [-0.23186992, -0.2683126, 0.036442682]\n",
      "Iter 5863, loss [-0.17127779, -0.22587931, 0.054601528]\n",
      "Iter 5864, loss [-0.18540113, -0.23525125, 0.04985012]\n",
      "Iter 5865, loss [-0.22545996, -0.26296994, 0.037509985]\n",
      "Iter 5866, loss [-0.21957406, -0.2589515, 0.03937743]\n",
      "Iter 5867, loss [-0.22364134, -0.26255694, 0.038915604]\n",
      "Iter 5868, loss [-0.2153563, -0.25563577, 0.040279463]\n",
      "Iter 5869, loss [-0.22860119, -0.2662434, 0.03764221]\n",
      "Iter 5870, loss [-0.18461289, -0.23020615, 0.04559326]\n",
      "Iter 5871, loss [-0.2166644, -0.25828803, 0.04162362]\n",
      "Iter 5872, loss [-0.23097512, -0.26793888, 0.036963753]\n",
      "Iter 5873, loss [-0.213618, -0.25146407, 0.037846074]\n",
      "Iter 5874, loss [-0.23153704, -0.2666085, 0.035071455]\n",
      "Iter 5875, loss [-0.22450939, -0.26184568, 0.037336282]\n",
      "Iter 5876, loss [-0.12291778, -0.18833473, 0.065416954]\n",
      "Iter 5877, loss [-0.23060441, -0.2672942, 0.036689788]\n",
      "Iter 5878, loss [-0.22325799, -0.2567019, 0.033443898]\n",
      "Iter 5879, loss [-0.21729203, -0.25274837, 0.035456344]\n",
      "Iter 5880, loss [-0.21824923, -0.25081897, 0.03256973]\n",
      "Iter 5881, loss [-0.22411112, -0.25945786, 0.035346728]\n",
      "Iter 5882, loss [-0.22281285, -0.2584344, 0.035621565]\n",
      "Iter 5883, loss [-0.21234399, -0.2502698, 0.037925806]\n",
      "Iter 5884, loss [-0.21004668, -0.25091872, 0.040872045]\n",
      "Iter 5885, loss [-0.21146367, -0.2567464, 0.045282736]\n",
      "Iter 5886, loss [-0.20639944, -0.2458819, 0.039482467]\n",
      "Iter 5887, loss [-0.2266788, -0.2664203, 0.0397415]\n",
      "Iter 5888, loss [-0.2162293, -0.25792336, 0.04169406]\n",
      "Iter 5889, loss [-0.21695274, -0.25511694, 0.038164195]\n",
      "Iter 5890, loss [-0.22574288, -0.26251483, 0.036771946]\n",
      "Iter 5891, loss [-0.22645268, -0.2641607, 0.037708014]\n",
      "Iter 5892, loss [-0.22006375, -0.25953856, 0.039474815]\n",
      "Iter 5893, loss [-0.21308479, -0.24932772, 0.03624294]\n",
      "Iter 5894, loss [-0.22152598, -0.26086769, 0.039341703]\n",
      "Iter 5895, loss [-0.22101703, -0.26014972, 0.039132677]\n",
      "Iter 5896, loss [-0.21705286, -0.25623867, 0.039185807]\n",
      "Iter 5897, loss [-0.22065093, -0.25937063, 0.038719695]\n",
      "Iter 5898, loss [-0.21597695, -0.2556254, 0.039648443]\n",
      "Iter 5899, loss [-0.2195502, -0.25794554, 0.03839533]\n",
      "Iter 5900, loss [-0.21463276, -0.2505694, 0.03593664]\n",
      "Iter 5901, loss [-0.22674921, -0.26178274, 0.03503352]\n",
      "Iter 5902, loss [-0.20790407, -0.24847865, 0.04057458]\n",
      "Iter 5903, loss [-0.22434159, -0.26065123, 0.036309645]\n",
      "Iter 5904, loss [-0.22555204, -0.26245877, 0.036906734]\n",
      "Iter 5905, loss [-0.22561347, -0.26383403, 0.038220562]\n",
      "Iter 5906, loss [-0.22034791, -0.25967082, 0.039322916]\n",
      "Iter 5907, loss [-0.22374925, -0.26337194, 0.039622694]\n",
      "Iter 5908, loss [-0.22929765, -0.26595277, 0.03665511]\n",
      "Iter 5909, loss [-0.21531323, -0.25674295, 0.04142972]\n",
      "Iter 5910, loss [-0.2256298, -0.26414376, 0.03851395]\n",
      "Iter 5911, loss [-0.1876587, -0.23265763, 0.044998936]\n",
      "Iter 5912, loss [-0.22276786, -0.26098412, 0.03821626]\n",
      "Iter 5913, loss [-0.16989888, -0.21845359, 0.0485547]\n",
      "Iter 5914, loss [-0.19968383, -0.24534005, 0.045656215]\n",
      "Iter 5915, loss [-0.2302567, -0.26857254, 0.03831583]\n",
      "Iter 5916, loss [-0.22438112, -0.26488656, 0.040505446]\n",
      "Iter 5917, loss [-0.2219997, -0.2612054, 0.039205693]\n",
      "Iter 5918, loss [-0.21895038, -0.2600218, 0.041071426]\n",
      "Iter 5919, loss [-0.22534877, -0.2609628, 0.035614036]\n",
      "Iter 5920, loss [-0.19471888, -0.24336997, 0.048651084]\n",
      "Iter 5921, loss [-0.18081945, -0.23095365, 0.050134204]\n",
      "Iter 5922, loss [-0.21492454, -0.25620782, 0.041283272]\n",
      "Iter 5923, loss [-0.22488582, -0.2617597, 0.03687387]\n",
      "Iter 5924, loss [-0.21394062, -0.2543341, 0.040393475]\n",
      "Iter 5925, loss [-0.22623628, -0.2624091, 0.036172815]\n",
      "Iter 5926, loss [-0.2095, -0.25101757, 0.041517567]\n",
      "Iter 5927, loss [-0.21753597, -0.25852606, 0.04099008]\n",
      "Iter 5928, loss [-0.18196401, -0.23365077, 0.051686764]\n",
      "Iter 5929, loss [-0.22279319, -0.26244825, 0.039655052]\n",
      "Iter 5930, loss [-0.21444705, -0.2527899, 0.03834286]\n",
      "Iter 5931, loss [-0.22640756, -0.26211593, 0.035708368]\n",
      "Iter 5932, loss [-0.22363763, -0.2604781, 0.036840484]\n",
      "Iter 5933, loss [-0.22103831, -0.26146692, 0.040428605]\n",
      "Iter 5934, loss [-0.22519794, -0.2640679, 0.03886994]\n",
      "Iter 5935, loss [-0.21799272, -0.25683913, 0.0388464]\n",
      "Iter 5936, loss [-0.22553629, -0.2631925, 0.03765621]\n",
      "Iter 5937, loss [-0.22206107, -0.25659394, 0.034532875]\n",
      "Iter 5938, loss [-0.16504274, -0.22088517, 0.055842426]\n",
      "Iter 5939, loss [-0.22467877, -0.26290601, 0.03822724]\n",
      "Iter 5940, loss [-0.21362266, -0.25403893, 0.040416263]\n",
      "Iter 5941, loss [-0.21493742, -0.25391126, 0.03897384]\n",
      "Iter 5942, loss [-0.21949737, -0.25768155, 0.03818418]\n",
      "Iter 5943, loss [-0.2266075, -0.26346055, 0.036853038]\n",
      "Iter 5944, loss [-0.22340496, -0.26138106, 0.0379761]\n",
      "Iter 5945, loss [-0.21726944, -0.25641525, 0.039145812]\n",
      "Iter 5946, loss [-0.22758637, -0.2636004, 0.03601403]\n",
      "Iter 5947, loss [-0.222794, -0.26012447, 0.03733048]\n",
      "Iter 5948, loss [-0.22428006, -0.26199666, 0.037716597]\n",
      "Iter 5949, loss [-0.2080527, -0.25127026, 0.043217566]\n",
      "Iter 5950, loss [-0.21399024, -0.25254968, 0.03855943]\n",
      "Iter 5951, loss [-0.22598547, -0.26524764, 0.039262176]\n",
      "Iter 5952, loss [-0.20877194, -0.24966685, 0.040894914]\n",
      "Iter 5953, loss [-0.22712648, -0.26354158, 0.036415093]\n",
      "Iter 5954, loss [-0.22310206, -0.2601195, 0.03701743]\n",
      "Iter 5955, loss [-0.21681874, -0.25634348, 0.03952475]\n",
      "Iter 5956, loss [-0.18516622, -0.23547636, 0.050310135]\n",
      "Iter 5957, loss [-0.22322303, -0.26308352, 0.039860487]\n",
      "Iter 5958, loss [-0.2305192, -0.26817068, 0.037651483]\n",
      "Iter 5959, loss [-0.22642508, -0.2631643, 0.036739223]\n",
      "Iter 5960, loss [-0.21198776, -0.2517864, 0.039798655]\n",
      "Iter 5961, loss [-0.2239587, -0.26452953, 0.040570825]\n",
      "Iter 5962, loss [-0.14124002, -0.20108989, 0.05984987]\n",
      "Iter 5963, loss [-0.22314039, -0.26177016, 0.038629767]\n",
      "Iter 5964, loss [-0.22462226, -0.2630605, 0.038438242]\n",
      "Iter 5965, loss [-0.22385955, -0.26200363, 0.038144074]\n",
      "Iter 5966, loss [-0.22097757, -0.2591315, 0.03815391]\n",
      "Iter 5967, loss [-0.21902788, -0.25458091, 0.035553046]\n",
      "Iter 5968, loss [-0.21481013, -0.25490496, 0.04009482]\n",
      "Iter 5969, loss [-0.21341437, -0.25519392, 0.041779544]\n",
      "Iter 5970, loss [-0.21116258, -0.25201952, 0.040856946]\n",
      "Iter 5971, loss [-0.13303316, -0.19472288, 0.061689716]\n",
      "Iter 5972, loss [-0.2290659, -0.26466966, 0.035603754]\n",
      "Iter 5973, loss [-0.22302935, -0.26007596, 0.03704662]\n",
      "Iter 5974, loss [-0.22004052, -0.25662196, 0.036581438]\n",
      "Iter 5975, loss [-0.21887833, -0.25659513, 0.03771681]\n",
      "Iter 5976, loss [-0.2260158, -0.2623538, 0.03633801]\n",
      "Iter 5977, loss [-0.22080292, -0.2597713, 0.038968366]\n",
      "Iter 5978, loss [-0.21882938, -0.25767514, 0.038845763]\n",
      "Iter 5979, loss [-0.22269681, -0.25984693, 0.037150115]\n",
      "Iter 5980, loss [-0.22674266, -0.2640873, 0.037344627]\n",
      "Iter 5981, loss [-0.21807873, -0.2553479, 0.03726917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 5982, loss [-0.21826532, -0.2566245, 0.038359165]\n",
      "Iter 5983, loss [-0.17150654, -0.2258198, 0.054313257]\n",
      "Iter 5984, loss [-0.22703007, -0.2644346, 0.037404545]\n",
      "Iter 5985, loss [-0.21425244, -0.25331038, 0.039057948]\n",
      "Iter 5986, loss [-0.21424969, -0.25566658, 0.041416895]\n",
      "Iter 5987, loss [-0.21983811, -0.2592436, 0.039405495]\n",
      "Iter 5988, loss [-0.22374162, -0.25876838, 0.035026755]\n",
      "Iter 5989, loss [-0.21106955, -0.24963805, 0.03856849]\n",
      "Iter 5990, loss [-0.22686931, -0.2608193, 0.03394998]\n",
      "Iter 5991, loss [-0.22150704, -0.25834063, 0.03683358]\n",
      "Iter 5992, loss [-0.22269942, -0.25977728, 0.03707786]\n",
      "Iter 5993, loss [-0.18949604, -0.23735552, 0.04785947]\n",
      "Iter 5994, loss [-0.21994768, -0.25935438, 0.039406706]\n",
      "Iter 5995, loss [-0.22427243, -0.2625087, 0.03823626]\n",
      "Iter 5996, loss [-0.21646959, -0.25373724, 0.037267663]\n",
      "Iter 5997, loss [-0.21346405, -0.2517866, 0.038322546]\n",
      "Iter 5998, loss [-0.22685635, -0.26150617, 0.03464982]\n",
      "Iter 5999, loss [-0.2338814, -0.2676101, 0.033728704]\n",
      "Iter 6000, loss [-0.22618236, -0.26342648, 0.037244126]\n",
      "Iter 6001, loss [-0.22668305, -0.2641834, 0.037500344]\n",
      "Iter 6002, loss [-0.23354779, -0.26948372, 0.035935923]\n",
      "Iter 6003, loss [-0.21456636, -0.2563376, 0.041771244]\n",
      "Iter 6004, loss [-0.22338419, -0.26267025, 0.039286062]\n",
      "Iter 6005, loss [-0.222315, -0.2620229, 0.03970791]\n",
      "Iter 6006, loss [-0.22195582, -0.26014665, 0.038190827]\n",
      "Iter 6007, loss [-0.22274135, -0.26049793, 0.03775658]\n",
      "Iter 6008, loss [-0.22747147, -0.26259074, 0.03511926]\n",
      "Iter 6009, loss [-0.22051744, -0.26077333, 0.040255886]\n",
      "Iter 6010, loss [-0.21791255, -0.2558019, 0.03788933]\n",
      "Iter 6011, loss [-0.22486883, -0.26033044, 0.035461605]\n",
      "Iter 6012, loss [-0.22172779, -0.2583751, 0.036647327]\n",
      "Iter 6013, loss [-0.22680941, -0.26413405, 0.03732463]\n",
      "Iter 6014, loss [-0.21884947, -0.25921974, 0.04037027]\n",
      "Iter 6015, loss [-0.22186962, -0.26076946, 0.03889983]\n",
      "Iter 6016, loss [-0.22205642, -0.261569, 0.039512575]\n",
      "Iter 6017, loss [-0.22420709, -0.26199657, 0.03778948]\n",
      "Iter 6018, loss [-0.22914767, -0.2662238, 0.03707611]\n",
      "Iter 6019, loss [-0.22345671, -0.2608272, 0.037370503]\n",
      "Iter 6020, loss [-0.21128538, -0.24985075, 0.038565367]\n",
      "Iter 6021, loss [-0.20540416, -0.24658126, 0.04117709]\n",
      "Iter 6022, loss [-0.22701031, -0.26336178, 0.03635148]\n",
      "Iter 6023, loss [-0.22771515, -0.26554048, 0.03782533]\n",
      "Iter 6024, loss [-0.21284631, -0.253982, 0.04113569]\n",
      "Iter 6025, loss [-0.21327385, -0.25349757, 0.04022372]\n",
      "Iter 6026, loss [-0.2180337, -0.25747538, 0.039441675]\n",
      "Iter 6027, loss [-0.21657833, -0.25557852, 0.03900019]\n",
      "Iter 6028, loss [-0.22859395, -0.26630622, 0.03771227]\n",
      "Iter 6029, loss [-0.2240291, -0.26341605, 0.039386965]\n",
      "Iter 6030, loss [-0.22074759, -0.2575237, 0.036776103]\n",
      "Iter 6031, loss [-0.22398403, -0.2620653, 0.03808125]\n",
      "Iter 6032, loss [-0.21032134, -0.2518868, 0.041565478]\n",
      "Iter 6033, loss [-0.21392612, -0.25660506, 0.042678937]\n",
      "Iter 6034, loss [-0.22380811, -0.26235527, 0.038547166]\n",
      "Iter 6035, loss [-0.22366992, -0.26244798, 0.038778063]\n",
      "Iter 6036, loss [-0.20560408, -0.24874851, 0.043144435]\n",
      "Iter 6037, loss [-0.23041046, -0.26622164, 0.035811182]\n",
      "Iter 6038, loss [-0.20867574, -0.25025886, 0.041583117]\n",
      "Iter 6039, loss [-0.20688055, -0.24760935, 0.04072879]\n",
      "Iter 6040, loss [-0.20653465, -0.24680567, 0.04027102]\n",
      "Iter 6041, loss [-0.22215256, -0.26187766, 0.0397251]\n",
      "Iter 6042, loss [-0.21645336, -0.2543406, 0.03788723]\n",
      "Iter 6043, loss [-0.21535775, -0.25236145, 0.037003696]\n",
      "Iter 6044, loss [-0.22626133, -0.26190504, 0.035643708]\n",
      "Iter 6045, loss [-0.21394837, -0.25289935, 0.038950987]\n",
      "Iter 6046, loss [-0.22320834, -0.26176184, 0.038553506]\n",
      "Iter 6047, loss [-0.22757564, -0.26376015, 0.036184505]\n",
      "Iter 6048, loss [-0.22914168, -0.265787, 0.036645323]\n",
      "Iter 6049, loss [-0.23247102, -0.26774135, 0.035270326]\n",
      "Iter 6050, loss [-0.21432644, -0.25230372, 0.03797727]\n",
      "Iter 6051, loss [-0.22444844, -0.26233009, 0.03788164]\n",
      "Iter 6052, loss [-0.2256057, -0.26636633, 0.040760636]\n",
      "Iter 6053, loss [-0.22311229, -0.26270297, 0.03959068]\n",
      "Iter 6054, loss [-0.21848181, -0.2589528, 0.040470995]\n",
      "Iter 6055, loss [-0.21382967, -0.25332555, 0.03949589]\n",
      "Iter 6056, loss [-0.21656454, -0.25618663, 0.039622094]\n",
      "Iter 6057, loss [-0.23047078, -0.2660574, 0.035586625]\n",
      "Iter 6058, loss [-0.22274144, -0.25954357, 0.036802128]\n",
      "Iter 6059, loss [-0.21476617, -0.25320506, 0.038438883]\n",
      "Iter 6060, loss [-0.22322677, -0.2617803, 0.03855352]\n",
      "Iter 6061, loss [-0.22345144, -0.26073566, 0.037284225]\n",
      "Iter 6062, loss [-0.22305444, -0.2622332, 0.03917876]\n",
      "Iter 6063, loss [-0.2290334, -0.2650623, 0.03602891]\n",
      "Iter 6064, loss [-0.22908755, -0.26590824, 0.036820695]\n",
      "Iter 6065, loss [-0.22372912, -0.26158023, 0.03785111]\n",
      "Iter 6066, loss [-0.22619599, -0.26320076, 0.037004776]\n",
      "Iter 6067, loss [-0.23028764, -0.26664886, 0.03636121]\n",
      "Iter 6068, loss [-0.22638574, -0.26464334, 0.03825759]\n",
      "Iter 6069, loss [-0.20762208, -0.24871029, 0.0410882]\n",
      "Iter 6070, loss [-0.21981598, -0.26002273, 0.040206745]\n",
      "Iter 6071, loss [-0.22432154, -0.26164907, 0.03732752]\n",
      "Iter 6072, loss [-0.22479054, -0.26241794, 0.037627406]\n",
      "Iter 6073, loss [-0.21445958, -0.25420523, 0.039745644]\n",
      "Iter 6074, loss [-0.22032647, -0.25844738, 0.038120907]\n",
      "Iter 6075, loss [-0.23547916, -0.2703055, 0.034826353]\n",
      "Iter 6076, loss [-0.23123805, -0.26624346, 0.0350054]\n",
      "Iter 6077, loss [-0.23443079, -0.26968256, 0.035251774]\n",
      "Iter 6078, loss [-0.21881682, -0.25775605, 0.038939245]\n",
      "Iter 6079, loss [-0.21539685, -0.25686187, 0.04146502]\n",
      "Iter 6080, loss [-0.21966794, -0.26129466, 0.041626714]\n",
      "Iter 6081, loss [-0.21633656, -0.25770706, 0.041370492]\n",
      "Iter 6082, loss [-0.22867435, -0.26593038, 0.03725604]\n",
      "Iter 6083, loss [-0.22680794, -0.26378676, 0.036978826]\n",
      "Iter 6084, loss [-0.23027602, -0.26645234, 0.036176324]\n",
      "Iter 6085, loss [-0.13364658, -0.19252548, 0.058878895]\n",
      "Iter 6086, loss [-0.2252112, -0.2634144, 0.038203213]\n",
      "Iter 6087, loss [-0.21956831, -0.25909635, 0.039528042]\n",
      "Iter 6088, loss [-0.22424704, -0.26248804, 0.038241]\n",
      "Iter 6089, loss [-0.23185219, -0.26663917, 0.03478698]\n",
      "Iter 6090, loss [-0.2210587, -0.25922832, 0.03816962]\n",
      "Iter 6091, loss [-0.22111148, -0.25924876, 0.03813728]\n",
      "Iter 6092, loss [-0.22826928, -0.2639755, 0.03570623]\n",
      "Iter 6093, loss [-0.21380869, -0.25498345, 0.041174766]\n",
      "Iter 6094, loss [-0.23165727, -0.26831725, 0.036659982]\n",
      "Iter 6095, loss [-0.22304076, -0.26191962, 0.038878866]\n",
      "Iter 6096, loss [-0.20912805, -0.24996394, 0.040835895]\n",
      "Iter 6097, loss [-0.21480325, -0.255043, 0.04023975]\n",
      "Iter 6098, loss [-0.21360621, -0.25517917, 0.04157296]\n",
      "Iter 6099, loss [-0.21685039, -0.25632843, 0.03947805]\n",
      "Iter 6100, loss [-0.22529426, -0.26333317, 0.038038906]\n",
      "Iter 6101, loss [-0.21929154, -0.2573684, 0.03807684]\n",
      "Iter 6102, loss [-0.22137734, -0.26150897, 0.04013163]\n",
      "Iter 6103, loss [-0.21497066, -0.25641298, 0.04144232]\n",
      "Iter 6104, loss [-0.22818291, -0.2652241, 0.03704118]\n",
      "Iter 6105, loss [-0.22953974, -0.26454136, 0.03500162]\n",
      "Iter 6106, loss [-0.2255538, -0.2631364, 0.037582587]\n",
      "Iter 6107, loss [-0.22228596, -0.25911495, 0.036828987]\n",
      "Iter 6108, loss [-0.21713464, -0.2562732, 0.03913857]\n",
      "Iter 6109, loss [-0.22745709, -0.26360983, 0.036152735]\n",
      "Iter 6110, loss [-0.20933008, -0.2506882, 0.04135812]\n",
      "Iter 6111, loss [-0.21802115, -0.25766882, 0.039647676]\n",
      "Iter 6112, loss [-0.22013892, -0.25980163, 0.039662708]\n",
      "Iter 6113, loss [-0.22433509, -0.26258284, 0.03824775]\n",
      "Iter 6114, loss [-0.22452193, -0.26268074, 0.0381588]\n",
      "Iter 6115, loss [-0.24100229, -0.27539366, 0.034391366]\n",
      "Iter 6116, loss [-0.21966591, -0.2574024, 0.037736475]\n",
      "Iter 6117, loss [-0.22739163, -0.26518542, 0.037793778]\n",
      "Iter 6118, loss [-0.19194637, -0.24048778, 0.04854141]\n",
      "Iter 6119, loss [-0.21782285, -0.25834686, 0.040524013]\n",
      "Iter 6120, loss [-0.21309265, -0.25537968, 0.042287022]\n",
      "Iter 6121, loss [-0.19745824, -0.24227571, 0.04481747]\n",
      "Iter 6122, loss [-0.2206863, -0.25733855, 0.036652252]\n",
      "Iter 6123, loss [-0.22990415, -0.26506162, 0.035157464]\n",
      "Iter 6124, loss [-0.22049832, -0.25879756, 0.038299236]\n",
      "Iter 6125, loss [-0.21693751, -0.25561297, 0.038675454]\n",
      "Iter 6126, loss [-0.22141758, -0.26021406, 0.03879648]\n",
      "Iter 6127, loss [-0.22414917, -0.26291186, 0.03876268]\n",
      "Iter 6128, loss [-0.19202702, -0.23880194, 0.046774924]\n",
      "Iter 6129, loss [-0.22018963, -0.25937724, 0.039187618]\n",
      "Iter 6130, loss [-0.22306801, -0.26158834, 0.03852032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6131, loss [-0.2226864, -0.26245734, 0.039770946]\n",
      "Iter 6132, loss [-0.2174468, -0.25701806, 0.03957126]\n",
      "Iter 6133, loss [-0.22594407, -0.26070017, 0.0347561]\n",
      "Iter 6134, loss [-0.23440322, -0.26886714, 0.03446391]\n",
      "Iter 6135, loss [-0.16289657, -0.21553922, 0.052642643]\n",
      "Iter 6136, loss [-0.1852022, -0.23409721, 0.048895016]\n",
      "Iter 6137, loss [-0.22859102, -0.2649839, 0.03639286]\n",
      "Iter 6138, loss [-0.23373118, -0.26805478, 0.034323603]\n",
      "Iter 6139, loss [-0.1858741, -0.23554094, 0.049666844]\n",
      "Iter 6140, loss [-0.23192376, -0.26829162, 0.036367856]\n",
      "Iter 6141, loss [-0.21284504, -0.25019625, 0.037351202]\n",
      "Iter 6142, loss [-0.2294662, -0.2665558, 0.037089594]\n",
      "Iter 6143, loss [-0.18646654, -0.23742662, 0.05096008]\n",
      "Iter 6144, loss [-0.21437415, -0.25416633, 0.039792176]\n",
      "Iter 6145, loss [-0.2276491, -0.26344767, 0.035798572]\n",
      "Iter 6146, loss [-0.22729814, -0.2656514, 0.038353257]\n",
      "Iter 6147, loss [-0.22952002, -0.26925325, 0.03973323]\n",
      "Iter 6148, loss [-0.20089781, -0.24638599, 0.04548818]\n",
      "Iter 6149, loss [-0.17571434, -0.22677842, 0.051064067]\n",
      "Iter 6150, loss [-0.21854924, -0.2566612, 0.03811197]\n",
      "Iter 6151, loss [-0.21856165, -0.25635645, 0.0377948]\n",
      "Iter 6152, loss [-0.22373842, -0.26137856, 0.03764014]\n",
      "Iter 6153, loss [-0.23086435, -0.26536483, 0.03450048]\n",
      "Iter 6154, loss [-0.2289461, -0.26525185, 0.036305737]\n",
      "Iter 6155, loss [-0.2280136, -0.26500928, 0.03699568]\n",
      "Iter 6156, loss [-0.21868914, -0.25758052, 0.038891368]\n",
      "Iter 6157, loss [-0.22434147, -0.26338232, 0.039040845]\n",
      "Iter 6158, loss [-0.22405037, -0.26140165, 0.037351288]\n",
      "Iter 6159, loss [-0.21365964, -0.2518286, 0.03816896]\n",
      "Iter 6160, loss [-0.22991028, -0.2652609, 0.03535063]\n",
      "Iter 6161, loss [-0.21620044, -0.2558843, 0.03968384]\n",
      "Iter 6162, loss [-0.21821326, -0.2536254, 0.035412125]\n",
      "Iter 6163, loss [-0.21484978, -0.25251836, 0.03766857]\n",
      "Iter 6164, loss [-0.22783437, -0.2648058, 0.036971413]\n",
      "Iter 6165, loss [-0.21970777, -0.2605573, 0.040849518]\n",
      "Iter 6166, loss [-0.22222392, -0.2592879, 0.037063967]\n",
      "Iter 6167, loss [-0.22659385, -0.2651367, 0.038542844]\n",
      "Iter 6168, loss [-0.23071441, -0.26642108, 0.03570666]\n",
      "Iter 6169, loss [-0.2302959, -0.26603377, 0.035737865]\n",
      "Iter 6170, loss [-0.22791752, -0.26367897, 0.035761446]\n",
      "Iter 6171, loss [-0.22522414, -0.26444456, 0.039220423]\n",
      "Iter 6172, loss [-0.22818711, -0.263854, 0.03566689]\n",
      "Iter 6173, loss [-0.22538137, -0.26328743, 0.037906058]\n",
      "Iter 6174, loss [-0.22212075, -0.26072577, 0.038605016]\n",
      "Iter 6175, loss [-0.22430545, -0.2602381, 0.03593266]\n",
      "Iter 6176, loss [-0.20599076, -0.24902551, 0.04303474]\n",
      "Iter 6177, loss [-0.20859043, -0.24971329, 0.04112285]\n",
      "Iter 6178, loss [-0.20619437, -0.2469154, 0.040721025]\n",
      "Iter 6179, loss [-0.23149651, -0.26669067, 0.03519416]\n",
      "Iter 6180, loss [-0.23086917, -0.26668626, 0.035817083]\n",
      "Iter 6181, loss [-0.22168301, -0.26022965, 0.03854664]\n",
      "Iter 6182, loss [-0.15752943, -0.21082033, 0.053290904]\n",
      "Iter 6183, loss [-0.20104703, -0.24784282, 0.04679578]\n",
      "Iter 6184, loss [-0.2272288, -0.26477984, 0.03755103]\n",
      "Iter 6185, loss [-0.22554773, -0.26347864, 0.0379309]\n",
      "Iter 6186, loss [-0.22443312, -0.26054385, 0.036110725]\n",
      "Iter 6187, loss [-0.22732854, -0.26323748, 0.035908937]\n",
      "Iter 6188, loss [-0.1942306, -0.23981749, 0.045586884]\n",
      "Iter 6189, loss [-0.23092438, -0.26630327, 0.035378885]\n",
      "Iter 6190, loss [-0.2164039, -0.2546024, 0.0381985]\n",
      "Iter 6191, loss [-0.22633427, -0.26230273, 0.035968453]\n",
      "Iter 6192, loss [-0.21927515, -0.2598434, 0.04056827]\n",
      "Iter 6193, loss [-0.22182037, -0.26048055, 0.03866018]\n",
      "Iter 6194, loss [-0.21868193, -0.25787592, 0.039193995]\n",
      "Iter 6195, loss [-0.22361875, -0.26115698, 0.03753823]\n",
      "Iter 6196, loss [-0.21675317, -0.25445017, 0.037697002]\n",
      "Iter 6197, loss [-0.2122862, -0.25093937, 0.038653165]\n",
      "Iter 6198, loss [-0.23051065, -0.26564735, 0.035136692]\n",
      "Iter 6199, loss [-0.2299752, -0.26708323, 0.037108026]\n",
      "Iter 6200, loss [-0.22096956, -0.25888795, 0.037918396]\n",
      "Iter 6201, loss [-0.22780669, -0.26503748, 0.037230797]\n",
      "Iter 6202, loss [-0.22356664, -0.26317176, 0.039605122]\n",
      "Iter 6203, loss [-0.21456552, -0.25592205, 0.041356526]\n",
      "Iter 6204, loss [-0.20050427, -0.24221021, 0.041705936]\n",
      "Iter 6205, loss [-0.22331558, -0.2619143, 0.03859873]\n",
      "Iter 6206, loss [-0.23139887, -0.26689696, 0.0354981]\n",
      "Iter 6207, loss [-0.22631273, -0.26321214, 0.036899414]\n",
      "Iter 6208, loss [-0.22080831, -0.25814012, 0.037331805]\n",
      "Iter 6209, loss [-0.22743824, -0.2650811, 0.037642863]\n",
      "Iter 6210, loss [-0.21783456, -0.25735593, 0.039521363]\n",
      "Iter 6211, loss [-0.19469067, -0.23635541, 0.041664742]\n",
      "Iter 6212, loss [-0.22456461, -0.26191315, 0.03734854]\n",
      "Iter 6213, loss [-0.21778873, -0.25627622, 0.038487487]\n",
      "Iter 6214, loss [-0.21518634, -0.25398237, 0.03879602]\n",
      "Iter 6215, loss [-0.22707495, -0.26280242, 0.03572748]\n",
      "Iter 6216, loss [-0.21777569, -0.25652385, 0.03874816]\n",
      "Iter 6217, loss [-0.22573388, -0.26367235, 0.037938483]\n",
      "Iter 6218, loss [-0.22273335, -0.26222032, 0.039486982]\n",
      "Iter 6219, loss [-0.21480592, -0.25377393, 0.03896801]\n",
      "Iter 6220, loss [-0.17235944, -0.22519411, 0.05283467]\n",
      "Iter 6221, loss [-0.2228736, -0.2612695, 0.03839591]\n",
      "Iter 6222, loss [-0.22014096, -0.25863576, 0.038494788]\n",
      "Iter 6223, loss [-0.21299312, -0.2531149, 0.04012179]\n",
      "Iter 6224, loss [-0.21268862, -0.25289303, 0.0402044]\n",
      "Iter 6225, loss [-0.22464263, -0.26180628, 0.037163645]\n",
      "Iter 6226, loss [-0.20554082, -0.24949746, 0.043956637]\n",
      "Iter 6227, loss [-0.2269191, -0.26410562, 0.03718652]\n",
      "Iter 6228, loss [-0.21114129, -0.25452244, 0.043381155]\n",
      "Iter 6229, loss [-0.22355056, -0.26137453, 0.037823983]\n",
      "Iter 6230, loss [-0.21993873, -0.25871032, 0.0387716]\n",
      "Iter 6231, loss [-0.22766007, -0.26460958, 0.0369495]\n",
      "Iter 6232, loss [-0.22726691, -0.2641165, 0.03684959]\n",
      "Iter 6233, loss [-0.22224721, -0.2599656, 0.03771838]\n",
      "Iter 6234, loss [-0.22771063, -0.26415864, 0.036447998]\n",
      "Iter 6235, loss [-0.23217264, -0.2695343, 0.037361648]\n",
      "Iter 6236, loss [-0.22780855, -0.26566184, 0.037853282]\n",
      "Iter 6237, loss [-0.16341193, -0.21621905, 0.052807122]\n",
      "Iter 6238, loss [-0.2190735, -0.25815874, 0.03908524]\n",
      "Iter 6239, loss [-0.23154345, -0.26911676, 0.037573315]\n",
      "Iter 6240, loss [-0.23133543, -0.26734447, 0.03600904]\n",
      "Iter 6241, loss [-0.23121831, -0.26763913, 0.03642083]\n",
      "Iter 6242, loss [-0.2152921, -0.25481048, 0.03951838]\n",
      "Iter 6243, loss [-0.22414377, -0.2616595, 0.037515722]\n",
      "Iter 6244, loss [-0.22383723, -0.26331383, 0.039476603]\n",
      "Iter 6245, loss [-0.23272398, -0.2672307, 0.0345067]\n",
      "Iter 6246, loss [-0.23229226, -0.26718754, 0.034895275]\n",
      "Iter 6247, loss [-0.22870132, -0.2658519, 0.03715059]\n",
      "Iter 6248, loss [-0.22399563, -0.26220113, 0.038205504]\n",
      "Iter 6249, loss [-0.22424474, -0.2627956, 0.038550854]\n",
      "Iter 6250, loss [-0.23227854, -0.26906663, 0.03678809]\n",
      "Iter 6251, loss [-0.22392553, -0.26364142, 0.03971589]\n",
      "Iter 6252, loss [-0.21786627, -0.25810048, 0.040234204]\n",
      "Iter 6253, loss [-0.21088395, -0.25247064, 0.04158669]\n",
      "Iter 6254, loss [-0.22436145, -0.26137918, 0.037017725]\n",
      "Iter 6255, loss [-0.21468833, -0.25379035, 0.03910201]\n",
      "Iter 6256, loss [-0.21781728, -0.2546305, 0.036813226]\n",
      "Iter 6257, loss [-0.22165969, -0.25942564, 0.037765943]\n",
      "Iter 6258, loss [-0.22049426, -0.25769076, 0.037196502]\n",
      "Iter 6259, loss [-0.2253749, -0.26114956, 0.035774644]\n",
      "Iter 6260, loss [-0.213192, -0.25121802, 0.03802602]\n",
      "Iter 6261, loss [-0.22603157, -0.26465428, 0.038622703]\n",
      "Iter 6262, loss [-0.197388, -0.24381955, 0.046431553]\n",
      "Iter 6263, loss [-0.22668628, -0.26362744, 0.036941152]\n",
      "Iter 6264, loss [-0.22566652, -0.26337776, 0.03771124]\n",
      "Iter 6265, loss [-0.1660381, -0.21917926, 0.05314116]\n",
      "Iter 6266, loss [-0.21182325, -0.25241268, 0.04058943]\n",
      "Iter 6267, loss [-0.2175116, -0.26031277, 0.04280117]\n",
      "Iter 6268, loss [-0.21156737, -0.25280732, 0.041239943]\n",
      "Iter 6269, loss [-0.22671892, -0.26499483, 0.038275912]\n",
      "Iter 6270, loss [-0.2233381, -0.26211113, 0.03877303]\n",
      "Iter 6271, loss [-0.22382104, -0.26267508, 0.038854033]\n",
      "Iter 6272, loss [-0.21464078, -0.2531292, 0.038488433]\n",
      "Iter 6273, loss [-0.22429058, -0.26144782, 0.03715723]\n",
      "Iter 6274, loss [-0.22177693, -0.25994793, 0.038170993]\n",
      "Iter 6275, loss [-0.21601562, -0.2539617, 0.03794609]\n",
      "Iter 6276, loss [-0.22816141, -0.26617768, 0.03801628]\n",
      "Iter 6277, loss [-0.21361195, -0.25366402, 0.040052075]\n",
      "Iter 6278, loss [-0.22636583, -0.26604572, 0.039679892]\n",
      "Iter 6279, loss [-0.22237563, -0.26266435, 0.040288717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6280, loss [-0.2165229, -0.25682205, 0.040299155]\n",
      "Iter 6281, loss [-0.22441, -0.26274893, 0.038338922]\n",
      "Iter 6282, loss [-0.21321416, -0.25095633, 0.037742175]\n",
      "Iter 6283, loss [-0.21723488, -0.25426748, 0.0370326]\n",
      "Iter 6284, loss [-0.22818929, -0.26374945, 0.035560157]\n",
      "Iter 6285, loss [-0.22072408, -0.26031268, 0.039588593]\n",
      "Iter 6286, loss [-0.17995545, -0.2349324, 0.054976948]\n",
      "Iter 6287, loss [-0.22481607, -0.2637882, 0.038972124]\n",
      "Iter 6288, loss [-0.16430864, -0.2187743, 0.054465666]\n",
      "Iter 6289, loss [-0.217096, -0.25709555, 0.039999537]\n",
      "Iter 6290, loss [-0.20770921, -0.25124687, 0.043537658]\n",
      "Iter 6291, loss [-0.22617227, -0.26587656, 0.039704293]\n",
      "Iter 6292, loss [-0.22657523, -0.26420274, 0.037627526]\n",
      "Iter 6293, loss [-0.22881883, -0.2649014, 0.036082562]\n",
      "Iter 6294, loss [-0.21615839, -0.25272545, 0.03656707]\n",
      "Iter 6295, loss [-0.22606917, -0.2606908, 0.034621637]\n",
      "Iter 6296, loss [-0.22469097, -0.26184297, 0.03715199]\n",
      "Iter 6297, loss [-0.22676805, -0.26218003, 0.035411984]\n",
      "Iter 6298, loss [-0.22428024, -0.2619545, 0.037674252]\n",
      "Iter 6299, loss [-0.22954297, -0.26724684, 0.03770388]\n",
      "Iter 6300, loss [-0.21774778, -0.25907192, 0.04132414]\n",
      "Iter 6301, loss [-0.22045341, -0.26112062, 0.040667202]\n",
      "Iter 6302, loss [-0.22487547, -0.262968, 0.038092535]\n",
      "Iter 6303, loss [-0.2235482, -0.26075572, 0.037207514]\n",
      "Iter 6304, loss [-0.22363164, -0.2616367, 0.038005065]\n",
      "Iter 6305, loss [-0.20565975, -0.24731247, 0.041652717]\n",
      "Iter 6306, loss [-0.23154515, -0.26659048, 0.035045333]\n",
      "Iter 6307, loss [-0.22747412, -0.26380858, 0.036334462]\n",
      "Iter 6308, loss [-0.19574857, -0.24103087, 0.04528231]\n",
      "Iter 6309, loss [-0.18841399, -0.24189368, 0.053479683]\n",
      "Iter 6310, loss [-0.2250704, -0.26373878, 0.03866838]\n",
      "Iter 6311, loss [-0.21048668, -0.250744, 0.040257305]\n",
      "Iter 6312, loss [-0.21999145, -0.25998494, 0.039993502]\n",
      "Iter 6313, loss [-0.22022793, -0.26044956, 0.040221628]\n",
      "Iter 6314, loss [-0.2093029, -0.25127432, 0.041971408]\n",
      "Iter 6315, loss [-0.2234881, -0.2574678, 0.0339797]\n",
      "Iter 6316, loss [-0.2134377, -0.25059462, 0.03715691]\n",
      "Iter 6317, loss [-0.22590573, -0.26345077, 0.03754504]\n",
      "Iter 6318, loss [-0.20575982, -0.24629155, 0.04053172]\n",
      "Iter 6319, loss [-0.21504568, -0.25479695, 0.039751273]\n",
      "Iter 6320, loss [-0.2235341, -0.26039982, 0.03686571]\n",
      "Iter 6321, loss [-0.21752998, -0.25812584, 0.040595856]\n",
      "Iter 6322, loss [-0.22357538, -0.2633714, 0.039796017]\n",
      "Iter 6323, loss [-0.22352171, -0.26438043, 0.040858723]\n",
      "Iter 6324, loss [-0.22892407, -0.26505476, 0.036130693]\n",
      "Iter 6325, loss [-0.22353974, -0.26128381, 0.03774408]\n",
      "Iter 6326, loss [-0.23229557, -0.2663316, 0.034036037]\n",
      "Iter 6327, loss [-0.22578618, -0.26241475, 0.03662858]\n",
      "Iter 6328, loss [-0.2322674, -0.26669192, 0.03442453]\n",
      "Iter 6329, loss [-0.22892176, -0.26637533, 0.037453577]\n",
      "Iter 6330, loss [-0.22796363, -0.2641342, 0.036170572]\n",
      "Iter 6331, loss [-0.22840668, -0.26508892, 0.036682233]\n",
      "Iter 6332, loss [-0.21182068, -0.25582767, 0.04400699]\n",
      "Iter 6333, loss [-0.22602268, -0.26515278, 0.039130103]\n",
      "Iter 6334, loss [-0.2110594, -0.25427637, 0.04321696]\n",
      "Iter 6335, loss [-0.21707356, -0.2569855, 0.039911933]\n",
      "Iter 6336, loss [-0.23118936, -0.26723337, 0.036044013]\n",
      "Iter 6337, loss [-0.22853039, -0.26477462, 0.036244225]\n",
      "Iter 6338, loss [-0.19926664, -0.24285157, 0.043584928]\n",
      "Iter 6339, loss [-0.21673045, -0.25653645, 0.039806016]\n",
      "Iter 6340, loss [-0.1821955, -0.23127596, 0.04908046]\n",
      "Iter 6341, loss [-0.2241016, -0.26227042, 0.038168818]\n",
      "Iter 6342, loss [-0.22869104, -0.26660946, 0.037918415]\n",
      "Iter 6343, loss [-0.216633, -0.25790924, 0.04127623]\n",
      "Iter 6344, loss [-0.2278325, -0.26547125, 0.037638754]\n",
      "Iter 6345, loss [-0.22546463, -0.26302227, 0.037557643]\n",
      "Iter 6346, loss [-0.22482368, -0.2606023, 0.03577862]\n",
      "Iter 6347, loss [-0.22963844, -0.2657623, 0.036123853]\n",
      "Iter 6348, loss [-0.2212309, -0.2601622, 0.038931306]\n",
      "Iter 6349, loss [-0.22913654, -0.2671619, 0.03802536]\n",
      "Iter 6350, loss [-0.21723004, -0.2572867, 0.040056657]\n",
      "Iter 6351, loss [-0.22216406, -0.26127672, 0.039112657]\n",
      "Iter 6352, loss [-0.21600881, -0.2563808, 0.04037199]\n",
      "Iter 6353, loss [-0.21715268, -0.25585708, 0.0387044]\n",
      "Iter 6354, loss [-0.22830467, -0.26326168, 0.034957003]\n",
      "Iter 6355, loss [-0.22601867, -0.26304153, 0.037022866]\n",
      "Iter 6356, loss [-0.21799287, -0.25823793, 0.04024505]\n",
      "Iter 6357, loss [-0.2252951, -0.26266906, 0.037373953]\n",
      "Iter 6358, loss [-0.21642673, -0.2556995, 0.039272763]\n",
      "Iter 6359, loss [-0.23072152, -0.2685426, 0.03782107]\n",
      "Iter 6360, loss [-0.18558165, -0.23519985, 0.049618196]\n",
      "Iter 6361, loss [-0.23395464, -0.26971895, 0.03576431]\n",
      "Iter 6362, loss [-0.21609984, -0.25573766, 0.039637815]\n",
      "Iter 6363, loss [-0.22711639, -0.264456, 0.03733961]\n",
      "Iter 6364, loss [-0.2184227, -0.2578594, 0.039436713]\n",
      "Iter 6365, loss [-0.22751896, -0.26367348, 0.036154523]\n",
      "Iter 6366, loss [-0.17894866, -0.22177154, 0.04282288]\n",
      "Iter 6367, loss [-0.22121385, -0.25744897, 0.036235124]\n",
      "Iter 6368, loss [-0.2282218, -0.26399967, 0.035777867]\n",
      "Iter 6369, loss [-0.21773434, -0.25775787, 0.040023535]\n",
      "Iter 6370, loss [-0.22221813, -0.2604752, 0.03825706]\n",
      "Iter 6371, loss [-0.2296185, -0.2652429, 0.035624396]\n",
      "Iter 6372, loss [-0.23449469, -0.26945776, 0.03496308]\n",
      "Iter 6373, loss [-0.20902672, -0.25084352, 0.04181681]\n",
      "Iter 6374, loss [-0.22254051, -0.25994006, 0.037399545]\n",
      "Iter 6375, loss [-0.22309609, -0.2600499, 0.036953818]\n",
      "Iter 6376, loss [-0.16754664, -0.22124638, 0.05369973]\n",
      "Iter 6377, loss [-0.2144044, -0.2528859, 0.0384815]\n",
      "Iter 6378, loss [-0.2176646, -0.2572139, 0.039549284]\n",
      "Iter 6379, loss [-0.22825646, -0.2664883, 0.03823185]\n",
      "Iter 6380, loss [-0.219706, -0.25720033, 0.037494324]\n",
      "Iter 6381, loss [-0.22259761, -0.26081496, 0.038217355]\n",
      "Iter 6382, loss [-0.1973026, -0.24024242, 0.042939823]\n",
      "Iter 6383, loss [-0.20741732, -0.25020587, 0.04278855]\n",
      "Iter 6384, loss [-0.21231696, -0.24870464, 0.03638769]\n",
      "Iter 6385, loss [-0.23410825, -0.26952928, 0.035421025]\n",
      "Iter 6386, loss [-0.23067945, -0.26556104, 0.034881584]\n",
      "Iter 6387, loss [-0.21588017, -0.25372607, 0.037845895]\n",
      "Iter 6388, loss [-0.22234711, -0.26226312, 0.039916]\n",
      "Iter 6389, loss [-0.22383624, -0.26304555, 0.039209306]\n",
      "Iter 6390, loss [-0.22458482, -0.26441625, 0.039831437]\n",
      "Iter 6391, loss [-0.22154236, -0.26036248, 0.03882011]\n",
      "Iter 6392, loss [-0.22289053, -0.2606696, 0.037779063]\n",
      "Iter 6393, loss [-0.2260552, -0.26100704, 0.034951836]\n",
      "Iter 6394, loss [-0.23146012, -0.26688796, 0.03542783]\n",
      "Iter 6395, loss [-0.22630192, -0.2650821, 0.038780168]\n",
      "Iter 6396, loss [-0.16368303, -0.22319992, 0.0595169]\n",
      "Iter 6397, loss [-0.21152931, -0.25324553, 0.041716214]\n",
      "Iter 6398, loss [-0.22357029, -0.26218632, 0.03861603]\n",
      "Iter 6399, loss [-0.2155309, -0.255505, 0.0399741]\n",
      "Iter 6400, loss [-0.22217575, -0.26087755, 0.038701795]\n",
      "Iter 6401, loss [-0.22692111, -0.26332533, 0.03640422]\n",
      "Iter 6402, loss [-0.22663316, -0.26159567, 0.034962513]\n",
      "Iter 6403, loss [-0.21942759, -0.25772738, 0.03829979]\n",
      "Iter 6404, loss [-0.22500506, -0.26291576, 0.037910692]\n",
      "Iter 6405, loss [-0.21919714, -0.25830346, 0.03910632]\n",
      "Iter 6406, loss [-0.21694976, -0.25618133, 0.039231576]\n",
      "Iter 6407, loss [-0.22009845, -0.25869867, 0.03860022]\n",
      "Iter 6408, loss [-0.22562188, -0.26330343, 0.03768155]\n",
      "Iter 6409, loss [-0.22198252, -0.25951535, 0.03753282]\n",
      "Iter 6410, loss [-0.2267232, -0.26322693, 0.03650374]\n",
      "Iter 6411, loss [-0.23355964, -0.26800764, 0.034447998]\n",
      "Iter 6412, loss [-0.22333483, -0.26032418, 0.036989342]\n",
      "Iter 6413, loss [-0.21768145, -0.25440618, 0.03672473]\n",
      "Iter 6414, loss [-0.20949689, -0.24909294, 0.039596044]\n",
      "Iter 6415, loss [-0.213643, -0.2533254, 0.0396824]\n",
      "Iter 6416, loss [-0.20465219, -0.24700499, 0.04235279]\n",
      "Iter 6417, loss [-0.22354867, -0.26247784, 0.03892918]\n",
      "Iter 6418, loss [-0.23502815, -0.27126175, 0.036233597]\n",
      "Iter 6419, loss [-0.21728262, -0.25782967, 0.040547043]\n",
      "Iter 6420, loss [-0.2254974, -0.26209423, 0.036596835]\n",
      "Iter 6421, loss [-0.23078254, -0.26922786, 0.03844532]\n",
      "Iter 6422, loss [-0.22112454, -0.25920132, 0.038076773]\n",
      "Iter 6423, loss [-0.2238568, -0.2626245, 0.038767688]\n",
      "Iter 6424, loss [-0.22316398, -0.2626786, 0.039514616]\n",
      "Iter 6425, loss [-0.23039262, -0.26661628, 0.03622366]\n",
      "Iter 6426, loss [-0.22061098, -0.25851774, 0.037906766]\n",
      "Iter 6427, loss [-0.2263092, -0.26370507, 0.03739588]\n",
      "Iter 6428, loss [-0.22432876, -0.2630405, 0.038711764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6429, loss [-0.21541837, -0.25306174, 0.03764338]\n",
      "Iter 6430, loss [-0.22104043, -0.2604696, 0.03942915]\n",
      "Iter 6431, loss [-0.22252312, -0.2595906, 0.037067465]\n",
      "Iter 6432, loss [-0.21228625, -0.2543502, 0.042063937]\n",
      "Iter 6433, loss [-0.2272357, -0.26469374, 0.037458032]\n",
      "Iter 6434, loss [-0.2220239, -0.2597384, 0.037714474]\n",
      "Iter 6435, loss [-0.22339864, -0.26191974, 0.038521096]\n",
      "Iter 6436, loss [-0.16700482, -0.2195237, 0.052518874]\n",
      "Iter 6437, loss [-0.21255288, -0.255658, 0.043105133]\n",
      "Iter 6438, loss [-0.24080165, -0.2758179, 0.03501625]\n",
      "Iter 6439, loss [-0.2288351, -0.26626348, 0.037428375]\n",
      "Iter 6440, loss [-0.21596037, -0.25508893, 0.039128557]\n",
      "Iter 6441, loss [-0.22703642, -0.26539692, 0.038360514]\n",
      "Iter 6442, loss [-0.21338579, -0.25262108, 0.03923529]\n",
      "Iter 6443, loss [-0.2171574, -0.25601017, 0.03885278]\n",
      "Iter 6444, loss [-0.22091776, -0.25946343, 0.03854566]\n",
      "Iter 6445, loss [-0.2263989, -0.2630686, 0.036669683]\n",
      "Iter 6446, loss [-0.21498315, -0.25624943, 0.041266277]\n",
      "Iter 6447, loss [-0.2291674, -0.26667383, 0.03750644]\n",
      "Iter 6448, loss [-0.21882369, -0.25825784, 0.03943415]\n",
      "Iter 6449, loss [-0.22381605, -0.26222053, 0.038404476]\n",
      "Iter 6450, loss [-0.21988669, -0.26021698, 0.0403303]\n",
      "Iter 6451, loss [-0.22556637, -0.25948763, 0.033921253]\n",
      "Iter 6452, loss [-0.206043, -0.2490387, 0.042995684]\n",
      "Iter 6453, loss [-0.22949779, -0.26626337, 0.036765575]\n",
      "Iter 6454, loss [-0.23218288, -0.26835516, 0.036172286]\n",
      "Iter 6455, loss [-0.22850618, -0.26549202, 0.036985844]\n",
      "Iter 6456, loss [-0.23009196, -0.26527464, 0.035182677]\n",
      "Iter 6457, loss [-0.22578907, -0.26405737, 0.038268294]\n",
      "Iter 6458, loss [-0.15990613, -0.21588038, 0.055974245]\n",
      "Iter 6459, loss [-0.22684559, -0.26299044, 0.036144856]\n",
      "Iter 6460, loss [-0.22351626, -0.26232624, 0.03880998]\n",
      "Iter 6461, loss [-0.22695783, -0.26398575, 0.03702792]\n",
      "Iter 6462, loss [-0.21719427, -0.25730622, 0.040111944]\n",
      "Iter 6463, loss [-0.22023886, -0.262382, 0.042143144]\n",
      "Iter 6464, loss [-0.22514266, -0.26395437, 0.038811706]\n",
      "Iter 6465, loss [-0.21418867, -0.25510988, 0.04092121]\n",
      "Iter 6466, loss [-0.21839207, -0.25518653, 0.03679446]\n",
      "Iter 6467, loss [-0.22687916, -0.2667096, 0.039830428]\n",
      "Iter 6468, loss [-0.21876678, -0.25974166, 0.040974885]\n",
      "Iter 6469, loss [-0.19936278, -0.24365525, 0.044292457]\n",
      "Iter 6470, loss [-0.19752014, -0.24131212, 0.043791976]\n",
      "Iter 6471, loss [-0.1845316, -0.22914036, 0.044608764]\n",
      "Iter 6472, loss [-0.21860397, -0.25778756, 0.03918358]\n",
      "Iter 6473, loss [-0.21139123, -0.25247926, 0.041088026]\n",
      "Iter 6474, loss [-0.21879476, -0.25823206, 0.039437298]\n",
      "Iter 6475, loss [-0.23048778, -0.26693997, 0.03645219]\n",
      "Iter 6476, loss [-0.21904236, -0.25855663, 0.039514273]\n",
      "Iter 6477, loss [-0.21693307, -0.25589338, 0.038960304]\n",
      "Iter 6478, loss [-0.22771987, -0.2642267, 0.036506828]\n",
      "Iter 6479, loss [-0.23364887, -0.2682012, 0.034552343]\n",
      "Iter 6480, loss [-0.22854358, -0.26635763, 0.03781405]\n",
      "Iter 6481, loss [-0.22486699, -0.2635785, 0.038711518]\n",
      "Iter 6482, loss [-0.22906129, -0.26564535, 0.036584064]\n",
      "Iter 6483, loss [-0.20159099, -0.24103884, 0.039447866]\n",
      "Iter 6484, loss [-0.22611089, -0.26150292, 0.03539203]\n",
      "Iter 6485, loss [-0.22559139, -0.26286492, 0.03727352]\n",
      "Iter 6486, loss [-0.22649296, -0.26376182, 0.037268862]\n",
      "Iter 6487, loss [-0.20640531, -0.25016037, 0.04375505]\n",
      "Iter 6488, loss [-0.22378261, -0.26234815, 0.03856553]\n",
      "Iter 6489, loss [-0.22072898, -0.25909695, 0.03836797]\n",
      "Iter 6490, loss [-0.229481, -0.26731485, 0.03783385]\n",
      "Iter 6491, loss [-0.22457483, -0.2600901, 0.03551528]\n",
      "Iter 6492, loss [-0.22505012, -0.26219887, 0.037148744]\n",
      "Iter 6493, loss [-0.21079424, -0.2514695, 0.04067526]\n",
      "Iter 6494, loss [-0.22406162, -0.2623546, 0.03829299]\n",
      "Iter 6495, loss [-0.22636224, -0.26512578, 0.038763538]\n",
      "Iter 6496, loss [-0.22678542, -0.26371503, 0.036929607]\n",
      "Iter 6497, loss [-0.22350389, -0.26237947, 0.038875576]\n",
      "Iter 6498, loss [-0.2198802, -0.25851312, 0.038632937]\n",
      "Iter 6499, loss [-0.22244512, -0.2581709, 0.035725784]\n",
      "Iter 6500, loss [-0.20960316, -0.24984069, 0.04023753]\n",
      "Iter 6501, loss [-0.21797399, -0.255226, 0.03725199]\n",
      "Iter 6502, loss [-0.22400871, -0.26259932, 0.03859061]\n",
      "Iter 6503, loss [-0.22200885, -0.26192343, 0.03991457]\n",
      "Iter 6504, loss [-0.21655266, -0.257926, 0.041373324]\n",
      "Iter 6505, loss [-0.22851312, -0.26634088, 0.03782776]\n",
      "Iter 6506, loss [-0.22199862, -0.26136538, 0.039366767]\n",
      "Iter 6507, loss [-0.21863842, -0.2554946, 0.036856174]\n",
      "Iter 6508, loss [-0.21169603, -0.2526607, 0.040964656]\n",
      "Iter 6509, loss [-0.17877, -0.21846008, 0.03969007]\n",
      "Iter 6510, loss [-0.22742543, -0.26342347, 0.035998043]\n",
      "Iter 6511, loss [-0.20594242, -0.2476486, 0.041706175]\n",
      "Iter 6512, loss [-0.15590255, -0.21078548, 0.054882925]\n",
      "Iter 6513, loss [-0.22803684, -0.26583275, 0.03779592]\n",
      "Iter 6514, loss [-0.23048249, -0.26805434, 0.03757184]\n",
      "Iter 6515, loss [-0.2272757, -0.26685044, 0.039574735]\n",
      "Iter 6516, loss [-0.15697023, -0.21377748, 0.056807257]\n",
      "Iter 6517, loss [-0.2306677, -0.2686389, 0.03797121]\n",
      "Iter 6518, loss [-0.21959652, -0.25849256, 0.038896035]\n",
      "Iter 6519, loss [-0.23039815, -0.26634997, 0.03595183]\n",
      "Iter 6520, loss [-0.22995019, -0.26544058, 0.035490386]\n",
      "Iter 6521, loss [-0.22658414, -0.263078, 0.036493875]\n",
      "Iter 6522, loss [-0.20265219, -0.24400747, 0.04135528]\n",
      "Iter 6523, loss [-0.22099026, -0.2601683, 0.03917806]\n",
      "Iter 6524, loss [-0.19871911, -0.24507815, 0.04635904]\n",
      "Iter 6525, loss [-0.21753043, -0.25466236, 0.03713193]\n",
      "Iter 6526, loss [-0.21560846, -0.2544929, 0.038884446]\n",
      "Iter 6527, loss [-0.22299013, -0.25843403, 0.03544391]\n",
      "Iter 6528, loss [-0.21805395, -0.25710285, 0.039048895]\n",
      "Iter 6529, loss [-0.2082088, -0.25058255, 0.042373743]\n",
      "Iter 6530, loss [-0.22526848, -0.2639867, 0.03871823]\n",
      "Iter 6531, loss [-0.1913154, -0.24043927, 0.049123865]\n",
      "Iter 6532, loss [-0.22358969, -0.2636624, 0.04007271]\n",
      "Iter 6533, loss [-0.21899438, -0.2593051, 0.04031071]\n",
      "Iter 6534, loss [-0.19587678, -0.24402736, 0.04815058]\n",
      "Iter 6535, loss [-0.22695264, -0.26495624, 0.038003586]\n",
      "Iter 6536, loss [-0.21431127, -0.2538563, 0.039545022]\n",
      "Iter 6537, loss [-0.23223636, -0.26546282, 0.033226453]\n",
      "Iter 6538, loss [-0.22844797, -0.26294354, 0.03449556]\n",
      "Iter 6539, loss [-0.22603083, -0.2601968, 0.03416598]\n",
      "Iter 6540, loss [-0.21756431, -0.2560357, 0.03847137]\n",
      "Iter 6541, loss [-0.22414249, -0.26253313, 0.038390636]\n",
      "Iter 6542, loss [-0.22043353, -0.2598975, 0.039463967]\n",
      "Iter 6543, loss [-0.22708724, -0.2635454, 0.036458146]\n",
      "Iter 6544, loss [-0.21751568, -0.25705278, 0.039537102]\n",
      "Iter 6545, loss [-0.21639489, -0.25635874, 0.039963856]\n",
      "Iter 6546, loss [-0.22170344, -0.2591638, 0.037460364]\n",
      "Iter 6547, loss [-0.2251017, -0.25848404, 0.03338234]\n",
      "Iter 6548, loss [-0.22127852, -0.257742, 0.03646347]\n",
      "Iter 6549, loss [-0.22491412, -0.26195478, 0.037040662]\n",
      "Iter 6550, loss [-0.23204246, -0.26717952, 0.035137065]\n",
      "Iter 6551, loss [-0.22784957, -0.26591983, 0.03807026]\n",
      "Iter 6552, loss [-0.23320197, -0.26989424, 0.036692273]\n",
      "Iter 6553, loss [-0.2175201, -0.25709638, 0.039576273]\n",
      "Iter 6554, loss [-0.22297251, -0.26096812, 0.037995603]\n",
      "Iter 6555, loss [-0.21931717, -0.25736645, 0.038049273]\n",
      "Iter 6556, loss [-0.22054294, -0.25851294, 0.037970003]\n",
      "Iter 6557, loss [-0.22129776, -0.25889885, 0.037601095]\n",
      "Iter 6558, loss [-0.2186824, -0.25760922, 0.038926825]\n",
      "Iter 6559, loss [-0.2227298, -0.2619354, 0.039205607]\n",
      "Iter 6560, loss [-0.21800978, -0.25727245, 0.039262667]\n",
      "Iter 6561, loss [-0.22598891, -0.26414725, 0.038158342]\n",
      "Iter 6562, loss [-0.22453503, -0.25996482, 0.035429794]\n",
      "Iter 6563, loss [-0.15771356, -0.2119011, 0.054187533]\n",
      "Iter 6564, loss [-0.22675066, -0.26149035, 0.034739688]\n",
      "Iter 6565, loss [-0.17372023, -0.2261197, 0.052399468]\n",
      "Iter 6566, loss [-0.22453335, -0.26288787, 0.038354512]\n",
      "Iter 6567, loss [-0.19541876, -0.24439737, 0.04897861]\n",
      "Iter 6568, loss [-0.217796, -0.25964624, 0.04185023]\n",
      "Iter 6569, loss [-0.23333892, -0.27150652, 0.038167603]\n",
      "Iter 6570, loss [-0.21690166, -0.2568457, 0.03994406]\n",
      "Iter 6571, loss [-0.2262098, -0.2643444, 0.038134586]\n",
      "Iter 6572, loss [-0.226836, -0.26450112, 0.03766512]\n",
      "Iter 6573, loss [-0.21134414, -0.2497406, 0.038396463]\n",
      "Iter 6574, loss [-0.2264398, -0.2631508, 0.036711015]\n",
      "Iter 6575, loss [-0.2192621, -0.25782958, 0.038567476]\n",
      "Iter 6576, loss [-0.23347375, -0.2679633, 0.034489535]\n",
      "Iter 6577, loss [-0.19401492, -0.24172153, 0.0477066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6578, loss [-0.20826477, -0.24995607, 0.04169131]\n",
      "Iter 6579, loss [-0.21784964, -0.2582107, 0.04036104]\n",
      "Iter 6580, loss [-0.22522527, -0.26312637, 0.037901096]\n",
      "Iter 6581, loss [-0.2214804, -0.25906855, 0.037588157]\n",
      "Iter 6582, loss [-0.22777146, -0.26519862, 0.037427153]\n",
      "Iter 6583, loss [-0.2169494, -0.25648677, 0.03953737]\n",
      "Iter 6584, loss [-0.22393121, -0.26339024, 0.039459035]\n",
      "Iter 6585, loss [-0.22717012, -0.26371014, 0.036540017]\n",
      "Iter 6586, loss [-0.22632237, -0.26299614, 0.036673766]\n",
      "Iter 6587, loss [-0.21725005, -0.25768352, 0.04043346]\n",
      "Iter 6588, loss [-0.2195012, -0.2593452, 0.039844006]\n",
      "Iter 6589, loss [-0.23030642, -0.26648846, 0.036182053]\n",
      "Iter 6590, loss [-0.15657331, -0.21190053, 0.055327218]\n",
      "Iter 6591, loss [-0.21993132, -0.25810692, 0.038175594]\n",
      "Iter 6592, loss [-0.21996722, -0.25827786, 0.038310647]\n",
      "Iter 6593, loss [-0.2164808, -0.25720882, 0.040728018]\n",
      "Iter 6594, loss [-0.22585888, -0.26276013, 0.036901247]\n",
      "Iter 6595, loss [-0.22230476, -0.2615461, 0.03924134]\n",
      "Iter 6596, loss [-0.22142789, -0.25933015, 0.03790226]\n",
      "Iter 6597, loss [-0.22249788, -0.26139218, 0.038894303]\n",
      "Iter 6598, loss [-0.21469125, -0.25424945, 0.0395582]\n",
      "Iter 6599, loss [-0.21546145, -0.25487623, 0.03941478]\n",
      "Iter 6600, loss [-0.22188057, -0.25852823, 0.036647663]\n",
      "Iter 6601, loss [-0.22230107, -0.259341, 0.03703993]\n",
      "Iter 6602, loss [-0.22521284, -0.2630214, 0.03780856]\n",
      "Iter 6603, loss [-0.2231904, -0.26101175, 0.03782136]\n",
      "Iter 6604, loss [-0.22219789, -0.26254755, 0.040349662]\n",
      "Iter 6605, loss [-0.21396515, -0.25483721, 0.04087206]\n",
      "Iter 6606, loss [-0.21996278, -0.2601804, 0.04021763]\n",
      "Iter 6607, loss [-0.21969184, -0.25723273, 0.037540883]\n",
      "Iter 6608, loss [-0.22603104, -0.2607369, 0.03470587]\n",
      "Iter 6609, loss [-0.21192726, -0.2517818, 0.03985452]\n",
      "Iter 6610, loss [-0.17217343, -0.22678664, 0.054613214]\n",
      "Iter 6611, loss [-0.2229294, -0.25999448, 0.037065074]\n",
      "Iter 6612, loss [-0.21486133, -0.25602004, 0.041158702]\n",
      "Iter 6613, loss [-0.22571449, -0.26299667, 0.037282184]\n",
      "Iter 6614, loss [-0.18293285, -0.23345664, 0.05052378]\n",
      "Iter 6615, loss [-0.22707015, -0.2643375, 0.037267357]\n",
      "Iter 6616, loss [-0.2199606, -0.25866905, 0.03870844]\n",
      "Iter 6617, loss [-0.22134149, -0.25920093, 0.03785944]\n",
      "Iter 6618, loss [-0.222007, -0.25974867, 0.037741657]\n",
      "Iter 6619, loss [-0.21746373, -0.25842872, 0.040964983]\n",
      "Iter 6620, loss [-0.16820347, -0.22215804, 0.053954564]\n",
      "Iter 6621, loss [-0.22746028, -0.26400495, 0.036544666]\n",
      "Iter 6622, loss [-0.2188335, -0.2583145, 0.039480977]\n",
      "Iter 6623, loss [-0.2303865, -0.26594406, 0.035557576]\n",
      "Iter 6624, loss [-0.22588778, -0.26564586, 0.039758086]\n",
      "Iter 6625, loss [-0.23109044, -0.26834276, 0.037252318]\n",
      "Iter 6626, loss [-0.19495088, -0.24073556, 0.04578469]\n",
      "Iter 6627, loss [-0.2272925, -0.26480967, 0.03751717]\n",
      "Iter 6628, loss [-0.20501238, -0.251751, 0.046738617]\n",
      "Iter 6629, loss [-0.22025841, -0.26034942, 0.04009101]\n",
      "Iter 6630, loss [-0.22191274, -0.2619489, 0.040036168]\n",
      "Iter 6631, loss [-0.18874022, -0.23740844, 0.048668217]\n",
      "Iter 6632, loss [-0.22554466, -0.26190788, 0.036363207]\n",
      "Iter 6633, loss [-0.2230581, -0.2623569, 0.0392988]\n",
      "Iter 6634, loss [-0.23105487, -0.26541567, 0.034360804]\n",
      "Iter 6635, loss [-0.23397635, -0.26996347, 0.035987124]\n",
      "Iter 6636, loss [-0.22663131, -0.26599473, 0.03936341]\n",
      "Iter 6637, loss [-0.22876735, -0.26596236, 0.03719501]\n",
      "Iter 6638, loss [-0.22610328, -0.26313877, 0.037035488]\n",
      "Iter 6639, loss [-0.223324, -0.26251763, 0.039193626]\n",
      "Iter 6640, loss [-0.23309287, -0.2702697, 0.037176814]\n",
      "Iter 6641, loss [-0.21993876, -0.25925738, 0.039318614]\n",
      "Iter 6642, loss [-0.1891388, -0.24079847, 0.05165967]\n",
      "Iter 6643, loss [-0.22563091, -0.26220113, 0.036570214]\n",
      "Iter 6644, loss [-0.2308837, -0.2674799, 0.03659619]\n",
      "Iter 6645, loss [-0.22071709, -0.2604877, 0.039770618]\n",
      "Iter 6646, loss [-0.22806634, -0.26566544, 0.0375991]\n",
      "Iter 6647, loss [-0.19556536, -0.24086781, 0.045302447]\n",
      "Iter 6648, loss [-0.16088241, -0.22127594, 0.06039352]\n",
      "Iter 6649, loss [-0.22053696, -0.2607862, 0.04024924]\n",
      "Iter 6650, loss [-0.21707267, -0.2561534, 0.03908073]\n",
      "Iter 6651, loss [-0.23072016, -0.2654795, 0.034759343]\n",
      "Iter 6652, loss [-0.23383096, -0.26799795, 0.034167]\n",
      "Iter 6653, loss [-0.21152794, -0.2532536, 0.041725658]\n",
      "Iter 6654, loss [-0.21590953, -0.2556069, 0.03969736]\n",
      "Iter 6655, loss [-0.20083976, -0.23921469, 0.03837493]\n",
      "Iter 6656, loss [-0.22152701, -0.2600393, 0.038512286]\n",
      "Iter 6657, loss [-0.21216202, -0.25199762, 0.039835595]\n",
      "Iter 6658, loss [-0.22997545, -0.266354, 0.036378548]\n",
      "Iter 6659, loss [-0.21580651, -0.25709927, 0.04129275]\n",
      "Iter 6660, loss [-0.22690861, -0.26167932, 0.03477071]\n",
      "Iter 6661, loss [-0.22144899, -0.26097357, 0.03952459]\n",
      "Iter 6662, loss [-0.2303264, -0.265433, 0.035106614]\n",
      "Iter 6663, loss [-0.2134696, -0.2530639, 0.0395943]\n",
      "Iter 6664, loss [-0.2292628, -0.26491702, 0.03565421]\n",
      "Iter 6665, loss [-0.14793131, -0.20202295, 0.054091647]\n",
      "Iter 6666, loss [-0.16726303, -0.22343162, 0.056168582]\n",
      "Iter 6667, loss [-0.21706747, -0.25817186, 0.04110439]\n",
      "Iter 6668, loss [-0.22228637, -0.26174814, 0.03946176]\n",
      "Iter 6669, loss [-0.21985605, -0.260088, 0.040231943]\n",
      "Iter 6670, loss [-0.21804245, -0.2570433, 0.039000858]\n",
      "Iter 6671, loss [-0.22662914, -0.26344857, 0.036819436]\n",
      "Iter 6672, loss [-0.2163294, -0.2503026, 0.03397321]\n",
      "Iter 6673, loss [-0.23081493, -0.26588827, 0.03507334]\n",
      "Iter 6674, loss [-0.21722187, -0.25350413, 0.036282253]\n",
      "Iter 6675, loss [-0.2236774, -0.26080617, 0.03712877]\n",
      "Iter 6676, loss [-0.2204985, -0.26108077, 0.04058227]\n",
      "Iter 6677, loss [-0.20252949, -0.25046444, 0.047934946]\n",
      "Iter 6678, loss [-0.21934547, -0.25874987, 0.039404403]\n",
      "Iter 6679, loss [-0.2229124, -0.2602737, 0.037361294]\n",
      "Iter 6680, loss [-0.22784151, -0.2640031, 0.036161583]\n",
      "Iter 6681, loss [-0.23187774, -0.26662797, 0.034750223]\n",
      "Iter 6682, loss [-0.22734609, -0.26409504, 0.03674894]\n",
      "Iter 6683, loss [-0.16946954, -0.22032955, 0.05086001]\n",
      "Iter 6684, loss [-0.22675434, -0.26335877, 0.036604434]\n",
      "Iter 6685, loss [-0.16114098, -0.22076678, 0.059625812]\n",
      "Iter 6686, loss [-0.22338691, -0.26224202, 0.0388551]\n",
      "Iter 6687, loss [-0.17897534, -0.23125514, 0.052279796]\n",
      "Iter 6688, loss [-0.17154458, -0.22623971, 0.05469513]\n",
      "Iter 6689, loss [-0.21968679, -0.25713217, 0.037445378]\n",
      "Iter 6690, loss [-0.22449328, -0.26213565, 0.037642375]\n",
      "Iter 6691, loss [-0.2293686, -0.26713407, 0.03776548]\n",
      "Iter 6692, loss [-0.22210005, -0.2610227, 0.03892263]\n",
      "Iter 6693, loss [-0.22457847, -0.26357308, 0.038994614]\n",
      "Iter 6694, loss [-0.23062222, -0.26839146, 0.037769243]\n",
      "Iter 6695, loss [-0.2245299, -0.263108, 0.03857808]\n",
      "Iter 6696, loss [-0.22817513, -0.26595423, 0.03777909]\n",
      "Iter 6697, loss [-0.22517034, -0.26267707, 0.03750673]\n",
      "Iter 6698, loss [-0.20530975, -0.24314995, 0.037840195]\n",
      "Iter 6699, loss [-0.19352868, -0.23887405, 0.045345366]\n",
      "Iter 6700, loss [-0.22158617, -0.25806248, 0.036476307]\n",
      "Iter 6701, loss [-0.22286248, -0.25941208, 0.03654959]\n",
      "Iter 6702, loss [-0.21781354, -0.25686768, 0.039054137]\n",
      "Iter 6703, loss [-0.1718618, -0.22311807, 0.05125626]\n",
      "Iter 6704, loss [-0.21851204, -0.25832114, 0.039809093]\n",
      "Iter 6705, loss [-0.22344042, -0.2613649, 0.03792448]\n",
      "Iter 6706, loss [-0.21619196, -0.2551925, 0.039000526]\n",
      "Iter 6707, loss [-0.21332392, -0.250911, 0.03758707]\n",
      "Iter 6708, loss [-0.20993164, -0.25044075, 0.040509105]\n",
      "Iter 6709, loss [-0.2138491, -0.2562213, 0.042372204]\n",
      "Iter 6710, loss [-0.21284595, -0.25351644, 0.04067048]\n",
      "Iter 6711, loss [-0.22601065, -0.26338482, 0.03737416]\n",
      "Iter 6712, loss [-0.2236814, -0.26394778, 0.04026638]\n",
      "Iter 6713, loss [-0.22233817, -0.26119763, 0.03885946]\n",
      "Iter 6714, loss [-0.23124714, -0.26511976, 0.03387262]\n",
      "Iter 6715, loss [-0.20928788, -0.24908876, 0.039800886]\n",
      "Iter 6716, loss [-0.22279051, -0.26194412, 0.039153606]\n",
      "Iter 6717, loss [-0.18301225, -0.23386174, 0.05084949]\n",
      "Iter 6718, loss [-0.19667768, -0.24126238, 0.044584684]\n",
      "Iter 6719, loss [-0.22355063, -0.25897032, 0.03541969]\n",
      "Iter 6720, loss [-0.22685155, -0.2646425, 0.037790958]\n",
      "Iter 6721, loss [-0.2315238, -0.26611546, 0.034591656]\n",
      "Iter 6722, loss [-0.22057247, -0.26005647, 0.039484]\n",
      "Iter 6723, loss [-0.22412005, -0.26224032, 0.038120277]\n",
      "Iter 6724, loss [-0.22527473, -0.2626145, 0.03733976]\n",
      "Iter 6725, loss [-0.22078972, -0.25776267, 0.036972955]\n",
      "Iter 6726, loss [-0.18214726, -0.23444687, 0.0522996]\n",
      "Iter 6727, loss [-0.2237966, -0.260785, 0.036988404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6728, loss [-0.21390277, -0.25377834, 0.039875574]\n",
      "Iter 6729, loss [-0.16919051, -0.22062463, 0.05143411]\n",
      "Iter 6730, loss [-0.16856387, -0.22297974, 0.054415863]\n",
      "Iter 6731, loss [-0.21444377, -0.25515708, 0.040713318]\n",
      "Iter 6732, loss [-0.2251344, -0.26065058, 0.03551618]\n",
      "Iter 6733, loss [-0.20278531, -0.24519075, 0.04240544]\n",
      "Iter 6734, loss [-0.1855506, -0.23635548, 0.05080489]\n",
      "Iter 6735, loss [-0.21357785, -0.25566596, 0.042088106]\n",
      "Iter 6736, loss [-0.22404702, -0.26390687, 0.039859843]\n",
      "Iter 6737, loss [-0.22466603, -0.2628415, 0.038175456]\n",
      "Iter 6738, loss [-0.22146466, -0.26051772, 0.03905305]\n",
      "Iter 6739, loss [-0.22764745, -0.26463807, 0.036990605]\n",
      "Iter 6740, loss [-0.2229988, -0.2609054, 0.03790661]\n",
      "Iter 6741, loss [-0.2197461, -0.26056507, 0.04081897]\n",
      "Iter 6742, loss [-0.2300762, -0.26659042, 0.036514223]\n",
      "Iter 6743, loss [-0.22369683, -0.2635776, 0.039880782]\n",
      "Iter 6744, loss [-0.13600579, -0.19989388, 0.063888095]\n",
      "Iter 6745, loss [-0.21894792, -0.25855288, 0.039604962]\n",
      "Iter 6746, loss [-0.22993688, -0.26461175, 0.034674864]\n",
      "Iter 6747, loss [-0.20823035, -0.24779856, 0.039568216]\n",
      "Iter 6748, loss [-0.21102265, -0.24869207, 0.037669428]\n",
      "Iter 6749, loss [-0.2150935, -0.254815, 0.039721526]\n",
      "Iter 6750, loss [-0.21986884, -0.25854808, 0.03867925]\n",
      "Iter 6751, loss [-0.2221258, -0.26048413, 0.038358334]\n",
      "Iter 6752, loss [-0.22825548, -0.26412478, 0.0358693]\n",
      "Iter 6753, loss [-0.22611418, -0.2630629, 0.036948703]\n",
      "Iter 6754, loss [-0.22346377, -0.26201707, 0.038553305]\n",
      "Iter 6755, loss [-0.2176995, -0.25717407, 0.03947458]\n",
      "Iter 6756, loss [-0.22097903, -0.25821006, 0.03723102]\n",
      "Iter 6757, loss [-0.22592281, -0.2618426, 0.035919797]\n",
      "Iter 6758, loss [-0.22445393, -0.26241118, 0.037957247]\n",
      "Iter 6759, loss [-0.2031403, -0.24657255, 0.04343225]\n",
      "Iter 6760, loss [-0.21088044, -0.25141722, 0.040536772]\n",
      "Iter 6761, loss [-0.22343597, -0.26110548, 0.037669513]\n",
      "Iter 6762, loss [-0.21798187, -0.2595402, 0.041558318]\n",
      "Iter 6763, loss [-0.22315323, -0.26129985, 0.038146608]\n",
      "Iter 6764, loss [-0.22875515, -0.2638405, 0.035085358]\n",
      "Iter 6765, loss [-0.22415145, -0.2597345, 0.03558306]\n",
      "Iter 6766, loss [-0.21461105, -0.25290293, 0.038291868]\n",
      "Iter 6767, loss [-0.21967074, -0.25915104, 0.039480302]\n",
      "Iter 6768, loss [-0.21014364, -0.25258476, 0.04244111]\n",
      "Iter 6769, loss [-0.21957237, -0.25882828, 0.039255917]\n",
      "Iter 6770, loss [-0.2279845, -0.26534626, 0.037361752]\n",
      "Iter 6771, loss [-0.22969323, -0.26691142, 0.037218176]\n",
      "Iter 6772, loss [-0.22655484, -0.26403347, 0.03747862]\n",
      "Iter 6773, loss [-0.16952616, -0.22178777, 0.052261613]\n",
      "Iter 6774, loss [-0.2173489, -0.25701937, 0.039670475]\n",
      "Iter 6775, loss [-0.21575177, -0.25303486, 0.03728309]\n",
      "Iter 6776, loss [-0.22213918, -0.25994396, 0.03780478]\n",
      "Iter 6777, loss [-0.21061832, -0.25137895, 0.04076063]\n",
      "Iter 6778, loss [-0.22542708, -0.26290628, 0.037479207]\n",
      "Iter 6779, loss [-0.21685183, -0.25623763, 0.0393858]\n",
      "Iter 6780, loss [-0.22321981, -0.25971037, 0.036490552]\n",
      "Iter 6781, loss [-0.2190159, -0.2580895, 0.03907362]\n",
      "Iter 6782, loss [-0.2198804, -0.2581156, 0.038235188]\n",
      "Iter 6783, loss [-0.23071471, -0.266984, 0.03626928]\n",
      "Iter 6784, loss [-0.22760409, -0.26489842, 0.03729433]\n",
      "Iter 6785, loss [-0.22931418, -0.26494202, 0.035627842]\n",
      "Iter 6786, loss [-0.20730285, -0.25117588, 0.043873027]\n",
      "Iter 6787, loss [-0.22735032, -0.26471078, 0.037360456]\n",
      "Iter 6788, loss [-0.22259909, -0.26166615, 0.039067052]\n",
      "Iter 6789, loss [-0.16683635, -0.22397748, 0.05714112]\n",
      "Iter 6790, loss [-0.23123719, -0.2672088, 0.035971623]\n",
      "Iter 6791, loss [-0.23265558, -0.2708262, 0.038170606]\n",
      "Iter 6792, loss [-0.2222833, -0.261113, 0.038829684]\n",
      "Iter 6793, loss [-0.2279969, -0.26651448, 0.03851758]\n",
      "Iter 6794, loss [-0.23519559, -0.27112, 0.03592442]\n",
      "Iter 6795, loss [-0.22701308, -0.26400054, 0.03698745]\n",
      "Iter 6796, loss [-0.18300214, -0.2349571, 0.051954947]\n",
      "Iter 6797, loss [-0.21114, -0.25010824, 0.03896823]\n",
      "Iter 6798, loss [-0.1895633, -0.23517473, 0.045611423]\n",
      "Iter 6799, loss [-0.22470942, -0.26266807, 0.037958656]\n",
      "Iter 6800, loss [-0.21961097, -0.25712612, 0.03751515]\n",
      "Iter 6801, loss [-0.22792923, -0.26523978, 0.03731054]\n",
      "Iter 6802, loss [-0.17439517, -0.22726509, 0.05286991]\n",
      "Iter 6803, loss [-0.21175289, -0.2545256, 0.042772703]\n",
      "Iter 6804, loss [-0.22033611, -0.2629506, 0.042614486]\n",
      "Iter 6805, loss [-0.22000553, -0.25968888, 0.039683357]\n",
      "Iter 6806, loss [-0.22643884, -0.26235464, 0.035915807]\n",
      "Iter 6807, loss [-0.22662255, -0.26596776, 0.039345212]\n",
      "Iter 6808, loss [-0.23013154, -0.26845747, 0.038325943]\n",
      "Iter 6809, loss [-0.22223319, -0.26056585, 0.038332652]\n",
      "Iter 6810, loss [-0.22631618, -0.26195723, 0.035641037]\n",
      "Iter 6811, loss [-0.21596193, -0.2540776, 0.038115673]\n",
      "Iter 6812, loss [-0.22383916, -0.26278383, 0.03894467]\n",
      "Iter 6813, loss [-0.22238876, -0.26104817, 0.038659405]\n",
      "Iter 6814, loss [-0.2088347, -0.2503345, 0.041499805]\n",
      "Iter 6815, loss [-0.22118711, -0.25962818, 0.038441066]\n",
      "Iter 6816, loss [-0.22355321, -0.26033828, 0.036785074]\n",
      "Iter 6817, loss [-0.212338, -0.25135615, 0.039018147]\n",
      "Iter 6818, loss [-0.22768915, -0.26551157, 0.03782242]\n",
      "Iter 6819, loss [-0.20971856, -0.25312757, 0.04340902]\n",
      "Iter 6820, loss [-0.22447242, -0.26212838, 0.03765596]\n",
      "Iter 6821, loss [-0.23418318, -0.2691174, 0.03493421]\n",
      "Iter 6822, loss [-0.21536656, -0.25461856, 0.039251998]\n",
      "Iter 6823, loss [-0.22331959, -0.2608207, 0.03750109]\n",
      "Iter 6824, loss [-0.22394378, -0.26173654, 0.037792753]\n",
      "Iter 6825, loss [-0.21935508, -0.25750953, 0.03815445]\n",
      "Iter 6826, loss [-0.22467622, -0.26216593, 0.037489716]\n",
      "Iter 6827, loss [-0.22378623, -0.26269794, 0.0389117]\n",
      "Iter 6828, loss [-0.19598724, -0.24275985, 0.04677261]\n",
      "Iter 6829, loss [-0.19022423, -0.2357666, 0.04554237]\n",
      "Iter 6830, loss [-0.13827386, -0.19749035, 0.05921648]\n",
      "Iter 6831, loss [-0.21440175, -0.25368398, 0.039282225]\n",
      "Iter 6832, loss [-0.21955685, -0.2580012, 0.038444355]\n",
      "Iter 6833, loss [-0.2218279, -0.25986192, 0.038034018]\n",
      "Iter 6834, loss [-0.22552691, -0.26154014, 0.036013227]\n",
      "Iter 6835, loss [-0.22745675, -0.26521266, 0.03775591]\n",
      "Iter 6836, loss [-0.22891247, -0.2655683, 0.036655806]\n",
      "Iter 6837, loss [-0.21772157, -0.25724798, 0.039526414]\n",
      "Iter 6838, loss [-0.17562638, -0.22629198, 0.0506656]\n",
      "Iter 6839, loss [-0.22610775, -0.2613743, 0.03526655]\n",
      "Iter 6840, loss [-0.17919102, -0.22372451, 0.044533484]\n",
      "Iter 6841, loss [-0.22769308, -0.26501828, 0.03732521]\n",
      "Iter 6842, loss [-0.23015805, -0.26589587, 0.035737827]\n",
      "Iter 6843, loss [-0.21986724, -0.2573129, 0.037445646]\n",
      "Iter 6844, loss [-0.22792366, -0.26495638, 0.03703273]\n",
      "Iter 6845, loss [-0.21300243, -0.2545891, 0.041586682]\n",
      "Iter 6846, loss [-0.22746763, -0.26556605, 0.03809842]\n",
      "Iter 6847, loss [-0.21086958, -0.25090954, 0.04003995]\n",
      "Iter 6848, loss [-0.2174815, -0.25694668, 0.039465185]\n",
      "Iter 6849, loss [-0.21586905, -0.2553266, 0.039457545]\n",
      "Iter 6850, loss [-0.22449034, -0.2610959, 0.036605574]\n",
      "Iter 6851, loss [-0.21717104, -0.25573677, 0.038565718]\n",
      "Iter 6852, loss [-0.22230025, -0.2611376, 0.038837355]\n",
      "Iter 6853, loss [-0.22009836, -0.26205587, 0.04195751]\n",
      "Iter 6854, loss [-0.21911815, -0.25981864, 0.040700495]\n",
      "Iter 6855, loss [-0.22473198, -0.26320797, 0.03847599]\n",
      "Iter 6856, loss [-0.22601919, -0.2638478, 0.037828606]\n",
      "Iter 6857, loss [-0.21356902, -0.25339225, 0.03982324]\n",
      "Iter 6858, loss [-0.22067699, -0.25788325, 0.037206255]\n",
      "Iter 6859, loss [-0.21907708, -0.25685805, 0.037780963]\n",
      "Iter 6860, loss [-0.17235531, -0.22549653, 0.053141218]\n",
      "Iter 6861, loss [-0.22026913, -0.25852233, 0.038253203]\n",
      "Iter 6862, loss [-0.22251652, -0.25943312, 0.036916595]\n",
      "Iter 6863, loss [-0.22147901, -0.2622699, 0.0407909]\n",
      "Iter 6864, loss [-0.2140072, -0.2543316, 0.040324382]\n",
      "Iter 6865, loss [-0.22089455, -0.25694227, 0.03604772]\n",
      "Iter 6866, loss [-0.22338243, -0.26349694, 0.040114503]\n",
      "Iter 6867, loss [-0.22995052, -0.26591307, 0.03596255]\n",
      "Iter 6868, loss [-0.22405861, -0.26105136, 0.036992744]\n",
      "Iter 6869, loss [-0.22433223, -0.26291013, 0.038577903]\n",
      "Iter 6870, loss [-0.22373232, -0.26096773, 0.0372354]\n",
      "Iter 6871, loss [-0.21639994, -0.2564191, 0.040019155]\n",
      "Iter 6872, loss [-0.23089692, -0.26661798, 0.035721064]\n",
      "Iter 6873, loss [-0.22948265, -0.2657201, 0.03623744]\n",
      "Iter 6874, loss [-0.22534032, -0.2642689, 0.03892858]\n",
      "Iter 6875, loss [-0.22742113, -0.2644078, 0.03698667]\n",
      "Iter 6876, loss [-0.21714854, -0.25793874, 0.0407902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 6877, loss [-0.2266583, -0.26444936, 0.03779106]\n",
      "Iter 6878, loss [-0.13368657, -0.19301085, 0.05932428]\n",
      "Iter 6879, loss [-0.21533635, -0.25431472, 0.038978364]\n",
      "Iter 6880, loss [-0.2164923, -0.25303218, 0.03653989]\n",
      "Iter 6881, loss [-0.22027488, -0.25707838, 0.036803495]\n",
      "Iter 6882, loss [-0.19775619, -0.24162373, 0.04386754]\n",
      "Iter 6883, loss [-0.2199402, -0.25737342, 0.03743322]\n",
      "Iter 6884, loss [-0.23167151, -0.2676318, 0.035960287]\n",
      "Iter 6885, loss [-0.21202962, -0.25473672, 0.042707097]\n",
      "Iter 6886, loss [-0.22020799, -0.25953346, 0.03932548]\n",
      "Iter 6887, loss [-0.23231499, -0.26814592, 0.035830926]\n",
      "Iter 6888, loss [-0.2193514, -0.25730276, 0.03795136]\n",
      "Iter 6889, loss [-0.22589208, -0.26469964, 0.038807556]\n",
      "Iter 6890, loss [-0.21488652, -0.25558156, 0.04069505]\n",
      "Iter 6891, loss [-0.21487498, -0.25455913, 0.039684143]\n",
      "Iter 6892, loss [-0.16366358, -0.21617302, 0.052509442]\n",
      "Iter 6893, loss [-0.21764125, -0.25740498, 0.039763734]\n",
      "Iter 6894, loss [-0.22324216, -0.26148424, 0.038242064]\n",
      "Iter 6895, loss [-0.2273632, -0.26272672, 0.035363518]\n",
      "Iter 6896, loss [-0.22362736, -0.26079038, 0.03716301]\n",
      "Iter 6897, loss [-0.22028616, -0.25902048, 0.038734317]\n",
      "Iter 6898, loss [-0.20687857, -0.2500473, 0.043168724]\n",
      "Iter 6899, loss [-0.2237843, -0.26085448, 0.037070177]\n",
      "Iter 6900, loss [-0.21989806, -0.2556464, 0.035748344]\n",
      "Iter 6901, loss [-0.21846935, -0.2579739, 0.039504554]\n",
      "Iter 6902, loss [-0.21911386, -0.25873148, 0.03961762]\n",
      "Iter 6903, loss [-0.22921994, -0.2653808, 0.036160856]\n",
      "Iter 6904, loss [-0.22977626, -0.26713783, 0.03736156]\n",
      "Iter 6905, loss [-0.21038434, -0.25022158, 0.039837237]\n",
      "Iter 6906, loss [-0.21610472, -0.2567965, 0.040691793]\n",
      "Iter 6907, loss [-0.2159401, -0.2568243, 0.04088421]\n",
      "Iter 6908, loss [-0.22365364, -0.25985512, 0.03620147]\n",
      "Iter 6909, loss [-0.21389556, -0.25486803, 0.040972464]\n",
      "Iter 6910, loss [-0.22452933, -0.2645614, 0.040032096]\n",
      "Iter 6911, loss [-0.2343956, -0.27094734, 0.036551744]\n",
      "Iter 6912, loss [-0.22328682, -0.2591917, 0.035904866]\n",
      "Iter 6913, loss [-0.23517682, -0.27057567, 0.035398852]\n",
      "Iter 6914, loss [-0.23164415, -0.26640016, 0.034755997]\n",
      "Iter 6915, loss [-0.2277488, -0.2653395, 0.0375907]\n",
      "Iter 6916, loss [-0.22748673, -0.2658197, 0.038332976]\n",
      "Iter 6917, loss [-0.21252166, -0.25238582, 0.039864164]\n",
      "Iter 6918, loss [-0.15267754, -0.21141492, 0.058737382]\n",
      "Iter 6919, loss [-0.22683042, -0.2645536, 0.037723176]\n",
      "Iter 6920, loss [-0.21699333, -0.25564602, 0.03865268]\n",
      "Iter 6921, loss [-0.22867465, -0.26437175, 0.035697106]\n",
      "Iter 6922, loss [-0.2292423, -0.26303717, 0.033794887]\n",
      "Iter 6923, loss [-0.22979675, -0.2667746, 0.03697784]\n",
      "Iter 6924, loss [-0.22534089, -0.26348034, 0.03813945]\n",
      "Iter 6925, loss [-0.2276462, -0.2632801, 0.035633884]\n",
      "Iter 6926, loss [-0.16586554, -0.22209318, 0.056227636]\n",
      "Iter 6927, loss [-0.22529416, -0.26292259, 0.037628423]\n",
      "Iter 6928, loss [-0.21332169, -0.2530148, 0.039693125]\n",
      "Iter 6929, loss [-0.22419474, -0.26033235, 0.03613761]\n",
      "Iter 6930, loss [-0.21611337, -0.25552306, 0.03940968]\n",
      "Iter 6931, loss [-0.22394638, -0.26120174, 0.03725536]\n",
      "Iter 6932, loss [-0.21346481, -0.25477237, 0.041307554]\n",
      "Iter 6933, loss [-0.2187865, -0.25821427, 0.039427772]\n",
      "Iter 6934, loss [-0.22741085, -0.26349616, 0.03608531]\n",
      "Iter 6935, loss [-0.2207868, -0.2591487, 0.03836189]\n",
      "Iter 6936, loss [-0.1959987, -0.2422561, 0.046257406]\n",
      "Iter 6937, loss [-0.22964257, -0.2656907, 0.036048137]\n",
      "Iter 6938, loss [-0.22852865, -0.26443493, 0.035906278]\n",
      "Iter 6939, loss [-0.2192363, -0.25692114, 0.03768484]\n",
      "Iter 6940, loss [-0.2231552, -0.25969416, 0.036538966]\n",
      "Iter 6941, loss [-0.23117901, -0.2678679, 0.036688883]\n",
      "Iter 6942, loss [-0.20322499, -0.24460453, 0.041379534]\n",
      "Iter 6943, loss [-0.15901873, -0.21873981, 0.059721075]\n",
      "Iter 6944, loss [-0.21957743, -0.25941762, 0.03984019]\n",
      "Iter 6945, loss [-0.21719834, -0.25586343, 0.03866509]\n",
      "Iter 6946, loss [-0.22785197, -0.26543072, 0.037578743]\n",
      "Iter 6947, loss [-0.22969523, -0.26551443, 0.035819195]\n",
      "Iter 6948, loss [-0.21955964, -0.25863996, 0.03908033]\n",
      "Iter 6949, loss [-0.23085254, -0.2663227, 0.03547015]\n",
      "Iter 6950, loss [-0.22772762, -0.26431477, 0.036587156]\n",
      "Iter 6951, loss [-0.2237098, -0.26084065, 0.037130848]\n",
      "Iter 6952, loss [-0.21794678, -0.25803688, 0.040090095]\n",
      "Iter 6953, loss [-0.21750267, -0.25662974, 0.039127063]\n",
      "Iter 6954, loss [-0.21644193, -0.25700265, 0.04056073]\n",
      "Iter 6955, loss [-0.20580217, -0.24665464, 0.04085247]\n",
      "Iter 6956, loss [-0.21699421, -0.25629556, 0.039301354]\n",
      "Iter 6957, loss [-0.22844674, -0.2650851, 0.03663836]\n",
      "Iter 6958, loss [-0.21673527, -0.25647408, 0.039738804]\n",
      "Iter 6959, loss [-0.22869761, -0.26400757, 0.035309955]\n",
      "Iter 6960, loss [-0.22785461, -0.26394156, 0.036086943]\n",
      "Iter 6961, loss [-0.22950387, -0.26584685, 0.036342986]\n",
      "Iter 6962, loss [-0.22321418, -0.26163292, 0.038418736]\n",
      "Iter 6963, loss [-0.2213342, -0.25937602, 0.03804181]\n",
      "Iter 6964, loss [-0.19380778, -0.24095756, 0.04714977]\n",
      "Iter 6965, loss [-0.21922266, -0.25907832, 0.039855655]\n",
      "Iter 6966, loss [-0.21937306, -0.25859845, 0.039225385]\n",
      "Iter 6967, loss [-0.2283774, -0.26619375, 0.03781634]\n",
      "Iter 6968, loss [-0.20424312, -0.24576885, 0.041525718]\n",
      "Iter 6969, loss [-0.22740668, -0.26488498, 0.037478298]\n",
      "Iter 6970, loss [-0.2136, -0.25337547, 0.039775476]\n",
      "Iter 6971, loss [-0.22287863, -0.2599687, 0.03709007]\n",
      "Iter 6972, loss [-0.2285926, -0.26497695, 0.036384344]\n",
      "Iter 6973, loss [-0.22145143, -0.2604159, 0.038964473]\n",
      "Iter 6974, loss [-0.21950714, -0.25702235, 0.037515208]\n",
      "Iter 6975, loss [-0.22417948, -0.26424614, 0.04006666]\n",
      "Iter 6976, loss [-0.21930945, -0.26000276, 0.040693317]\n",
      "Iter 6977, loss [-0.2139155, -0.25339827, 0.03948277]\n",
      "Iter 6978, loss [-0.22429976, -0.25957072, 0.03527096]\n",
      "Iter 6979, loss [-0.22516955, -0.26207083, 0.03690128]\n",
      "Iter 6980, loss [-0.21661633, -0.25108683, 0.034470506]\n",
      "Iter 6981, loss [-0.21821985, -0.256386, 0.038166165]\n",
      "Iter 6982, loss [-0.21940225, -0.2602129, 0.04081065]\n",
      "Iter 6983, loss [-0.23034649, -0.26755014, 0.037203655]\n",
      "Iter 6984, loss [-0.22399737, -0.26353168, 0.039534315]\n",
      "Iter 6985, loss [-0.22789976, -0.26637816, 0.038478404]\n",
      "Iter 6986, loss [-0.20108216, -0.24404494, 0.04296279]\n",
      "Iter 6987, loss [-0.22632718, -0.26229978, 0.03597259]\n",
      "Iter 6988, loss [-0.21736726, -0.25534394, 0.03797669]\n",
      "Iter 6989, loss [-0.20262021, -0.24544257, 0.04282237]\n",
      "Iter 6990, loss [-0.2138873, -0.25301796, 0.039130665]\n",
      "Iter 6991, loss [-0.22167951, -0.25993478, 0.03825527]\n",
      "Iter 6992, loss [-0.22233552, -0.2611124, 0.038776882]\n",
      "Iter 6993, loss [-0.22418109, -0.2639298, 0.039748725]\n",
      "Iter 6994, loss [-0.21782377, -0.25737253, 0.03954876]\n",
      "Iter 6995, loss [-0.22331198, -0.26053575, 0.037223767]\n",
      "Iter 6996, loss [-0.23220947, -0.2685156, 0.036306113]\n",
      "Iter 6997, loss [-0.18566604, -0.23732871, 0.05166267]\n",
      "Iter 6998, loss [-0.22718188, -0.26289994, 0.035718054]\n",
      "Iter 6999, loss [-0.22773859, -0.26353145, 0.035792857]\n",
      "Iter 7000, loss [-0.22481664, -0.26296777, 0.038151126]\n",
      "Iter 7001, loss [-0.21601371, -0.25673378, 0.04072006]\n",
      "Iter 7002, loss [-0.21321478, -0.25575686, 0.04254207]\n",
      "Iter 7003, loss [-0.21160904, -0.252313, 0.040703952]\n",
      "Iter 7004, loss [-0.22867401, -0.26448643, 0.035812423]\n",
      "Iter 7005, loss [-0.21265525, -0.25261852, 0.039963275]\n",
      "Iter 7006, loss [-0.22848782, -0.26372138, 0.035233565]\n",
      "Iter 7007, loss [-0.2200255, -0.2590284, 0.03900291]\n",
      "Iter 7008, loss [-0.22509763, -0.26201326, 0.03691563]\n",
      "Iter 7009, loss [-0.22733021, -0.26470682, 0.037376605]\n",
      "Iter 7010, loss [-0.21984278, -0.25875065, 0.03890787]\n",
      "Iter 7011, loss [-0.21250147, -0.25257498, 0.040073518]\n",
      "Iter 7012, loss [-0.22233927, -0.25983256, 0.037493285]\n",
      "Iter 7013, loss [-0.23069352, -0.2667011, 0.03600759]\n",
      "Iter 7014, loss [-0.23340988, -0.2680708, 0.034660902]\n",
      "Iter 7015, loss [-0.19936866, -0.24725035, 0.047881685]\n",
      "Iter 7016, loss [-0.21832518, -0.2565754, 0.038250223]\n",
      "Iter 7017, loss [-0.22503033, -0.2614786, 0.036448263]\n",
      "Iter 7018, loss [-0.21372738, -0.25151694, 0.03778956]\n",
      "Iter 7019, loss [-0.2186989, -0.25435868, 0.035659775]\n",
      "Iter 7020, loss [-0.2248123, -0.26102316, 0.036210872]\n",
      "Iter 7021, loss [-0.2136837, -0.25078484, 0.037101146]\n",
      "Iter 7022, loss [-0.21348129, -0.25431743, 0.04083614]\n",
      "Iter 7023, loss [-0.22122972, -0.2613566, 0.04012687]\n",
      "Iter 7024, loss [-0.18172911, -0.23166479, 0.04993569]\n",
      "Iter 7025, loss [-0.22531052, -0.26396832, 0.038657803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7026, loss [-0.22206035, -0.260392, 0.03833165]\n",
      "Iter 7027, loss [-0.21963826, -0.25905347, 0.039415207]\n",
      "Iter 7028, loss [-0.230504, -0.26673287, 0.036228858]\n",
      "Iter 7029, loss [-0.2140734, -0.25324842, 0.03917502]\n",
      "Iter 7030, loss [-0.21478924, -0.2542371, 0.03944784]\n",
      "Iter 7031, loss [-0.2080562, -0.24830347, 0.040247273]\n",
      "Iter 7032, loss [-0.21956296, -0.2565321, 0.03696914]\n",
      "Iter 7033, loss [-0.22463895, -0.26176643, 0.037127476]\n",
      "Iter 7034, loss [-0.22427319, -0.2616496, 0.03737642]\n",
      "Iter 7035, loss [-0.21732932, -0.25678372, 0.039454408]\n",
      "Iter 7036, loss [-0.22656395, -0.26460445, 0.038040504]\n",
      "Iter 7037, loss [-0.21319416, -0.2543328, 0.04113865]\n",
      "Iter 7038, loss [-0.23076552, -0.2675018, 0.036736272]\n",
      "Iter 7039, loss [-0.1913247, -0.23902717, 0.047702473]\n",
      "Iter 7040, loss [-0.20909286, -0.24983877, 0.040745907]\n",
      "Iter 7041, loss [-0.21830913, -0.2575807, 0.03927156]\n",
      "Iter 7042, loss [-0.22070082, -0.25979212, 0.0390913]\n",
      "Iter 7043, loss [-0.22577906, -0.26278389, 0.03700483]\n",
      "Iter 7044, loss [-0.23178394, -0.26549184, 0.033707898]\n",
      "Iter 7045, loss [-0.22756307, -0.26403558, 0.03647251]\n",
      "Iter 7046, loss [-0.22761, -0.26496917, 0.03735916]\n",
      "Iter 7047, loss [-0.22835298, -0.26473546, 0.036382478]\n",
      "Iter 7048, loss [-0.19498035, -0.23680775, 0.04182739]\n",
      "Iter 7049, loss [-0.23072034, -0.26617014, 0.03544981]\n",
      "Iter 7050, loss [-0.22430627, -0.26121408, 0.03690781]\n",
      "Iter 7051, loss [-0.22150049, -0.25940695, 0.037906475]\n",
      "Iter 7052, loss [-0.21439093, -0.25403228, 0.039641358]\n",
      "Iter 7053, loss [-0.22770724, -0.26357374, 0.035866495]\n",
      "Iter 7054, loss [-0.21814206, -0.2589122, 0.040770143]\n",
      "Iter 7055, loss [-0.2230556, -0.26109883, 0.038043223]\n",
      "Iter 7056, loss [-0.2218831, -0.26057503, 0.038691923]\n",
      "Iter 7057, loss [-0.22808413, -0.2663524, 0.03826825]\n",
      "Iter 7058, loss [-0.22816664, -0.26415458, 0.03598794]\n",
      "Iter 7059, loss [-0.23016381, -0.26512158, 0.034957774]\n",
      "Iter 7060, loss [-0.22409277, -0.261857, 0.037764233]\n",
      "Iter 7061, loss [-0.20742305, -0.25031933, 0.042896282]\n",
      "Iter 7062, loss [-0.2340783, -0.26823354, 0.034155235]\n",
      "Iter 7063, loss [-0.21514353, -0.2566201, 0.041476585]\n",
      "Iter 7064, loss [-0.2272433, -0.26495984, 0.03771653]\n",
      "Iter 7065, loss [-0.21474445, -0.25619757, 0.04145313]\n",
      "Iter 7066, loss [-0.23009317, -0.26687035, 0.036777183]\n",
      "Iter 7067, loss [-0.22827525, -0.2652923, 0.037017033]\n",
      "Iter 7068, loss [-0.22710195, -0.26423794, 0.037135985]\n",
      "Iter 7069, loss [-0.21018288, -0.2508344, 0.040651523]\n",
      "Iter 7070, loss [-0.2191977, -0.25877246, 0.03957476]\n",
      "Iter 7071, loss [-0.22380696, -0.26069832, 0.036891352]\n",
      "Iter 7072, loss [-0.2233246, -0.2615278, 0.038203206]\n",
      "Iter 7073, loss [-0.22538382, -0.2638211, 0.038437285]\n",
      "Iter 7074, loss [-0.21279298, -0.25277597, 0.03998299]\n",
      "Iter 7075, loss [-0.2151985, -0.2553033, 0.040104788]\n",
      "Iter 7076, loss [-0.21660852, -0.25459385, 0.037985325]\n",
      "Iter 7077, loss [-0.2332417, -0.26985404, 0.03661234]\n",
      "Iter 7078, loss [-0.21831664, -0.25777817, 0.039461516]\n",
      "Iter 7079, loss [-0.22706531, -0.26267123, 0.035605922]\n",
      "Iter 7080, loss [-0.22324777, -0.2613058, 0.03805804]\n",
      "Iter 7081, loss [-0.2166301, -0.2573973, 0.040767185]\n",
      "Iter 7082, loss [-0.22117317, -0.26077497, 0.039601795]\n",
      "Iter 7083, loss [-0.2286044, -0.26614416, 0.037539747]\n",
      "Iter 7084, loss [-0.22426412, -0.26286745, 0.03860333]\n",
      "Iter 7085, loss [-0.222463, -0.2599328, 0.03746979]\n",
      "Iter 7086, loss [-0.19393684, -0.24215692, 0.04822008]\n",
      "Iter 7087, loss [-0.22797337, -0.2635072, 0.035533812]\n",
      "Iter 7088, loss [-0.21824306, -0.2587868, 0.040543728]\n",
      "Iter 7089, loss [-0.22085007, -0.25858897, 0.037738904]\n",
      "Iter 7090, loss [-0.22416827, -0.25967246, 0.035504192]\n",
      "Iter 7091, loss [-0.2194984, -0.2607166, 0.041218188]\n",
      "Iter 7092, loss [-0.22015126, -0.25871092, 0.038559657]\n",
      "Iter 7093, loss [-0.21110137, -0.252585, 0.041483626]\n",
      "Iter 7094, loss [-0.22964862, -0.2678532, 0.038204588]\n",
      "Iter 7095, loss [-0.2309199, -0.2676242, 0.036704298]\n",
      "Iter 7096, loss [-0.23143831, -0.26655474, 0.03511643]\n",
      "Iter 7097, loss [-0.2216601, -0.26089257, 0.039232455]\n",
      "Iter 7098, loss [-0.22248201, -0.26139984, 0.03891782]\n",
      "Iter 7099, loss [-0.2136258, -0.25386813, 0.040242326]\n",
      "Iter 7100, loss [-0.22273739, -0.26213345, 0.03939606]\n",
      "Iter 7101, loss [-0.23585422, -0.27095708, 0.03510286]\n",
      "Iter 7102, loss [-0.23196119, -0.26709467, 0.03513349]\n",
      "Iter 7103, loss [-0.2329068, -0.26870075, 0.03579394]\n",
      "Iter 7104, loss [-0.21799141, -0.25608683, 0.038095407]\n",
      "Iter 7105, loss [-0.22803563, -0.2644681, 0.036432475]\n",
      "Iter 7106, loss [-0.23098963, -0.26581147, 0.03482184]\n",
      "Iter 7107, loss [-0.2206356, -0.26003638, 0.039400786]\n",
      "Iter 7108, loss [-0.23107661, -0.2673603, 0.036283683]\n",
      "Iter 7109, loss [-0.21194606, -0.25156578, 0.03961973]\n",
      "Iter 7110, loss [-0.20948586, -0.2504375, 0.040951636]\n",
      "Iter 7111, loss [-0.23199746, -0.26882356, 0.036826104]\n",
      "Iter 7112, loss [-0.22162482, -0.25886905, 0.03724423]\n",
      "Iter 7113, loss [-0.22645997, -0.26175585, 0.035295885]\n",
      "Iter 7114, loss [-0.20275316, -0.24868625, 0.04593309]\n",
      "Iter 7115, loss [-0.22822538, -0.26625124, 0.038025863]\n",
      "Iter 7116, loss [-0.21145493, -0.25026262, 0.03880769]\n",
      "Iter 7117, loss [-0.22941856, -0.2649676, 0.035549026]\n",
      "Iter 7118, loss [-0.223816, -0.2625684, 0.038752407]\n",
      "Iter 7119, loss [-0.23123342, -0.2673784, 0.03614497]\n",
      "Iter 7120, loss [-0.22372189, -0.26092792, 0.037206016]\n",
      "Iter 7121, loss [-0.22322354, -0.26094636, 0.03772282]\n",
      "Iter 7122, loss [-0.21896794, -0.25785732, 0.038889375]\n",
      "Iter 7123, loss [-0.21277963, -0.25214887, 0.03936924]\n",
      "Iter 7124, loss [-0.23380983, -0.2673962, 0.033586383]\n",
      "Iter 7125, loss [-0.19581747, -0.24403968, 0.04822221]\n",
      "Iter 7126, loss [-0.21941523, -0.26021913, 0.040803894]\n",
      "Iter 7127, loss [-0.2274251, -0.26449484, 0.037069734]\n",
      "Iter 7128, loss [-0.22833514, -0.26695588, 0.038620748]\n",
      "Iter 7129, loss [-0.23316854, -0.2692287, 0.036060162]\n",
      "Iter 7130, loss [-0.22913642, -0.263881, 0.034744576]\n",
      "Iter 7131, loss [-0.2290322, -0.26538318, 0.03635098]\n",
      "Iter 7132, loss [-0.22905944, -0.2643487, 0.03528924]\n",
      "Iter 7133, loss [-0.21955582, -0.25815198, 0.03859615]\n",
      "Iter 7134, loss [-0.22278897, -0.26213157, 0.039342593]\n",
      "Iter 7135, loss [-0.22583164, -0.2639989, 0.038167253]\n",
      "Iter 7136, loss [-0.21673052, -0.25654367, 0.039813146]\n",
      "Iter 7137, loss [-0.22921534, -0.26559317, 0.036377832]\n",
      "Iter 7138, loss [-0.22114953, -0.25891268, 0.037763145]\n",
      "Iter 7139, loss [-0.21604574, -0.25488663, 0.03884089]\n",
      "Iter 7140, loss [-0.18979251, -0.23431626, 0.044523746]\n",
      "Iter 7141, loss [-0.21893576, -0.25687188, 0.037936114]\n",
      "Iter 7142, loss [-0.22748756, -0.26333904, 0.035851486]\n",
      "Iter 7143, loss [-0.22262421, -0.2608956, 0.03827139]\n",
      "Iter 7144, loss [-0.2099978, -0.25454104, 0.044543236]\n",
      "Iter 7145, loss [-0.21364117, -0.2544819, 0.04084074]\n",
      "Iter 7146, loss [-0.22775277, -0.26463124, 0.036878467]\n",
      "Iter 7147, loss [-0.22094476, -0.26012298, 0.03917823]\n",
      "Iter 7148, loss [-0.2228052, -0.26132128, 0.03851608]\n",
      "Iter 7149, loss [-0.22030354, -0.258215, 0.037911467]\n",
      "Iter 7150, loss [-0.22491634, -0.2618705, 0.036954172]\n",
      "Iter 7151, loss [-0.22892968, -0.26555815, 0.03662847]\n",
      "Iter 7152, loss [-0.22480655, -0.26137277, 0.036566228]\n",
      "Iter 7153, loss [-0.22324565, -0.2626694, 0.03942377]\n",
      "Iter 7154, loss [-0.20938542, -0.25009373, 0.04070831]\n",
      "Iter 7155, loss [-0.2311686, -0.2679715, 0.036802888]\n",
      "Iter 7156, loss [-0.22615942, -0.26543835, 0.039278932]\n",
      "Iter 7157, loss [-0.21676055, -0.25777414, 0.04101359]\n",
      "Iter 7158, loss [-0.21774815, -0.2600556, 0.042307448]\n",
      "Iter 7159, loss [-0.23404571, -0.2696918, 0.035646077]\n",
      "Iter 7160, loss [-0.16152179, -0.21515316, 0.053631365]\n",
      "Iter 7161, loss [-0.21769723, -0.25753498, 0.039837755]\n",
      "Iter 7162, loss [-0.22428672, -0.26316383, 0.03887711]\n",
      "Iter 7163, loss [-0.22505298, -0.26269296, 0.037639983]\n",
      "Iter 7164, loss [-0.22712152, -0.26544636, 0.038324844]\n",
      "Iter 7165, loss [-0.2249454, -0.26375893, 0.03881354]\n",
      "Iter 7166, loss [-0.2253381, -0.2638459, 0.038507797]\n",
      "Iter 7167, loss [-0.22908491, -0.2662428, 0.037157893]\n",
      "Iter 7168, loss [-0.23094778, -0.26790574, 0.036957964]\n",
      "Iter 7169, loss [-0.22569193, -0.26445392, 0.038761992]\n",
      "Iter 7170, loss [-0.22613528, -0.26660588, 0.040470608]\n",
      "Iter 7171, loss [-0.23467475, -0.26889312, 0.03421838]\n",
      "Iter 7172, loss [-0.22575852, -0.26248497, 0.036726445]\n",
      "Iter 7173, loss [-0.20758532, -0.24821109, 0.040625766]\n",
      "Iter 7174, loss [-0.21837847, -0.25700143, 0.03862296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7175, loss [-0.21861076, -0.25490615, 0.036295384]\n",
      "Iter 7176, loss [-0.2183599, -0.2574345, 0.03907459]\n",
      "Iter 7177, loss [-0.23495297, -0.27034292, 0.03538994]\n",
      "Iter 7178, loss [-0.2272708, -0.26379898, 0.036528185]\n",
      "Iter 7179, loss [-0.22807893, -0.2634423, 0.035363376]\n",
      "Iter 7180, loss [-0.21634139, -0.25600553, 0.03966413]\n",
      "Iter 7181, loss [-0.22560191, -0.26400098, 0.038399067]\n",
      "Iter 7182, loss [-0.22244714, -0.26069704, 0.03824989]\n",
      "Iter 7183, loss [-0.22231811, -0.26022133, 0.037903223]\n",
      "Iter 7184, loss [-0.18909296, -0.23697776, 0.04788479]\n",
      "Iter 7185, loss [-0.22857484, -0.2655202, 0.03694534]\n",
      "Iter 7186, loss [-0.21309166, -0.25526887, 0.04217721]\n",
      "Iter 7187, loss [-0.16338676, -0.21677, 0.053383227]\n",
      "Iter 7188, loss [-0.22330768, -0.2611009, 0.0377932]\n",
      "Iter 7189, loss [-0.2323542, -0.2678666, 0.03551241]\n",
      "Iter 7190, loss [-0.18338755, -0.2325294, 0.049141847]\n",
      "Iter 7191, loss [-0.22303192, -0.25994304, 0.03691111]\n",
      "Iter 7192, loss [-0.23499247, -0.26901898, 0.034026504]\n",
      "Iter 7193, loss [-0.22356789, -0.26153487, 0.03796698]\n",
      "Iter 7194, loss [-0.2153312, -0.2528858, 0.037554592]\n",
      "Iter 7195, loss [-0.2007148, -0.24543092, 0.044716112]\n",
      "Iter 7196, loss [-0.23204875, -0.2662917, 0.03424295]\n",
      "Iter 7197, loss [-0.22541665, -0.26285064, 0.037433993]\n",
      "Iter 7198, loss [-0.2316564, -0.2668233, 0.035166882]\n",
      "Iter 7199, loss [-0.23532525, -0.2703254, 0.035000153]\n",
      "Iter 7200, loss [-0.21305132, -0.25388956, 0.040838234]\n",
      "Iter 7201, loss [-0.22418532, -0.2621235, 0.037938174]\n",
      "Iter 7202, loss [-0.21580812, -0.25508493, 0.03927681]\n",
      "Iter 7203, loss [-0.2302388, -0.26622263, 0.03598383]\n",
      "Iter 7204, loss [-0.21528837, -0.2549025, 0.039614134]\n",
      "Iter 7205, loss [-0.22462448, -0.25991595, 0.03529146]\n",
      "Iter 7206, loss [-0.2145372, -0.25576836, 0.041231163]\n",
      "Iter 7207, loss [-0.20886873, -0.24838264, 0.039513912]\n",
      "Iter 7208, loss [-0.21434514, -0.25552016, 0.04117502]\n",
      "Iter 7209, loss [-0.22226003, -0.25732917, 0.035069145]\n",
      "Iter 7210, loss [-0.21185455, -0.25341073, 0.041556187]\n",
      "Iter 7211, loss [-0.21647727, -0.2553903, 0.03891302]\n",
      "Iter 7212, loss [-0.20920178, -0.25096187, 0.041760087]\n",
      "Iter 7213, loss [-0.22177604, -0.25889608, 0.03712005]\n",
      "Iter 7214, loss [-0.22119185, -0.2597218, 0.038529932]\n",
      "Iter 7215, loss [-0.22263572, -0.2616608, 0.0390251]\n",
      "Iter 7216, loss [-0.22889608, -0.2655969, 0.036700815]\n",
      "Iter 7217, loss [-0.20771585, -0.24835962, 0.040643767]\n",
      "Iter 7218, loss [-0.22684775, -0.26394042, 0.037092667]\n",
      "Iter 7219, loss [-0.2188437, -0.25885606, 0.040012367]\n",
      "Iter 7220, loss [-0.22126669, -0.26060024, 0.03933356]\n",
      "Iter 7221, loss [-0.22556013, -0.2627427, 0.037182566]\n",
      "Iter 7222, loss [-0.23309547, -0.26889214, 0.03579668]\n",
      "Iter 7223, loss [-0.22739795, -0.26559687, 0.03819891]\n",
      "Iter 7224, loss [-0.2181809, -0.25829077, 0.04010988]\n",
      "Iter 7225, loss [-0.22561744, -0.26356325, 0.0379458]\n",
      "Iter 7226, loss [-0.21399894, -0.25477833, 0.040779382]\n",
      "Iter 7227, loss [-0.2180956, -0.25630432, 0.038208716]\n",
      "Iter 7228, loss [-0.22120179, -0.26019052, 0.038988728]\n",
      "Iter 7229, loss [-0.22172886, -0.26011246, 0.038383596]\n",
      "Iter 7230, loss [-0.22331502, -0.2609225, 0.03760748]\n",
      "Iter 7231, loss [-0.19493203, -0.23657964, 0.041647613]\n",
      "Iter 7232, loss [-0.21576256, -0.2542283, 0.038465735]\n",
      "Iter 7233, loss [-0.21488765, -0.2543988, 0.03951115]\n",
      "Iter 7234, loss [-0.19349658, -0.23607388, 0.042577293]\n",
      "Iter 7235, loss [-0.22984138, -0.2654549, 0.035613514]\n",
      "Iter 7236, loss [-0.22566399, -0.26358378, 0.037919797]\n",
      "Iter 7237, loss [-0.20567478, -0.24889264, 0.04321785]\n",
      "Iter 7238, loss [-0.21848394, -0.2559344, 0.037450448]\n",
      "Iter 7239, loss [-0.21747768, -0.25610015, 0.038622465]\n",
      "Iter 7240, loss [-0.21600989, -0.25411633, 0.038106445]\n",
      "Iter 7241, loss [-0.21854416, -0.25654757, 0.038003415]\n",
      "Iter 7242, loss [-0.21796048, -0.2556807, 0.03772023]\n",
      "Iter 7243, loss [-0.2209484, -0.259726, 0.038777597]\n",
      "Iter 7244, loss [-0.22050962, -0.2596315, 0.0391219]\n",
      "Iter 7245, loss [-0.21271381, -0.25353605, 0.040822234]\n",
      "Iter 7246, loss [-0.15108064, -0.20332445, 0.05224382]\n",
      "Iter 7247, loss [-0.2228551, -0.26016548, 0.03731038]\n",
      "Iter 7248, loss [-0.20677048, -0.24912444, 0.042353958]\n",
      "Iter 7249, loss [-0.22348924, -0.26107576, 0.037586525]\n",
      "Iter 7250, loss [-0.2238782, -0.261059, 0.037180778]\n",
      "Iter 7251, loss [-0.21510547, -0.25257638, 0.0374709]\n",
      "Iter 7252, loss [-0.22732702, -0.2646273, 0.037300296]\n",
      "Iter 7253, loss [-0.22513276, -0.2640217, 0.038888924]\n",
      "Iter 7254, loss [-0.2180492, -0.26104268, 0.042993486]\n",
      "Iter 7255, loss [-0.23122421, -0.26895845, 0.03773424]\n",
      "Iter 7256, loss [-0.22072756, -0.25922582, 0.038498253]\n",
      "Iter 7257, loss [-0.22561684, -0.26344487, 0.03782803]\n",
      "Iter 7258, loss [-0.22307232, -0.26092353, 0.03785121]\n",
      "Iter 7259, loss [-0.21170475, -0.2532514, 0.041546658]\n",
      "Iter 7260, loss [-0.21407622, -0.25268102, 0.038604792]\n",
      "Iter 7261, loss [-0.23061827, -0.26617065, 0.035552382]\n",
      "Iter 7262, loss [-0.22412696, -0.26205164, 0.037924677]\n",
      "Iter 7263, loss [-0.22450149, -0.26227978, 0.03777828]\n",
      "Iter 7264, loss [-0.21606861, -0.25797305, 0.041904435]\n",
      "Iter 7265, loss [-0.2275203, -0.26462054, 0.037100244]\n",
      "Iter 7266, loss [-0.16570929, -0.21777059, 0.0520613]\n",
      "Iter 7267, loss [-0.18654837, -0.23504694, 0.04849857]\n",
      "Iter 7268, loss [-0.22685793, -0.262036, 0.03517806]\n",
      "Iter 7269, loss [-0.2212056, -0.2591226, 0.037917003]\n",
      "Iter 7270, loss [-0.22922271, -0.26431596, 0.035093244]\n",
      "Iter 7271, loss [-0.2160419, -0.2563929, 0.04035101]\n",
      "Iter 7272, loss [-0.18943712, -0.23437956, 0.04494244]\n",
      "Iter 7273, loss [-0.22306675, -0.2611363, 0.038069542]\n",
      "Iter 7274, loss [-0.23007259, -0.26387006, 0.03379747]\n",
      "Iter 7275, loss [-0.22244641, -0.2598124, 0.037366]\n",
      "Iter 7276, loss [-0.15074319, -0.20267749, 0.051934298]\n",
      "Iter 7277, loss [-0.20892045, -0.24819024, 0.039269783]\n",
      "Iter 7278, loss [-0.22401068, -0.26156446, 0.03755379]\n",
      "Iter 7279, loss [-0.2267663, -0.26461563, 0.037849322]\n",
      "Iter 7280, loss [-0.21869943, -0.26050594, 0.04180651]\n",
      "Iter 7281, loss [-0.19118494, -0.23876151, 0.047576576]\n",
      "Iter 7282, loss [-0.22301987, -0.26326367, 0.040243804]\n",
      "Iter 7283, loss [-0.2261075, -0.26344165, 0.03733416]\n",
      "Iter 7284, loss [-0.18266353, -0.2337364, 0.051072866]\n",
      "Iter 7285, loss [-0.22943589, -0.26680967, 0.037373774]\n",
      "Iter 7286, loss [-0.22065869, -0.25878295, 0.03812426]\n",
      "Iter 7287, loss [-0.22529772, -0.26122835, 0.035930634]\n",
      "Iter 7288, loss [-0.22480297, -0.26167384, 0.036870874]\n",
      "Iter 7289, loss [-0.19036692, -0.23578238, 0.045415454]\n",
      "Iter 7290, loss [-0.21822438, -0.25540584, 0.037181474]\n",
      "Iter 7291, loss [-0.21715152, -0.25620258, 0.039051063]\n",
      "Iter 7292, loss [-0.22661981, -0.26367617, 0.037056364]\n",
      "Iter 7293, loss [-0.18651128, -0.23423453, 0.047723256]\n",
      "Iter 7294, loss [-0.21140304, -0.25138232, 0.03997928]\n",
      "Iter 7295, loss [-0.22465764, -0.26128018, 0.036622535]\n",
      "Iter 7296, loss [-0.22447208, -0.2610166, 0.03654453]\n",
      "Iter 7297, loss [-0.22888795, -0.2657891, 0.036901142]\n",
      "Iter 7298, loss [-0.2183888, -0.25757867, 0.039189875]\n",
      "Iter 7299, loss [-0.21961918, -0.25765333, 0.038034134]\n",
      "Iter 7300, loss [-0.20920365, -0.25100815, 0.041804504]\n",
      "Iter 7301, loss [-0.22206154, -0.25922224, 0.03716069]\n",
      "Iter 7302, loss [-0.2220059, -0.2625197, 0.040513787]\n",
      "Iter 7303, loss [-0.21801084, -0.2578137, 0.03980285]\n",
      "Iter 7304, loss [-0.22376874, -0.26100594, 0.03723719]\n",
      "Iter 7305, loss [-0.23051405, -0.2661685, 0.035654455]\n",
      "Iter 7306, loss [-0.22913674, -0.26567057, 0.03653384]\n",
      "Iter 7307, loss [-0.21075976, -0.25193155, 0.041171797]\n",
      "Iter 7308, loss [-0.22045505, -0.25846866, 0.038013615]\n",
      "Iter 7309, loss [-0.22102726, -0.257867, 0.036839746]\n",
      "Iter 7310, loss [-0.2199514, -0.25857267, 0.03862126]\n",
      "Iter 7311, loss [-0.16151549, -0.21451867, 0.053003177]\n",
      "Iter 7312, loss [-0.23051031, -0.2660218, 0.03551148]\n",
      "Iter 7313, loss [-0.21833593, -0.256712, 0.03837607]\n",
      "Iter 7314, loss [-0.19375221, -0.23840293, 0.04465072]\n",
      "Iter 7315, loss [-0.21273443, -0.25405556, 0.041321136]\n",
      "Iter 7316, loss [-0.21537039, -0.25659716, 0.04122677]\n",
      "Iter 7317, loss [-0.21620537, -0.25454283, 0.038337458]\n",
      "Iter 7318, loss [-0.2261332, -0.26371214, 0.03757894]\n",
      "Iter 7319, loss [-0.22031553, -0.2587174, 0.03840186]\n",
      "Iter 7320, loss [-0.21290456, -0.24976733, 0.036862772]\n",
      "Iter 7321, loss [-0.21274176, -0.25231537, 0.039573602]\n",
      "Iter 7322, loss [-0.22379018, -0.2616008, 0.037810605]\n",
      "Iter 7323, loss [-0.22769937, -0.2644871, 0.03678772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7324, loss [-0.20744465, -0.2510427, 0.043598037]\n",
      "Iter 7325, loss [-0.22455218, -0.26232308, 0.037770897]\n",
      "Iter 7326, loss [-0.23132384, -0.26691067, 0.035586827]\n",
      "Iter 7327, loss [-0.23066533, -0.26803428, 0.037368946]\n",
      "Iter 7328, loss [-0.21352547, -0.25189713, 0.03837166]\n",
      "Iter 7329, loss [-0.22738875, -0.26436082, 0.036972057]\n",
      "Iter 7330, loss [-0.21129967, -0.25275216, 0.04145248]\n",
      "Iter 7331, loss [-0.2215897, -0.2600884, 0.03849871]\n",
      "Iter 7332, loss [-0.22308442, -0.26035693, 0.037272505]\n",
      "Iter 7333, loss [-0.16182226, -0.21367191, 0.051849645]\n",
      "Iter 7334, loss [-0.23098958, -0.26664454, 0.03565497]\n",
      "Iter 7335, loss [-0.22970048, -0.2659551, 0.03625461]\n",
      "Iter 7336, loss [-0.22910076, -0.26660767, 0.0375069]\n",
      "Iter 7337, loss [-0.17815936, -0.21800306, 0.039843716]\n",
      "Iter 7338, loss [-0.22795483, -0.2632607, 0.035305865]\n",
      "Iter 7339, loss [-0.22160715, -0.2584227, 0.03681556]\n",
      "Iter 7340, loss [-0.22310363, -0.25976327, 0.03665964]\n",
      "Iter 7341, loss [-0.23398308, -0.26930356, 0.035320476]\n",
      "Iter 7342, loss [-0.19687343, -0.24122594, 0.044352517]\n",
      "Iter 7343, loss [-0.22377995, -0.2610737, 0.03729376]\n",
      "Iter 7344, loss [-0.22075598, -0.2597569, 0.03900091]\n",
      "Iter 7345, loss [-0.22984788, -0.2660423, 0.03619441]\n",
      "Iter 7346, loss [-0.22153062, -0.25915152, 0.0376209]\n",
      "Iter 7347, loss [-0.23146243, -0.2669936, 0.035531178]\n",
      "Iter 7348, loss [-0.22593442, -0.26184815, 0.03591374]\n",
      "Iter 7349, loss [-0.21246088, -0.25185603, 0.03939515]\n",
      "Iter 7350, loss [-0.22485766, -0.2632728, 0.03841513]\n",
      "Iter 7351, loss [-0.22006577, -0.25723588, 0.037170116]\n",
      "Iter 7352, loss [-0.2209251, -0.26027492, 0.03934983]\n",
      "Iter 7353, loss [-0.22712407, -0.26380098, 0.036676913]\n",
      "Iter 7354, loss [-0.2187272, -0.25826803, 0.03954082]\n",
      "Iter 7355, loss [-0.21914412, -0.25730088, 0.03815676]\n",
      "Iter 7356, loss [-0.22104706, -0.25973317, 0.038686108]\n",
      "Iter 7357, loss [-0.21878617, -0.2591413, 0.04035513]\n",
      "Iter 7358, loss [-0.21544369, -0.25499317, 0.03954948]\n",
      "Iter 7359, loss [-0.22669859, -0.26558295, 0.038884357]\n",
      "Iter 7360, loss [-0.229596, -0.26649398, 0.03689797]\n",
      "Iter 7361, loss [-0.21728596, -0.2558496, 0.03856364]\n",
      "Iter 7362, loss [-0.17226703, -0.22446772, 0.052200686]\n",
      "Iter 7363, loss [-0.22958642, -0.2662097, 0.03662327]\n",
      "Iter 7364, loss [-0.18822488, -0.23772222, 0.049497336]\n",
      "Iter 7365, loss [-0.23088613, -0.26726505, 0.03637892]\n",
      "Iter 7366, loss [-0.21924339, -0.25800598, 0.03876258]\n",
      "Iter 7367, loss [-0.21907893, -0.2580742, 0.038995266]\n",
      "Iter 7368, loss [-0.22789282, -0.26372844, 0.03583563]\n",
      "Iter 7369, loss [-0.22481407, -0.26291388, 0.038099807]\n",
      "Iter 7370, loss [-0.21745278, -0.25805613, 0.040603355]\n",
      "Iter 7371, loss [-0.22313479, -0.26126772, 0.038132932]\n",
      "Iter 7372, loss [-0.21160169, -0.2528205, 0.041218802]\n",
      "Iter 7373, loss [-0.23398396, -0.26855972, 0.034575768]\n",
      "Iter 7374, loss [-0.22741477, -0.26416412, 0.036749348]\n",
      "Iter 7375, loss [-0.22655302, -0.26357353, 0.037020504]\n",
      "Iter 7376, loss [-0.21632425, -0.25716925, 0.040844988]\n",
      "Iter 7377, loss [-0.22498685, -0.26034507, 0.035358217]\n",
      "Iter 7378, loss [-0.22047095, -0.26010782, 0.03963686]\n",
      "Iter 7379, loss [-0.19691855, -0.24240322, 0.045484684]\n",
      "Iter 7380, loss [-0.2140557, -0.25539374, 0.041338038]\n",
      "Iter 7381, loss [-0.226203, -0.26597768, 0.03977468]\n",
      "Iter 7382, loss [-0.17226148, -0.22414611, 0.051884644]\n",
      "Iter 7383, loss [-0.21730413, -0.25604552, 0.03874139]\n",
      "Iter 7384, loss [-0.22153634, -0.26091638, 0.039380036]\n",
      "Iter 7385, loss [-0.23090291, -0.26838621, 0.037483305]\n",
      "Iter 7386, loss [-0.22382757, -0.25999582, 0.03616825]\n",
      "Iter 7387, loss [-0.22713345, -0.26526803, 0.03813457]\n",
      "Iter 7388, loss [-0.22160213, -0.25998974, 0.03838761]\n",
      "Iter 7389, loss [-0.2267485, -0.26343897, 0.03669047]\n",
      "Iter 7390, loss [-0.22992767, -0.26720178, 0.037274107]\n",
      "Iter 7391, loss [-0.22420269, -0.26161894, 0.037416257]\n",
      "Iter 7392, loss [-0.22922921, -0.2644961, 0.035266872]\n",
      "Iter 7393, loss [-0.22505593, -0.26279438, 0.03773844]\n",
      "Iter 7394, loss [-0.23138303, -0.2673451, 0.035962075]\n",
      "Iter 7395, loss [-0.22130793, -0.25861803, 0.037310094]\n",
      "Iter 7396, loss [-0.21310273, -0.25027788, 0.037175145]\n",
      "Iter 7397, loss [-0.22347118, -0.26185346, 0.03838228]\n",
      "Iter 7398, loss [-0.22723794, -0.26453212, 0.037294175]\n",
      "Iter 7399, loss [-0.22992237, -0.26570177, 0.0357794]\n",
      "Iter 7400, loss [-0.2014689, -0.24513702, 0.04366812]\n",
      "Iter 7401, loss [-0.20007282, -0.24466173, 0.044588916]\n",
      "Iter 7402, loss [-0.22466318, -0.26292816, 0.03826497]\n",
      "Iter 7403, loss [-0.2100923, -0.24828812, 0.038195826]\n",
      "Iter 7404, loss [-0.2279326, -0.2646026, 0.036669996]\n",
      "Iter 7405, loss [-0.22849919, -0.2656832, 0.03718402]\n",
      "Iter 7406, loss [-0.19735211, -0.24232891, 0.0449768]\n",
      "Iter 7407, loss [-0.2031577, -0.24550107, 0.042343386]\n",
      "Iter 7408, loss [-0.22308904, -0.2621892, 0.039100163]\n",
      "Iter 7409, loss [-0.2184696, -0.25663802, 0.038168415]\n",
      "Iter 7410, loss [-0.22625935, -0.26252264, 0.036263283]\n",
      "Iter 7411, loss [-0.22967483, -0.26458815, 0.034913316]\n",
      "Iter 7412, loss [-0.19269902, -0.23512676, 0.04242774]\n",
      "Iter 7413, loss [-0.22639443, -0.2629443, 0.036549885]\n",
      "Iter 7414, loss [-0.22422124, -0.26209903, 0.037877783]\n",
      "Iter 7415, loss [-0.23437718, -0.2701209, 0.03574372]\n",
      "Iter 7416, loss [-0.21927851, -0.26007968, 0.040801167]\n",
      "Iter 7417, loss [-0.22079007, -0.25813088, 0.0373408]\n",
      "Iter 7418, loss [-0.2319371, -0.2669377, 0.035000604]\n",
      "Iter 7419, loss [-0.22873577, -0.26406112, 0.03532535]\n",
      "Iter 7420, loss [-0.16286507, -0.22304317, 0.060178097]\n",
      "Iter 7421, loss [-0.22696716, -0.2628198, 0.03585265]\n",
      "Iter 7422, loss [-0.21330401, -0.25327465, 0.039970636]\n",
      "Iter 7423, loss [-0.22178553, -0.25989637, 0.038110834]\n",
      "Iter 7424, loss [-0.21779332, -0.25614712, 0.038353793]\n",
      "Iter 7425, loss [-0.22168204, -0.2607981, 0.039116062]\n",
      "Iter 7426, loss [-0.21844362, -0.25819752, 0.039753895]\n",
      "Iter 7427, loss [-0.21527268, -0.25474402, 0.03947134]\n",
      "Iter 7428, loss [-0.22726607, -0.2653553, 0.038089216]\n",
      "Iter 7429, loss [-0.22719634, -0.26338646, 0.036190115]\n",
      "Iter 7430, loss [-0.16883086, -0.21790592, 0.049075067]\n",
      "Iter 7431, loss [-0.22572349, -0.26298058, 0.03725709]\n",
      "Iter 7432, loss [-0.2156289, -0.25517908, 0.03955017]\n",
      "Iter 7433, loss [-0.22599488, -0.2641811, 0.038186215]\n",
      "Iter 7434, loss [-0.22775799, -0.2658874, 0.038129423]\n",
      "Iter 7435, loss [-0.22362971, -0.2629723, 0.039342582]\n",
      "Iter 7436, loss [-0.19792321, -0.24218021, 0.044256996]\n",
      "Iter 7437, loss [-0.22654474, -0.2625333, 0.03598857]\n",
      "Iter 7438, loss [-0.22073159, -0.2584244, 0.03769282]\n",
      "Iter 7439, loss [-0.21146531, -0.25162178, 0.040156465]\n",
      "Iter 7440, loss [-0.2172696, -0.2560988, 0.038829207]\n",
      "Iter 7441, loss [-0.22620672, -0.2625107, 0.036303967]\n",
      "Iter 7442, loss [-0.21629402, -0.2551071, 0.038813077]\n",
      "Iter 7443, loss [-0.22021338, -0.25937736, 0.039163977]\n",
      "Iter 7444, loss [-0.21908468, -0.25869426, 0.039609574]\n",
      "Iter 7445, loss [-0.22013079, -0.25978556, 0.03965478]\n",
      "Iter 7446, loss [-0.22794884, -0.26611397, 0.038165115]\n",
      "Iter 7447, loss [-0.21656562, -0.2568685, 0.040302888]\n",
      "Iter 7448, loss [-0.22220448, -0.25884667, 0.036642186]\n",
      "Iter 7449, loss [-0.21281345, -0.25596148, 0.043148026]\n",
      "Iter 7450, loss [-0.22543022, -0.2620761, 0.036645897]\n",
      "Iter 7451, loss [-0.212381, -0.251971, 0.039589997]\n",
      "Iter 7452, loss [-0.21949771, -0.25867793, 0.03918022]\n",
      "Iter 7453, loss [-0.22731435, -0.26372507, 0.036410715]\n",
      "Iter 7454, loss [-0.22778532, -0.26480514, 0.037019815]\n",
      "Iter 7455, loss [-0.21989913, -0.25859788, 0.03869875]\n",
      "Iter 7456, loss [-0.22136554, -0.26038516, 0.03901961]\n",
      "Iter 7457, loss [-0.22458357, -0.25992894, 0.03534537]\n",
      "Iter 7458, loss [-0.22390649, -0.26098895, 0.037082467]\n",
      "Iter 7459, loss [-0.22355393, -0.2610845, 0.037530575]\n",
      "Iter 7460, loss [-0.22349516, -0.26250032, 0.039005164]\n",
      "Iter 7461, loss [-0.20758754, -0.24561858, 0.03803105]\n",
      "Iter 7462, loss [-0.22318204, -0.2605564, 0.037374366]\n",
      "Iter 7463, loss [-0.2304314, -0.2662922, 0.035860818]\n",
      "Iter 7464, loss [-0.22001925, -0.25932562, 0.039306372]\n",
      "Iter 7465, loss [-0.2309808, -0.267292, 0.036311194]\n",
      "Iter 7466, loss [-0.22294779, -0.26141298, 0.038465187]\n",
      "Iter 7467, loss [-0.22540583, -0.26197776, 0.03657193]\n",
      "Iter 7468, loss [-0.22525886, -0.26186648, 0.03660762]\n",
      "Iter 7469, loss [-0.22456588, -0.2613876, 0.036821708]\n",
      "Iter 7470, loss [-0.22363633, -0.2626479, 0.039011575]\n",
      "Iter 7471, loss [-0.23110889, -0.26742226, 0.03631337]\n",
      "Iter 7472, loss [-0.22778882, -0.2645876, 0.03679879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7473, loss [-0.21981144, -0.2583259, 0.038514458]\n",
      "Iter 7474, loss [-0.22545376, -0.26325986, 0.037806086]\n",
      "Iter 7475, loss [-0.22873569, -0.26641273, 0.037677057]\n",
      "Iter 7476, loss [-0.21859394, -0.2551441, 0.036550146]\n",
      "Iter 7477, loss [-0.21120694, -0.25123635, 0.040029403]\n",
      "Iter 7478, loss [-0.22872713, -0.26372, 0.034992877]\n",
      "Iter 7479, loss [-0.21769513, -0.2571655, 0.039470363]\n",
      "Iter 7480, loss [-0.22752008, -0.26502222, 0.03750214]\n",
      "Iter 7481, loss [-0.22580025, -0.26260975, 0.036809497]\n",
      "Iter 7482, loss [-0.20014128, -0.2449, 0.04475872]\n",
      "Iter 7483, loss [-0.22700602, -0.265513, 0.038506985]\n",
      "Iter 7484, loss [-0.2301083, -0.2667679, 0.03665958]\n",
      "Iter 7485, loss [-0.22203097, -0.25890535, 0.036874384]\n",
      "Iter 7486, loss [-0.21630874, -0.25497186, 0.038663127]\n",
      "Iter 7487, loss [-0.21819694, -0.25796875, 0.03977181]\n",
      "Iter 7488, loss [-0.22661524, -0.26497844, 0.0383632]\n",
      "Iter 7489, loss [-0.22412556, -0.2622264, 0.03810083]\n",
      "Iter 7490, loss [-0.226271, -0.2646273, 0.038356297]\n",
      "Iter 7491, loss [-0.2281012, -0.2654815, 0.037380315]\n",
      "Iter 7492, loss [-0.22420692, -0.26024932, 0.0360424]\n",
      "Iter 7493, loss [-0.22014953, -0.25804558, 0.037896052]\n",
      "Iter 7494, loss [-0.22653572, -0.26242983, 0.03589411]\n",
      "Iter 7495, loss [-0.22710206, -0.26326534, 0.03616328]\n",
      "Iter 7496, loss [-0.22863987, -0.26553473, 0.036894865]\n",
      "Iter 7497, loss [-0.20777051, -0.24833417, 0.040563654]\n",
      "Iter 7498, loss [-0.22415963, -0.2620587, 0.03789907]\n",
      "Iter 7499, loss [-0.21855488, -0.2567911, 0.038236223]\n",
      "Iter 7500, loss [-0.2013667, -0.24417853, 0.04281185]\n",
      "Iter 7501, loss [-0.22434777, -0.26394418, 0.03959641]\n",
      "Iter 7502, loss [-0.22812939, -0.26506647, 0.036937095]\n",
      "Iter 7503, loss [-0.22857612, -0.26674753, 0.03817141]\n",
      "Iter 7504, loss [-0.21558793, -0.2558943, 0.04030637]\n",
      "Iter 7505, loss [-0.21842739, -0.26027784, 0.04185044]\n",
      "Iter 7506, loss [-0.18599635, -0.23786646, 0.051870104]\n",
      "Iter 7507, loss [-0.23385139, -0.26798823, 0.034136847]\n",
      "Iter 7508, loss [-0.22197102, -0.25997773, 0.03800671]\n",
      "Iter 7509, loss [-0.22494343, -0.26162922, 0.036685795]\n",
      "Iter 7510, loss [-0.21507344, -0.25328797, 0.038214542]\n",
      "Iter 7511, loss [-0.20936851, -0.2517025, 0.04233397]\n",
      "Iter 7512, loss [-0.2295551, -0.2663355, 0.036780395]\n",
      "Iter 7513, loss [-0.22414958, -0.2602696, 0.036120035]\n",
      "Iter 7514, loss [-0.22455482, -0.2621684, 0.037613586]\n",
      "Iter 7515, loss [-0.21915564, -0.26098004, 0.041824397]\n",
      "Iter 7516, loss [-0.21794789, -0.25666407, 0.038716182]\n",
      "Iter 7517, loss [-0.2165448, -0.25537995, 0.038835134]\n",
      "Iter 7518, loss [-0.21132666, -0.24984518, 0.03851852]\n",
      "Iter 7519, loss [-0.21863984, -0.25336844, 0.034728598]\n",
      "Iter 7520, loss [-0.20435226, -0.24261418, 0.03826192]\n",
      "Iter 7521, loss [-0.21534559, -0.2531188, 0.03777323]\n",
      "Iter 7522, loss [-0.22324419, -0.2602242, 0.036979996]\n",
      "Iter 7523, loss [-0.22768441, -0.26490507, 0.03722065]\n",
      "Iter 7524, loss [-0.22511083, -0.26551068, 0.040399842]\n",
      "Iter 7525, loss [-0.20415635, -0.24955688, 0.04540053]\n",
      "Iter 7526, loss [-0.22344437, -0.26082543, 0.037381046]\n",
      "Iter 7527, loss [-0.21352105, -0.252021, 0.038499966]\n",
      "Iter 7528, loss [-0.21609747, -0.25383845, 0.037740972]\n",
      "Iter 7529, loss [-0.22663091, -0.26128653, 0.034655612]\n",
      "Iter 7530, loss [-0.19058946, -0.23646075, 0.04587128]\n",
      "Iter 7531, loss [-0.22190008, -0.25953943, 0.037639357]\n",
      "Iter 7532, loss [-0.20363176, -0.2454184, 0.04178665]\n",
      "Iter 7533, loss [-0.22649157, -0.2635382, 0.037046637]\n",
      "Iter 7534, loss [-0.22300571, -0.25999188, 0.036986172]\n",
      "Iter 7535, loss [-0.21763276, -0.2592069, 0.041574135]\n",
      "Iter 7536, loss [-0.22289896, -0.26013455, 0.037235584]\n",
      "Iter 7537, loss [-0.2167758, -0.25366247, 0.036886655]\n",
      "Iter 7538, loss [-0.22911659, -0.26341632, 0.03429973]\n",
      "Iter 7539, loss [-0.21013199, -0.24933061, 0.039198622]\n",
      "Iter 7540, loss [-0.21657899, -0.2546988, 0.038119823]\n",
      "Iter 7541, loss [-0.22006199, -0.2593158, 0.0392538]\n",
      "Iter 7542, loss [-0.22806393, -0.26617098, 0.038107052]\n",
      "Iter 7543, loss [-0.22276299, -0.26059055, 0.037827563]\n",
      "Iter 7544, loss [-0.2250559, -0.26606423, 0.041008316]\n",
      "Iter 7545, loss [-0.22261734, -0.26087174, 0.0382544]\n",
      "Iter 7546, loss [-0.21886721, -0.25949347, 0.040626258]\n",
      "Iter 7547, loss [-0.2238587, -0.26105306, 0.037194353]\n",
      "Iter 7548, loss [-0.23369294, -0.2683713, 0.034678366]\n",
      "Iter 7549, loss [-0.22743571, -0.2638623, 0.036426604]\n",
      "Iter 7550, loss [-0.21825822, -0.25630018, 0.038041964]\n",
      "Iter 7551, loss [-0.23425794, -0.2693204, 0.03506246]\n",
      "Iter 7552, loss [-0.21809575, -0.2586214, 0.04052564]\n",
      "Iter 7553, loss [-0.21994516, -0.26053423, 0.040589064]\n",
      "Iter 7554, loss [-0.22481039, -0.26211023, 0.03729984]\n",
      "Iter 7555, loss [-0.2234732, -0.26036027, 0.036887065]\n",
      "Iter 7556, loss [-0.22724912, -0.26406366, 0.036814548]\n",
      "Iter 7557, loss [-0.21194126, -0.25433952, 0.04239826]\n",
      "Iter 7558, loss [-0.22442141, -0.26145616, 0.037034757]\n",
      "Iter 7559, loss [-0.22236812, -0.2620397, 0.039671563]\n",
      "Iter 7560, loss [-0.23172598, -0.26838928, 0.03666331]\n",
      "Iter 7561, loss [-0.22417657, -0.26307768, 0.0389011]\n",
      "Iter 7562, loss [-0.2213784, -0.26006147, 0.038683068]\n",
      "Iter 7563, loss [-0.21895507, -0.25776702, 0.03881196]\n",
      "Iter 7564, loss [-0.22470707, -0.2649522, 0.040245146]\n",
      "Iter 7565, loss [-0.14106333, -0.20158601, 0.060522668]\n",
      "Iter 7566, loss [-0.219965, -0.26058444, 0.040619444]\n",
      "Iter 7567, loss [-0.18556297, -0.23544782, 0.049884856]\n",
      "Iter 7568, loss [-0.21129583, -0.24930355, 0.038007718]\n",
      "Iter 7569, loss [-0.22431988, -0.26122454, 0.036904663]\n",
      "Iter 7570, loss [-0.21968576, -0.25817463, 0.038488857]\n",
      "Iter 7571, loss [-0.22434776, -0.2611032, 0.03675546]\n",
      "Iter 7572, loss [-0.221986, -0.2617593, 0.039773308]\n",
      "Iter 7573, loss [-0.22822559, -0.26562816, 0.037402578]\n",
      "Iter 7574, loss [-0.23096707, -0.26848948, 0.03752241]\n",
      "Iter 7575, loss [-0.21652874, -0.25775233, 0.041223593]\n",
      "Iter 7576, loss [-0.21467179, -0.25547394, 0.040802147]\n",
      "Iter 7577, loss [-0.22365811, -0.2617731, 0.038114995]\n",
      "Iter 7578, loss [-0.22207794, -0.26123697, 0.039159037]\n",
      "Iter 7579, loss [-0.22097474, -0.26027027, 0.039295517]\n",
      "Iter 7580, loss [-0.21400867, -0.2544353, 0.040426627]\n",
      "Iter 7581, loss [-0.22955878, -0.26489738, 0.03533859]\n",
      "Iter 7582, loss [-0.23114508, -0.26836804, 0.037222944]\n",
      "Iter 7583, loss [-0.23438105, -0.2690357, 0.034654647]\n",
      "Iter 7584, loss [-0.21838345, -0.25838745, 0.040003996]\n",
      "Iter 7585, loss [-0.21843839, -0.25517213, 0.036733743]\n",
      "Iter 7586, loss [-0.22046643, -0.25997174, 0.0395053]\n",
      "Iter 7587, loss [-0.22337173, -0.262034, 0.038662266]\n",
      "Iter 7588, loss [-0.23102833, -0.26743448, 0.036406144]\n",
      "Iter 7589, loss [-0.21385446, -0.25301656, 0.039162096]\n",
      "Iter 7590, loss [-0.23041356, -0.265923, 0.035509437]\n",
      "Iter 7591, loss [-0.22548246, -0.2625785, 0.037096016]\n",
      "Iter 7592, loss [-0.22853462, -0.26665652, 0.038121894]\n",
      "Iter 7593, loss [-0.2259918, -0.26303753, 0.037045732]\n",
      "Iter 7594, loss [-0.22877796, -0.267408, 0.038630053]\n",
      "Iter 7595, loss [-0.2313709, -0.2682676, 0.036896713]\n",
      "Iter 7596, loss [-0.21323475, -0.25473335, 0.04149861]\n",
      "Iter 7597, loss [-0.18183163, -0.23499376, 0.05316212]\n",
      "Iter 7598, loss [-0.21514797, -0.25362772, 0.038479753]\n",
      "Iter 7599, loss [-0.1784468, -0.21914355, 0.040696755]\n",
      "Iter 7600, loss [-0.2278526, -0.26433283, 0.036480233]\n",
      "Iter 7601, loss [-0.23502447, -0.26884416, 0.03381969]\n",
      "Iter 7602, loss [-0.21861058, -0.25679073, 0.03818014]\n",
      "Iter 7603, loss [-0.2103923, -0.25140536, 0.041013055]\n",
      "Iter 7604, loss [-0.21828568, -0.25852755, 0.040241867]\n",
      "Iter 7605, loss [-0.23289146, -0.2680928, 0.03520136]\n",
      "Iter 7606, loss [-0.21323976, -0.25480306, 0.041563295]\n",
      "Iter 7607, loss [-0.14170738, -0.20132087, 0.059613492]\n",
      "Iter 7608, loss [-0.21567065, -0.25705293, 0.041382287]\n",
      "Iter 7609, loss [-0.23540924, -0.27069354, 0.035284292]\n",
      "Iter 7610, loss [-0.1618428, -0.21584603, 0.05400324]\n",
      "Iter 7611, loss [-0.22105905, -0.25812134, 0.03706228]\n",
      "Iter 7612, loss [-0.22261721, -0.26379782, 0.04118061]\n",
      "Iter 7613, loss [-0.22629362, -0.26543447, 0.039140843]\n",
      "Iter 7614, loss [-0.22700855, -0.2668202, 0.039811637]\n",
      "Iter 7615, loss [-0.23132016, -0.26731014, 0.035989985]\n",
      "Iter 7616, loss [-0.22577754, -0.26429006, 0.038512528]\n",
      "Iter 7617, loss [-0.22731455, -0.26339045, 0.03607591]\n",
      "Iter 7618, loss [-0.2275399, -0.26335752, 0.035817616]\n",
      "Iter 7619, loss [-0.22130996, -0.26028705, 0.03897708]\n",
      "Iter 7620, loss [-0.20551792, -0.24701868, 0.04150077]\n",
      "Iter 7621, loss [-0.22077447, -0.25931132, 0.03853685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7622, loss [-0.2271775, -0.2636629, 0.0364854]\n",
      "Iter 7623, loss [-0.21931005, -0.25735006, 0.03804001]\n",
      "Iter 7624, loss [-0.21714777, -0.2573774, 0.04022962]\n",
      "Iter 7625, loss [-0.22762024, -0.2641179, 0.036497645]\n",
      "Iter 7626, loss [-0.22588183, -0.26322967, 0.03734784]\n",
      "Iter 7627, loss [-0.23033153, -0.26578873, 0.035457205]\n",
      "Iter 7628, loss [-0.22774553, -0.26506117, 0.037315637]\n",
      "Iter 7629, loss [-0.22350928, -0.26168677, 0.03817749]\n",
      "Iter 7630, loss [-0.22696228, -0.2657223, 0.038760018]\n",
      "Iter 7631, loss [-0.22624347, -0.26403907, 0.03779561]\n",
      "Iter 7632, loss [-0.22459821, -0.2627451, 0.038146894]\n",
      "Iter 7633, loss [-0.22409652, -0.26101685, 0.03692032]\n",
      "Iter 7634, loss [-0.21659613, -0.2560559, 0.039459772]\n",
      "Iter 7635, loss [-0.2290304, -0.26276785, 0.033737443]\n",
      "Iter 7636, loss [-0.22842024, -0.26430464, 0.035884395]\n",
      "Iter 7637, loss [-0.22830954, -0.26309705, 0.0347875]\n",
      "Iter 7638, loss [-0.21642342, -0.25626832, 0.039844893]\n",
      "Iter 7639, loss [-0.20909435, -0.2509188, 0.04182446]\n",
      "Iter 7640, loss [-0.22326812, -0.26108947, 0.037821345]\n",
      "Iter 7641, loss [-0.22464827, -0.2617558, 0.037107535]\n",
      "Iter 7642, loss [-0.2214007, -0.25904244, 0.037641745]\n",
      "Iter 7643, loss [-0.22423215, -0.26005933, 0.035827175]\n",
      "Iter 7644, loss [-0.2254195, -0.26242897, 0.037009463]\n",
      "Iter 7645, loss [-0.22402698, -0.26175275, 0.037725784]\n",
      "Iter 7646, loss [-0.22814669, -0.26568732, 0.037540626]\n",
      "Iter 7647, loss [-0.23399329, -0.26973954, 0.035746254]\n",
      "Iter 7648, loss [-0.19829354, -0.24219626, 0.043902725]\n",
      "Iter 7649, loss [-0.21700431, -0.25725535, 0.04025103]\n",
      "Iter 7650, loss [-0.21522954, -0.25409195, 0.0388624]\n",
      "Iter 7651, loss [-0.23027062, -0.2645965, 0.034325875]\n",
      "Iter 7652, loss [-0.21894209, -0.2592989, 0.040356796]\n",
      "Iter 7653, loss [-0.15655756, -0.21199499, 0.05543743]\n",
      "Iter 7654, loss [-0.22241363, -0.26032424, 0.03791061]\n",
      "Iter 7655, loss [-0.22472566, -0.26311952, 0.038393855]\n",
      "Iter 7656, loss [-0.22718886, -0.26372185, 0.036532994]\n",
      "Iter 7657, loss [-0.20516472, -0.24824591, 0.04308119]\n",
      "Iter 7658, loss [-0.2132132, -0.25321096, 0.039997764]\n",
      "Iter 7659, loss [-0.1738072, -0.22601709, 0.052209884]\n",
      "Iter 7660, loss [-0.22509691, -0.26300696, 0.037910044]\n",
      "Iter 7661, loss [-0.22729328, -0.26420423, 0.03691095]\n",
      "Iter 7662, loss [-0.20527647, -0.24460728, 0.03933081]\n",
      "Iter 7663, loss [-0.21501307, -0.2538907, 0.038877618]\n",
      "Iter 7664, loss [-0.21990658, -0.25961873, 0.039712146]\n",
      "Iter 7665, loss [-0.22327143, -0.26110077, 0.037829332]\n",
      "Iter 7666, loss [-0.22530144, -0.26383296, 0.03853151]\n",
      "Iter 7667, loss [-0.1709141, -0.2227809, 0.0518668]\n",
      "Iter 7668, loss [-0.2151471, -0.2557589, 0.040611822]\n",
      "Iter 7669, loss [-0.22117183, -0.25846872, 0.0372969]\n",
      "Iter 7670, loss [-0.22332543, -0.26096275, 0.037637327]\n",
      "Iter 7671, loss [-0.16160187, -0.21555713, 0.05395525]\n",
      "Iter 7672, loss [-0.22619346, -0.26426435, 0.038070895]\n",
      "Iter 7673, loss [-0.2296479, -0.2660861, 0.036438204]\n",
      "Iter 7674, loss [-0.22103447, -0.25986803, 0.03883355]\n",
      "Iter 7675, loss [-0.22427495, -0.26192442, 0.03764947]\n",
      "Iter 7676, loss [-0.21973243, -0.25796166, 0.038229227]\n",
      "Iter 7677, loss [-0.21605574, -0.25554204, 0.039486304]\n",
      "Iter 7678, loss [-0.22310501, -0.26149517, 0.038390152]\n",
      "Iter 7679, loss [-0.23088628, -0.26824823, 0.03736195]\n",
      "Iter 7680, loss [-0.22239363, -0.26059788, 0.03820426]\n",
      "Iter 7681, loss [-0.22837538, -0.26611492, 0.037739538]\n",
      "Iter 7682, loss [-0.22568089, -0.26307762, 0.03739673]\n",
      "Iter 7683, loss [-0.21750797, -0.25656536, 0.039057385]\n",
      "Iter 7684, loss [-0.22158201, -0.2593423, 0.0377603]\n",
      "Iter 7685, loss [-0.22288698, -0.25831917, 0.035432186]\n",
      "Iter 7686, loss [-0.21513581, -0.25541937, 0.04028356]\n",
      "Iter 7687, loss [-0.21752572, -0.25681588, 0.03929016]\n",
      "Iter 7688, loss [-0.2225021, -0.26081172, 0.038309615]\n",
      "Iter 7689, loss [-0.21830034, -0.25711164, 0.038811304]\n",
      "Iter 7690, loss [-0.21280447, -0.2551483, 0.042343833]\n",
      "Iter 7691, loss [-0.13157222, -0.19589855, 0.06432633]\n",
      "Iter 7692, loss [-0.22479263, -0.263685, 0.038892366]\n",
      "Iter 7693, loss [-0.21164106, -0.2518508, 0.04020976]\n",
      "Iter 7694, loss [-0.22510725, -0.26088455, 0.035777308]\n",
      "Iter 7695, loss [-0.17004964, -0.22229579, 0.052246146]\n",
      "Iter 7696, loss [-0.21718876, -0.25665054, 0.039461777]\n",
      "Iter 7697, loss [-0.21915612, -0.25916776, 0.040011648]\n",
      "Iter 7698, loss [-0.22562067, -0.26419652, 0.03857584]\n",
      "Iter 7699, loss [-0.22392966, -0.26397923, 0.04004957]\n",
      "Iter 7700, loss [-0.22722486, -0.26550007, 0.038275212]\n",
      "Iter 7701, loss [-0.22461095, -0.2616654, 0.037054457]\n",
      "Iter 7702, loss [-0.22882536, -0.2636258, 0.034800433]\n",
      "Iter 7703, loss [-0.22931917, -0.26318482, 0.03386565]\n",
      "Iter 7704, loss [-0.21499093, -0.25178888, 0.036797952]\n",
      "Iter 7705, loss [-0.22252163, -0.26090539, 0.038383745]\n",
      "Iter 7706, loss [-0.2238206, -0.26348776, 0.03966716]\n",
      "Iter 7707, loss [-0.226381, -0.26468745, 0.038306445]\n",
      "Iter 7708, loss [-0.2061952, -0.2497407, 0.043545496]\n",
      "Iter 7709, loss [-0.21677452, -0.2586381, 0.041863587]\n",
      "Iter 7710, loss [-0.21335949, -0.25484428, 0.041484788]\n",
      "Iter 7711, loss [-0.22761214, -0.2649268, 0.03731466]\n",
      "Iter 7712, loss [-0.21729085, -0.25430247, 0.037011616]\n",
      "Iter 7713, loss [-0.22603971, -0.26416418, 0.038124472]\n",
      "Iter 7714, loss [-0.2296369, -0.2647285, 0.035091594]\n",
      "Iter 7715, loss [-0.20996618, -0.24857873, 0.038612552]\n",
      "Iter 7716, loss [-0.22273828, -0.26187795, 0.039139673]\n",
      "Iter 7717, loss [-0.21803112, -0.2593822, 0.041351065]\n",
      "Iter 7718, loss [-0.21986234, -0.25957295, 0.039710604]\n",
      "Iter 7719, loss [-0.22144678, -0.2607898, 0.03934303]\n",
      "Iter 7720, loss [-0.22534055, -0.26235342, 0.03701287]\n",
      "Iter 7721, loss [-0.2126495, -0.25313002, 0.040480524]\n",
      "Iter 7722, loss [-0.23312867, -0.2664109, 0.03328222]\n",
      "Iter 7723, loss [-0.19640447, -0.24109879, 0.044694316]\n",
      "Iter 7724, loss [-0.2159374, -0.25177258, 0.035835184]\n",
      "Iter 7725, loss [-0.2251158, -0.263685, 0.038569175]\n",
      "Iter 7726, loss [-0.22695172, -0.26425555, 0.037303835]\n",
      "Iter 7727, loss [-0.21835056, -0.25657976, 0.038229194]\n",
      "Iter 7728, loss [-0.22517146, -0.2646541, 0.039482635]\n",
      "Iter 7729, loss [-0.22237462, -0.26078808, 0.038413472]\n",
      "Iter 7730, loss [-0.15738213, -0.21033713, 0.05295501]\n",
      "Iter 7731, loss [-0.22405863, -0.2639169, 0.039858278]\n",
      "Iter 7732, loss [-0.14235425, -0.20168026, 0.059326015]\n",
      "Iter 7733, loss [-0.23235431, -0.2661782, 0.033823878]\n",
      "Iter 7734, loss [-0.21925841, -0.2577816, 0.03852318]\n",
      "Iter 7735, loss [-0.2347608, -0.2698628, 0.035102]\n",
      "Iter 7736, loss [-0.2134665, -0.25056228, 0.03709579]\n",
      "Iter 7737, loss [-0.21930069, -0.25980026, 0.040499568]\n",
      "Iter 7738, loss [-0.2277515, -0.26670817, 0.038956665]\n",
      "Iter 7739, loss [-0.22667755, -0.26487988, 0.038202327]\n",
      "Iter 7740, loss [-0.21278922, -0.25453398, 0.04174475]\n",
      "Iter 7741, loss [-0.22709796, -0.26405165, 0.03695368]\n",
      "Iter 7742, loss [-0.21460861, -0.2545501, 0.039941486]\n",
      "Iter 7743, loss [-0.21739917, -0.25656, 0.03916083]\n",
      "Iter 7744, loss [-0.22172359, -0.25958464, 0.037861057]\n",
      "Iter 7745, loss [-0.22490495, -0.2631813, 0.038276352]\n",
      "Iter 7746, loss [-0.18552634, -0.2330614, 0.047535058]\n",
      "Iter 7747, loss [-0.22646004, -0.264845, 0.038384967]\n",
      "Iter 7748, loss [-0.20458412, -0.24775489, 0.043170758]\n",
      "Iter 7749, loss [-0.22478503, -0.26342452, 0.03863948]\n",
      "Iter 7750, loss [-0.22366862, -0.261102, 0.037433367]\n",
      "Iter 7751, loss [-0.22503349, -0.25916338, 0.03412988]\n",
      "Iter 7752, loss [-0.17046164, -0.21874918, 0.048287537]\n",
      "Iter 7753, loss [-0.2124702, -0.24899231, 0.0365221]\n",
      "Iter 7754, loss [-0.22565012, -0.26466396, 0.039013848]\n",
      "Iter 7755, loss [-0.21892025, -0.2605572, 0.04163696]\n",
      "Iter 7756, loss [-0.22722411, -0.26490438, 0.03768027]\n",
      "Iter 7757, loss [-0.22701177, -0.2641669, 0.037155114]\n",
      "Iter 7758, loss [-0.2252854, -0.2614984, 0.036212996]\n",
      "Iter 7759, loss [-0.23077334, -0.26673678, 0.035963427]\n",
      "Iter 7760, loss [-0.22000068, -0.25845733, 0.03845664]\n",
      "Iter 7761, loss [-0.22885264, -0.26529425, 0.036441606]\n",
      "Iter 7762, loss [-0.21902804, -0.25545898, 0.036430944]\n",
      "Iter 7763, loss [-0.22004631, -0.2585614, 0.03851509]\n",
      "Iter 7764, loss [-0.22897047, -0.2647422, 0.035771735]\n",
      "Iter 7765, loss [-0.22429408, -0.26234022, 0.038046133]\n",
      "Iter 7766, loss [-0.20667578, -0.24792016, 0.041244373]\n",
      "Iter 7767, loss [-0.21898627, -0.25725204, 0.038265757]\n",
      "Iter 7768, loss [-0.22110161, -0.25972903, 0.038627412]\n",
      "Iter 7769, loss [-0.22132587, -0.2609532, 0.03962732]\n",
      "Iter 7770, loss [-0.22906289, -0.266189, 0.037126128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7771, loss [-0.21935281, -0.25825506, 0.03890225]\n",
      "Iter 7772, loss [-0.21538627, -0.2547607, 0.039374433]\n",
      "Iter 7773, loss [-0.22397366, -0.26198298, 0.03800931]\n",
      "Iter 7774, loss [-0.22580425, -0.26462853, 0.038824275]\n",
      "Iter 7775, loss [-0.22980921, -0.26653156, 0.036722347]\n",
      "Iter 7776, loss [-0.21717906, -0.2563048, 0.039125737]\n",
      "Iter 7777, loss [-0.22108713, -0.2600726, 0.03898547]\n",
      "Iter 7778, loss [-0.16356125, -0.21784665, 0.054285392]\n",
      "Iter 7779, loss [-0.22040394, -0.25868112, 0.038277186]\n",
      "Iter 7780, loss [-0.224465, -0.26269737, 0.038232367]\n",
      "Iter 7781, loss [-0.21012248, -0.2543163, 0.044193815]\n",
      "Iter 7782, loss [-0.22173202, -0.25943097, 0.037698954]\n",
      "Iter 7783, loss [-0.22945073, -0.26418176, 0.034731034]\n",
      "Iter 7784, loss [-0.20873627, -0.25046858, 0.041732308]\n",
      "Iter 7785, loss [-0.23122126, -0.2656831, 0.034461856]\n",
      "Iter 7786, loss [-0.21768181, -0.25692213, 0.039240316]\n",
      "Iter 7787, loss [-0.22515093, -0.26191533, 0.0367644]\n",
      "Iter 7788, loss [-0.22170864, -0.25961408, 0.037905443]\n",
      "Iter 7789, loss [-0.22401276, -0.26163423, 0.037621476]\n",
      "Iter 7790, loss [-0.21680592, -0.2569331, 0.040127177]\n",
      "Iter 7791, loss [-0.2120253, -0.25082725, 0.038801953]\n",
      "Iter 7792, loss [-0.20935363, -0.2497616, 0.04040797]\n",
      "Iter 7793, loss [-0.21733765, -0.2570673, 0.03972964]\n",
      "Iter 7794, loss [-0.2286468, -0.2636384, 0.034991607]\n",
      "Iter 7795, loss [-0.2182544, -0.25754303, 0.03928863]\n",
      "Iter 7796, loss [-0.20303121, -0.24430712, 0.041275904]\n",
      "Iter 7797, loss [-0.22494419, -0.26233634, 0.03739215]\n",
      "Iter 7798, loss [-0.2275697, -0.2656028, 0.038033105]\n",
      "Iter 7799, loss [-0.22697553, -0.26370683, 0.0367313]\n",
      "Iter 7800, loss [-0.22595711, -0.2641927, 0.038235586]\n",
      "Iter 7801, loss [-0.22408149, -0.2630309, 0.038949404]\n",
      "Iter 7802, loss [-0.18197092, -0.23422599, 0.05225507]\n",
      "Iter 7803, loss [-0.23106553, -0.2669984, 0.035932884]\n",
      "Iter 7804, loss [-0.22132464, -0.26065573, 0.03933109]\n",
      "Iter 7805, loss [-0.23254138, -0.26936197, 0.036820598]\n",
      "Iter 7806, loss [-0.18650527, -0.23613177, 0.049626496]\n",
      "Iter 7807, loss [-0.16038589, -0.21903226, 0.058646362]\n",
      "Iter 7808, loss [-0.2224724, -0.2631191, 0.04064671]\n",
      "Iter 7809, loss [-0.22125813, -0.26062986, 0.03937172]\n",
      "Iter 7810, loss [-0.22336932, -0.2603741, 0.037004784]\n",
      "Iter 7811, loss [-0.20650734, -0.248295, 0.04178765]\n",
      "Iter 7812, loss [-0.19242749, -0.23872475, 0.046297275]\n",
      "Iter 7813, loss [-0.22247666, -0.25737667, 0.034900002]\n",
      "Iter 7814, loss [-0.21918878, -0.25528574, 0.036096953]\n",
      "Iter 7815, loss [-0.21849993, -0.25768593, 0.039186]\n",
      "Iter 7816, loss [-0.22630043, -0.2626087, 0.03630827]\n",
      "Iter 7817, loss [-0.21027492, -0.2526108, 0.042335883]\n",
      "Iter 7818, loss [-0.22441235, -0.26327386, 0.03886152]\n",
      "Iter 7819, loss [-0.22493371, -0.26288947, 0.03795577]\n",
      "Iter 7820, loss [-0.22409347, -0.26204744, 0.037953965]\n",
      "Iter 7821, loss [-0.22466783, -0.26200554, 0.037337705]\n",
      "Iter 7822, loss [-0.22804269, -0.26318827, 0.035145573]\n",
      "Iter 7823, loss [-0.22278033, -0.26058835, 0.037808012]\n",
      "Iter 7824, loss [-0.21917854, -0.25783893, 0.038660392]\n",
      "Iter 7825, loss [-0.2177747, -0.258842, 0.041067287]\n",
      "Iter 7826, loss [-0.22011438, -0.25913018, 0.0390158]\n",
      "Iter 7827, loss [-0.21776712, -0.25885192, 0.041084792]\n",
      "Iter 7828, loss [-0.22871596, -0.26609042, 0.037374467]\n",
      "Iter 7829, loss [-0.22585388, -0.2643152, 0.038461313]\n",
      "Iter 7830, loss [-0.22602771, -0.26255184, 0.036524132]\n",
      "Iter 7831, loss [-0.22231226, -0.26000667, 0.037694406]\n",
      "Iter 7832, loss [-0.21968062, -0.25690755, 0.037226927]\n",
      "Iter 7833, loss [-0.22986302, -0.26433977, 0.034476765]\n",
      "Iter 7834, loss [-0.22392681, -0.26138282, 0.037456002]\n",
      "Iter 7835, loss [-0.2058369, -0.2498154, 0.043978494]\n",
      "Iter 7836, loss [-0.22666155, -0.26501784, 0.038356286]\n",
      "Iter 7837, loss [-0.16717692, -0.22858061, 0.06140369]\n",
      "Iter 7838, loss [-0.22153576, -0.25880975, 0.037273988]\n",
      "Iter 7839, loss [-0.22212619, -0.26021466, 0.038088474]\n",
      "Iter 7840, loss [-0.20393318, -0.24481839, 0.040885214]\n",
      "Iter 7841, loss [-0.19707987, -0.24412447, 0.047044598]\n",
      "Iter 7842, loss [-0.22020508, -0.25856405, 0.038358968]\n",
      "Iter 7843, loss [-0.21403193, -0.25363272, 0.039600782]\n",
      "Iter 7844, loss [-0.21868229, -0.2596849, 0.041002598]\n",
      "Iter 7845, loss [-0.21997838, -0.2608079, 0.04082952]\n",
      "Iter 7846, loss [-0.20322601, -0.24748954, 0.044263523]\n",
      "Iter 7847, loss [-0.22371933, -0.26128387, 0.037564553]\n",
      "Iter 7848, loss [-0.20861733, -0.25082728, 0.042209953]\n",
      "Iter 7849, loss [-0.23347548, -0.26816684, 0.034691356]\n",
      "Iter 7850, loss [-0.22262527, -0.2601435, 0.03751822]\n",
      "Iter 7851, loss [-0.21336253, -0.25330013, 0.0399376]\n",
      "Iter 7852, loss [-0.22202209, -0.26125875, 0.039236657]\n",
      "Iter 7853, loss [-0.22408631, -0.26151085, 0.037424542]\n",
      "Iter 7854, loss [-0.22950554, -0.26572153, 0.036215987]\n",
      "Iter 7855, loss [-0.21719931, -0.25762552, 0.040426206]\n",
      "Iter 7856, loss [-0.22781676, -0.26337156, 0.03555479]\n",
      "Iter 7857, loss [-0.21989782, -0.25892982, 0.039031997]\n",
      "Iter 7858, loss [-0.22152679, -0.26071668, 0.03918989]\n",
      "Iter 7859, loss [-0.22467718, -0.26287752, 0.03820034]\n",
      "Iter 7860, loss [-0.20906797, -0.24924514, 0.040177163]\n",
      "Iter 7861, loss [-0.22424856, -0.2630608, 0.038812254]\n",
      "Iter 7862, loss [-0.2246588, -0.2647153, 0.040056515]\n",
      "Iter 7863, loss [-0.22428045, -0.2608584, 0.036577947]\n",
      "Iter 7864, loss [-0.22424507, -0.2624, 0.03815493]\n",
      "Iter 7865, loss [-0.22342035, -0.26354823, 0.04012788]\n",
      "Iter 7866, loss [-0.22554958, -0.26299512, 0.037445538]\n",
      "Iter 7867, loss [-0.21817982, -0.25650412, 0.038324293]\n",
      "Iter 7868, loss [-0.22418337, -0.26056135, 0.036377978]\n",
      "Iter 7869, loss [-0.2209405, -0.25849724, 0.037556745]\n",
      "Iter 7870, loss [-0.22457892, -0.26109764, 0.03651873]\n",
      "Iter 7871, loss [-0.21168613, -0.2522973, 0.04061117]\n",
      "Iter 7872, loss [-0.20019677, -0.2445983, 0.044401523]\n",
      "Iter 7873, loss [-0.2185868, -0.25819734, 0.039610527]\n",
      "Iter 7874, loss [-0.15945978, -0.21479002, 0.055330228]\n",
      "Iter 7875, loss [-0.18330139, -0.23233578, 0.049034387]\n",
      "Iter 7876, loss [-0.22076893, -0.2600625, 0.03929355]\n",
      "Iter 7877, loss [-0.21858072, -0.2555008, 0.036920078]\n",
      "Iter 7878, loss [-0.20099859, -0.24501118, 0.044012588]\n",
      "Iter 7879, loss [-0.22159329, -0.25967383, 0.038080547]\n",
      "Iter 7880, loss [-0.23231134, -0.2672288, 0.03491748]\n",
      "Iter 7881, loss [-0.22078688, -0.25896358, 0.038176697]\n",
      "Iter 7882, loss [-0.2084696, -0.24953312, 0.04106351]\n",
      "Iter 7883, loss [-0.22595677, -0.26359951, 0.037642747]\n",
      "Iter 7884, loss [-0.21894155, -0.256945, 0.03800346]\n",
      "Iter 7885, loss [-0.16451134, -0.22159363, 0.057082295]\n",
      "Iter 7886, loss [-0.22912675, -0.26563698, 0.03651022]\n",
      "Iter 7887, loss [-0.2155366, -0.25589806, 0.040361464]\n",
      "Iter 7888, loss [-0.21660109, -0.25627926, 0.03967817]\n",
      "Iter 7889, loss [-0.22205386, -0.25965452, 0.037600663]\n",
      "Iter 7890, loss [-0.21583036, -0.25631878, 0.040488422]\n",
      "Iter 7891, loss [-0.20296663, -0.24695577, 0.043989137]\n",
      "Iter 7892, loss [-0.22586237, -0.26212183, 0.036259457]\n",
      "Iter 7893, loss [-0.21666133, -0.25736755, 0.040706214]\n",
      "Iter 7894, loss [-0.21710935, -0.25600153, 0.038892187]\n",
      "Iter 7895, loss [-0.19154638, -0.23892853, 0.047382146]\n",
      "Iter 7896, loss [-0.22526851, -0.26189438, 0.036625855]\n",
      "Iter 7897, loss [-0.21855833, -0.25905186, 0.04049353]\n",
      "Iter 7898, loss [-0.21648583, -0.25677642, 0.040290587]\n",
      "Iter 7899, loss [-0.21632867, -0.256421, 0.040092334]\n",
      "Iter 7900, loss [-0.20153677, -0.24470554, 0.043168776]\n",
      "Iter 7901, loss [-0.22323915, -0.2616015, 0.03836235]\n",
      "Iter 7902, loss [-0.23179865, -0.26831445, 0.036515802]\n",
      "Iter 7903, loss [-0.22773258, -0.26397595, 0.03624336]\n",
      "Iter 7904, loss [-0.15641972, -0.21106063, 0.05464091]\n",
      "Iter 7905, loss [-0.22467211, -0.26220325, 0.037531137]\n",
      "Iter 7906, loss [-0.22376063, -0.26293254, 0.03917191]\n",
      "Iter 7907, loss [-0.215502, -0.25332844, 0.037826456]\n",
      "Iter 7908, loss [-0.21692659, -0.2547096, 0.037783016]\n",
      "Iter 7909, loss [-0.21906945, -0.2598484, 0.040778928]\n",
      "Iter 7910, loss [-0.22424985, -0.2630726, 0.038822755]\n",
      "Iter 7911, loss [-0.22782698, -0.26540062, 0.037573643]\n",
      "Iter 7912, loss [-0.21388823, -0.25318822, 0.039300002]\n",
      "Iter 7913, loss [-0.2253948, -0.26257542, 0.037180617]\n",
      "Iter 7914, loss [-0.22698322, -0.2639245, 0.036941282]\n",
      "Iter 7915, loss [-0.22732405, -0.2625232, 0.03519915]\n",
      "Iter 7916, loss [-0.22703956, -0.26295665, 0.035917085]\n",
      "Iter 7917, loss [-0.23092759, -0.26794004, 0.03701245]\n",
      "Iter 7918, loss [-0.22349982, -0.2619452, 0.038445365]\n",
      "Iter 7919, loss [-0.21857224, -0.2619017, 0.043329462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 7920, loss [-0.21224949, -0.25340027, 0.04115077]\n",
      "Iter 7921, loss [-0.23151428, -0.26990563, 0.038391344]\n",
      "Iter 7922, loss [-0.2102917, -0.24914603, 0.038854335]\n",
      "Iter 7923, loss [-0.21899343, -0.26094168, 0.04194826]\n",
      "Iter 7924, loss [-0.21232593, -0.25520006, 0.042874124]\n",
      "Iter 7925, loss [-0.22347975, -0.26015183, 0.036672093]\n",
      "Iter 7926, loss [-0.220469, -0.25781718, 0.037348185]\n",
      "Iter 7927, loss [-0.22762541, -0.26387954, 0.036254123]\n",
      "Iter 7928, loss [-0.23057595, -0.26619792, 0.035621967]\n",
      "Iter 7929, loss [-0.23111361, -0.26672438, 0.035610765]\n",
      "Iter 7930, loss [-0.22218746, -0.26074293, 0.03855548]\n",
      "Iter 7931, loss [-0.22292888, -0.25986624, 0.036937363]\n",
      "Iter 7932, loss [-0.22564203, -0.26349968, 0.03785765]\n",
      "Iter 7933, loss [-0.22295053, -0.2632663, 0.040315762]\n",
      "Iter 7934, loss [-0.21958888, -0.25812376, 0.03853488]\n",
      "Iter 7935, loss [-0.22204329, -0.26214814, 0.040104847]\n",
      "Iter 7936, loss [-0.22282898, -0.25891942, 0.036090434]\n",
      "Iter 7937, loss [-0.22352588, -0.2595809, 0.036055025]\n",
      "Iter 7938, loss [-0.22535008, -0.2616445, 0.03629443]\n",
      "Iter 7939, loss [-0.2248484, -0.26386118, 0.039012775]\n",
      "Iter 7940, loss [-0.23058605, -0.26820615, 0.0376201]\n",
      "Iter 7941, loss [-0.22478232, -0.26379865, 0.039016344]\n",
      "Iter 7942, loss [-0.22612438, -0.26330632, 0.037181936]\n",
      "Iter 7943, loss [-0.22181866, -0.26009488, 0.03827622]\n",
      "Iter 7944, loss [-0.22351748, -0.2606098, 0.037092324]\n",
      "Iter 7945, loss [-0.2164698, -0.25634205, 0.03987226]\n",
      "Iter 7946, loss [-0.22357917, -0.25954467, 0.0359655]\n",
      "Iter 7947, loss [-0.22590764, -0.2618743, 0.035966653]\n",
      "Iter 7948, loss [-0.22063255, -0.2591465, 0.038513966]\n",
      "Iter 7949, loss [-0.22277856, -0.26272127, 0.03994271]\n",
      "Iter 7950, loss [-0.2241587, -0.2627735, 0.03861481]\n",
      "Iter 7951, loss [-0.22498822, -0.26385868, 0.038870454]\n",
      "Iter 7952, loss [-0.22515804, -0.26349452, 0.03833649]\n",
      "Iter 7953, loss [-0.22889137, -0.26598445, 0.037093073]\n",
      "Iter 7954, loss [-0.21672073, -0.25459224, 0.03787151]\n",
      "Iter 7955, loss [-0.22547047, -0.26168764, 0.036217168]\n",
      "Iter 7956, loss [-0.22143206, -0.2586766, 0.037244536]\n",
      "Iter 7957, loss [-0.2157893, -0.25280595, 0.03701664]\n",
      "Iter 7958, loss [-0.21388549, -0.25445005, 0.040564574]\n",
      "Iter 7959, loss [-0.22527346, -0.263622, 0.038348526]\n",
      "Iter 7960, loss [-0.22100453, -0.2614859, 0.040481374]\n",
      "Iter 7961, loss [-0.2252686, -0.2637513, 0.038482692]\n",
      "Iter 7962, loss [-0.22707243, -0.26401517, 0.03694273]\n",
      "Iter 7963, loss [-0.22570956, -0.26325113, 0.037541576]\n",
      "Iter 7964, loss [-0.21763867, -0.25664014, 0.039001457]\n",
      "Iter 7965, loss [-0.22148912, -0.25859773, 0.037108615]\n",
      "Iter 7966, loss [-0.22379571, -0.26070383, 0.036908112]\n",
      "Iter 7967, loss [-0.21154766, -0.25348818, 0.041940525]\n",
      "Iter 7968, loss [-0.22460335, -0.26311448, 0.038511135]\n",
      "Iter 7969, loss [-0.21577884, -0.2562057, 0.040426865]\n",
      "Iter 7970, loss [-0.22866988, -0.26629403, 0.037624154]\n",
      "Iter 7971, loss [-0.22101834, -0.26083204, 0.03981369]\n",
      "Iter 7972, loss [-0.23136106, -0.26787165, 0.03651058]\n",
      "Iter 7973, loss [-0.21957059, -0.25769088, 0.038120285]\n",
      "Iter 7974, loss [-0.22645311, -0.26323187, 0.03677876]\n",
      "Iter 7975, loss [-0.220164, -0.25988024, 0.039716236]\n",
      "Iter 7976, loss [-0.22299603, -0.26224142, 0.039245404]\n",
      "Iter 7977, loss [-0.22239557, -0.2597631, 0.037367523]\n",
      "Iter 7978, loss [-0.22339466, -0.26083127, 0.037436597]\n",
      "Iter 7979, loss [-0.22181383, -0.25946614, 0.03765231]\n",
      "Iter 7980, loss [-0.23026806, -0.26710808, 0.036840014]\n",
      "Iter 7981, loss [-0.21846206, -0.25776, 0.039297923]\n",
      "Iter 7982, loss [-0.22699359, -0.26471233, 0.03771874]\n",
      "Iter 7983, loss [-0.23010501, -0.265178, 0.03507298]\n",
      "Iter 7984, loss [-0.22395219, -0.2612284, 0.03727622]\n",
      "Iter 7985, loss [-0.22413231, -0.26280168, 0.03866936]\n",
      "Iter 7986, loss [-0.20379351, -0.24772419, 0.04393068]\n",
      "Iter 7987, loss [-0.2234166, -0.2628954, 0.039478805]\n",
      "Iter 7988, loss [-0.2278169, -0.26510352, 0.03728662]\n",
      "Iter 7989, loss [-0.17241776, -0.22559331, 0.05317556]\n",
      "Iter 7990, loss [-0.22666311, -0.26467577, 0.038012646]\n",
      "Iter 7991, loss [-0.22768424, -0.26422346, 0.03653921]\n",
      "Iter 7992, loss [-0.20996642, -0.25052112, 0.040554702]\n",
      "Iter 7993, loss [-0.21922307, -0.2583438, 0.039120715]\n",
      "Iter 7994, loss [-0.22580527, -0.2630674, 0.037262127]\n",
      "Iter 7995, loss [-0.2234749, -0.2625312, 0.039056282]\n",
      "Iter 7996, loss [-0.22364798, -0.2618792, 0.038231224]\n",
      "Iter 7997, loss [-0.22704872, -0.26291472, 0.035865996]\n",
      "Iter 7998, loss [-0.21962786, -0.25695798, 0.03733013]\n",
      "Iter 7999, loss [-0.22799096, -0.2657842, 0.03779325]\n",
      "Iter 8000, loss [-0.22821444, -0.26533538, 0.037120935]\n",
      "Iter 8001, loss [-0.22373414, -0.2639973, 0.040263142]\n",
      "Iter 8002, loss [-0.2290129, -0.26740393, 0.038391024]\n",
      "Iter 8003, loss [-0.22690624, -0.2650167, 0.038110465]\n",
      "Iter 8004, loss [-0.22011243, -0.25913474, 0.039022315]\n",
      "Iter 8005, loss [-0.2216178, -0.25960186, 0.03798406]\n",
      "Iter 8006, loss [-0.21109596, -0.25223613, 0.04114016]\n",
      "Iter 8007, loss [-0.22360882, -0.2598619, 0.036253057]\n",
      "Iter 8008, loss [-0.22292231, -0.26064765, 0.037725348]\n",
      "Iter 8009, loss [-0.22777629, -0.26327965, 0.035503365]\n",
      "Iter 8010, loss [-0.23224345, -0.2679687, 0.03572527]\n",
      "Iter 8011, loss [-0.22600864, -0.2640957, 0.03808705]\n",
      "Iter 8012, loss [-0.21792957, -0.25777856, 0.03984898]\n",
      "Iter 8013, loss [-0.2135225, -0.25449228, 0.040969796]\n",
      "Iter 8014, loss [-0.22352009, -0.25920045, 0.035680365]\n",
      "Iter 8015, loss [-0.22345966, -0.26040834, 0.036948673]\n",
      "Iter 8016, loss [-0.2244196, -0.26140675, 0.03698715]\n",
      "Iter 8017, loss [-0.23128347, -0.26547682, 0.034193352]\n",
      "Iter 8018, loss [-0.22796729, -0.26368585, 0.03571856]\n",
      "Iter 8019, loss [-0.2227787, -0.2618753, 0.039096605]\n",
      "Iter 8020, loss [-0.21079175, -0.2529945, 0.042202756]\n",
      "Iter 8021, loss [-0.2262058, -0.2653844, 0.039178606]\n",
      "Iter 8022, loss [-0.20989604, -0.2507539, 0.040857866]\n",
      "Iter 8023, loss [-0.23196203, -0.267979, 0.036016967]\n",
      "Iter 8024, loss [-0.22234918, -0.2601568, 0.03780763]\n",
      "Iter 8025, loss [-0.22568683, -0.26052627, 0.034839436]\n",
      "Iter 8026, loss [-0.22856005, -0.26526308, 0.036703035]\n",
      "Iter 8027, loss [-0.21104148, -0.25187862, 0.040837146]\n",
      "Iter 8028, loss [-0.2207719, -0.26143274, 0.040660843]\n",
      "Iter 8029, loss [-0.21515721, -0.2568173, 0.041660096]\n",
      "Iter 8030, loss [-0.22823668, -0.26547018, 0.037233494]\n",
      "Iter 8031, loss [-0.20280476, -0.24639307, 0.04358831]\n",
      "Iter 8032, loss [-0.22262198, -0.25961414, 0.036992155]\n",
      "Iter 8033, loss [-0.21677278, -0.25624052, 0.039467733]\n",
      "Iter 8034, loss [-0.22922383, -0.26388097, 0.034657136]\n",
      "Iter 8035, loss [-0.22264585, -0.2621381, 0.039492242]\n",
      "Iter 8036, loss [-0.22313936, -0.2608723, 0.03773294]\n",
      "Iter 8037, loss [-0.13672933, -0.19667561, 0.059946284]\n",
      "Iter 8038, loss [-0.20534256, -0.24704371, 0.04170115]\n",
      "Iter 8039, loss [-0.21610549, -0.25534594, 0.039240453]\n",
      "Iter 8040, loss [-0.15856081, -0.21601993, 0.057459123]\n",
      "Iter 8041, loss [-0.22225879, -0.25992745, 0.037668657]\n",
      "Iter 8042, loss [-0.22338226, -0.26335818, 0.039975904]\n",
      "Iter 8043, loss [-0.22327316, -0.26182494, 0.03855177]\n",
      "Iter 8044, loss [-0.20167132, -0.24391992, 0.042248603]\n",
      "Iter 8045, loss [-0.22450708, -0.25936192, 0.034854848]\n",
      "Iter 8046, loss [-0.22303478, -0.25865135, 0.03561656]\n",
      "Iter 8047, loss [-0.22490594, -0.2620613, 0.037155367]\n",
      "Iter 8048, loss [-0.22900398, -0.26439232, 0.035388336]\n",
      "Iter 8049, loss [-0.16685207, -0.22190666, 0.05505459]\n",
      "Iter 8050, loss [-0.23078954, -0.26564172, 0.03485217]\n",
      "Iter 8051, loss [-0.22042035, -0.2619415, 0.04152115]\n",
      "Iter 8052, loss [-0.200414, -0.24007885, 0.039664853]\n",
      "Iter 8053, loss [-0.22062126, -0.25903407, 0.038412813]\n",
      "Iter 8054, loss [-0.21964726, -0.2585049, 0.038857643]\n",
      "Iter 8055, loss [-0.22056688, -0.25886285, 0.038295966]\n",
      "Iter 8056, loss [-0.22610724, -0.26151758, 0.035410352]\n",
      "Iter 8057, loss [-0.19171599, -0.23788135, 0.04616537]\n",
      "Iter 8058, loss [-0.22701263, -0.2653292, 0.038316578]\n",
      "Iter 8059, loss [-0.21904427, -0.25859603, 0.03955177]\n",
      "Iter 8060, loss [-0.22245249, -0.26049584, 0.038043346]\n",
      "Iter 8061, loss [-0.21983072, -0.25970048, 0.03986975]\n",
      "Iter 8062, loss [-0.13618974, -0.20097598, 0.06478624]\n",
      "Iter 8063, loss [-0.2169362, -0.25694546, 0.040009253]\n",
      "Iter 8064, loss [-0.22703987, -0.26269317, 0.035653293]\n",
      "Iter 8065, loss [-0.22154716, -0.25688273, 0.03533557]\n",
      "Iter 8066, loss [-0.23053211, -0.26485935, 0.034327246]\n",
      "Iter 8067, loss [-0.2164304, -0.2537187, 0.03728831]\n",
      "Iter 8068, loss [-0.22085714, -0.2604246, 0.039567474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8069, loss [-0.22592123, -0.26453945, 0.038618222]\n",
      "Iter 8070, loss [-0.22364491, -0.26430774, 0.040662825]\n",
      "Iter 8071, loss [-0.22741805, -0.2674201, 0.040002063]\n",
      "Iter 8072, loss [-0.20820202, -0.24775271, 0.03955069]\n",
      "Iter 8073, loss [-0.23031768, -0.2671234, 0.03680572]\n",
      "Iter 8074, loss [-0.22493684, -0.26191673, 0.03697989]\n",
      "Iter 8075, loss [-0.2257029, -0.2621067, 0.036403786]\n",
      "Iter 8076, loss [-0.14021003, -0.19582684, 0.05561681]\n",
      "Iter 8077, loss [-0.21506132, -0.2547091, 0.039647773]\n",
      "Iter 8078, loss [-0.22805767, -0.26681602, 0.03875835]\n",
      "Iter 8079, loss [-0.2291933, -0.26843855, 0.039245248]\n",
      "Iter 8080, loss [-0.19916761, -0.24593231, 0.0467647]\n",
      "Iter 8081, loss [-0.22696431, -0.26351216, 0.03654785]\n",
      "Iter 8082, loss [-0.18943419, -0.23400223, 0.044568043]\n",
      "Iter 8083, loss [-0.22582752, -0.2617465, 0.03591899]\n",
      "Iter 8084, loss [-0.19899291, -0.24070217, 0.04170926]\n",
      "Iter 8085, loss [-0.2263026, -0.26142168, 0.035119094]\n",
      "Iter 8086, loss [-0.22000426, -0.25900856, 0.0390043]\n",
      "Iter 8087, loss [-0.2298809, -0.2671279, 0.03724701]\n",
      "Iter 8088, loss [-0.22149453, -0.26065928, 0.03916476]\n",
      "Iter 8089, loss [-0.15797341, -0.21776581, 0.0597924]\n",
      "Iter 8090, loss [-0.21811795, -0.25777265, 0.03965471]\n",
      "Iter 8091, loss [-0.15648994, -0.21381378, 0.057323836]\n",
      "Iter 8092, loss [-0.21114977, -0.25142056, 0.04027079]\n",
      "Iter 8093, loss [-0.23408532, -0.26913422, 0.035048902]\n",
      "Iter 8094, loss [-0.21649693, -0.2563195, 0.039822564]\n",
      "Iter 8095, loss [-0.22394814, -0.2594615, 0.035513353]\n",
      "Iter 8096, loss [-0.22747219, -0.26527852, 0.037806325]\n",
      "Iter 8097, loss [-0.22504358, -0.26314193, 0.03809835]\n",
      "Iter 8098, loss [-0.22074915, -0.26120228, 0.040453125]\n",
      "Iter 8099, loss [-0.22506914, -0.262849, 0.03777986]\n",
      "Iter 8100, loss [-0.2286353, -0.26485083, 0.036215525]\n",
      "Iter 8101, loss [-0.22426617, -0.26145342, 0.03718724]\n",
      "Iter 8102, loss [-0.22659269, -0.26205626, 0.03546357]\n",
      "Iter 8103, loss [-0.21537417, -0.2547825, 0.039408334]\n",
      "Iter 8104, loss [-0.20251302, -0.24330606, 0.040793028]\n",
      "Iter 8105, loss [-0.22142972, -0.25673607, 0.03530635]\n",
      "Iter 8106, loss [-0.23090872, -0.26716438, 0.036255665]\n",
      "Iter 8107, loss [-0.22029172, -0.2622035, 0.041911792]\n",
      "Iter 8108, loss [-0.23085961, -0.26786262, 0.037003018]\n",
      "Iter 8109, loss [-0.22703014, -0.26553258, 0.03850244]\n",
      "Iter 8110, loss [-0.2175081, -0.2574791, 0.039970987]\n",
      "Iter 8111, loss [-0.2265226, -0.26364863, 0.037126042]\n",
      "Iter 8112, loss [-0.22455546, -0.25916967, 0.034614205]\n",
      "Iter 8113, loss [-0.22061351, -0.25892448, 0.038310967]\n",
      "Iter 8114, loss [-0.22134995, -0.25924, 0.037890047]\n",
      "Iter 8115, loss [-0.22840321, -0.26585045, 0.03744724]\n",
      "Iter 8116, loss [-0.2134946, -0.25431627, 0.04082168]\n",
      "Iter 8117, loss [-0.22538556, -0.26318195, 0.037796393]\n",
      "Iter 8118, loss [-0.22087188, -0.25948825, 0.038616374]\n",
      "Iter 8119, loss [-0.2231834, -0.26063854, 0.037455145]\n",
      "Iter 8120, loss [-0.22280397, -0.25901762, 0.03621365]\n",
      "Iter 8121, loss [-0.14996263, -0.19787979, 0.047917157]\n",
      "Iter 8122, loss [-0.22006962, -0.25884855, 0.038778935]\n",
      "Iter 8123, loss [-0.22591779, -0.264988, 0.039070226]\n",
      "Iter 8124, loss [-0.21987937, -0.26197764, 0.04209827]\n",
      "Iter 8125, loss [-0.226946, -0.26698488, 0.040038876]\n",
      "Iter 8126, loss [-0.22789638, -0.26534072, 0.037444334]\n",
      "Iter 8127, loss [-0.21779852, -0.25841543, 0.040616915]\n",
      "Iter 8128, loss [-0.2305421, -0.26590076, 0.035358664]\n",
      "Iter 8129, loss [-0.23068665, -0.26721495, 0.0365283]\n",
      "Iter 8130, loss [-0.19335867, -0.24011046, 0.046751782]\n",
      "Iter 8131, loss [-0.23074187, -0.26765522, 0.036913346]\n",
      "Iter 8132, loss [-0.21857774, -0.2572309, 0.038653165]\n",
      "Iter 8133, loss [-0.23447832, -0.27088, 0.036401697]\n",
      "Iter 8134, loss [-0.22805679, -0.26549256, 0.037435763]\n",
      "Iter 8135, loss [-0.18500486, -0.23359053, 0.04858566]\n",
      "Iter 8136, loss [-0.22302069, -0.26062906, 0.03760837]\n",
      "Iter 8137, loss [-0.22026865, -0.26127294, 0.04100428]\n",
      "Iter 8138, loss [-0.16047761, -0.21956976, 0.05909214]\n",
      "Iter 8139, loss [-0.22361957, -0.26059332, 0.036973756]\n",
      "Iter 8140, loss [-0.22236441, -0.25965866, 0.037294254]\n",
      "Iter 8141, loss [-0.21731293, -0.2570584, 0.03974548]\n",
      "Iter 8142, loss [-0.2256873, -0.26471832, 0.039031025]\n",
      "Iter 8143, loss [-0.22273031, -0.25946563, 0.036735322]\n",
      "Iter 8144, loss [-0.22613253, -0.26564774, 0.03951521]\n",
      "Iter 8145, loss [-0.21788824, -0.25753665, 0.039648406]\n",
      "Iter 8146, loss [-0.22312838, -0.26122773, 0.03809935]\n",
      "Iter 8147, loss [-0.21945494, -0.2581997, 0.038744755]\n",
      "Iter 8148, loss [-0.22530064, -0.26184464, 0.036543995]\n",
      "Iter 8149, loss [-0.2210945, -0.2576059, 0.036511403]\n",
      "Iter 8150, loss [-0.22493884, -0.26249033, 0.0375515]\n",
      "Iter 8151, loss [-0.22283745, -0.2611561, 0.038318656]\n",
      "Iter 8152, loss [-0.21919748, -0.25764036, 0.03844288]\n",
      "Iter 8153, loss [-0.21957462, -0.25849587, 0.038921252]\n",
      "Iter 8154, loss [-0.22375642, -0.26173005, 0.037973627]\n",
      "Iter 8155, loss [-0.22471717, -0.26388395, 0.039166786]\n",
      "Iter 8156, loss [-0.21532953, -0.2543923, 0.03906276]\n",
      "Iter 8157, loss [-0.23156902, -0.26819688, 0.036627866]\n",
      "Iter 8158, loss [-0.22396286, -0.2618946, 0.03793176]\n",
      "Iter 8159, loss [-0.18226583, -0.23352352, 0.05125768]\n",
      "Iter 8160, loss [-0.22492263, -0.26360777, 0.038685136]\n",
      "Iter 8161, loss [-0.2297689, -0.26548904, 0.035720136]\n",
      "Iter 8162, loss [-0.21972907, -0.26025343, 0.04052437]\n",
      "Iter 8163, loss [-0.16657847, -0.21969397, 0.053115495]\n",
      "Iter 8164, loss [-0.22218753, -0.26115257, 0.03896503]\n",
      "Iter 8165, loss [-0.21511321, -0.2540451, 0.038931888]\n",
      "Iter 8166, loss [-0.22792423, -0.26372924, 0.035805024]\n",
      "Iter 8167, loss [-0.22484156, -0.26246914, 0.03762757]\n",
      "Iter 8168, loss [-0.22842506, -0.26471248, 0.036287434]\n",
      "Iter 8169, loss [-0.22487168, -0.26215634, 0.037284657]\n",
      "Iter 8170, loss [-0.21441862, -0.25508344, 0.040664822]\n",
      "Iter 8171, loss [-0.23104092, -0.2664196, 0.035378672]\n",
      "Iter 8172, loss [-0.21256718, -0.25372666, 0.041159473]\n",
      "Iter 8173, loss [-0.19322866, -0.23664697, 0.0434183]\n",
      "Iter 8174, loss [-0.22376207, -0.26162678, 0.03786471]\n",
      "Iter 8175, loss [-0.21041855, -0.25245345, 0.042034887]\n",
      "Iter 8176, loss [-0.22703491, -0.26252103, 0.035486113]\n",
      "Iter 8177, loss [-0.18654975, -0.23541136, 0.048861615]\n",
      "Iter 8178, loss [-0.22038755, -0.2582957, 0.037908167]\n",
      "Iter 8179, loss [-0.23079528, -0.2667292, 0.035933923]\n",
      "Iter 8180, loss [-0.20911145, -0.24980904, 0.04069759]\n",
      "Iter 8181, loss [-0.18638934, -0.23854776, 0.052158415]\n",
      "Iter 8182, loss [-0.2209134, -0.26061162, 0.03969823]\n",
      "Iter 8183, loss [-0.21114162, -0.2539647, 0.04282307]\n",
      "Iter 8184, loss [-0.1673118, -0.22501965, 0.057707846]\n",
      "Iter 8185, loss [-0.22188056, -0.25729978, 0.035419222]\n",
      "Iter 8186, loss [-0.22983465, -0.26467326, 0.03483861]\n",
      "Iter 8187, loss [-0.22783023, -0.2644439, 0.03661368]\n",
      "Iter 8188, loss [-0.22944263, -0.26670465, 0.03726202]\n",
      "Iter 8189, loss [-0.21960807, -0.25777277, 0.0381647]\n",
      "Iter 8190, loss [-0.22686891, -0.2633648, 0.03649588]\n",
      "Iter 8191, loss [-0.22414127, -0.26105735, 0.036916077]\n",
      "Iter 8192, loss [-0.22446872, -0.26127395, 0.036805224]\n",
      "Iter 8193, loss [-0.22408769, -0.25979197, 0.035704277]\n",
      "Iter 8194, loss [-0.2147506, -0.25465602, 0.03990541]\n",
      "Iter 8195, loss [-0.22733003, -0.26245892, 0.0351289]\n",
      "Iter 8196, loss [-0.21236828, -0.25167322, 0.03930495]\n",
      "Iter 8197, loss [-0.22851086, -0.26506773, 0.036556877]\n",
      "Iter 8198, loss [-0.23045304, -0.2666777, 0.03622466]\n",
      "Iter 8199, loss [-0.23134205, -0.26797134, 0.036629282]\n",
      "Iter 8200, loss [-0.23217419, -0.2688423, 0.03666813]\n",
      "Iter 8201, loss [-0.23097739, -0.26734984, 0.03637246]\n",
      "Iter 8202, loss [-0.22730504, -0.26515028, 0.037845235]\n",
      "Iter 8203, loss [-0.18284515, -0.2323215, 0.049476363]\n",
      "Iter 8204, loss [-0.22880691, -0.26502112, 0.036214195]\n",
      "Iter 8205, loss [-0.22607896, -0.26377437, 0.037695415]\n",
      "Iter 8206, loss [-0.22687137, -0.26345932, 0.03658796]\n",
      "Iter 8207, loss [-0.15819897, -0.21273112, 0.054532155]\n",
      "Iter 8208, loss [-0.22403371, -0.25986254, 0.035828836]\n",
      "Iter 8209, loss [-0.21564835, -0.255504, 0.03985566]\n",
      "Iter 8210, loss [-0.2194251, -0.25876465, 0.03933956]\n",
      "Iter 8211, loss [-0.17907995, -0.2243023, 0.045222364]\n",
      "Iter 8212, loss [-0.22317228, -0.2613721, 0.038199816]\n",
      "Iter 8213, loss [-0.22571012, -0.26059934, 0.03488922]\n",
      "Iter 8214, loss [-0.22864807, -0.2641066, 0.035458542]\n",
      "Iter 8215, loss [-0.2203429, -0.25725618, 0.036913276]\n",
      "Iter 8216, loss [-0.2134421, -0.2537089, 0.040266793]\n",
      "Iter 8217, loss [-0.2228003, -0.26202515, 0.03922485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8218, loss [-0.22641343, -0.26413062, 0.03771719]\n",
      "Iter 8219, loss [-0.21868923, -0.25913948, 0.04045025]\n",
      "Iter 8220, loss [-0.21784595, -0.25890455, 0.041058592]\n",
      "Iter 8221, loss [-0.22356486, -0.26271176, 0.039146893]\n",
      "Iter 8222, loss [-0.2273899, -0.26454085, 0.03715095]\n",
      "Iter 8223, loss [-0.23060381, -0.2656621, 0.035058297]\n",
      "Iter 8224, loss [-0.2245469, -0.26150772, 0.036960825]\n",
      "Iter 8225, loss [-0.22321361, -0.25801724, 0.03480363]\n",
      "Iter 8226, loss [-0.22507572, -0.26305914, 0.037983418]\n",
      "Iter 8227, loss [-0.17288613, -0.22639522, 0.05350908]\n",
      "Iter 8228, loss [-0.21815789, -0.25790045, 0.039742555]\n",
      "Iter 8229, loss [-0.23234962, -0.26901868, 0.036669057]\n",
      "Iter 8230, loss [-0.2221783, -0.2613906, 0.039212298]\n",
      "Iter 8231, loss [-0.14610712, -0.2063297, 0.060222577]\n",
      "Iter 8232, loss [-0.2270427, -0.26388443, 0.036841728]\n",
      "Iter 8233, loss [-0.22363324, -0.26067525, 0.037042003]\n",
      "Iter 8234, loss [-0.21524376, -0.2545525, 0.03930875]\n",
      "Iter 8235, loss [-0.22846813, -0.2645915, 0.03612335]\n",
      "Iter 8236, loss [-0.22515643, -0.26072618, 0.035569753]\n",
      "Iter 8237, loss [-0.22889584, -0.26495975, 0.03606391]\n",
      "Iter 8238, loss [-0.22449091, -0.26265192, 0.038161017]\n",
      "Iter 8239, loss [-0.22493427, -0.26376945, 0.038835183]\n",
      "Iter 8240, loss [-0.21969013, -0.26009867, 0.040408537]\n",
      "Iter 8241, loss [-0.22099903, -0.2612283, 0.04022927]\n",
      "Iter 8242, loss [-0.22991505, -0.2682614, 0.038346358]\n",
      "Iter 8243, loss [-0.22290999, -0.2615219, 0.038611915]\n",
      "Iter 8244, loss [-0.21059006, -0.2517184, 0.041128337]\n",
      "Iter 8245, loss [-0.22953996, -0.2659136, 0.036373653]\n",
      "Iter 8246, loss [-0.18516111, -0.23454127, 0.049380153]\n",
      "Iter 8247, loss [-0.20599318, -0.25022802, 0.044234842]\n",
      "Iter 8248, loss [-0.2132222, -0.25500196, 0.041779757]\n",
      "Iter 8249, loss [-0.22033992, -0.2596934, 0.039353497]\n",
      "Iter 8250, loss [-0.23450917, -0.2691806, 0.03467143]\n",
      "Iter 8251, loss [-0.21908718, -0.25960678, 0.040519588]\n",
      "Iter 8252, loss [-0.22099367, -0.26004258, 0.03904891]\n",
      "Iter 8253, loss [-0.22419016, -0.2603878, 0.036197644]\n",
      "Iter 8254, loss [-0.21770987, -0.25791523, 0.040205356]\n",
      "Iter 8255, loss [-0.22234468, -0.26197803, 0.03963335]\n",
      "Iter 8256, loss [-0.2257708, -0.2630881, 0.037317306]\n",
      "Iter 8257, loss [-0.21573028, -0.25628135, 0.040551066]\n",
      "Iter 8258, loss [-0.16232008, -0.21567918, 0.0533591]\n",
      "Iter 8259, loss [-0.22790454, -0.26387075, 0.035966203]\n",
      "Iter 8260, loss [-0.22095813, -0.2617587, 0.040800557]\n",
      "Iter 8261, loss [-0.23117186, -0.26726505, 0.036093187]\n",
      "Iter 8262, loss [-0.17418133, -0.22586784, 0.051686507]\n",
      "Iter 8263, loss [-0.22729798, -0.26310095, 0.035802975]\n",
      "Iter 8264, loss [-0.222013, -0.2614169, 0.039403923]\n",
      "Iter 8265, loss [-0.22306041, -0.26274273, 0.039682314]\n",
      "Iter 8266, loss [-0.20459618, -0.24459505, 0.039998874]\n",
      "Iter 8267, loss [-0.1680752, -0.22617611, 0.058100916]\n",
      "Iter 8268, loss [-0.22263235, -0.2599391, 0.03730675]\n",
      "Iter 8269, loss [-0.22566943, -0.2634667, 0.037797254]\n",
      "Iter 8270, loss [-0.22840297, -0.2644958, 0.03609281]\n",
      "Iter 8271, loss [-0.22022867, -0.25914586, 0.03891718]\n",
      "Iter 8272, loss [-0.16748342, -0.22106843, 0.053585015]\n",
      "Iter 8273, loss [-0.22709312, -0.26309523, 0.03600211]\n",
      "Iter 8274, loss [-0.21733855, -0.25680083, 0.039462287]\n",
      "Iter 8275, loss [-0.22116032, -0.2597625, 0.038602173]\n",
      "Iter 8276, loss [-0.1467438, -0.20554653, 0.058802724]\n",
      "Iter 8277, loss [-0.2108733, -0.2506862, 0.0398129]\n",
      "Iter 8278, loss [-0.22044846, -0.25822562, 0.037777156]\n",
      "Iter 8279, loss [-0.22008508, -0.25850517, 0.038420074]\n",
      "Iter 8280, loss [-0.22261247, -0.26055455, 0.03794208]\n",
      "Iter 8281, loss [-0.22303116, -0.25996718, 0.036936022]\n",
      "Iter 8282, loss [-0.22429445, -0.26312324, 0.03882879]\n",
      "Iter 8283, loss [-0.2197763, -0.26039973, 0.040623426]\n",
      "Iter 8284, loss [-0.18635581, -0.23841575, 0.052059934]\n",
      "Iter 8285, loss [-0.22340715, -0.26237267, 0.038965516]\n",
      "Iter 8286, loss [-0.21151538, -0.25447467, 0.042959288]\n",
      "Iter 8287, loss [-0.22620986, -0.26582307, 0.039613202]\n",
      "Iter 8288, loss [-0.1949546, -0.23679437, 0.041839764]\n",
      "Iter 8289, loss [-0.2259891, -0.26227582, 0.036286704]\n",
      "Iter 8290, loss [-0.22984125, -0.26341033, 0.03356908]\n",
      "Iter 8291, loss [-0.21681571, -0.2542021, 0.037386384]\n",
      "Iter 8292, loss [-0.21889403, -0.2562078, 0.037313767]\n",
      "Iter 8293, loss [-0.22232053, -0.26024598, 0.037925452]\n",
      "Iter 8294, loss [-0.21030182, -0.253674, 0.04337219]\n",
      "Iter 8295, loss [-0.22237009, -0.26054993, 0.038179837]\n",
      "Iter 8296, loss [-0.23024803, -0.26745147, 0.03720343]\n",
      "Iter 8297, loss [-0.21500361, -0.2547965, 0.039792895]\n",
      "Iter 8298, loss [-0.20366096, -0.24678476, 0.04312379]\n",
      "Iter 8299, loss [-0.21173546, -0.25298905, 0.041253593]\n",
      "Iter 8300, loss [-0.22013329, -0.25636223, 0.036228936]\n",
      "Iter 8301, loss [-0.21627037, -0.25556183, 0.03929146]\n",
      "Iter 8302, loss [-0.22302529, -0.26140338, 0.038378082]\n",
      "Iter 8303, loss [-0.22871698, -0.26504043, 0.03632344]\n",
      "Iter 8304, loss [-0.22658162, -0.26527128, 0.03868966]\n",
      "Iter 8305, loss [-0.21965371, -0.25943837, 0.039784655]\n",
      "Iter 8306, loss [-0.21531788, -0.25586888, 0.040551007]\n",
      "Iter 8307, loss [-0.23190935, -0.26841882, 0.03650947]\n",
      "Iter 8308, loss [-0.22157598, -0.25971663, 0.03814065]\n",
      "Iter 8309, loss [-0.22426777, -0.2622675, 0.037999734]\n",
      "Iter 8310, loss [-0.22856843, -0.2645779, 0.036009453]\n",
      "Iter 8311, loss [-0.22311884, -0.26008126, 0.036962412]\n",
      "Iter 8312, loss [-0.23222461, -0.26571566, 0.033491045]\n",
      "Iter 8313, loss [-0.22575064, -0.26282737, 0.037076723]\n",
      "Iter 8314, loss [-0.22134364, -0.26065916, 0.03931553]\n",
      "Iter 8315, loss [-0.22840711, -0.26601842, 0.037611306]\n",
      "Iter 8316, loss [-0.21819912, -0.25688073, 0.03868161]\n",
      "Iter 8317, loss [-0.19264765, -0.23947449, 0.04682684]\n",
      "Iter 8318, loss [-0.15850902, -0.21478762, 0.056278598]\n",
      "Iter 8319, loss [-0.22402236, -0.26263705, 0.038614687]\n",
      "Iter 8320, loss [-0.21797049, -0.2598324, 0.041861914]\n",
      "Iter 8321, loss [-0.22646758, -0.26445833, 0.037990745]\n",
      "Iter 8322, loss [-0.2200914, -0.25889608, 0.038804688]\n",
      "Iter 8323, loss [-0.22013164, -0.25953317, 0.03940154]\n",
      "Iter 8324, loss [-0.21208927, -0.2545659, 0.042476617]\n",
      "Iter 8325, loss [-0.22678444, -0.26362142, 0.03683699]\n",
      "Iter 8326, loss [-0.21804675, -0.2580029, 0.039956152]\n",
      "Iter 8327, loss [-0.20832454, -0.25201198, 0.043687448]\n",
      "Iter 8328, loss [-0.221708, -0.2606037, 0.038895696]\n",
      "Iter 8329, loss [-0.2159249, -0.2549224, 0.038997486]\n",
      "Iter 8330, loss [-0.22950485, -0.26540923, 0.035904385]\n",
      "Iter 8331, loss [-0.22582464, -0.26369572, 0.037871074]\n",
      "Iter 8332, loss [-0.22811697, -0.26569733, 0.037580352]\n",
      "Iter 8333, loss [-0.20528254, -0.24233344, 0.03705091]\n",
      "Iter 8334, loss [-0.2240026, -0.260884, 0.03688138]\n",
      "Iter 8335, loss [-0.22618786, -0.2630481, 0.036860265]\n",
      "Iter 8336, loss [-0.2348423, -0.27088642, 0.036044117]\n",
      "Iter 8337, loss [-0.22576502, -0.26307872, 0.037313707]\n",
      "Iter 8338, loss [-0.22500426, -0.2622304, 0.037226148]\n",
      "Iter 8339, loss [-0.23167345, -0.26679534, 0.035121888]\n",
      "Iter 8340, loss [-0.2181828, -0.25637257, 0.03818976]\n",
      "Iter 8341, loss [-0.21669045, -0.25595063, 0.03926018]\n",
      "Iter 8342, loss [-0.21512567, -0.2549901, 0.039864432]\n",
      "Iter 8343, loss [-0.2323589, -0.26707757, 0.03471867]\n",
      "Iter 8344, loss [-0.21833068, -0.26006496, 0.04173427]\n",
      "Iter 8345, loss [-0.22360776, -0.26158115, 0.037973385]\n",
      "Iter 8346, loss [-0.22219929, -0.25998652, 0.03778723]\n",
      "Iter 8347, loss [-0.22595319, -0.26238513, 0.03643194]\n",
      "Iter 8348, loss [-0.22071409, -0.25904846, 0.038334366]\n",
      "Iter 8349, loss [-0.22436772, -0.26138765, 0.03701992]\n",
      "Iter 8350, loss [-0.2342664, -0.26939833, 0.03513194]\n",
      "Iter 8351, loss [-0.22520477, -0.26033026, 0.03512549]\n",
      "Iter 8352, loss [-0.23008585, -0.26662216, 0.036536314]\n",
      "Iter 8353, loss [-0.23339105, -0.2691529, 0.03576187]\n",
      "Iter 8354, loss [-0.21910347, -0.25808182, 0.038978353]\n",
      "Iter 8355, loss [-0.21983486, -0.25820148, 0.038366623]\n",
      "Iter 8356, loss [-0.20882294, -0.2469916, 0.03816867]\n",
      "Iter 8357, loss [-0.2310996, -0.26668295, 0.035583355]\n",
      "Iter 8358, loss [-0.21399577, -0.25443503, 0.04043926]\n",
      "Iter 8359, loss [-0.21487191, -0.25469857, 0.03982666]\n",
      "Iter 8360, loss [-0.22488394, -0.26209974, 0.037215807]\n",
      "Iter 8361, loss [-0.2285285, -0.26360217, 0.035073675]\n",
      "Iter 8362, loss [-0.23849304, -0.2739775, 0.035484448]\n",
      "Iter 8363, loss [-0.22682416, -0.2643454, 0.037521236]\n",
      "Iter 8364, loss [-0.22757976, -0.26517665, 0.037596893]\n",
      "Iter 8365, loss [-0.21638927, -0.25623932, 0.039850064]\n",
      "Iter 8366, loss [-0.2192383, -0.25971037, 0.040472075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8367, loss [-0.21068838, -0.25308183, 0.04239344]\n",
      "Iter 8368, loss [-0.21491143, -0.25378057, 0.038869135]\n",
      "Iter 8369, loss [-0.22018315, -0.2554874, 0.035304263]\n",
      "Iter 8370, loss [-0.21629393, -0.25371462, 0.03742069]\n",
      "Iter 8371, loss [-0.22241943, -0.2564022, 0.03398277]\n",
      "Iter 8372, loss [-0.15706024, -0.20624533, 0.049185097]\n",
      "Iter 8373, loss [-0.21497115, -0.25379774, 0.038826585]\n",
      "Iter 8374, loss [-0.22506465, -0.2632609, 0.038196247]\n",
      "Iter 8375, loss [-0.21826382, -0.25943002, 0.0411662]\n",
      "Iter 8376, loss [-0.21866733, -0.26008224, 0.041414917]\n",
      "Iter 8377, loss [-0.21817327, -0.258548, 0.04037472]\n",
      "Iter 8378, loss [-0.20762327, -0.24877518, 0.041151904]\n",
      "Iter 8379, loss [-0.23186763, -0.26727206, 0.03540443]\n",
      "Iter 8380, loss [-0.22559223, -0.26041895, 0.034826733]\n",
      "Iter 8381, loss [-0.2129411, -0.2501627, 0.037221596]\n",
      "Iter 8382, loss [-0.2196687, -0.2578837, 0.038214996]\n",
      "Iter 8383, loss [-0.21255636, -0.25237975, 0.039823383]\n",
      "Iter 8384, loss [-0.22026518, -0.25598145, 0.03571627]\n",
      "Iter 8385, loss [-0.21913524, -0.25763506, 0.038499817]\n",
      "Iter 8386, loss [-0.21735954, -0.25693318, 0.039573636]\n",
      "Iter 8387, loss [-0.21904564, -0.25593433, 0.03688868]\n",
      "Iter 8388, loss [-0.21575949, -0.25641698, 0.040657483]\n",
      "Iter 8389, loss [-0.22825618, -0.2645161, 0.0362599]\n",
      "Iter 8390, loss [-0.22946662, -0.26513368, 0.03566706]\n",
      "Iter 8391, loss [-0.22031948, -0.25623804, 0.03591856]\n",
      "Iter 8392, loss [-0.21500856, -0.256131, 0.041122444]\n",
      "Iter 8393, loss [-0.21531962, -0.25610685, 0.04078724]\n",
      "Iter 8394, loss [-0.22092551, -0.25789437, 0.036968865]\n",
      "Iter 8395, loss [-0.22837299, -0.26537466, 0.03700167]\n",
      "Iter 8396, loss [-0.17134203, -0.22574343, 0.054401394]\n",
      "Iter 8397, loss [-0.22166091, -0.25988972, 0.038228802]\n",
      "Iter 8398, loss [-0.22047989, -0.2592413, 0.03876142]\n",
      "Iter 8399, loss [-0.22288641, -0.25876832, 0.0358819]\n",
      "Iter 8400, loss [-0.21695605, -0.25590715, 0.038951106]\n",
      "Iter 8401, loss [-0.2213596, -0.2592796, 0.037920013]\n",
      "Iter 8402, loss [-0.21550472, -0.25320658, 0.03770186]\n",
      "Iter 8403, loss [-0.22431658, -0.2636177, 0.039301112]\n",
      "Iter 8404, loss [-0.2268255, -0.26591736, 0.039091848]\n",
      "Iter 8405, loss [-0.21721761, -0.25772947, 0.040511858]\n",
      "Iter 8406, loss [-0.21675134, -0.2559474, 0.03919607]\n",
      "Iter 8407, loss [-0.21211755, -0.25397205, 0.04185451]\n",
      "Iter 8408, loss [-0.22790495, -0.2646113, 0.03670636]\n",
      "Iter 8409, loss [-0.22424605, -0.26125994, 0.03701388]\n",
      "Iter 8410, loss [-0.22669408, -0.2624118, 0.035717722]\n",
      "Iter 8411, loss [-0.21934408, -0.25906593, 0.03972184]\n",
      "Iter 8412, loss [-0.1895976, -0.23390116, 0.044303548]\n",
      "Iter 8413, loss [-0.22250089, -0.26021364, 0.03771276]\n",
      "Iter 8414, loss [-0.21244524, -0.25655797, 0.044112727]\n",
      "Iter 8415, loss [-0.22929952, -0.26764378, 0.038344268]\n",
      "Iter 8416, loss [-0.23116057, -0.26828438, 0.037123818]\n",
      "Iter 8417, loss [-0.22292268, -0.261657, 0.038734313]\n",
      "Iter 8418, loss [-0.21988735, -0.25946692, 0.03957957]\n",
      "Iter 8419, loss [-0.22766751, -0.26499403, 0.03732652]\n",
      "Iter 8420, loss [-0.2272929, -0.26399112, 0.036698215]\n",
      "Iter 8421, loss [-0.22447409, -0.2605786, 0.03610451]\n",
      "Iter 8422, loss [-0.22315192, -0.26236826, 0.039216332]\n",
      "Iter 8423, loss [-0.22481248, -0.26245874, 0.037646264]\n",
      "Iter 8424, loss [-0.22367957, -0.26281384, 0.03913427]\n",
      "Iter 8425, loss [-0.22429323, -0.26295346, 0.03866023]\n",
      "Iter 8426, loss [-0.21193177, -0.25412768, 0.042195912]\n",
      "Iter 8427, loss [-0.21754102, -0.25784764, 0.04030661]\n",
      "Iter 8428, loss [-0.21831429, -0.25808978, 0.03977549]\n",
      "Iter 8429, loss [-0.2244362, -0.2623152, 0.037879027]\n",
      "Iter 8430, loss [-0.22858828, -0.26465172, 0.03606343]\n",
      "Iter 8431, loss [-0.22401433, -0.26221746, 0.03820313]\n",
      "Iter 8432, loss [-0.2239818, -0.2615296, 0.037547793]\n",
      "Iter 8433, loss [-0.2257937, -0.26332226, 0.037528556]\n",
      "Iter 8434, loss [-0.22580448, -0.26251367, 0.03670919]\n",
      "Iter 8435, loss [-0.22663766, -0.26227018, 0.035632513]\n",
      "Iter 8436, loss [-0.22602355, -0.26243585, 0.03641229]\n",
      "Iter 8437, loss [-0.2248778, -0.2614485, 0.036570705]\n",
      "Iter 8438, loss [-0.21517064, -0.25490388, 0.039733246]\n",
      "Iter 8439, loss [-0.22551352, -0.26551193, 0.039998412]\n",
      "Iter 8440, loss [-0.22411296, -0.26110944, 0.036996484]\n",
      "Iter 8441, loss [-0.21825479, -0.25852484, 0.040270045]\n",
      "Iter 8442, loss [-0.22874181, -0.2654221, 0.0366803]\n",
      "Iter 8443, loss [-0.2271568, -0.26628208, 0.039125275]\n",
      "Iter 8444, loss [-0.20820203, -0.24926715, 0.041065108]\n",
      "Iter 8445, loss [-0.22867872, -0.26540056, 0.03672184]\n",
      "Iter 8446, loss [-0.21891226, -0.25566056, 0.036748305]\n",
      "Iter 8447, loss [-0.22281098, -0.2612431, 0.038432114]\n",
      "Iter 8448, loss [-0.21992233, -0.25737673, 0.037454393]\n",
      "Iter 8449, loss [-0.23293237, -0.267359, 0.034426615]\n",
      "Iter 8450, loss [-0.23078176, -0.26735887, 0.036577098]\n",
      "Iter 8451, loss [-0.21095455, -0.25274074, 0.041786194]\n",
      "Iter 8452, loss [-0.23101655, -0.26779377, 0.036777224]\n",
      "Iter 8453, loss [-0.22009233, -0.25745785, 0.037365533]\n",
      "Iter 8454, loss [-0.22753084, -0.26380137, 0.03627052]\n",
      "Iter 8455, loss [-0.19416511, -0.23685695, 0.042691838]\n",
      "Iter 8456, loss [-0.23127341, -0.267596, 0.03632259]\n",
      "Iter 8457, loss [-0.2300978, -0.26547372, 0.035375923]\n",
      "Iter 8458, loss [-0.21756239, -0.2567513, 0.039188907]\n",
      "Iter 8459, loss [-0.22767009, -0.2646369, 0.036966812]\n",
      "Iter 8460, loss [-0.22508144, -0.2623589, 0.037277468]\n",
      "Iter 8461, loss [-0.23099515, -0.26755455, 0.036559395]\n",
      "Iter 8462, loss [-0.22974613, -0.2653319, 0.035585757]\n",
      "Iter 8463, loss [-0.21664667, -0.25613984, 0.03949318]\n",
      "Iter 8464, loss [-0.21217045, -0.25250664, 0.040336188]\n",
      "Iter 8465, loss [-0.21040908, -0.251841, 0.041431926]\n",
      "Iter 8466, loss [-0.22310467, -0.2614212, 0.03831653]\n",
      "Iter 8467, loss [-0.22602406, -0.26070777, 0.034683697]\n",
      "Iter 8468, loss [-0.22352998, -0.2617109, 0.038180936]\n",
      "Iter 8469, loss [-0.2152608, -0.25562134, 0.040360533]\n",
      "Iter 8470, loss [-0.22627786, -0.26488754, 0.038609676]\n",
      "Iter 8471, loss [-0.23145238, -0.26780686, 0.036354482]\n",
      "Iter 8472, loss [-0.22356597, -0.26151708, 0.037951116]\n",
      "Iter 8473, loss [-0.23137459, -0.26813823, 0.03676363]\n",
      "Iter 8474, loss [-0.22843128, -0.26396906, 0.03553778]\n",
      "Iter 8475, loss [-0.21797484, -0.2583101, 0.040335264]\n",
      "Iter 8476, loss [-0.21692926, -0.25430402, 0.03737477]\n",
      "Iter 8477, loss [-0.18801165, -0.2348293, 0.04681766]\n",
      "Iter 8478, loss [-0.22376874, -0.26176473, 0.03799599]\n",
      "Iter 8479, loss [-0.21915154, -0.2560291, 0.036877554]\n",
      "Iter 8480, loss [-0.20803268, -0.25073794, 0.04270525]\n",
      "Iter 8481, loss [-0.22770934, -0.26469374, 0.0369844]\n",
      "Iter 8482, loss [-0.22472522, -0.26163563, 0.03691041]\n",
      "Iter 8483, loss [-0.22421832, -0.26148456, 0.037266236]\n",
      "Iter 8484, loss [-0.22683482, -0.26404196, 0.037207138]\n",
      "Iter 8485, loss [-0.20988661, -0.2508095, 0.040922873]\n",
      "Iter 8486, loss [-0.19141997, -0.23936261, 0.04794264]\n",
      "Iter 8487, loss [-0.15893728, -0.21429065, 0.05535338]\n",
      "Iter 8488, loss [-0.22097108, -0.26104817, 0.040077098]\n",
      "Iter 8489, loss [-0.22721696, -0.26498502, 0.03776806]\n",
      "Iter 8490, loss [-0.2275694, -0.2644341, 0.03686469]\n",
      "Iter 8491, loss [-0.22810116, -0.2639155, 0.03581434]\n",
      "Iter 8492, loss [-0.22794674, -0.26432246, 0.036375716]\n",
      "Iter 8493, loss [-0.22149143, -0.25960603, 0.038114615]\n",
      "Iter 8494, loss [-0.22203952, -0.26069972, 0.038660206]\n",
      "Iter 8495, loss [-0.21740405, -0.25848773, 0.041083682]\n",
      "Iter 8496, loss [-0.22560829, -0.26422814, 0.03861984]\n",
      "Iter 8497, loss [-0.22497356, -0.26302192, 0.03804835]\n",
      "Iter 8498, loss [-0.22354971, -0.26174715, 0.038197443]\n",
      "Iter 8499, loss [-0.23170993, -0.26858243, 0.0368725]\n",
      "Iter 8500, loss [-0.2150251, -0.25241753, 0.037392437]\n",
      "Iter 8501, loss [-0.2169398, -0.25617498, 0.03923518]\n",
      "Iter 8502, loss [-0.20892864, -0.25019518, 0.04126653]\n",
      "Iter 8503, loss [-0.23600817, -0.27174696, 0.0357388]\n",
      "Iter 8504, loss [-0.21834731, -0.25817105, 0.03982374]\n",
      "Iter 8505, loss [-0.23023015, -0.26684785, 0.036617704]\n",
      "Iter 8506, loss [-0.228604, -0.26770657, 0.03910257]\n",
      "Iter 8507, loss [-0.21649654, -0.25481194, 0.0383154]\n",
      "Iter 8508, loss [-0.20991477, -0.25089327, 0.0409785]\n",
      "Iter 8509, loss [-0.22786416, -0.2628172, 0.034953043]\n",
      "Iter 8510, loss [-0.22678648, -0.26214528, 0.035358798]\n",
      "Iter 8511, loss [-0.21652296, -0.25676093, 0.040237967]\n",
      "Iter 8512, loss [-0.2176196, -0.256948, 0.0393284]\n",
      "Iter 8513, loss [-0.22194383, -0.26124644, 0.039302614]\n",
      "Iter 8514, loss [-0.21730351, -0.25686023, 0.03955672]\n",
      "Iter 8515, loss [-0.2259111, -0.26368073, 0.037769627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8516, loss [-0.22571158, -0.26239666, 0.036685072]\n",
      "Iter 8517, loss [-0.22039507, -0.2583515, 0.03795643]\n",
      "Iter 8518, loss [-0.22407693, -0.2614028, 0.037325855]\n",
      "Iter 8519, loss [-0.21643768, -0.25551116, 0.03907348]\n",
      "Iter 8520, loss [-0.2181977, -0.257789, 0.039591283]\n",
      "Iter 8521, loss [-0.21497121, -0.25381202, 0.038840793]\n",
      "Iter 8522, loss [-0.20914158, -0.2504097, 0.041268103]\n",
      "Iter 8523, loss [-0.2114459, -0.2508828, 0.039436914]\n",
      "Iter 8524, loss [-0.22412446, -0.26237807, 0.038253605]\n",
      "Iter 8525, loss [-0.15301073, -0.21000047, 0.05698975]\n",
      "Iter 8526, loss [-0.22285022, -0.26051223, 0.037662018]\n",
      "Iter 8527, loss [-0.2281318, -0.26561964, 0.037487835]\n",
      "Iter 8528, loss [-0.21789235, -0.2590678, 0.04117545]\n",
      "Iter 8529, loss [-0.21874866, -0.25947857, 0.040729918]\n",
      "Iter 8530, loss [-0.23025313, -0.26643842, 0.036185287]\n",
      "Iter 8531, loss [-0.21173617, -0.25122848, 0.039492317]\n",
      "Iter 8532, loss [-0.22201908, -0.26151, 0.039490946]\n",
      "Iter 8533, loss [-0.2153358, -0.25441587, 0.03908007]\n",
      "Iter 8534, loss [-0.18630512, -0.23917656, 0.052871436]\n",
      "Iter 8535, loss [-0.2266752, -0.26457912, 0.03790392]\n",
      "Iter 8536, loss [-0.18671082, -0.2363668, 0.049655974]\n",
      "Iter 8537, loss [-0.2230895, -0.2617782, 0.038688704]\n",
      "Iter 8538, loss [-0.2008798, -0.2458959, 0.04501611]\n",
      "Iter 8539, loss [-0.2245277, -0.26332724, 0.03879954]\n",
      "Iter 8540, loss [-0.22853771, -0.26554063, 0.037002917]\n",
      "Iter 8541, loss [-0.22057539, -0.26059324, 0.040017843]\n",
      "Iter 8542, loss [-0.2270695, -0.26552427, 0.038454764]\n",
      "Iter 8543, loss [-0.22605747, -0.2635666, 0.037509136]\n",
      "Iter 8544, loss [-0.20759445, -0.25049344, 0.04289899]\n",
      "Iter 8545, loss [-0.22746032, -0.26456046, 0.037100136]\n",
      "Iter 8546, loss [-0.22174685, -0.25844204, 0.036695193]\n",
      "Iter 8547, loss [-0.21712083, -0.25414637, 0.03702555]\n",
      "Iter 8548, loss [-0.21402653, -0.25448385, 0.040457323]\n",
      "Iter 8549, loss [-0.21589234, -0.2544199, 0.03852754]\n",
      "Iter 8550, loss [-0.23351806, -0.26866847, 0.035150405]\n",
      "Iter 8551, loss [-0.2193402, -0.25759196, 0.038251765]\n",
      "Iter 8552, loss [-0.17381227, -0.22645776, 0.052645486]\n",
      "Iter 8553, loss [-0.22632377, -0.26436588, 0.038042113]\n",
      "Iter 8554, loss [-0.23251235, -0.26956737, 0.037055008]\n",
      "Iter 8555, loss [-0.21909368, -0.25639072, 0.037297048]\n",
      "Iter 8556, loss [-0.23441064, -0.2696469, 0.03523626]\n",
      "Iter 8557, loss [-0.21254596, -0.2551227, 0.04257673]\n",
      "Iter 8558, loss [-0.2298573, -0.2661344, 0.036277108]\n",
      "Iter 8559, loss [-0.22342148, -0.26177186, 0.03835038]\n",
      "Iter 8560, loss [-0.22611067, -0.26364866, 0.037537985]\n",
      "Iter 8561, loss [-0.22889997, -0.26381055, 0.034910575]\n",
      "Iter 8562, loss [-0.22414698, -0.26169926, 0.037552282]\n",
      "Iter 8563, loss [-0.22742794, -0.26435348, 0.036925536]\n",
      "Iter 8564, loss [-0.21389797, -0.25345224, 0.039554264]\n",
      "Iter 8565, loss [-0.21738346, -0.25480238, 0.037418913]\n",
      "Iter 8566, loss [-0.22855718, -0.26287895, 0.03432177]\n",
      "Iter 8567, loss [-0.22456045, -0.26126054, 0.036700085]\n",
      "Iter 8568, loss [-0.2180408, -0.25836626, 0.040325463]\n",
      "Iter 8569, loss [-0.22436486, -0.26254457, 0.038179707]\n",
      "Iter 8570, loss [-0.22251007, -0.26166573, 0.039155655]\n",
      "Iter 8571, loss [-0.23112062, -0.26800078, 0.036880165]\n",
      "Iter 8572, loss [-0.21643728, -0.25437206, 0.037934788]\n",
      "Iter 8573, loss [-0.2293113, -0.267393, 0.03808169]\n",
      "Iter 8574, loss [-0.2129852, -0.25359234, 0.04060714]\n",
      "Iter 8575, loss [-0.22958435, -0.26625407, 0.036669713]\n",
      "Iter 8576, loss [-0.20900641, -0.248911, 0.039904576]\n",
      "Iter 8577, loss [-0.22147736, -0.2595982, 0.038120836]\n",
      "Iter 8578, loss [-0.22601607, -0.26347303, 0.03745696]\n",
      "Iter 8579, loss [-0.22197078, -0.25923592, 0.037265133]\n",
      "Iter 8580, loss [-0.23034859, -0.26480076, 0.034452163]\n",
      "Iter 8581, loss [-0.22648443, -0.26345617, 0.036971737]\n",
      "Iter 8582, loss [-0.23078075, -0.26634538, 0.03556463]\n",
      "Iter 8583, loss [-0.21100347, -0.25161496, 0.040611487]\n",
      "Iter 8584, loss [-0.21954694, -0.26067865, 0.041131698]\n",
      "Iter 8585, loss [-0.21812311, -0.2580876, 0.039964493]\n",
      "Iter 8586, loss [-0.22248338, -0.26001304, 0.03752966]\n",
      "Iter 8587, loss [-0.22915867, -0.26640242, 0.037243746]\n",
      "Iter 8588, loss [-0.22545274, -0.2637673, 0.038314566]\n",
      "Iter 8589, loss [-0.23143554, -0.26725832, 0.035822786]\n",
      "Iter 8590, loss [-0.21320213, -0.2538872, 0.040685073]\n",
      "Iter 8591, loss [-0.21820317, -0.25821483, 0.040011656]\n",
      "Iter 8592, loss [-0.2237879, -0.26098403, 0.037196137]\n",
      "Iter 8593, loss [-0.22537993, -0.26493457, 0.03955464]\n",
      "Iter 8594, loss [-0.22564924, -0.2630954, 0.03744617]\n",
      "Iter 8595, loss [-0.22442718, -0.26250505, 0.038077872]\n",
      "Iter 8596, loss [-0.22381353, -0.26057592, 0.036762387]\n",
      "Iter 8597, loss [-0.22946501, -0.26423386, 0.03476885]\n",
      "Iter 8598, loss [-0.21843848, -0.25807843, 0.03963995]\n",
      "Iter 8599, loss [-0.22493644, -0.26446176, 0.039525315]\n",
      "Iter 8600, loss [-0.23061542, -0.26805377, 0.037438344]\n",
      "Iter 8601, loss [-0.22780305, -0.26618752, 0.03838446]\n",
      "Iter 8602, loss [-0.22424704, -0.26383743, 0.03959039]\n",
      "Iter 8603, loss [-0.21558836, -0.2548899, 0.03930155]\n",
      "Iter 8604, loss [-0.21972841, -0.25829136, 0.03856296]\n",
      "Iter 8605, loss [-0.23245704, -0.26669607, 0.03423903]\n",
      "Iter 8606, loss [-0.21071894, -0.25183085, 0.0411119]\n",
      "Iter 8607, loss [-0.13685577, -0.19544964, 0.05859387]\n",
      "Iter 8608, loss [-0.22002481, -0.2604949, 0.04047008]\n",
      "Iter 8609, loss [-0.1872227, -0.23867303, 0.051450323]\n",
      "Iter 8610, loss [-0.22433065, -0.26214465, 0.037814002]\n",
      "Iter 8611, loss [-0.22022852, -0.25973177, 0.03950324]\n",
      "Iter 8612, loss [-0.23154953, -0.2679136, 0.036364075]\n",
      "Iter 8613, loss [-0.21488526, -0.2553192, 0.04043395]\n",
      "Iter 8614, loss [-0.21650027, -0.25168908, 0.03518881]\n",
      "Iter 8615, loss [-0.22953561, -0.26487896, 0.035343356]\n",
      "Iter 8616, loss [-0.21606722, -0.25540504, 0.039337806]\n",
      "Iter 8617, loss [-0.22628888, -0.26442719, 0.038138293]\n",
      "Iter 8618, loss [-0.22834533, -0.2660123, 0.037666976]\n",
      "Iter 8619, loss [-0.23087677, -0.2686059, 0.03772911]\n",
      "Iter 8620, loss [-0.2237232, -0.26118124, 0.03745804]\n",
      "Iter 8621, loss [-0.22662424, -0.26443648, 0.037812248]\n",
      "Iter 8622, loss [-0.21694231, -0.2566912, 0.03974887]\n",
      "Iter 8623, loss [-0.22247559, -0.2597514, 0.03727583]\n",
      "Iter 8624, loss [-0.22263497, -0.25999635, 0.037361383]\n",
      "Iter 8625, loss [-0.21964706, -0.25819692, 0.03854985]\n",
      "Iter 8626, loss [-0.21211618, -0.25060606, 0.038489886]\n",
      "Iter 8627, loss [-0.2194618, -0.25792, 0.0384582]\n",
      "Iter 8628, loss [-0.20328909, -0.24563639, 0.042347305]\n",
      "Iter 8629, loss [-0.2280797, -0.26594222, 0.037862502]\n",
      "Iter 8630, loss [-0.21640134, -0.25268242, 0.03628108]\n",
      "Iter 8631, loss [-0.22715044, -0.26438084, 0.037230402]\n",
      "Iter 8632, loss [-0.22269467, -0.26056743, 0.03787276]\n",
      "Iter 8633, loss [-0.22297892, -0.25986856, 0.036889642]\n",
      "Iter 8634, loss [-0.21032447, -0.2516023, 0.041277826]\n",
      "Iter 8635, loss [-0.2214252, -0.2598933, 0.03846809]\n",
      "Iter 8636, loss [-0.22218, -0.2621146, 0.039934617]\n",
      "Iter 8637, loss [-0.21098006, -0.25141415, 0.04043409]\n",
      "Iter 8638, loss [-0.23298371, -0.2676728, 0.03468909]\n",
      "Iter 8639, loss [-0.21813537, -0.25619113, 0.03805576]\n",
      "Iter 8640, loss [-0.21930806, -0.25883105, 0.039522987]\n",
      "Iter 8641, loss [-0.2256777, -0.26537883, 0.03970113]\n",
      "Iter 8642, loss [-0.22471012, -0.26328123, 0.0385711]\n",
      "Iter 8643, loss [-0.2323914, -0.26948467, 0.037093267]\n",
      "Iter 8644, loss [-0.2017132, -0.24485224, 0.043139033]\n",
      "Iter 8645, loss [-0.22684534, -0.2659386, 0.03909327]\n",
      "Iter 8646, loss [-0.21406, -0.25275293, 0.038692933]\n",
      "Iter 8647, loss [-0.22022083, -0.2597967, 0.039575867]\n",
      "Iter 8648, loss [-0.22106777, -0.2595975, 0.038529735]\n",
      "Iter 8649, loss [-0.22687632, -0.26462168, 0.037745364]\n",
      "Iter 8650, loss [-0.22929966, -0.26668286, 0.0373832]\n",
      "Iter 8651, loss [-0.20937887, -0.25132298, 0.04194411]\n",
      "Iter 8652, loss [-0.22901972, -0.2658943, 0.036874574]\n",
      "Iter 8653, loss [-0.22796154, -0.2646879, 0.036726348]\n",
      "Iter 8654, loss [-0.22319616, -0.260534, 0.03733782]\n",
      "Iter 8655, loss [-0.1828222, -0.23387253, 0.051050335]\n",
      "Iter 8656, loss [-0.21464986, -0.2550589, 0.040409066]\n",
      "Iter 8657, loss [-0.23107526, -0.26826134, 0.037186082]\n",
      "Iter 8658, loss [-0.20926058, -0.24669017, 0.037429582]\n",
      "Iter 8659, loss [-0.22122201, -0.259265, 0.038042992]\n",
      "Iter 8660, loss [-0.20268983, -0.24902984, 0.04634001]\n",
      "Iter 8661, loss [-0.22178254, -0.2595237, 0.037741154]\n",
      "Iter 8662, loss [-0.21986578, -0.2582246, 0.038358822]\n",
      "Iter 8663, loss [-0.22055745, -0.26052526, 0.039967805]\n",
      "Iter 8664, loss [-0.22416933, -0.2604004, 0.036231082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8665, loss [-0.22135074, -0.25930128, 0.037950534]\n",
      "Iter 8666, loss [-0.22211555, -0.26014805, 0.038032494]\n",
      "Iter 8667, loss [-0.22491817, -0.26037994, 0.035461765]\n",
      "Iter 8668, loss [-0.17789863, -0.2175148, 0.039616164]\n",
      "Iter 8669, loss [-0.23287466, -0.268652, 0.035777327]\n",
      "Iter 8670, loss [-0.22787115, -0.26589823, 0.03802708]\n",
      "Iter 8671, loss [-0.21574455, -0.25489074, 0.039146185]\n",
      "Iter 8672, loss [-0.22531617, -0.26473013, 0.039413966]\n",
      "Iter 8673, loss [-0.22808026, -0.26664802, 0.038567763]\n",
      "Iter 8674, loss [-0.23101674, -0.26792106, 0.03690432]\n",
      "Iter 8675, loss [-0.22049046, -0.2603098, 0.039819323]\n",
      "Iter 8676, loss [-0.22832397, -0.2650116, 0.03668764]\n",
      "Iter 8677, loss [-0.22170529, -0.2602226, 0.038517334]\n",
      "Iter 8678, loss [-0.22191314, -0.26071918, 0.038806036]\n",
      "Iter 8679, loss [-0.22726214, -0.2642272, 0.036965072]\n",
      "Iter 8680, loss [-0.22261101, -0.2611101, 0.038499087]\n",
      "Iter 8681, loss [-0.20390108, -0.24645846, 0.04255738]\n",
      "Iter 8682, loss [-0.22534454, -0.26393, 0.038585454]\n",
      "Iter 8683, loss [-0.21727896, -0.25851786, 0.041238897]\n",
      "Iter 8684, loss [-0.23090497, -0.26679346, 0.0358885]\n",
      "Iter 8685, loss [-0.21167758, -0.25025094, 0.038573362]\n",
      "Iter 8686, loss [-0.23230219, -0.26719737, 0.03489518]\n",
      "Iter 8687, loss [-0.22715633, -0.26363412, 0.03647779]\n",
      "Iter 8688, loss [-0.22452562, -0.26258847, 0.038062856]\n",
      "Iter 8689, loss [-0.22420001, -0.2619982, 0.037798204]\n",
      "Iter 8690, loss [-0.22463472, -0.26311114, 0.038476422]\n",
      "Iter 8691, loss [-0.22621602, -0.26531008, 0.039094053]\n",
      "Iter 8692, loss [-0.22211552, -0.26153526, 0.039419733]\n",
      "Iter 8693, loss [-0.22687367, -0.26394176, 0.0370681]\n",
      "Iter 8694, loss [-0.16151638, -0.21609496, 0.054578573]\n",
      "Iter 8695, loss [-0.22620948, -0.26367152, 0.037462037]\n",
      "Iter 8696, loss [-0.171339, -0.22504519, 0.05370618]\n",
      "Iter 8697, loss [-0.22486088, -0.2627786, 0.037917726]\n",
      "Iter 8698, loss [-0.16222751, -0.21524967, 0.053022157]\n",
      "Iter 8699, loss [-0.22702944, -0.26440963, 0.037380185]\n",
      "Iter 8700, loss [-0.22502488, -0.26414338, 0.0391185]\n",
      "Iter 8701, loss [-0.23152235, -0.26848873, 0.036966383]\n",
      "Iter 8702, loss [-0.22327979, -0.260546, 0.037266213]\n",
      "Iter 8703, loss [-0.22747493, -0.26415202, 0.0366771]\n",
      "Iter 8704, loss [-0.14955756, -0.20525001, 0.055692457]\n",
      "Iter 8705, loss [-0.23145352, -0.266936, 0.035482477]\n",
      "Iter 8706, loss [-0.22409122, -0.26195756, 0.037866335]\n",
      "Iter 8707, loss [-0.23133105, -0.26697528, 0.03564423]\n",
      "Iter 8708, loss [-0.21950212, -0.25866097, 0.039158855]\n",
      "Iter 8709, loss [-0.21851511, -0.25897247, 0.04045735]\n",
      "Iter 8710, loss [-0.20581657, -0.24944483, 0.043628257]\n",
      "Iter 8711, loss [-0.2247805, -0.2605156, 0.0357351]\n",
      "Iter 8712, loss [-0.22385648, -0.26112688, 0.037270393]\n",
      "Iter 8713, loss [-0.2236384, -0.25814492, 0.034506515]\n",
      "Iter 8714, loss [-0.22940066, -0.26576853, 0.036367856]\n",
      "Iter 8715, loss [-0.21824323, -0.25813532, 0.03989209]\n",
      "Iter 8716, loss [-0.22636622, -0.26301315, 0.036646925]\n",
      "Iter 8717, loss [-0.21495119, -0.25456497, 0.039613783]\n",
      "Iter 8718, loss [-0.22475812, -0.2616695, 0.036911376]\n",
      "Iter 8719, loss [-0.2230643, -0.25992036, 0.03685605]\n",
      "Iter 8720, loss [-0.21811566, -0.25744262, 0.03932696]\n",
      "Iter 8721, loss [-0.21632929, -0.25688717, 0.040557876]\n",
      "Iter 8722, loss [-0.22341375, -0.26216716, 0.038753405]\n",
      "Iter 8723, loss [-0.23095602, -0.2664897, 0.035533696]\n",
      "Iter 8724, loss [-0.15769024, -0.21232471, 0.054634467]\n",
      "Iter 8725, loss [-0.22413804, -0.26197344, 0.037835404]\n",
      "Iter 8726, loss [-0.2155641, -0.25558713, 0.04002303]\n",
      "Iter 8727, loss [-0.21429649, -0.25265265, 0.038356163]\n",
      "Iter 8728, loss [-0.19345309, -0.2408406, 0.047387507]\n",
      "Iter 8729, loss [-0.21890092, -0.25802532, 0.0391244]\n",
      "Iter 8730, loss [-0.22028063, -0.2591752, 0.038894575]\n",
      "Iter 8731, loss [-0.22711739, -0.2644003, 0.037282914]\n",
      "Iter 8732, loss [-0.21672778, -0.25650665, 0.03977887]\n",
      "Iter 8733, loss [-0.22586933, -0.26107186, 0.035202533]\n",
      "Iter 8734, loss [-0.22531661, -0.26122966, 0.035913043]\n",
      "Iter 8735, loss [-0.22287288, -0.25996467, 0.037091788]\n",
      "Iter 8736, loss [-0.23410174, -0.26929718, 0.035195436]\n",
      "Iter 8737, loss [-0.22393835, -0.26371723, 0.03977889]\n",
      "Iter 8738, loss [-0.21378815, -0.25279576, 0.039007604]\n",
      "Iter 8739, loss [-0.22570162, -0.2652286, 0.039526984]\n",
      "Iter 8740, loss [-0.22400728, -0.26107275, 0.037065484]\n",
      "Iter 8741, loss [-0.2213727, -0.26109824, 0.039725535]\n",
      "Iter 8742, loss [-0.21530005, -0.25535437, 0.040054314]\n",
      "Iter 8743, loss [-0.18691805, -0.23549363, 0.048575576]\n",
      "Iter 8744, loss [-0.21001679, -0.25315106, 0.04313428]\n",
      "Iter 8745, loss [-0.22779188, -0.26461378, 0.0368219]\n",
      "Iter 8746, loss [-0.22652897, -0.26365864, 0.03712967]\n",
      "Iter 8747, loss [-0.22716218, -0.26669386, 0.039531678]\n",
      "Iter 8748, loss [-0.21577702, -0.2551703, 0.03939326]\n",
      "Iter 8749, loss [-0.23407793, -0.27001852, 0.03594058]\n",
      "Iter 8750, loss [-0.21532582, -0.25519335, 0.039867535]\n",
      "Iter 8751, loss [-0.21635975, -0.25698346, 0.04062371]\n",
      "Iter 8752, loss [-0.24132614, -0.27592787, 0.034601733]\n",
      "Iter 8753, loss [-0.20380414, -0.2446892, 0.040885057]\n",
      "Iter 8754, loss [-0.22571227, -0.26367617, 0.037963904]\n",
      "Iter 8755, loss [-0.17236763, -0.22621445, 0.05384683]\n",
      "Iter 8756, loss [-0.20598221, -0.24601977, 0.04003755]\n",
      "Iter 8757, loss [-0.21747348, -0.2561548, 0.03868132]\n",
      "Iter 8758, loss [-0.22637448, -0.26478952, 0.03841504]\n",
      "Iter 8759, loss [-0.20610484, -0.24736023, 0.041255392]\n",
      "Iter 8760, loss [-0.21983607, -0.25905272, 0.039216653]\n",
      "Iter 8761, loss [-0.22330782, -0.26236194, 0.039054126]\n",
      "Iter 8762, loss [-0.22750072, -0.26562047, 0.03811975]\n",
      "Iter 8763, loss [-0.22400418, -0.26217696, 0.038172785]\n",
      "Iter 8764, loss [-0.21755901, -0.25720152, 0.039642505]\n",
      "Iter 8765, loss [-0.2112841, -0.2519296, 0.040645514]\n",
      "Iter 8766, loss [-0.22428218, -0.26394948, 0.03966731]\n",
      "Iter 8767, loss [-0.21757612, -0.25688118, 0.039305065]\n",
      "Iter 8768, loss [-0.22284438, -0.26095802, 0.03811364]\n",
      "Iter 8769, loss [-0.22386855, -0.26173812, 0.037869573]\n",
      "Iter 8770, loss [-0.22808035, -0.2659308, 0.037850454]\n",
      "Iter 8771, loss [-0.22584, -0.26457095, 0.038730957]\n",
      "Iter 8772, loss [-0.22570416, -0.26300418, 0.037300028]\n",
      "Iter 8773, loss [-0.22858492, -0.26522183, 0.036636926]\n",
      "Iter 8774, loss [-0.2281861, -0.26626772, 0.038081616]\n",
      "Iter 8775, loss [-0.21838659, -0.2567546, 0.03836801]\n",
      "Iter 8776, loss [-0.22464493, -0.26241276, 0.037767828]\n",
      "Iter 8777, loss [-0.21244247, -0.25227576, 0.039833292]\n",
      "Iter 8778, loss [-0.23455355, -0.2704215, 0.03586796]\n",
      "Iter 8779, loss [-0.22447656, -0.26106963, 0.036593065]\n",
      "Iter 8780, loss [-0.2196822, -0.2589091, 0.03922691]\n",
      "Iter 8781, loss [-0.22893211, -0.26596835, 0.037036236]\n",
      "Iter 8782, loss [-0.22612165, -0.26546118, 0.039339527]\n",
      "Iter 8783, loss [-0.21133102, -0.25255215, 0.041221123]\n",
      "Iter 8784, loss [-0.22473429, -0.26100418, 0.036269885]\n",
      "Iter 8785, loss [-0.20792256, -0.2504835, 0.04256095]\n",
      "Iter 8786, loss [-0.22430924, -0.26209563, 0.03778639]\n",
      "Iter 8787, loss [-0.2080653, -0.2502998, 0.042234506]\n",
      "Iter 8788, loss [-0.2281563, -0.26233304, 0.034176737]\n",
      "Iter 8789, loss [-0.22317074, -0.25992367, 0.03675292]\n",
      "Iter 8790, loss [-0.21863629, -0.25743222, 0.038795933]\n",
      "Iter 8791, loss [-0.17470512, -0.22635469, 0.05164957]\n",
      "Iter 8792, loss [-0.22577655, -0.26337618, 0.037599623]\n",
      "Iter 8793, loss [-0.23401953, -0.26872423, 0.034704696]\n",
      "Iter 8794, loss [-0.21850729, -0.25822917, 0.039721876]\n",
      "Iter 8795, loss [-0.22945571, -0.26617652, 0.036720805]\n",
      "Iter 8796, loss [-0.22406982, -0.26342824, 0.03935842]\n",
      "Iter 8797, loss [-0.22777122, -0.26462212, 0.036850903]\n",
      "Iter 8798, loss [-0.22689395, -0.2659744, 0.03908046]\n",
      "Iter 8799, loss [-0.22846033, -0.2640995, 0.035639178]\n",
      "Iter 8800, loss [-0.22182515, -0.25868195, 0.0368568]\n",
      "Iter 8801, loss [-0.22816995, -0.26487404, 0.036704093]\n",
      "Iter 8802, loss [-0.225122, -0.26171657, 0.036594562]\n",
      "Iter 8803, loss [-0.22741441, -0.26533738, 0.037922964]\n",
      "Iter 8804, loss [-0.2299502, -0.26630068, 0.036350474]\n",
      "Iter 8805, loss [-0.22924718, -0.26625893, 0.037011735]\n",
      "Iter 8806, loss [-0.22266805, -0.26118058, 0.038512528]\n",
      "Iter 8807, loss [-0.22832914, -0.26445776, 0.03612862]\n",
      "Iter 8808, loss [-0.18515849, -0.23032072, 0.045162223]\n",
      "Iter 8809, loss [-0.22858888, -0.26541466, 0.036825784]\n",
      "Iter 8810, loss [-0.22383916, -0.26045546, 0.036616296]\n",
      "Iter 8811, loss [-0.17847958, -0.21749653, 0.03901694]\n",
      "Iter 8812, loss [-0.23109403, -0.2658433, 0.034749262]\n",
      "Iter 8813, loss [-0.2314927, -0.26632175, 0.03482905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8814, loss [-0.21542272, -0.25651124, 0.041088518]\n",
      "Iter 8815, loss [-0.1853856, -0.23219898, 0.046813384]\n",
      "Iter 8816, loss [-0.21077867, -0.25176, 0.040981337]\n",
      "Iter 8817, loss [-0.21749176, -0.25768274, 0.04019098]\n",
      "Iter 8818, loss [-0.19476017, -0.23569308, 0.04093291]\n",
      "Iter 8819, loss [-0.22989646, -0.26573932, 0.03584286]\n",
      "Iter 8820, loss [-0.22206211, -0.25911126, 0.037049137]\n",
      "Iter 8821, loss [-0.23112917, -0.26706713, 0.035937965]\n",
      "Iter 8822, loss [-0.22316127, -0.26070407, 0.037542805]\n",
      "Iter 8823, loss [-0.21460418, -0.2562333, 0.04162912]\n",
      "Iter 8824, loss [-0.22167031, -0.2595294, 0.037859093]\n",
      "Iter 8825, loss [-0.2163323, -0.25749186, 0.041159555]\n",
      "Iter 8826, loss [-0.2218932, -0.26364207, 0.041748866]\n",
      "Iter 8827, loss [-0.20642948, -0.24996512, 0.043535642]\n",
      "Iter 8828, loss [-0.22069812, -0.25695178, 0.03625367]\n",
      "Iter 8829, loss [-0.2246769, -0.2615448, 0.03686788]\n",
      "Iter 8830, loss [-0.21168019, -0.25013185, 0.038451653]\n",
      "Iter 8831, loss [-0.22229585, -0.2613259, 0.039030038]\n",
      "Iter 8832, loss [-0.18937021, -0.23747145, 0.048101228]\n",
      "Iter 8833, loss [-0.22634828, -0.2637327, 0.03738442]\n",
      "Iter 8834, loss [-0.22404106, -0.26265565, 0.038614582]\n",
      "Iter 8835, loss [-0.21800107, -0.26176605, 0.04376498]\n",
      "Iter 8836, loss [-0.23038442, -0.26710778, 0.03672336]\n",
      "Iter 8837, loss [-0.22746137, -0.2643772, 0.03691583]\n",
      "Iter 8838, loss [-0.21633357, -0.25493667, 0.038603105]\n",
      "Iter 8839, loss [-0.22036271, -0.2576398, 0.03727709]\n",
      "Iter 8840, loss [-0.213738, -0.2529759, 0.03923791]\n",
      "Iter 8841, loss [-0.22580943, -0.26150808, 0.035698645]\n",
      "Iter 8842, loss [-0.21842822, -0.25457639, 0.036148157]\n",
      "Iter 8843, loss [-0.20971054, -0.25176415, 0.042053606]\n",
      "Iter 8844, loss [-0.20702246, -0.25002912, 0.043006655]\n",
      "Iter 8845, loss [-0.22716339, -0.2634566, 0.036293227]\n",
      "Iter 8846, loss [-0.19904238, -0.24473998, 0.045697592]\n",
      "Iter 8847, loss [-0.20593837, -0.246958, 0.04101964]\n",
      "Iter 8848, loss [-0.19860041, -0.24733117, 0.04873076]\n",
      "Iter 8849, loss [-0.22139773, -0.26028672, 0.03888899]\n",
      "Iter 8850, loss [-0.23020105, -0.26787743, 0.03767638]\n",
      "Iter 8851, loss [-0.22458288, -0.26285273, 0.038269855]\n",
      "Iter 8852, loss [-0.22401826, -0.26357543, 0.03955717]\n",
      "Iter 8853, loss [-0.22446701, -0.26228842, 0.03782141]\n",
      "Iter 8854, loss [-0.22920841, -0.26451066, 0.035302255]\n",
      "Iter 8855, loss [-0.21164311, -0.2521964, 0.040553287]\n",
      "Iter 8856, loss [-0.22455344, -0.26041216, 0.035858728]\n",
      "Iter 8857, loss [-0.22860298, -0.26314765, 0.034544684]\n",
      "Iter 8858, loss [-0.22879758, -0.2648205, 0.036022894]\n",
      "Iter 8859, loss [-0.16356681, -0.21697913, 0.05341232]\n",
      "Iter 8860, loss [-0.23503925, -0.26951134, 0.03447209]\n",
      "Iter 8861, loss [-0.19549969, -0.24357347, 0.048073776]\n",
      "Iter 8862, loss [-0.21505849, -0.25554264, 0.04048415]\n",
      "Iter 8863, loss [-0.22573216, -0.26311436, 0.037382197]\n",
      "Iter 8864, loss [-0.22412753, -0.2617569, 0.037629373]\n",
      "Iter 8865, loss [-0.2290967, -0.2672536, 0.038156908]\n",
      "Iter 8866, loss [-0.22733003, -0.26445767, 0.037127636]\n",
      "Iter 8867, loss [-0.17432612, -0.22752726, 0.053201135]\n",
      "Iter 8868, loss [-0.21947058, -0.260434, 0.040963423]\n",
      "Iter 8869, loss [-0.21958147, -0.25884715, 0.039265677]\n",
      "Iter 8870, loss [-0.22411865, -0.26160848, 0.037489824]\n",
      "Iter 8871, loss [-0.21490856, -0.25649777, 0.04158921]\n",
      "Iter 8872, loss [-0.22090709, -0.2576693, 0.0367622]\n",
      "Iter 8873, loss [-0.22981542, -0.26755285, 0.037737425]\n",
      "Iter 8874, loss [-0.21636039, -0.2559398, 0.039579414]\n",
      "Iter 8875, loss [-0.23081893, -0.26573944, 0.034920514]\n",
      "Iter 8876, loss [-0.20374322, -0.2448991, 0.041155867]\n",
      "Iter 8877, loss [-0.23224208, -0.26622275, 0.033980668]\n",
      "Iter 8878, loss [-0.19110458, -0.23569869, 0.044594105]\n",
      "Iter 8879, loss [-0.21965735, -0.25938466, 0.039727315]\n",
      "Iter 8880, loss [-0.22104067, -0.26124856, 0.04020789]\n",
      "Iter 8881, loss [-0.21624656, -0.25614652, 0.039899956]\n",
      "Iter 8882, loss [-0.22502115, -0.26324502, 0.038223855]\n",
      "Iter 8883, loss [-0.2214939, -0.25841624, 0.036922332]\n",
      "Iter 8884, loss [-0.2280817, -0.26358324, 0.035501536]\n",
      "Iter 8885, loss [-0.21702346, -0.25476748, 0.037744015]\n",
      "Iter 8886, loss [-0.22511628, -0.25985765, 0.034741364]\n",
      "Iter 8887, loss [-0.21527378, -0.25637624, 0.041102454]\n",
      "Iter 8888, loss [-0.23288839, -0.27107668, 0.038188294]\n",
      "Iter 8889, loss [-0.20798482, -0.25086737, 0.042882547]\n",
      "Iter 8890, loss [-0.20695755, -0.249578, 0.04262045]\n",
      "Iter 8891, loss [-0.21420187, -0.2554142, 0.041212328]\n",
      "Iter 8892, loss [-0.23065159, -0.26662704, 0.035975456]\n",
      "Iter 8893, loss [-0.22135366, -0.2593194, 0.03796573]\n",
      "Iter 8894, loss [-0.22248796, -0.2589778, 0.03648985]\n",
      "Iter 8895, loss [-0.20988959, -0.24923232, 0.039342735]\n",
      "Iter 8896, loss [-0.2277379, -0.2647771, 0.037039198]\n",
      "Iter 8897, loss [-0.20811543, -0.25086913, 0.042753693]\n",
      "Iter 8898, loss [-0.22622505, -0.26579818, 0.03957314]\n",
      "Iter 8899, loss [-0.22606426, -0.26342943, 0.037365176]\n",
      "Iter 8900, loss [-0.22516853, -0.2656872, 0.040518664]\n",
      "Iter 8901, loss [-0.22522852, -0.26390094, 0.038672417]\n",
      "Iter 8902, loss [-0.20591015, -0.24707109, 0.04116095]\n",
      "Iter 8903, loss [-0.21906564, -0.25688124, 0.037815604]\n",
      "Iter 8904, loss [-0.22559637, -0.2614025, 0.035806123]\n",
      "Iter 8905, loss [-0.21910973, -0.2550364, 0.035926685]\n",
      "Iter 8906, loss [-0.22086184, -0.2591442, 0.03828235]\n",
      "Iter 8907, loss [-0.2293041, -0.26572514, 0.036421027]\n",
      "Iter 8908, loss [-0.13671099, -0.20101513, 0.06430414]\n",
      "Iter 8909, loss [-0.2237213, -0.26297283, 0.03925153]\n",
      "Iter 8910, loss [-0.22916679, -0.2658565, 0.03668971]\n",
      "Iter 8911, loss [-0.20091276, -0.23885088, 0.037938114]\n",
      "Iter 8912, loss [-0.19766742, -0.24021438, 0.042546954]\n",
      "Iter 8913, loss [-0.18617646, -0.23619795, 0.050021484]\n",
      "Iter 8914, loss [-0.20616254, -0.24794196, 0.04177941]\n",
      "Iter 8915, loss [-0.2176715, -0.25888, 0.041208487]\n",
      "Iter 8916, loss [-0.22904399, -0.26808438, 0.039040394]\n",
      "Iter 8917, loss [-0.23118602, -0.26899672, 0.0378107]\n",
      "Iter 8918, loss [-0.23067743, -0.26783872, 0.037161287]\n",
      "Iter 8919, loss [-0.22726007, -0.26435965, 0.037099585]\n",
      "Iter 8920, loss [-0.22740702, -0.2640471, 0.036640063]\n",
      "Iter 8921, loss [-0.17108846, -0.22364585, 0.05255739]\n",
      "Iter 8922, loss [-0.22249009, -0.26090467, 0.038414583]\n",
      "Iter 8923, loss [-0.22906694, -0.2644384, 0.03537145]\n",
      "Iter 8924, loss [-0.21801575, -0.25677255, 0.0387568]\n",
      "Iter 8925, loss [-0.22810096, -0.26466233, 0.036561362]\n",
      "Iter 8926, loss [-0.21506926, -0.25437677, 0.039307505]\n",
      "Iter 8927, loss [-0.2253716, -0.26178673, 0.036415122]\n",
      "Iter 8928, loss [-0.2215154, -0.2593994, 0.037884012]\n",
      "Iter 8929, loss [-0.23258147, -0.26804072, 0.035459246]\n",
      "Iter 8930, loss [-0.22422466, -0.2623862, 0.038161546]\n",
      "Iter 8931, loss [-0.22945361, -0.26635015, 0.036896538]\n",
      "Iter 8932, loss [-0.216507, -0.25715125, 0.04064424]\n",
      "Iter 8933, loss [-0.23009151, -0.2684397, 0.038348194]\n",
      "Iter 8934, loss [-0.22130963, -0.26083913, 0.039529506]\n",
      "Iter 8935, loss [-0.16547522, -0.22249952, 0.057024296]\n",
      "Iter 8936, loss [-0.22877301, -0.26598734, 0.037214324]\n",
      "Iter 8937, loss [-0.22806646, -0.26433975, 0.036273282]\n",
      "Iter 8938, loss [-0.22512737, -0.26311928, 0.03799191]\n",
      "Iter 8939, loss [-0.22557162, -0.26298103, 0.03740941]\n",
      "Iter 8940, loss [-0.22822689, -0.26490882, 0.03668194]\n",
      "Iter 8941, loss [-0.21358028, -0.25146753, 0.037887238]\n",
      "Iter 8942, loss [-0.23026642, -0.26693955, 0.03667313]\n",
      "Iter 8943, loss [-0.22008842, -0.2574413, 0.037352897]\n",
      "Iter 8944, loss [-0.22432965, -0.26222762, 0.037897978]\n",
      "Iter 8945, loss [-0.22772633, -0.26447856, 0.036752235]\n",
      "Iter 8946, loss [-0.21546543, -0.25630108, 0.04083565]\n",
      "Iter 8947, loss [-0.22482042, -0.2630908, 0.038270365]\n",
      "Iter 8948, loss [-0.22267112, -0.26059762, 0.037926488]\n",
      "Iter 8949, loss [-0.2199349, -0.26110777, 0.04117288]\n",
      "Iter 8950, loss [-0.22709718, -0.26368707, 0.03658989]\n",
      "Iter 8951, loss [-0.2194959, -0.25692555, 0.037429642]\n",
      "Iter 8952, loss [-0.22195545, -0.25909066, 0.037135206]\n",
      "Iter 8953, loss [-0.21804598, -0.25646767, 0.038421687]\n",
      "Iter 8954, loss [-0.23034433, -0.26638797, 0.036043644]\n",
      "Iter 8955, loss [-0.22197711, -0.25610405, 0.034126937]\n",
      "Iter 8956, loss [-0.21810517, -0.25792646, 0.039821293]\n",
      "Iter 8957, loss [-0.21962404, -0.25896484, 0.03934079]\n",
      "Iter 8958, loss [-0.19498, -0.24116382, 0.046183825]\n",
      "Iter 8959, loss [-0.20801407, -0.24937047, 0.041356407]\n",
      "Iter 8960, loss [-0.2177246, -0.2574218, 0.039697185]\n",
      "Iter 8961, loss [-0.21530789, -0.25291228, 0.03760439]\n",
      "Iter 8962, loss [-0.15816861, -0.21347468, 0.05530606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8963, loss [-0.22255044, -0.26048034, 0.037929904]\n",
      "Iter 8964, loss [-0.2198422, -0.25972912, 0.03988693]\n",
      "Iter 8965, loss [-0.2132726, -0.25330195, 0.040029354]\n",
      "Iter 8966, loss [-0.22905055, -0.26472408, 0.03567353]\n",
      "Iter 8967, loss [-0.22995749, -0.2663485, 0.036391012]\n",
      "Iter 8968, loss [-0.2118752, -0.2539805, 0.042105287]\n",
      "Iter 8969, loss [-0.16668406, -0.22268716, 0.05600309]\n",
      "Iter 8970, loss [-0.21797982, -0.25638503, 0.038405214]\n",
      "Iter 8971, loss [-0.22081305, -0.26040235, 0.039589297]\n",
      "Iter 8972, loss [-0.22843735, -0.2656209, 0.037183534]\n",
      "Iter 8973, loss [-0.22459406, -0.26368153, 0.03908748]\n",
      "Iter 8974, loss [-0.21836014, -0.257438, 0.039077863]\n",
      "Iter 8975, loss [-0.21850638, -0.2592099, 0.040703516]\n",
      "Iter 8976, loss [-0.22628129, -0.26091427, 0.034632977]\n",
      "Iter 8977, loss [-0.2154588, -0.25660744, 0.041148644]\n",
      "Iter 8978, loss [-0.2258835, -0.26465544, 0.038771946]\n",
      "Iter 8979, loss [-0.187112, -0.23992157, 0.05280956]\n",
      "Iter 8980, loss [-0.21704328, -0.25471634, 0.03767305]\n",
      "Iter 8981, loss [-0.21707971, -0.25794917, 0.04086946]\n",
      "Iter 8982, loss [-0.23316358, -0.27189967, 0.03873609]\n",
      "Iter 8983, loss [-0.22034678, -0.26057854, 0.040231757]\n",
      "Iter 8984, loss [-0.22530507, -0.26358908, 0.03828402]\n",
      "Iter 8985, loss [-0.22963431, -0.2670626, 0.03742829]\n",
      "Iter 8986, loss [-0.22852269, -0.26520938, 0.03668669]\n",
      "Iter 8987, loss [-0.15282297, -0.20688257, 0.054059595]\n",
      "Iter 8988, loss [-0.22187996, -0.26036543, 0.03848546]\n",
      "Iter 8989, loss [-0.21454798, -0.2547842, 0.04023622]\n",
      "Iter 8990, loss [-0.22580722, -0.26594484, 0.04013762]\n",
      "Iter 8991, loss [-0.23170279, -0.2695676, 0.037864815]\n",
      "Iter 8992, loss [-0.18403736, -0.23532435, 0.05128699]\n",
      "Iter 8993, loss [-0.2317602, -0.2688616, 0.037101388]\n",
      "Iter 8994, loss [-0.18719476, -0.24005465, 0.052859884]\n",
      "Iter 8995, loss [-0.2192421, -0.25828353, 0.039041437]\n",
      "Iter 8996, loss [-0.21340065, -0.25385103, 0.04045038]\n",
      "Iter 8997, loss [-0.21968034, -0.2569545, 0.037274145]\n",
      "Iter 8998, loss [-0.21119776, -0.25061402, 0.039416254]\n",
      "Iter 8999, loss [-0.21509714, -0.2518482, 0.036751047]\n",
      "Iter 9000, loss [-0.21556166, -0.25342333, 0.03786167]\n",
      "Iter 9001, loss [-0.20150809, -0.23969108, 0.038182985]\n",
      "Iter 9002, loss [-0.22176684, -0.25919253, 0.037425682]\n",
      "Iter 9003, loss [-0.22078472, -0.25780824, 0.037023515]\n",
      "Iter 9004, loss [-0.2252011, -0.262818, 0.037616905]\n",
      "Iter 9005, loss [-0.22364993, -0.26197347, 0.038323537]\n",
      "Iter 9006, loss [-0.22514617, -0.26320755, 0.038061388]\n",
      "Iter 9007, loss [-0.22083253, -0.25767422, 0.036841698]\n",
      "Iter 9008, loss [-0.23163426, -0.2663611, 0.034726832]\n",
      "Iter 9009, loss [-0.22441912, -0.26253504, 0.03811591]\n",
      "Iter 9010, loss [-0.22015, -0.25773466, 0.037584662]\n",
      "Iter 9011, loss [-0.21908367, -0.2581899, 0.039106213]\n",
      "Iter 9012, loss [-0.22107492, -0.2592526, 0.03817768]\n",
      "Iter 9013, loss [-0.22976711, -0.26738277, 0.037615653]\n",
      "Iter 9014, loss [-0.22694571, -0.26309812, 0.036152408]\n",
      "Iter 9015, loss [-0.22859757, -0.26594514, 0.037347574]\n",
      "Iter 9016, loss [-0.22615048, -0.2630298, 0.03687933]\n",
      "Iter 9017, loss [-0.21544965, -0.25502226, 0.039572615]\n",
      "Iter 9018, loss [-0.22950907, -0.26656702, 0.037057955]\n",
      "Iter 9019, loss [-0.21863061, -0.25777307, 0.039142467]\n",
      "Iter 9020, loss [-0.22548181, -0.26220468, 0.036722876]\n",
      "Iter 9021, loss [-0.2075396, -0.24450576, 0.036966156]\n",
      "Iter 9022, loss [-0.2278293, -0.26449138, 0.036662064]\n",
      "Iter 9023, loss [-0.22497934, -0.262306, 0.03732667]\n",
      "Iter 9024, loss [-0.2145447, -0.254798, 0.040253293]\n",
      "Iter 9025, loss [-0.21983653, -0.25747177, 0.037635237]\n",
      "Iter 9026, loss [-0.22776987, -0.26571542, 0.037945557]\n",
      "Iter 9027, loss [-0.22282955, -0.2616078, 0.038778238]\n",
      "Iter 9028, loss [-0.22369415, -0.2597883, 0.03609416]\n",
      "Iter 9029, loss [-0.22371614, -0.2611187, 0.03740257]\n",
      "Iter 9030, loss [-0.22291245, -0.25869158, 0.035779133]\n",
      "Iter 9031, loss [-0.22441952, -0.26071945, 0.036299933]\n",
      "Iter 9032, loss [-0.23051333, -0.26597056, 0.035457224]\n",
      "Iter 9033, loss [-0.21815944, -0.25577682, 0.03761738]\n",
      "Iter 9034, loss [-0.14992899, -0.21322921, 0.06330022]\n",
      "Iter 9035, loss [-0.2112478, -0.25225917, 0.041011356]\n",
      "Iter 9036, loss [-0.21500048, -0.25386083, 0.038860343]\n",
      "Iter 9037, loss [-0.21167839, -0.25487512, 0.043196734]\n",
      "Iter 9038, loss [-0.21770959, -0.25811064, 0.040401056]\n",
      "Iter 9039, loss [-0.22343163, -0.25995773, 0.036526103]\n",
      "Iter 9040, loss [-0.21949577, -0.2603355, 0.04083973]\n",
      "Iter 9041, loss [-0.22521403, -0.26293838, 0.03772434]\n",
      "Iter 9042, loss [-0.2297428, -0.2666728, 0.036929995]\n",
      "Iter 9043, loss [-0.20054474, -0.2431336, 0.04258886]\n",
      "Iter 9044, loss [-0.21617034, -0.25707403, 0.04090368]\n",
      "Iter 9045, loss [-0.2226895, -0.26084056, 0.03815107]\n",
      "Iter 9046, loss [-0.21396863, -0.25380754, 0.039838914]\n",
      "Iter 9047, loss [-0.21740411, -0.25751945, 0.040115338]\n",
      "Iter 9048, loss [-0.22385609, -0.26133525, 0.037479155]\n",
      "Iter 9049, loss [-0.22600639, -0.26236227, 0.03635589]\n",
      "Iter 9050, loss [-0.23311603, -0.26775175, 0.034635715]\n",
      "Iter 9051, loss [-0.22261526, -0.26220772, 0.039592456]\n",
      "Iter 9052, loss [-0.21178192, -0.25123763, 0.03945571]\n",
      "Iter 9053, loss [-0.21851063, -0.2586899, 0.04017928]\n",
      "Iter 9054, loss [-0.1893338, -0.23769085, 0.04835705]\n",
      "Iter 9055, loss [-0.22510177, -0.26358855, 0.038486775]\n",
      "Iter 9056, loss [-0.22514032, -0.26219034, 0.037050024]\n",
      "Iter 9057, loss [-0.20027941, -0.24428785, 0.04400843]\n",
      "Iter 9058, loss [-0.20147355, -0.24327123, 0.041797683]\n",
      "Iter 9059, loss [-0.22084634, -0.2591968, 0.038350444]\n",
      "Iter 9060, loss [-0.22719106, -0.26464602, 0.037454955]\n",
      "Iter 9061, loss [-0.15115699, -0.2068538, 0.055696808]\n",
      "Iter 9062, loss [-0.22430862, -0.26276332, 0.038454693]\n",
      "Iter 9063, loss [-0.22365357, -0.263302, 0.03964843]\n",
      "Iter 9064, loss [-0.22580667, -0.26370603, 0.03789936]\n",
      "Iter 9065, loss [-0.21783812, -0.25736532, 0.03952719]\n",
      "Iter 9066, loss [-0.22845308, -0.2654272, 0.036974113]\n",
      "Iter 9067, loss [-0.23583922, -0.2705557, 0.03471648]\n",
      "Iter 9068, loss [-0.22679365, -0.26201442, 0.03522078]\n",
      "Iter 9069, loss [-0.22647229, -0.26315096, 0.036678664]\n",
      "Iter 9070, loss [-0.22855546, -0.26528877, 0.03673331]\n",
      "Iter 9071, loss [-0.2254187, -0.26340926, 0.03799056]\n",
      "Iter 9072, loss [-0.22615506, -0.26244286, 0.036287803]\n",
      "Iter 9073, loss [-0.22594954, -0.26358342, 0.037633885]\n",
      "Iter 9074, loss [-0.21980263, -0.2582193, 0.03841667]\n",
      "Iter 9075, loss [-0.2291422, -0.26480785, 0.035665642]\n",
      "Iter 9076, loss [-0.23254564, -0.26680246, 0.034256816]\n",
      "Iter 9077, loss [-0.19659501, -0.24254525, 0.04595023]\n",
      "Iter 9078, loss [-0.22504352, -0.26431334, 0.039269824]\n",
      "Iter 9079, loss [-0.22815344, -0.26688147, 0.03872803]\n",
      "Iter 9080, loss [-0.22420688, -0.2645105, 0.04030363]\n",
      "Iter 9081, loss [-0.22369036, -0.26123184, 0.03754147]\n",
      "Iter 9082, loss [-0.22172868, -0.26016176, 0.038433068]\n",
      "Iter 9083, loss [-0.22700837, -0.26300484, 0.035996474]\n",
      "Iter 9084, loss [-0.230923, -0.26674733, 0.03582432]\n",
      "Iter 9085, loss [-0.22391167, -0.26022166, 0.03630998]\n",
      "Iter 9086, loss [-0.22036795, -0.2583655, 0.037997555]\n",
      "Iter 9087, loss [-0.21115264, -0.25146124, 0.040308602]\n",
      "Iter 9088, loss [-0.23102058, -0.2679954, 0.0369748]\n",
      "Iter 9089, loss [-0.22773045, -0.26622522, 0.038494766]\n",
      "Iter 9090, loss [-0.22164086, -0.26031923, 0.038678385]\n",
      "Iter 9091, loss [-0.21787089, -0.25832272, 0.040451825]\n",
      "Iter 9092, loss [-0.2315745, -0.26778206, 0.03620755]\n",
      "Iter 9093, loss [-0.23460683, -0.26956853, 0.034961708]\n",
      "Iter 9094, loss [-0.2325132, -0.2669403, 0.03442709]\n",
      "Iter 9095, loss [-0.20515956, -0.24642201, 0.041262448]\n",
      "Iter 9096, loss [-0.15287636, -0.20907567, 0.05619931]\n",
      "Iter 9097, loss [-0.21985872, -0.257845, 0.037986293]\n",
      "Iter 9098, loss [-0.2287994, -0.2666113, 0.037811905]\n",
      "Iter 9099, loss [-0.21514806, -0.25492996, 0.039781906]\n",
      "Iter 9100, loss [-0.23527728, -0.2706367, 0.03535943]\n",
      "Iter 9101, loss [-0.17802753, -0.21863087, 0.040603336]\n",
      "Iter 9102, loss [-0.22886226, -0.26546556, 0.0366033]\n",
      "Iter 9103, loss [-0.22554746, -0.2618447, 0.036297232]\n",
      "Iter 9104, loss [-0.21758845, -0.25644803, 0.038859576]\n",
      "Iter 9105, loss [-0.21765798, -0.2573476, 0.03968963]\n",
      "Iter 9106, loss [-0.22916752, -0.2645864, 0.03541886]\n",
      "Iter 9107, loss [-0.22085437, -0.2608261, 0.039971747]\n",
      "Iter 9108, loss [-0.14875484, -0.21019518, 0.06144034]\n",
      "Iter 9109, loss [-0.22415914, -0.26480848, 0.040649336]\n",
      "Iter 9110, loss [-0.23035711, -0.26640806, 0.036050953]\n",
      "Iter 9111, loss [-0.20190315, -0.24312072, 0.041217566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9112, loss [-0.2175431, -0.25655463, 0.039011545]\n",
      "Iter 9113, loss [-0.16265345, -0.21344864, 0.050795194]\n",
      "Iter 9114, loss [-0.21767141, -0.25794083, 0.04026942]\n",
      "Iter 9115, loss [-0.22027865, -0.25783554, 0.037556887]\n",
      "Iter 9116, loss [-0.2261307, -0.26436055, 0.03822985]\n",
      "Iter 9117, loss [-0.2275508, -0.26311257, 0.035561778]\n",
      "Iter 9118, loss [-0.15781027, -0.21503133, 0.057221062]\n",
      "Iter 9119, loss [-0.23136552, -0.26788932, 0.0365238]\n",
      "Iter 9120, loss [-0.22751552, -0.2659428, 0.038427293]\n",
      "Iter 9121, loss [-0.22582725, -0.26371595, 0.037888713]\n",
      "Iter 9122, loss [-0.21995232, -0.25902227, 0.039069947]\n",
      "Iter 9123, loss [-0.22530752, -0.262084, 0.036776487]\n",
      "Iter 9124, loss [-0.22388324, -0.2595262, 0.03564296]\n",
      "Iter 9125, loss [-0.229455, -0.26600647, 0.03655148]\n",
      "Iter 9126, loss [-0.22299398, -0.2598814, 0.036887422]\n",
      "Iter 9127, loss [-0.22657844, -0.26225567, 0.03567722]\n",
      "Iter 9128, loss [-0.22961459, -0.26591286, 0.036298275]\n",
      "Iter 9129, loss [-0.21638721, -0.25702977, 0.040642567]\n",
      "Iter 9130, loss [-0.20810014, -0.25106362, 0.042963468]\n",
      "Iter 9131, loss [-0.22589868, -0.26192024, 0.036021568]\n",
      "Iter 9132, loss [-0.19616796, -0.24024582, 0.044077855]\n",
      "Iter 9133, loss [-0.22120611, -0.25917888, 0.03797276]\n",
      "Iter 9134, loss [-0.22172052, -0.2584647, 0.036744185]\n",
      "Iter 9135, loss [-0.22720939, -0.2625485, 0.035339117]\n",
      "Iter 9136, loss [-0.21197423, -0.25260624, 0.040632002]\n",
      "Iter 9137, loss [-0.20599295, -0.24769251, 0.04169956]\n",
      "Iter 9138, loss [-0.2171022, -0.2581666, 0.041064404]\n",
      "Iter 9139, loss [-0.16027614, -0.21832392, 0.058047764]\n",
      "Iter 9140, loss [-0.16406918, -0.2181349, 0.054065727]\n",
      "Iter 9141, loss [-0.18843472, -0.24088767, 0.05245296]\n",
      "Iter 9142, loss [-0.22808146, -0.263506, 0.035424538]\n",
      "Iter 9143, loss [-0.19022486, -0.2369091, 0.046684258]\n",
      "Iter 9144, loss [-0.20355976, -0.24467245, 0.041112684]\n",
      "Iter 9145, loss [-0.23113908, -0.2666665, 0.03552742]\n",
      "Iter 9146, loss [-0.22691596, -0.26390004, 0.036984082]\n",
      "Iter 9147, loss [-0.2212619, -0.2594168, 0.03815488]\n",
      "Iter 9148, loss [-0.21783921, -0.25739908, 0.039559864]\n",
      "Iter 9149, loss [-0.22885427, -0.2655955, 0.036741227]\n",
      "Iter 9150, loss [-0.23040707, -0.26542023, 0.03501315]\n",
      "Iter 9151, loss [-0.2251753, -0.26114392, 0.035968613]\n",
      "Iter 9152, loss [-0.22106948, -0.25713778, 0.036068283]\n",
      "Iter 9153, loss [-0.2186024, -0.25873297, 0.040130567]\n",
      "Iter 9154, loss [-0.22027417, -0.258511, 0.038236838]\n",
      "Iter 9155, loss [-0.23125069, -0.26664758, 0.035396893]\n",
      "Iter 9156, loss [-0.22150074, -0.26098898, 0.03948824]\n",
      "Iter 9157, loss [-0.22314858, -0.26129916, 0.038150586]\n",
      "Iter 9158, loss [-0.2138719, -0.25466266, 0.040790774]\n",
      "Iter 9159, loss [-0.22483328, -0.26116514, 0.036331862]\n",
      "Iter 9160, loss [-0.22680917, -0.26347685, 0.03666767]\n",
      "Iter 9161, loss [-0.21427181, -0.25512257, 0.04085075]\n",
      "Iter 9162, loss [-0.22549918, -0.26179817, 0.03629899]\n",
      "Iter 9163, loss [-0.18713029, -0.2349142, 0.04778391]\n",
      "Iter 9164, loss [-0.2216403, -0.25975698, 0.03811668]\n",
      "Iter 9165, loss [-0.21665725, -0.2562639, 0.039606653]\n",
      "Iter 9166, loss [-0.22306822, -0.26220384, 0.03913562]\n",
      "Iter 9167, loss [-0.23326248, -0.268831, 0.035568528]\n",
      "Iter 9168, loss [-0.1850382, -0.23667254, 0.051634338]\n",
      "Iter 9169, loss [-0.22493279, -0.26419705, 0.039264265]\n",
      "Iter 9170, loss [-0.22825035, -0.2647971, 0.03654673]\n",
      "Iter 9171, loss [-0.22076954, -0.2580183, 0.03724877]\n",
      "Iter 9172, loss [-0.21858123, -0.25728804, 0.038706813]\n",
      "Iter 9173, loss [-0.19512215, -0.24271901, 0.047596864]\n",
      "Iter 9174, loss [-0.22578745, -0.2636047, 0.03781726]\n",
      "Iter 9175, loss [-0.16967103, -0.22877584, 0.059104815]\n",
      "Iter 9176, loss [-0.22717223, -0.2639863, 0.036814056]\n",
      "Iter 9177, loss [-0.22614649, -0.2643492, 0.038202696]\n",
      "Iter 9178, loss [-0.22452922, -0.26133457, 0.036805347]\n",
      "Iter 9179, loss [-0.15557916, -0.20820774, 0.052628573]\n",
      "Iter 9180, loss [-0.22218663, -0.25880286, 0.036616232]\n",
      "Iter 9181, loss [-0.22413176, -0.2624874, 0.038355656]\n",
      "Iter 9182, loss [-0.23033059, -0.26643094, 0.03610035]\n",
      "Iter 9183, loss [-0.1598835, -0.22196901, 0.062085506]\n",
      "Iter 9184, loss [-0.18856442, -0.23825963, 0.049695205]\n",
      "Iter 9185, loss [-0.22252843, -0.25997788, 0.03744944]\n",
      "Iter 9186, loss [-0.22321342, -0.25964826, 0.03643484]\n",
      "Iter 9187, loss [-0.22439593, -0.2610959, 0.036699988]\n",
      "Iter 9188, loss [-0.21740985, -0.25533566, 0.037925817]\n",
      "Iter 9189, loss [-0.20198089, -0.24494077, 0.042959876]\n",
      "Iter 9190, loss [-0.22098254, -0.26028883, 0.039306294]\n",
      "Iter 9191, loss [-0.21475996, -0.2545973, 0.039837345]\n",
      "Iter 9192, loss [-0.23070201, -0.26904973, 0.03834773]\n",
      "Iter 9193, loss [-0.20219192, -0.24425721, 0.042065285]\n",
      "Iter 9194, loss [-0.21597767, -0.25291756, 0.03693989]\n",
      "Iter 9195, loss [-0.21203405, -0.25058544, 0.03855139]\n",
      "Iter 9196, loss [-0.22202829, -0.25817692, 0.03614863]\n",
      "Iter 9197, loss [-0.22659972, -0.2640058, 0.037406087]\n",
      "Iter 9198, loss [-0.22371796, -0.2626615, 0.03894352]\n",
      "Iter 9199, loss [-0.21563071, -0.25615713, 0.040526412]\n",
      "Iter 9200, loss [-0.22805047, -0.26353154, 0.035481073]\n",
      "Iter 9201, loss [-0.21355933, -0.2529071, 0.039347768]\n",
      "Iter 9202, loss [-0.21968834, -0.2574311, 0.037742745]\n",
      "Iter 9203, loss [-0.21912685, -0.25868228, 0.039555423]\n",
      "Iter 9204, loss [-0.18920287, -0.23643228, 0.047229405]\n",
      "Iter 9205, loss [-0.22649932, -0.26386324, 0.03736391]\n",
      "Iter 9206, loss [-0.16762176, -0.22751284, 0.05989107]\n",
      "Iter 9207, loss [-0.227482, -0.2641297, 0.036647696]\n",
      "Iter 9208, loss [-0.18892033, -0.24105819, 0.052137848]\n",
      "Iter 9209, loss [-0.23002647, -0.2644608, 0.03443433]\n",
      "Iter 9210, loss [-0.21247834, -0.25165763, 0.0391793]\n",
      "Iter 9211, loss [-0.17303973, -0.22802065, 0.054980915]\n",
      "Iter 9212, loss [-0.2247181, -0.26276883, 0.038050737]\n",
      "Iter 9213, loss [-0.21151893, -0.25187403, 0.040355098]\n",
      "Iter 9214, loss [-0.2260158, -0.26392105, 0.037905242]\n",
      "Iter 9215, loss [-0.22894028, -0.2661115, 0.03717121]\n",
      "Iter 9216, loss [-0.20865217, -0.25054282, 0.04189065]\n",
      "Iter 9217, loss [-0.1941207, -0.24143483, 0.04731412]\n",
      "Iter 9218, loss [-0.22363737, -0.2621925, 0.03855511]\n",
      "Iter 9219, loss [-0.1972223, -0.24545068, 0.04822837]\n",
      "Iter 9220, loss [-0.21611784, -0.25690448, 0.040786643]\n",
      "Iter 9221, loss [-0.2143353, -0.25248826, 0.03815297]\n",
      "Iter 9222, loss [-0.18991607, -0.24142906, 0.051512986]\n",
      "Iter 9223, loss [-0.21568775, -0.2563939, 0.040706154]\n",
      "Iter 9224, loss [-0.23108542, -0.2685894, 0.037503995]\n",
      "Iter 9225, loss [-0.22335356, -0.26197535, 0.038621783]\n",
      "Iter 9226, loss [-0.22670329, -0.26523414, 0.038530853]\n",
      "Iter 9227, loss [-0.19362576, -0.23917614, 0.045550372]\n",
      "Iter 9228, loss [-0.20016949, -0.24694377, 0.046774283]\n",
      "Iter 9229, loss [-0.22461697, -0.2601486, 0.035531633]\n",
      "Iter 9230, loss [-0.22660117, -0.26124865, 0.03464748]\n",
      "Iter 9231, loss [-0.22487569, -0.26197273, 0.037097044]\n",
      "Iter 9232, loss [-0.21511905, -0.25339907, 0.03828002]\n",
      "Iter 9233, loss [-0.18834868, -0.23563205, 0.047283363]\n",
      "Iter 9234, loss [-0.2198822, -0.26039094, 0.04050873]\n",
      "Iter 9235, loss [-0.21983457, -0.25782216, 0.037987582]\n",
      "Iter 9236, loss [-0.22922213, -0.26588923, 0.036667094]\n",
      "Iter 9237, loss [-0.22420558, -0.26192638, 0.037720792]\n",
      "Iter 9238, loss [-0.22555676, -0.26151672, 0.035959966]\n",
      "Iter 9239, loss [-0.2245757, -0.2605057, 0.035930008]\n",
      "Iter 9240, loss [-0.22950451, -0.26374045, 0.034235936]\n",
      "Iter 9241, loss [-0.23195405, -0.26657784, 0.034623783]\n",
      "Iter 9242, loss [-0.22201207, -0.26117638, 0.039164312]\n",
      "Iter 9243, loss [-0.2338461, -0.2689539, 0.035107788]\n",
      "Iter 9244, loss [-0.22052024, -0.25899675, 0.038476516]\n",
      "Iter 9245, loss [-0.22355658, -0.26364547, 0.0400889]\n",
      "Iter 9246, loss [-0.19765033, -0.2433285, 0.04567817]\n",
      "Iter 9247, loss [-0.23026545, -0.2666724, 0.036406945]\n",
      "Iter 9248, loss [-0.23433438, -0.26890248, 0.03456811]\n",
      "Iter 9249, loss [-0.23160973, -0.26530272, 0.033692982]\n",
      "Iter 9250, loss [-0.21989566, -0.26171392, 0.041818257]\n",
      "Iter 9251, loss [-0.21639352, -0.25546595, 0.039072435]\n",
      "Iter 9252, loss [-0.22727242, -0.2642077, 0.03693527]\n",
      "Iter 9253, loss [-0.2263736, -0.2639823, 0.037608698]\n",
      "Iter 9254, loss [-0.22574785, -0.26466224, 0.038914375]\n",
      "Iter 9255, loss [-0.2133245, -0.25546682, 0.042142317]\n",
      "Iter 9256, loss [-0.2051917, -0.24519882, 0.040007107]\n",
      "Iter 9257, loss [-0.20969975, -0.25057563, 0.04087589]\n",
      "Iter 9258, loss [-0.2196607, -0.255466, 0.035805307]\n",
      "Iter 9259, loss [-0.22118494, -0.26056582, 0.039380886]\n",
      "Iter 9260, loss [-0.2247017, -0.26296926, 0.038267553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9261, loss [-0.22784272, -0.2633055, 0.035462763]\n",
      "Iter 9262, loss [-0.23046422, -0.2671192, 0.03665497]\n",
      "Iter 9263, loss [-0.2103161, -0.25109094, 0.040774837]\n",
      "Iter 9264, loss [-0.22568057, -0.26498166, 0.039301082]\n",
      "Iter 9265, loss [-0.23270462, -0.26950294, 0.036798313]\n",
      "Iter 9266, loss [-0.2208261, -0.259107, 0.038280893]\n",
      "Iter 9267, loss [-0.2130398, -0.25114182, 0.038102012]\n",
      "Iter 9268, loss [-0.19777676, -0.24297002, 0.045193255]\n",
      "Iter 9269, loss [-0.22674039, -0.26462504, 0.03788466]\n",
      "Iter 9270, loss [-0.1856774, -0.23289508, 0.047217682]\n",
      "Iter 9271, loss [-0.21119204, -0.25140834, 0.04021629]\n",
      "Iter 9272, loss [-0.20777076, -0.25056356, 0.042792793]\n",
      "Iter 9273, loss [-0.20703948, -0.24700622, 0.039966747]\n",
      "Iter 9274, loss [-0.2188598, -0.25430983, 0.035450026]\n",
      "Iter 9275, loss [-0.21747829, -0.2576357, 0.04015742]\n",
      "Iter 9276, loss [-0.22851412, -0.26424554, 0.035731416]\n",
      "Iter 9277, loss [-0.22331163, -0.2612879, 0.037976258]\n",
      "Iter 9278, loss [-0.21700658, -0.2581488, 0.04114221]\n",
      "Iter 9279, loss [-0.1430756, -0.20442843, 0.06135283]\n",
      "Iter 9280, loss [-0.21512252, -0.2546378, 0.03951529]\n",
      "Iter 9281, loss [-0.18779096, -0.23796979, 0.050178833]\n",
      "Iter 9282, loss [-0.22004235, -0.25701624, 0.036973886]\n",
      "Iter 9283, loss [-0.23552099, -0.27047494, 0.034953948]\n",
      "Iter 9284, loss [-0.23014459, -0.26721576, 0.03707117]\n",
      "Iter 9285, loss [-0.21705629, -0.25731546, 0.040259168]\n",
      "Iter 9286, loss [-0.21943499, -0.25884718, 0.03941218]\n",
      "Iter 9287, loss [-0.2115732, -0.25362566, 0.04205246]\n",
      "Iter 9288, loss [-0.2182521, -0.2584461, 0.040194]\n",
      "Iter 9289, loss [-0.22320655, -0.26213306, 0.038926505]\n",
      "Iter 9290, loss [-0.22784692, -0.26429278, 0.03644585]\n",
      "Iter 9291, loss [-0.22904152, -0.26360887, 0.03456735]\n",
      "Iter 9292, loss [-0.22706431, -0.2629278, 0.035863496]\n",
      "Iter 9293, loss [-0.21964975, -0.25616333, 0.036513586]\n",
      "Iter 9294, loss [-0.22059855, -0.2590853, 0.03848674]\n",
      "Iter 9295, loss [-0.22292541, -0.26167932, 0.038753908]\n",
      "Iter 9296, loss [-0.22707765, -0.26576594, 0.038688283]\n",
      "Iter 9297, loss [-0.21009952, -0.25109842, 0.040998913]\n",
      "Iter 9298, loss [-0.23235494, -0.26917875, 0.03682381]\n",
      "Iter 9299, loss [-0.23123297, -0.26785707, 0.03662411]\n",
      "Iter 9300, loss [-0.22801754, -0.26415548, 0.03613793]\n",
      "Iter 9301, loss [-0.22744912, -0.2638143, 0.036365177]\n",
      "Iter 9302, loss [-0.18783955, -0.24001613, 0.05217658]\n",
      "Iter 9303, loss [-0.23014733, -0.26500303, 0.034855686]\n",
      "Iter 9304, loss [-0.22340713, -0.26140687, 0.037999734]\n",
      "Iter 9305, loss [-0.22213638, -0.2599841, 0.037847735]\n",
      "Iter 9306, loss [-0.21801132, -0.2562226, 0.038211294]\n",
      "Iter 9307, loss [-0.21642584, -0.2566086, 0.040182766]\n",
      "Iter 9308, loss [-0.22302084, -0.25972542, 0.03670458]\n",
      "Iter 9309, loss [-0.2280784, -0.26522458, 0.03714618]\n",
      "Iter 9310, loss [-0.22025298, -0.25767, 0.037417006]\n",
      "Iter 9311, loss [-0.22105485, -0.26034093, 0.039286073]\n",
      "Iter 9312, loss [-0.2330963, -0.2692627, 0.036166396]\n",
      "Iter 9313, loss [-0.22018588, -0.25935376, 0.03916789]\n",
      "Iter 9314, loss [-0.22325659, -0.26083505, 0.037578464]\n",
      "Iter 9315, loss [-0.22675246, -0.26407465, 0.0373222]\n",
      "Iter 9316, loss [-0.21911019, -0.25717354, 0.038063355]\n",
      "Iter 9317, loss [-0.2150144, -0.25711745, 0.042103045]\n",
      "Iter 9318, loss [-0.21243528, -0.25515693, 0.04272165]\n",
      "Iter 9319, loss [-0.19563785, -0.24414994, 0.048512094]\n",
      "Iter 9320, loss [-0.2308724, -0.26683205, 0.03595967]\n",
      "Iter 9321, loss [-0.16153753, -0.22009428, 0.058556743]\n",
      "Iter 9322, loss [-0.22432232, -0.26135546, 0.037033133]\n",
      "Iter 9323, loss [-0.22479248, -0.2628327, 0.038040213]\n",
      "Iter 9324, loss [-0.22408241, -0.25930527, 0.035222866]\n",
      "Iter 9325, loss [-0.23215765, -0.26772216, 0.03556452]\n",
      "Iter 9326, loss [-0.1926569, -0.24005018, 0.047393285]\n",
      "Iter 9327, loss [-0.22161767, -0.26093358, 0.03931591]\n",
      "Iter 9328, loss [-0.22752973, -0.26459906, 0.037069313]\n",
      "Iter 9329, loss [-0.22385016, -0.2633257, 0.03947553]\n",
      "Iter 9330, loss [-0.22998533, -0.26505938, 0.03507405]\n",
      "Iter 9331, loss [-0.22500578, -0.2600082, 0.035002407]\n",
      "Iter 9332, loss [-0.23434687, -0.26846603, 0.034119155]\n",
      "Iter 9333, loss [-0.2245623, -0.26326334, 0.038701043]\n",
      "Iter 9334, loss [-0.2253191, -0.26346228, 0.038143173]\n",
      "Iter 9335, loss [-0.22092985, -0.26023394, 0.03930409]\n",
      "Iter 9336, loss [-0.22032285, -0.2569471, 0.03662426]\n",
      "Iter 9337, loss [-0.21407166, -0.25587127, 0.041799612]\n",
      "Iter 9338, loss [-0.22798991, -0.26339725, 0.035407327]\n",
      "Iter 9339, loss [-0.22785637, -0.26424134, 0.036384977]\n",
      "Iter 9340, loss [-0.21881878, -0.25462762, 0.03580883]\n",
      "Iter 9341, loss [-0.2249608, -0.2644797, 0.039518885]\n",
      "Iter 9342, loss [-0.22219764, -0.2626584, 0.040460754]\n",
      "Iter 9343, loss [-0.2241072, -0.2635807, 0.03947351]\n",
      "Iter 9344, loss [-0.22614683, -0.2641244, 0.03797756]\n",
      "Iter 9345, loss [-0.14885452, -0.20655042, 0.05769589]\n",
      "Iter 9346, loss [-0.2191512, -0.25780186, 0.038650658]\n",
      "Iter 9347, loss [-0.22308663, -0.26144844, 0.038361814]\n",
      "Iter 9348, loss [-0.21662405, -0.2548169, 0.038192846]\n",
      "Iter 9349, loss [-0.21893734, -0.25558928, 0.03665193]\n",
      "Iter 9350, loss [-0.21443105, -0.253557, 0.03912595]\n",
      "Iter 9351, loss [-0.23025271, -0.26674315, 0.036490433]\n",
      "Iter 9352, loss [-0.22901534, -0.26436827, 0.03535293]\n",
      "Iter 9353, loss [-0.21438932, -0.25622132, 0.041832]\n",
      "Iter 9354, loss [-0.21056041, -0.2521083, 0.041547894]\n",
      "Iter 9355, loss [-0.21506348, -0.25448802, 0.03942454]\n",
      "Iter 9356, loss [-0.22973144, -0.26493058, 0.03519913]\n",
      "Iter 9357, loss [-0.21254672, -0.25203046, 0.03948374]\n",
      "Iter 9358, loss [-0.23017739, -0.26538825, 0.03521086]\n",
      "Iter 9359, loss [-0.22406128, -0.26042998, 0.036368705]\n",
      "Iter 9360, loss [-0.2360765, -0.27115908, 0.035082586]\n",
      "Iter 9361, loss [-0.22426777, -0.26146814, 0.037200376]\n",
      "Iter 9362, loss [-0.2208314, -0.2600497, 0.0392183]\n",
      "Iter 9363, loss [-0.21996042, -0.2612277, 0.041267283]\n",
      "Iter 9364, loss [-0.22615802, -0.26291654, 0.036758505]\n",
      "Iter 9365, loss [-0.18364197, -0.23480582, 0.051163845]\n",
      "Iter 9366, loss [-0.21930775, -0.258421, 0.039113246]\n",
      "Iter 9367, loss [-0.22667547, -0.26198697, 0.0353115]\n",
      "Iter 9368, loss [-0.22708735, -0.26270306, 0.03561572]\n",
      "Iter 9369, loss [-0.23297992, -0.26848558, 0.03550566]\n",
      "Iter 9370, loss [-0.20539406, -0.25278348, 0.047389425]\n",
      "Iter 9371, loss [-0.21478516, -0.25642663, 0.041641477]\n",
      "Iter 9372, loss [-0.22828352, -0.2656365, 0.03735297]\n",
      "Iter 9373, loss [-0.22165415, -0.2608626, 0.03920844]\n",
      "Iter 9374, loss [-0.22312552, -0.26276088, 0.039635357]\n",
      "Iter 9375, loss [-0.21909091, -0.2593134, 0.040222496]\n",
      "Iter 9376, loss [-0.22019953, -0.25868446, 0.03848493]\n",
      "Iter 9377, loss [-0.22969946, -0.2654618, 0.035762332]\n",
      "Iter 9378, loss [-0.18886465, -0.23759857, 0.048733916]\n",
      "Iter 9379, loss [-0.22560513, -0.26139122, 0.035786096]\n",
      "Iter 9380, loss [-0.22851765, -0.26450086, 0.035983197]\n",
      "Iter 9381, loss [-0.2245156, -0.26227742, 0.037761822]\n",
      "Iter 9382, loss [-0.2188606, -0.25731945, 0.038458854]\n",
      "Iter 9383, loss [-0.21672097, -0.2571426, 0.040421642]\n",
      "Iter 9384, loss [-0.22006689, -0.25833642, 0.03826953]\n",
      "Iter 9385, loss [-0.22382121, -0.26210135, 0.038280144]\n",
      "Iter 9386, loss [-0.22726062, -0.26450542, 0.037244804]\n",
      "Iter 9387, loss [-0.2207267, -0.2597104, 0.038983703]\n",
      "Iter 9388, loss [-0.18994236, -0.23509605, 0.04515369]\n",
      "Iter 9389, loss [-0.22166888, -0.26078293, 0.039114043]\n",
      "Iter 9390, loss [-0.22746396, -0.26430255, 0.036838584]\n",
      "Iter 9391, loss [-0.21744397, -0.25768444, 0.040240474]\n",
      "Iter 9392, loss [-0.22682187, -0.26523387, 0.038412005]\n",
      "Iter 9393, loss [-0.22531572, -0.26422954, 0.038913816]\n",
      "Iter 9394, loss [-0.22624342, -0.26490703, 0.03866361]\n",
      "Iter 9395, loss [-0.22234224, -0.25761482, 0.03527258]\n",
      "Iter 9396, loss [-0.22636965, -0.26035604, 0.03398639]\n",
      "Iter 9397, loss [-0.20906325, -0.24596149, 0.036898237]\n",
      "Iter 9398, loss [-0.22944084, -0.2647686, 0.035327762]\n",
      "Iter 9399, loss [-0.22105306, -0.26060155, 0.039548486]\n",
      "Iter 9400, loss [-0.22460873, -0.26313746, 0.038528726]\n",
      "Iter 9401, loss [-0.22086719, -0.2603552, 0.039488025]\n",
      "Iter 9402, loss [-0.22930871, -0.26442072, 0.03511201]\n",
      "Iter 9403, loss [-0.21789472, -0.2578624, 0.039967667]\n",
      "Iter 9404, loss [-0.2243194, -0.2597997, 0.035480283]\n",
      "Iter 9405, loss [-0.18947527, -0.2323489, 0.042873636]\n",
      "Iter 9406, loss [-0.21860228, -0.25398982, 0.035387535]\n",
      "Iter 9407, loss [-0.21426761, -0.25328052, 0.03901291]\n",
      "Iter 9408, loss [-0.22685069, -0.26357412, 0.036723435]\n",
      "Iter 9409, loss [-0.22398503, -0.263851, 0.039865956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9410, loss [-0.22788145, -0.2665793, 0.038697854]\n",
      "Iter 9411, loss [-0.21464457, -0.25681272, 0.04216815]\n",
      "Iter 9412, loss [-0.22310214, -0.26086918, 0.037767038]\n",
      "Iter 9413, loss [-0.22124356, -0.25691095, 0.03566739]\n",
      "Iter 9414, loss [-0.18357635, -0.23160154, 0.04802519]\n",
      "Iter 9415, loss [-0.21505539, -0.25478032, 0.03972493]\n",
      "Iter 9416, loss [-0.2234796, -0.2620793, 0.038599692]\n",
      "Iter 9417, loss [-0.23081799, -0.26679796, 0.035979968]\n",
      "Iter 9418, loss [-0.21906027, -0.25775242, 0.038692143]\n",
      "Iter 9419, loss [-0.21709228, -0.26043674, 0.043344475]\n",
      "Iter 9420, loss [-0.22626677, -0.26519555, 0.03892877]\n",
      "Iter 9421, loss [-0.21933642, -0.25870174, 0.039365314]\n",
      "Iter 9422, loss [-0.22342287, -0.26479313, 0.041370254]\n",
      "Iter 9423, loss [-0.22338334, -0.26258454, 0.039201207]\n",
      "Iter 9424, loss [-0.22385338, -0.262576, 0.03872264]\n",
      "Iter 9425, loss [-0.19995412, -0.24201077, 0.042056642]\n",
      "Iter 9426, loss [-0.2131291, -0.25193292, 0.038803823]\n",
      "Iter 9427, loss [-0.21487525, -0.25353065, 0.038655408]\n",
      "Iter 9428, loss [-0.22347023, -0.26098305, 0.03751282]\n",
      "Iter 9429, loss [-0.22846878, -0.264815, 0.036346223]\n",
      "Iter 9430, loss [-0.2244766, -0.26353353, 0.039056927]\n",
      "Iter 9431, loss [-0.22440067, -0.26403987, 0.039639197]\n",
      "Iter 9432, loss [-0.21964946, -0.25907204, 0.03942257]\n",
      "Iter 9433, loss [-0.18784678, -0.23840904, 0.050562263]\n",
      "Iter 9434, loss [-0.2245515, -0.26025254, 0.03570103]\n",
      "Iter 9435, loss [-0.22576235, -0.2626249, 0.036862537]\n",
      "Iter 9436, loss [-0.23206265, -0.26703677, 0.034974113]\n",
      "Iter 9437, loss [-0.22809973, -0.26320925, 0.03510952]\n",
      "Iter 9438, loss [-0.21518439, -0.25490573, 0.03972134]\n",
      "Iter 9439, loss [-0.2157243, -0.25573117, 0.04000686]\n",
      "Iter 9440, loss [-0.22377536, -0.26330203, 0.039526667]\n",
      "Iter 9441, loss [-0.23064543, -0.267923, 0.037277564]\n",
      "Iter 9442, loss [-0.22266585, -0.26116237, 0.038496524]\n",
      "Iter 9443, loss [-0.23141037, -0.26854965, 0.037139278]\n",
      "Iter 9444, loss [-0.2252746, -0.2622152, 0.0369406]\n",
      "Iter 9445, loss [-0.22221336, -0.2600503, 0.03783693]\n",
      "Iter 9446, loss [-0.22390302, -0.26100272, 0.037099708]\n",
      "Iter 9447, loss [-0.22016324, -0.25958362, 0.039420377]\n",
      "Iter 9448, loss [-0.22754937, -0.2651954, 0.037646025]\n",
      "Iter 9449, loss [-0.2165193, -0.2519747, 0.035455406]\n",
      "Iter 9450, loss [-0.23436739, -0.2687641, 0.03439672]\n",
      "Iter 9451, loss [-0.21150486, -0.25019765, 0.038692787]\n",
      "Iter 9452, loss [-0.22146225, -0.2613234, 0.03986115]\n",
      "Iter 9453, loss [-0.23436676, -0.26891223, 0.034545463]\n",
      "Iter 9454, loss [-0.21810131, -0.25770915, 0.039607834]\n",
      "Iter 9455, loss [-0.20572121, -0.24755032, 0.04182911]\n",
      "Iter 9456, loss [-0.21294533, -0.2522902, 0.039344862]\n",
      "Iter 9457, loss [-0.21869947, -0.25560933, 0.036909863]\n",
      "Iter 9458, loss [-0.23000896, -0.2647554, 0.034746446]\n",
      "Iter 9459, loss [-0.22138862, -0.25864476, 0.037256137]\n",
      "Iter 9460, loss [-0.21215296, -0.25466892, 0.04251597]\n",
      "Iter 9461, loss [-0.2202214, -0.26334724, 0.043125845]\n",
      "Iter 9462, loss [-0.215569, -0.25873935, 0.043170348]\n",
      "Iter 9463, loss [-0.22614944, -0.26472667, 0.03857722]\n",
      "Iter 9464, loss [-0.22799504, -0.26546016, 0.037465133]\n",
      "Iter 9465, loss [-0.2013757, -0.24647513, 0.045099434]\n",
      "Iter 9466, loss [-0.22494066, -0.2623902, 0.03744954]\n",
      "Iter 9467, loss [-0.22059025, -0.2596415, 0.039051246]\n",
      "Iter 9468, loss [-0.22937083, -0.26519266, 0.035821825]\n",
      "Iter 9469, loss [-0.22586046, -0.2638817, 0.038021248]\n",
      "Iter 9470, loss [-0.20761988, -0.24995023, 0.042330347]\n",
      "Iter 9471, loss [-0.22137369, -0.2598335, 0.03845982]\n",
      "Iter 9472, loss [-0.228466, -0.26718122, 0.038715214]\n",
      "Iter 9473, loss [-0.22798409, -0.26477346, 0.036789376]\n",
      "Iter 9474, loss [-0.22580697, -0.26268417, 0.036877196]\n",
      "Iter 9475, loss [-0.22932963, -0.26482946, 0.035499826]\n",
      "Iter 9476, loss [-0.18673734, -0.23517534, 0.048437998]\n",
      "Iter 9477, loss [-0.17860027, -0.21833372, 0.03973345]\n",
      "Iter 9478, loss [-0.22956328, -0.26778972, 0.038226437]\n",
      "Iter 9479, loss [-0.24134386, -0.27602413, 0.03468027]\n",
      "Iter 9480, loss [-0.21971413, -0.25649056, 0.036776423]\n",
      "Iter 9481, loss [-0.1788061, -0.22065622, 0.041850116]\n",
      "Iter 9482, loss [-0.22697309, -0.26457173, 0.037598632]\n",
      "Iter 9483, loss [-0.23484425, -0.2696448, 0.034800548]\n",
      "Iter 9484, loss [-0.20867375, -0.2476421, 0.038968347]\n",
      "Iter 9485, loss [-0.23075587, -0.26603493, 0.035279065]\n",
      "Iter 9486, loss [-0.21847591, -0.257678, 0.039202094]\n",
      "Iter 9487, loss [-0.23263475, -0.26718888, 0.034554124]\n",
      "Iter 9488, loss [-0.2197918, -0.26007, 0.040278204]\n",
      "Iter 9489, loss [-0.22415438, -0.2635815, 0.03942714]\n",
      "Iter 9490, loss [-0.21130237, -0.252834, 0.04153162]\n",
      "Iter 9491, loss [-0.2212877, -0.26014146, 0.038853765]\n",
      "Iter 9492, loss [-0.22645772, -0.26361382, 0.0371561]\n",
      "Iter 9493, loss [-0.21314678, -0.24972019, 0.03657341]\n",
      "Iter 9494, loss [-0.2150976, -0.25279093, 0.03769333]\n",
      "Iter 9495, loss [-0.15736605, -0.21334803, 0.055981975]\n",
      "Iter 9496, loss [-0.2235567, -0.2620168, 0.038460106]\n",
      "Iter 9497, loss [-0.21823584, -0.2569243, 0.038688466]\n",
      "Iter 9498, loss [-0.21721548, -0.25781244, 0.04059696]\n",
      "Iter 9499, loss [-0.21983913, -0.25688094, 0.037041817]\n",
      "Iter 9500, loss [-0.2184769, -0.25885603, 0.040379126]\n",
      "Iter 9501, loss [-0.22636503, -0.26421767, 0.037852645]\n",
      "Iter 9502, loss [-0.23221098, -0.26681206, 0.034601074]\n",
      "Iter 9503, loss [-0.22767991, -0.26541367, 0.03773377]\n",
      "Iter 9504, loss [-0.21698546, -0.25760537, 0.040619906]\n",
      "Iter 9505, loss [-0.22003445, -0.26044574, 0.0404113]\n",
      "Iter 9506, loss [-0.21196187, -0.25328597, 0.041324113]\n",
      "Iter 9507, loss [-0.2273758, -0.26501212, 0.037636306]\n",
      "Iter 9508, loss [-0.2071138, -0.2496124, 0.042498603]\n",
      "Iter 9509, loss [-0.22976844, -0.26731715, 0.03754871]\n",
      "Iter 9510, loss [-0.22467376, -0.2632787, 0.03860493]\n",
      "Iter 9511, loss [-0.15640402, -0.21008754, 0.05368352]\n",
      "Iter 9512, loss [-0.21819289, -0.25869438, 0.04050149]\n",
      "Iter 9513, loss [-0.2272961, -0.26359734, 0.03630124]\n",
      "Iter 9514, loss [-0.19904613, -0.24494487, 0.045898728]\n",
      "Iter 9515, loss [-0.2204153, -0.26049218, 0.04007689]\n",
      "Iter 9516, loss [-0.21036834, -0.25287378, 0.042505436]\n",
      "Iter 9517, loss [-0.21527992, -0.2549166, 0.039636686]\n",
      "Iter 9518, loss [-0.21760054, -0.2546401, 0.03703956]\n",
      "Iter 9519, loss [-0.19988157, -0.24249882, 0.042617243]\n",
      "Iter 9520, loss [-0.2235254, -0.26175177, 0.038226373]\n",
      "Iter 9521, loss [-0.22002417, -0.25919622, 0.03917206]\n",
      "Iter 9522, loss [-0.20908713, -0.25269845, 0.043611325]\n",
      "Iter 9523, loss [-0.2241318, -0.26414782, 0.040016033]\n",
      "Iter 9524, loss [-0.23055941, -0.26756796, 0.037008557]\n",
      "Iter 9525, loss [-0.22198276, -0.26284868, 0.04086591]\n",
      "Iter 9526, loss [-0.220923, -0.26006195, 0.039138936]\n",
      "Iter 9527, loss [-0.2266379, -0.26147756, 0.03483966]\n",
      "Iter 9528, loss [-0.23343879, -0.2669519, 0.03351309]\n",
      "Iter 9529, loss [-0.22757575, -0.26297668, 0.035400927]\n",
      "Iter 9530, loss [-0.22596958, -0.26231003, 0.036340453]\n",
      "Iter 9531, loss [-0.22608782, -0.26397902, 0.03789119]\n",
      "Iter 9532, loss [-0.2192679, -0.259197, 0.039929092]\n",
      "Iter 9533, loss [-0.21748477, -0.25786966, 0.04038488]\n",
      "Iter 9534, loss [-0.22684748, -0.26574138, 0.03889389]\n",
      "Iter 9535, loss [-0.22239122, -0.26227024, 0.03987903]\n",
      "Iter 9536, loss [-0.21832737, -0.25789863, 0.039571263]\n",
      "Iter 9537, loss [-0.23136985, -0.2658301, 0.03446024]\n",
      "Iter 9538, loss [-0.2253665, -0.26245084, 0.037084334]\n",
      "Iter 9539, loss [-0.22050428, -0.25888076, 0.038376488]\n",
      "Iter 9540, loss [-0.21850885, -0.25825357, 0.039744716]\n",
      "Iter 9541, loss [-0.22265431, -0.26117754, 0.038523223]\n",
      "Iter 9542, loss [-0.22071281, -0.26032272, 0.0396099]\n",
      "Iter 9543, loss [-0.20609805, -0.24962209, 0.04352404]\n",
      "Iter 9544, loss [-0.21919204, -0.2565617, 0.037369654]\n",
      "Iter 9545, loss [-0.22608155, -0.26465786, 0.0385763]\n",
      "Iter 9546, loss [-0.22896688, -0.2657742, 0.03680731]\n",
      "Iter 9547, loss [-0.22655198, -0.26348847, 0.036936488]\n",
      "Iter 9548, loss [-0.21874356, -0.2577336, 0.038990043]\n",
      "Iter 9549, loss [-0.2155931, -0.25044578, 0.034852684]\n",
      "Iter 9550, loss [-0.20660937, -0.24944578, 0.042836405]\n",
      "Iter 9551, loss [-0.17841016, -0.22381784, 0.045407683]\n",
      "Iter 9552, loss [-0.21599892, -0.2546373, 0.038638376]\n",
      "Iter 9553, loss [-0.22464478, -0.2621566, 0.037511833]\n",
      "Iter 9554, loss [-0.22969538, -0.26661274, 0.036917366]\n",
      "Iter 9555, loss [-0.2174682, -0.25838423, 0.04091602]\n",
      "Iter 9556, loss [-0.19166538, -0.23727556, 0.045610167]\n",
      "Iter 9557, loss [-0.22013393, -0.2611568, 0.041022867]\n",
      "Iter 9558, loss [-0.2224958, -0.2619967, 0.039500892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9559, loss [-0.23365512, -0.27070466, 0.037049524]\n",
      "Iter 9560, loss [-0.2175282, -0.2573179, 0.039789703]\n",
      "Iter 9561, loss [-0.23035854, -0.2667372, 0.036378644]\n",
      "Iter 9562, loss [-0.21974814, -0.25775436, 0.03800622]\n",
      "Iter 9563, loss [-0.22553173, -0.2614997, 0.035967972]\n",
      "Iter 9564, loss [-0.2139355, -0.25133353, 0.037398048]\n",
      "Iter 9565, loss [-0.22555141, -0.2627035, 0.037152097]\n",
      "Iter 9566, loss [-0.18550472, -0.2327419, 0.047237188]\n",
      "Iter 9567, loss [-0.22520879, -0.26418716, 0.03897836]\n",
      "Iter 9568, loss [-0.23180082, -0.26885843, 0.037057616]\n",
      "Iter 9569, loss [-0.3093537, -0.31751427, 0.00816057]\n",
      "Iter 9570, loss [-0.20978454, -0.25328046, 0.04349592]\n",
      "Iter 9571, loss [-0.22435603, -0.26214945, 0.037793428]\n",
      "Iter 9572, loss [-0.1642603, -0.21859336, 0.05433306]\n",
      "Iter 9573, loss [-0.22510219, -0.2602831, 0.035180934]\n",
      "Iter 9574, loss [-0.2301481, -0.26462924, 0.034481138]\n",
      "Iter 9575, loss [-0.1870337, -0.23507448, 0.048040777]\n",
      "Iter 9576, loss [-0.2222313, -0.25966948, 0.037438177]\n",
      "Iter 9577, loss [-0.22796184, -0.26564154, 0.037679706]\n",
      "Iter 9578, loss [-0.22539793, -0.26297575, 0.037577823]\n",
      "Iter 9579, loss [-0.22141938, -0.2596127, 0.038193326]\n",
      "Iter 9580, loss [-0.2281479, -0.26568958, 0.03754168]\n",
      "Iter 9581, loss [-0.22516021, -0.260901, 0.035740793]\n",
      "Iter 9582, loss [-0.2270393, -0.2640295, 0.03699019]\n",
      "Iter 9583, loss [-0.2250703, -0.26093492, 0.035864614]\n",
      "Iter 9584, loss [-0.23115692, -0.26736236, 0.03620544]\n",
      "Iter 9585, loss [-0.23082164, -0.26723146, 0.036409833]\n",
      "Iter 9586, loss [-0.2336005, -0.26828295, 0.034682445]\n",
      "Iter 9587, loss [-0.22713989, -0.26461005, 0.037470166]\n",
      "Iter 9588, loss [-0.21874537, -0.25922203, 0.04047666]\n",
      "Iter 9589, loss [-0.20657821, -0.25042197, 0.04384376]\n",
      "Iter 9590, loss [-0.1996824, -0.24400163, 0.044319227]\n",
      "Iter 9591, loss [-0.21824047, -0.25802013, 0.03977966]\n",
      "Iter 9592, loss [-0.16686174, -0.22236702, 0.055505276]\n",
      "Iter 9593, loss [-0.22571108, -0.26408142, 0.03837034]\n",
      "Iter 9594, loss [-0.21834514, -0.25852078, 0.04017565]\n",
      "Iter 9595, loss [-0.16778027, -0.22768956, 0.059909295]\n",
      "Iter 9596, loss [-0.22901697, -0.26577026, 0.03675328]\n",
      "Iter 9597, loss [-0.23437375, -0.26972258, 0.03534884]\n",
      "Iter 9598, loss [-0.22850892, -0.2651134, 0.036604486]\n",
      "Iter 9599, loss [-0.22610457, -0.2601662, 0.034061622]\n",
      "Iter 9600, loss [-0.20658037, -0.24764565, 0.041065272]\n",
      "Iter 9601, loss [-0.23198962, -0.26835826, 0.03636863]\n",
      "Iter 9602, loss [-0.22439858, -0.261629, 0.03723041]\n",
      "Iter 9603, loss [-0.1852746, -0.23409902, 0.048824415]\n",
      "Iter 9604, loss [-0.22509125, -0.2628603, 0.037769046]\n",
      "Iter 9605, loss [-0.23145977, -0.2674653, 0.03600552]\n",
      "Iter 9606, loss [-0.22078325, -0.25821373, 0.03743048]\n",
      "Iter 9607, loss [-0.20818615, -0.2483855, 0.040199347]\n",
      "Iter 9608, loss [-0.22918847, -0.2653447, 0.036156233]\n",
      "Iter 9609, loss [-0.22149026, -0.2597825, 0.03829222]\n",
      "Iter 9610, loss [-0.23009187, -0.267284, 0.03719213]\n",
      "Iter 9611, loss [-0.22817141, -0.26533046, 0.037159063]\n",
      "Iter 9612, loss [-0.2276848, -0.26546177, 0.037776977]\n",
      "Iter 9613, loss [-0.22151148, -0.26164654, 0.040135052]\n",
      "Iter 9614, loss [-0.2285539, -0.2663064, 0.03775249]\n",
      "Iter 9615, loss [-0.22738141, -0.2634737, 0.036092278]\n",
      "Iter 9616, loss [-0.23130885, -0.26755002, 0.036241174]\n",
      "Iter 9617, loss [-0.13304557, -0.19394167, 0.0608961]\n",
      "Iter 9618, loss [-0.21990983, -0.25812635, 0.03821652]\n",
      "Iter 9619, loss [-0.23555814, -0.26985523, 0.03429709]\n",
      "Iter 9620, loss [-0.21512702, -0.25412363, 0.038996615]\n",
      "Iter 9621, loss [-0.2251441, -0.26147574, 0.03633164]\n",
      "Iter 9622, loss [-0.23026477, -0.2655087, 0.035243943]\n",
      "Iter 9623, loss [-0.21400349, -0.25720522, 0.04320173]\n",
      "Iter 9624, loss [-0.21486375, -0.2543385, 0.039474763]\n",
      "Iter 9625, loss [-0.15770653, -0.21193631, 0.05422979]\n",
      "Iter 9626, loss [-0.22079489, -0.2593012, 0.03850629]\n",
      "Iter 9627, loss [-0.22550356, -0.26399952, 0.038495954]\n",
      "Iter 9628, loss [-0.21417892, -0.2547969, 0.040617965]\n",
      "Iter 9629, loss [-0.22298183, -0.2626923, 0.039710477]\n",
      "Iter 9630, loss [-0.21144162, -0.25338838, 0.04194675]\n",
      "Iter 9631, loss [-0.21899346, -0.25790533, 0.03891187]\n",
      "Iter 9632, loss [-0.22653754, -0.26459464, 0.038057107]\n",
      "Iter 9633, loss [-0.1992341, -0.2444651, 0.045231007]\n",
      "Iter 9634, loss [-0.21732001, -0.25355, 0.036229983]\n",
      "Iter 9635, loss [-0.22760323, -0.265243, 0.037639767]\n",
      "Iter 9636, loss [-0.22761744, -0.26554286, 0.037925422]\n",
      "Iter 9637, loss [-0.15927249, -0.2179879, 0.058715403]\n",
      "Iter 9638, loss [-0.22132136, -0.2596348, 0.038313434]\n",
      "Iter 9639, loss [-0.22772227, -0.26508683, 0.037364554]\n",
      "Iter 9640, loss [-0.2226781, -0.26105666, 0.03837857]\n",
      "Iter 9641, loss [-0.1591272, -0.2102485, 0.051121294]\n",
      "Iter 9642, loss [-0.21622261, -0.25593275, 0.03971014]\n",
      "Iter 9643, loss [-0.22918995, -0.26691324, 0.03772329]\n",
      "Iter 9644, loss [-0.22081105, -0.26017302, 0.03936197]\n",
      "Iter 9645, loss [-0.22225598, -0.2612233, 0.038967308]\n",
      "Iter 9646, loss [-0.22203591, -0.2618755, 0.039839596]\n",
      "Iter 9647, loss [-0.22357276, -0.26091307, 0.03734031]\n",
      "Iter 9648, loss [-0.22394156, -0.2623564, 0.03841483]\n",
      "Iter 9649, loss [-0.13329145, -0.19474345, 0.061451994]\n",
      "Iter 9650, loss [-0.22102287, -0.25803798, 0.037015103]\n",
      "Iter 9651, loss [-0.22596492, -0.26197627, 0.03601135]\n",
      "Iter 9652, loss [-0.2208216, -0.25827366, 0.037452057]\n",
      "Iter 9653, loss [-0.22849503, -0.26597488, 0.037479844]\n",
      "Iter 9654, loss [-0.20838971, -0.25234398, 0.043954268]\n",
      "Iter 9655, loss [-0.22502504, -0.26324758, 0.038222536]\n",
      "Iter 9656, loss [-0.22157049, -0.262213, 0.0406425]\n",
      "Iter 9657, loss [-0.23178208, -0.26664555, 0.03486347]\n",
      "Iter 9658, loss [-0.23073637, -0.2659284, 0.035192005]\n",
      "Iter 9659, loss [-0.22861224, -0.26340353, 0.0347913]\n",
      "Iter 9660, loss [-0.18920569, -0.23482303, 0.045617342]\n",
      "Iter 9661, loss [-0.22385427, -0.26188555, 0.03803128]\n",
      "Iter 9662, loss [-0.2192797, -0.2594132, 0.0401335]\n",
      "Iter 9663, loss [-0.22064486, -0.26127473, 0.04062987]\n",
      "Iter 9664, loss [-0.21465005, -0.2554863, 0.04083626]\n",
      "Iter 9665, loss [-0.22540952, -0.2634186, 0.038009092]\n",
      "Iter 9666, loss [-0.2279054, -0.26504818, 0.03714278]\n",
      "Iter 9667, loss [-0.22867024, -0.26290068, 0.034230433]\n",
      "Iter 9668, loss [-0.2260006, -0.2633423, 0.03734168]\n",
      "Iter 9669, loss [-0.22042967, -0.25874588, 0.038316205]\n",
      "Iter 9670, loss [-0.22451118, -0.2614672, 0.036956005]\n",
      "Iter 9671, loss [-0.2272431, -0.26388547, 0.03664237]\n",
      "Iter 9672, loss [-0.2273708, -0.2665964, 0.039225604]\n",
      "Iter 9673, loss [-0.22243008, -0.2628582, 0.040428136]\n",
      "Iter 9674, loss [-0.22920243, -0.26530942, 0.03610699]\n",
      "Iter 9675, loss [-0.21366517, -0.25539926, 0.041734084]\n",
      "Iter 9676, loss [-0.22339776, -0.2607993, 0.03740152]\n",
      "Iter 9677, loss [-0.2242215, -0.26321444, 0.038992938]\n",
      "Iter 9678, loss [-0.22365898, -0.25973856, 0.036079593]\n",
      "Iter 9679, loss [-0.23157132, -0.26848796, 0.03691665]\n",
      "Iter 9680, loss [-0.2118846, -0.25274664, 0.04086204]\n",
      "Iter 9681, loss [-0.20583728, -0.2498818, 0.044044524]\n",
      "Iter 9682, loss [-0.2187173, -0.25850856, 0.03979125]\n",
      "Iter 9683, loss [-0.22261485, -0.2625351, 0.039920237]\n",
      "Iter 9684, loss [-0.22892544, -0.26537558, 0.03645014]\n",
      "Iter 9685, loss [-0.22593504, -0.26170528, 0.035770234]\n",
      "Iter 9686, loss [-0.21861103, -0.2576019, 0.038990848]\n",
      "Iter 9687, loss [-0.22218236, -0.25998834, 0.037805967]\n",
      "Iter 9688, loss [-0.21423697, -0.2571054, 0.042868428]\n",
      "Iter 9689, loss [-0.22167347, -0.2609969, 0.039323434]\n",
      "Iter 9690, loss [-0.22884586, -0.26497462, 0.036128763]\n",
      "Iter 9691, loss [-0.22271876, -0.26344296, 0.040724203]\n",
      "Iter 9692, loss [-0.22303286, -0.26357254, 0.040539682]\n",
      "Iter 9693, loss [-0.22306702, -0.2609016, 0.03783458]\n",
      "Iter 9694, loss [-0.22099909, -0.26047945, 0.03948035]\n",
      "Iter 9695, loss [-0.22471806, -0.2611918, 0.036473714]\n",
      "Iter 9696, loss [-0.21736456, -0.25713336, 0.0397688]\n",
      "Iter 9697, loss [-0.21298972, -0.2521541, 0.039164387]\n",
      "Iter 9698, loss [-0.22543012, -0.26157728, 0.036147166]\n",
      "Iter 9699, loss [-0.22502637, -0.2635978, 0.038571414]\n",
      "Iter 9700, loss [-0.23126066, -0.26760852, 0.036347874]\n",
      "Iter 9701, loss [-0.224908, -0.2645388, 0.039630808]\n",
      "Iter 9702, loss [-0.22832021, -0.2668466, 0.03852638]\n",
      "Iter 9703, loss [-0.19099945, -0.23864478, 0.047645323]\n",
      "Iter 9704, loss [-0.21347967, -0.2531891, 0.039709423]\n",
      "Iter 9705, loss [-0.22940993, -0.26534274, 0.0359328]\n",
      "Iter 9706, loss [-0.22768265, -0.26439282, 0.036710177]\n",
      "Iter 9707, loss [-0.22837391, -0.26604083, 0.037666924]\n",
      "Iter 9708, loss [-0.2171154, -0.25765845, 0.040543057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9709, loss [-0.23018563, -0.26711717, 0.036931545]\n",
      "Iter 9710, loss [-0.22510639, -0.26469448, 0.039588086]\n",
      "Iter 9711, loss [-0.23362981, -0.27018356, 0.036553755]\n",
      "Iter 9712, loss [-0.20481881, -0.24633662, 0.0415178]\n",
      "Iter 9713, loss [-0.22758405, -0.2652971, 0.037713062]\n",
      "Iter 9714, loss [-0.22898802, -0.26560375, 0.036615722]\n",
      "Iter 9715, loss [-0.22730593, -0.26345563, 0.036149696]\n",
      "Iter 9716, loss [-0.22432277, -0.26215366, 0.037830897]\n",
      "Iter 9717, loss [-0.22318381, -0.26122501, 0.03804121]\n",
      "Iter 9718, loss [-0.21573795, -0.25575897, 0.040021017]\n",
      "Iter 9719, loss [-0.2223008, -0.26046053, 0.038159724]\n",
      "Iter 9720, loss [-0.17991343, -0.23108059, 0.05116716]\n",
      "Iter 9721, loss [-0.22603357, -0.26405215, 0.038018577]\n",
      "Iter 9722, loss [-0.22831601, -0.26341492, 0.035098918]\n",
      "Iter 9723, loss [-0.22700447, -0.26451802, 0.03751355]\n",
      "Iter 9724, loss [-0.17871775, -0.21870379, 0.039986044]\n",
      "Iter 9725, loss [-0.2153685, -0.25427693, 0.038908437]\n",
      "Iter 9726, loss [-0.21937223, -0.2593631, 0.039990887]\n",
      "Iter 9727, loss [-0.22364984, -0.26242626, 0.03877641]\n",
      "Iter 9728, loss [-0.22713324, -0.26237655, 0.03524331]\n",
      "Iter 9729, loss [-0.22432218, -0.26149312, 0.03717093]\n",
      "Iter 9730, loss [-0.21646804, -0.25604466, 0.03957662]\n",
      "Iter 9731, loss [-0.22937483, -0.26514888, 0.035774056]\n",
      "Iter 9732, loss [-0.22924396, -0.2662314, 0.03698743]\n",
      "Iter 9733, loss [-0.22285101, -0.2617469, 0.038895912]\n",
      "Iter 9734, loss [-0.22427343, -0.26351985, 0.03924642]\n",
      "Iter 9735, loss [-0.23146024, -0.26706594, 0.035605703]\n",
      "Iter 9736, loss [-0.21499036, -0.25584304, 0.04085268]\n",
      "Iter 9737, loss [-0.21658492, -0.25696996, 0.040385038]\n",
      "Iter 9738, loss [-0.22122985, -0.2603563, 0.03912645]\n",
      "Iter 9739, loss [-0.22689262, -0.26458478, 0.037692167]\n",
      "Iter 9740, loss [-0.22658458, -0.2642928, 0.03770822]\n",
      "Iter 9741, loss [-0.2227175, -0.2602643, 0.03754682]\n",
      "Iter 9742, loss [-0.22882263, -0.264159, 0.035336357]\n",
      "Iter 9743, loss [-0.22578014, -0.26312372, 0.037343573]\n",
      "Iter 9744, loss [-0.23153324, -0.26706052, 0.035527274]\n",
      "Iter 9745, loss [-0.22398292, -0.26289266, 0.038909744]\n",
      "Iter 9746, loss [-0.21854977, -0.25422356, 0.035673782]\n",
      "Iter 9747, loss [-0.21826804, -0.25626493, 0.03799689]\n",
      "Iter 9748, loss [-0.22888684, -0.26606134, 0.037174486]\n",
      "Iter 9749, loss [-0.22020248, -0.25926954, 0.039067052]\n",
      "Iter 9750, loss [-0.2200279, -0.25813413, 0.03810624]\n",
      "Iter 9751, loss [-0.22790396, -0.26467308, 0.03676912]\n",
      "Iter 9752, loss [-0.22712336, -0.26200163, 0.03487827]\n",
      "Iter 9753, loss [-0.22581716, -0.26210183, 0.03628467]\n",
      "Iter 9754, loss [-0.21936777, -0.25594816, 0.03658039]\n",
      "Iter 9755, loss [-0.21615934, -0.2568875, 0.04072816]\n",
      "Iter 9756, loss [-0.22134939, -0.26150805, 0.04015866]\n",
      "Iter 9757, loss [-0.21212873, -0.25214523, 0.040016502]\n",
      "Iter 9758, loss [-0.22421385, -0.2629483, 0.038734447]\n",
      "Iter 9759, loss [-0.23023641, -0.26604912, 0.035812706]\n",
      "Iter 9760, loss [-0.22500291, -0.26190943, 0.036906518]\n",
      "Iter 9761, loss [-0.22829048, -0.2651851, 0.03689461]\n",
      "Iter 9762, loss [-0.23141178, -0.26620638, 0.0347946]\n",
      "Iter 9763, loss [-0.22144231, -0.26028672, 0.038844414]\n",
      "Iter 9764, loss [-0.2076358, -0.24924178, 0.04160598]\n",
      "Iter 9765, loss [-0.22812067, -0.26553568, 0.037415013]\n",
      "Iter 9766, loss [-0.20629668, -0.24957024, 0.04327355]\n",
      "Iter 9767, loss [-0.21525317, -0.25753105, 0.042277865]\n",
      "Iter 9768, loss [-0.22921439, -0.26652694, 0.03731255]\n",
      "Iter 9769, loss [-0.22746453, -0.2645346, 0.037070073]\n",
      "Iter 9770, loss [-0.1757516, -0.22663483, 0.050883226]\n",
      "Iter 9771, loss [-0.22798347, -0.26588568, 0.0379022]\n",
      "Iter 9772, loss [-0.22331354, -0.2620913, 0.03877777]\n",
      "Iter 9773, loss [-0.21884553, -0.25886026, 0.04001473]\n",
      "Iter 9774, loss [-0.23006609, -0.26729497, 0.03722888]\n",
      "Iter 9775, loss [-0.22422564, -0.2617131, 0.037487455]\n",
      "Iter 9776, loss [-0.227467, -0.26503068, 0.03756369]\n",
      "Iter 9777, loss [-0.22057614, -0.2602843, 0.039708175]\n",
      "Iter 9778, loss [-0.21555579, -0.25389853, 0.038342744]\n",
      "Iter 9779, loss [-0.2245024, -0.2611921, 0.036689714]\n",
      "Iter 9780, loss [-0.18611765, -0.23034835, 0.044230692]\n",
      "Iter 9781, loss [-0.22498009, -0.26404518, 0.03906509]\n",
      "Iter 9782, loss [-0.2329646, -0.270773, 0.03780839]\n",
      "Iter 9783, loss [-0.23468542, -0.2700053, 0.035319865]\n",
      "Iter 9784, loss [-0.2258262, -0.2638525, 0.038026296]\n",
      "Iter 9785, loss [-0.22656837, -0.26562092, 0.039052553]\n",
      "Iter 9786, loss [-0.22420031, -0.26272422, 0.03852392]\n",
      "Iter 9787, loss [-0.21639535, -0.25149906, 0.035103716]\n",
      "Iter 9788, loss [-0.22606906, -0.262381, 0.03631192]\n",
      "Iter 9789, loss [-0.23008224, -0.26504698, 0.034964737]\n",
      "Iter 9790, loss [-0.136838, -0.19691257, 0.060074568]\n",
      "Iter 9791, loss [-0.22909144, -0.26636827, 0.03727683]\n",
      "Iter 9792, loss [-0.21464486, -0.2564821, 0.041837227]\n",
      "Iter 9793, loss [-0.22318879, -0.2614959, 0.0383071]\n",
      "Iter 9794, loss [-0.21677557, -0.25712726, 0.04035168]\n",
      "Iter 9795, loss [-0.1775295, -0.22057632, 0.043046817]\n",
      "Iter 9796, loss [-0.23315181, -0.26739392, 0.034242105]\n",
      "Iter 9797, loss [-0.22350219, -0.2599311, 0.036428906]\n",
      "Iter 9798, loss [-0.23106791, -0.26513386, 0.034065947]\n",
      "Iter 9799, loss [-0.23175104, -0.2657417, 0.033990663]\n",
      "Iter 9800, loss [-0.21763612, -0.25629386, 0.038657736]\n",
      "Iter 9801, loss [-0.23206931, -0.2691445, 0.03707519]\n",
      "Iter 9802, loss [-0.21275754, -0.25416586, 0.04140831]\n",
      "Iter 9803, loss [-0.21612832, -0.25711307, 0.04098475]\n",
      "Iter 9804, loss [-0.22507182, -0.26271355, 0.03764173]\n",
      "Iter 9805, loss [-0.20875654, -0.25086397, 0.042107426]\n",
      "Iter 9806, loss [-0.13358775, -0.1924597, 0.05887195]\n",
      "Iter 9807, loss [-0.21817064, -0.2572769, 0.039106242]\n",
      "Iter 9808, loss [-0.23334526, -0.2671367, 0.033791434]\n",
      "Iter 9809, loss [-0.22975542, -0.26404497, 0.034289557]\n",
      "Iter 9810, loss [-0.22511023, -0.2625057, 0.03739548]\n",
      "Iter 9811, loss [-0.22740784, -0.2639387, 0.036530852]\n",
      "Iter 9812, loss [-0.23516461, -0.27041787, 0.03525325]\n",
      "Iter 9813, loss [-0.20855676, -0.252198, 0.04364125]\n",
      "Iter 9814, loss [-0.20393236, -0.24824609, 0.044313725]\n",
      "Iter 9815, loss [-0.22517169, -0.26250932, 0.037337627]\n",
      "Iter 9816, loss [-0.23193595, -0.26624638, 0.034310438]\n",
      "Iter 9817, loss [-0.22295266, -0.2583093, 0.035356633]\n",
      "Iter 9818, loss [-0.22325024, -0.2616907, 0.038440462]\n",
      "Iter 9819, loss [-0.20538041, -0.24666809, 0.04128767]\n",
      "Iter 9820, loss [-0.21554351, -0.25659466, 0.041051157]\n",
      "Iter 9821, loss [-0.23459071, -0.2688492, 0.034258485]\n",
      "Iter 9822, loss [-0.21510592, -0.25403163, 0.038925715]\n",
      "Iter 9823, loss [-0.22308013, -0.26017106, 0.037090935]\n",
      "Iter 9824, loss [-0.23226863, -0.26824722, 0.035978585]\n",
      "Iter 9825, loss [-0.22356576, -0.26156372, 0.03799797]\n",
      "Iter 9826, loss [-0.21738847, -0.257373, 0.039984535]\n",
      "Iter 9827, loss [-0.22790635, -0.2658096, 0.037903257]\n",
      "Iter 9828, loss [-0.22376797, -0.2622806, 0.038512643]\n",
      "Iter 9829, loss [-0.227685, -0.26564038, 0.03795538]\n",
      "Iter 9830, loss [-0.21125989, -0.2530036, 0.041743707]\n",
      "Iter 9831, loss [-0.22917831, -0.26436454, 0.03518623]\n",
      "Iter 9832, loss [-0.20324746, -0.24386124, 0.040613793]\n",
      "Iter 9833, loss [-0.21959451, -0.25557455, 0.035980053]\n",
      "Iter 9834, loss [-0.18696424, -0.23256616, 0.04560192]\n",
      "Iter 9835, loss [-0.2306484, -0.26458418, 0.033935778]\n",
      "Iter 9836, loss [-0.21342756, -0.25055897, 0.037131418]\n",
      "Iter 9837, loss [-0.23122102, -0.26674938, 0.03552837]\n",
      "Iter 9838, loss [-0.21634567, -0.25550133, 0.039155662]\n",
      "Iter 9839, loss [-0.21877202, -0.25827095, 0.039498933]\n",
      "Iter 9840, loss [-0.22770688, -0.26393205, 0.036225177]\n",
      "Iter 9841, loss [-0.22030278, -0.2603662, 0.040063426]\n",
      "Iter 9842, loss [-0.22065106, -0.2586181, 0.037967023]\n",
      "Iter 9843, loss [-0.22909725, -0.26467997, 0.03558273]\n",
      "Iter 9844, loss [-0.21855552, -0.25684643, 0.0382909]\n",
      "Iter 9845, loss [-0.22606173, -0.261704, 0.035642266]\n",
      "Iter 9846, loss [-0.23119949, -0.26825926, 0.037059765]\n",
      "Iter 9847, loss [-0.20129594, -0.23973821, 0.03844227]\n",
      "Iter 9848, loss [-0.22404581, -0.26277316, 0.03872735]\n",
      "Iter 9849, loss [-0.21237704, -0.25458455, 0.04220751]\n",
      "Iter 9850, loss [-0.21942958, -0.25551048, 0.0360809]\n",
      "Iter 9851, loss [-0.22758514, -0.2633877, 0.03580257]\n",
      "Iter 9852, loss [-0.1837121, -0.23217824, 0.048466153]\n",
      "Iter 9853, loss [-0.23029615, -0.2658653, 0.035569146]\n",
      "Iter 9854, loss [-0.22436461, -0.26147658, 0.037111975]\n",
      "Iter 9855, loss [-0.22754553, -0.26381275, 0.036267214]\n",
      "Iter 9856, loss [-0.22166461, -0.26097476, 0.039310157]\n",
      "Iter 9857, loss [-0.23402894, -0.26969567, 0.03566673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9858, loss [-0.23078737, -0.26547152, 0.034684148]\n",
      "Iter 9859, loss [-0.21884274, -0.25505736, 0.036214612]\n",
      "Iter 9860, loss [-0.22044206, -0.26039985, 0.039957784]\n",
      "Iter 9861, loss [-0.22054243, -0.26108122, 0.040538795]\n",
      "Iter 9862, loss [-0.2279503, -0.2637872, 0.035836898]\n",
      "Iter 9863, loss [-0.18878537, -0.23571502, 0.04692964]\n",
      "Iter 9864, loss [-0.21802673, -0.26161757, 0.043590836]\n",
      "Iter 9865, loss [-0.22438526, -0.2642223, 0.039837025]\n",
      "Iter 9866, loss [-0.22827138, -0.26374415, 0.035472766]\n",
      "Iter 9867, loss [-0.22636059, -0.26387906, 0.03751847]\n",
      "Iter 9868, loss [-0.21835044, -0.257619, 0.03926856]\n",
      "Iter 9869, loss [-0.20726882, -0.2477005, 0.040431675]\n",
      "Iter 9870, loss [-0.22693895, -0.26306695, 0.036127996]\n",
      "Iter 9871, loss [-0.23084673, -0.2656029, 0.03475616]\n",
      "Iter 9872, loss [-0.15720807, -0.21374722, 0.056539148]\n",
      "Iter 9873, loss [-0.22352138, -0.260578, 0.03705662]\n",
      "Iter 9874, loss [-0.21350527, -0.2513321, 0.03782683]\n",
      "Iter 9875, loss [-0.30901432, -0.3168929, 0.007878581]\n",
      "Iter 9876, loss [-0.22969934, -0.26526016, 0.035560817]\n",
      "Iter 9877, loss [-0.21809198, -0.25447154, 0.036379557]\n",
      "Iter 9878, loss [-0.22004661, -0.25753254, 0.037485927]\n",
      "Iter 9879, loss [-0.23088637, -0.2669301, 0.036043726]\n",
      "Iter 9880, loss [-0.2252366, -0.26329947, 0.038062863]\n",
      "Iter 9881, loss [-0.21614522, -0.25660554, 0.04046031]\n",
      "Iter 9882, loss [-0.22446163, -0.26224697, 0.037785333]\n",
      "Iter 9883, loss [-0.22779755, -0.26473632, 0.03693877]\n",
      "Iter 9884, loss [-0.2204728, -0.259854, 0.03938119]\n",
      "Iter 9885, loss [-0.22483677, -0.2625778, 0.03774103]\n",
      "Iter 9886, loss [-0.20958978, -0.25013074, 0.04054097]\n",
      "Iter 9887, loss [-0.2174331, -0.25603703, 0.038603928]\n",
      "Iter 9888, loss [-0.22798157, -0.2645197, 0.03653813]\n",
      "Iter 9889, loss [-0.22454865, -0.26098594, 0.036437284]\n",
      "Iter 9890, loss [-0.17034712, -0.22093087, 0.050583743]\n",
      "Iter 9891, loss [-0.23178792, -0.26797667, 0.03618875]\n",
      "Iter 9892, loss [-0.22419332, -0.26398453, 0.03979121]\n",
      "Iter 9893, loss [-0.23157716, -0.2682863, 0.036709137]\n",
      "Iter 9894, loss [-0.22711849, -0.26445773, 0.03733924]\n",
      "Iter 9895, loss [-0.22569704, -0.26371735, 0.03802032]\n",
      "Iter 9896, loss [-0.22470972, -0.26157928, 0.036869552]\n",
      "Iter 9897, loss [-0.22368371, -0.26038274, 0.036699034]\n",
      "Iter 9898, loss [-0.21907173, -0.2579185, 0.038846776]\n",
      "Iter 9899, loss [-0.14812475, -0.20959862, 0.06147386]\n",
      "Iter 9900, loss [-0.20257635, -0.24517758, 0.042601228]\n",
      "Iter 9901, loss [-0.22525808, -0.26068473, 0.035426643]\n",
      "Iter 9902, loss [-0.21638165, -0.25655115, 0.040169496]\n",
      "Iter 9903, loss [-0.21483548, -0.25314906, 0.03831358]\n",
      "Iter 9904, loss [-0.22547467, -0.26358002, 0.038105354]\n",
      "Iter 9905, loss [-0.22565183, -0.26410493, 0.038453095]\n",
      "Iter 9906, loss [-0.22397298, -0.26292315, 0.03895017]\n",
      "Iter 9907, loss [-0.22577927, -0.2640156, 0.03823632]\n",
      "Iter 9908, loss [-0.22082716, -0.25956547, 0.038738307]\n",
      "Iter 9909, loss [-0.22412547, -0.26261622, 0.03849074]\n",
      "Iter 9910, loss [-0.22841318, -0.26382062, 0.03540744]\n",
      "Iter 9911, loss [-0.22740832, -0.2618678, 0.03445947]\n",
      "Iter 9912, loss [-0.22508542, -0.26290813, 0.037822705]\n",
      "Iter 9913, loss [-0.22487697, -0.26389956, 0.039022595]\n",
      "Iter 9914, loss [-0.23361014, -0.26980853, 0.03619839]\n",
      "Iter 9915, loss [-0.22479111, -0.26355642, 0.038765304]\n",
      "Iter 9916, loss [-0.23088896, -0.26810017, 0.037211217]\n",
      "Iter 9917, loss [-0.22552618, -0.26311785, 0.03759166]\n",
      "Iter 9918, loss [-0.22651063, -0.2626389, 0.036128264]\n",
      "Iter 9919, loss [-0.21241759, -0.25272512, 0.040307533]\n",
      "Iter 9920, loss [-0.21865012, -0.2557504, 0.03710027]\n",
      "Iter 9921, loss [-0.23087361, -0.2651192, 0.034245588]\n",
      "Iter 9922, loss [-0.16008218, -0.21549366, 0.055411484]\n",
      "Iter 9923, loss [-0.21043557, -0.25185952, 0.041423954]\n",
      "Iter 9924, loss [-0.22708094, -0.26519763, 0.0381167]\n",
      "Iter 9925, loss [-0.22666752, -0.2640533, 0.03738577]\n",
      "Iter 9926, loss [-0.21489857, -0.2561647, 0.041266125]\n",
      "Iter 9927, loss [-0.20235503, -0.24755004, 0.04519501]\n",
      "Iter 9928, loss [-0.2249479, -0.26086825, 0.03592036]\n",
      "Iter 9929, loss [-0.2116034, -0.25181922, 0.04021582]\n",
      "Iter 9930, loss [-0.22580837, -0.26205587, 0.036247503]\n",
      "Iter 9931, loss [-0.2195403, -0.25833517, 0.038794875]\n",
      "Iter 9932, loss [-0.21408868, -0.2556885, 0.041599818]\n",
      "Iter 9933, loss [-0.2249232, -0.26452905, 0.03960586]\n",
      "Iter 9934, loss [-0.21924995, -0.2586177, 0.039367747]\n",
      "Iter 9935, loss [-0.23048627, -0.26663435, 0.036148064]\n",
      "Iter 9936, loss [-0.21974462, -0.25810152, 0.038356896]\n",
      "Iter 9937, loss [-0.22597772, -0.26386845, 0.03789073]\n",
      "Iter 9938, loss [-0.22344397, -0.26287332, 0.039429348]\n",
      "Iter 9939, loss [-0.22502372, -0.26157936, 0.036555648]\n",
      "Iter 9940, loss [-0.23284656, -0.26738214, 0.03453558]\n",
      "Iter 9941, loss [-0.1933672, -0.23666258, 0.04329538]\n",
      "Iter 9942, loss [-0.22790611, -0.26403308, 0.03612697]\n",
      "Iter 9943, loss [-0.22359781, -0.26206136, 0.038463544]\n",
      "Iter 9944, loss [-0.22400926, -0.26085055, 0.03684129]\n",
      "Iter 9945, loss [-0.23529783, -0.26911482, 0.033816993]\n",
      "Iter 9946, loss [-0.2325075, -0.26674336, 0.034235857]\n",
      "Iter 9947, loss [-0.17982022, -0.21997036, 0.040150132]\n",
      "Iter 9948, loss [-0.22634935, -0.2636913, 0.037341945]\n",
      "Iter 9949, loss [-0.22140017, -0.25892884, 0.037528664]\n",
      "Iter 9950, loss [-0.22537565, -0.26363957, 0.038263917]\n",
      "Iter 9951, loss [-0.18842444, -0.23586172, 0.047437273]\n",
      "Iter 9952, loss [-0.22433232, -0.26055074, 0.03621842]\n",
      "Iter 9953, loss [-0.23206389, -0.26929146, 0.03722757]\n",
      "Iter 9954, loss [-0.22028393, -0.2599815, 0.039697584]\n",
      "Iter 9955, loss [-0.22956592, -0.26767686, 0.03811094]\n",
      "Iter 9956, loss [-0.2344941, -0.2698969, 0.035402786]\n",
      "Iter 9957, loss [-0.21252197, -0.25103363, 0.03851167]\n",
      "Iter 9958, loss [-0.22250494, -0.26083338, 0.03832843]\n",
      "Iter 9959, loss [-0.2262087, -0.26071817, 0.034509465]\n",
      "Iter 9960, loss [-0.17119357, -0.22622079, 0.05502721]\n",
      "Iter 9961, loss [-0.23218177, -0.2668008, 0.03461902]\n",
      "Iter 9962, loss [-0.2119442, -0.2507224, 0.038778216]\n",
      "Iter 9963, loss [-0.23058125, -0.26658675, 0.036005504]\n",
      "Iter 9964, loss [-0.222201, -0.2610883, 0.038887307]\n",
      "Iter 9965, loss [-0.16361812, -0.21847242, 0.0548543]\n",
      "Iter 9966, loss [-0.2183961, -0.25884616, 0.040450074]\n",
      "Iter 9967, loss [-0.22758159, -0.2650598, 0.03747821]\n",
      "Iter 9968, loss [-0.2104248, -0.25242868, 0.04200388]\n",
      "Iter 9969, loss [-0.21623705, -0.25548398, 0.039246935]\n",
      "Iter 9970, loss [-0.2308459, -0.26656088, 0.03571499]\n",
      "Iter 9971, loss [-0.14868301, -0.20595884, 0.05727583]\n",
      "Iter 9972, loss [-0.20639586, -0.2493527, 0.042956825]\n",
      "Iter 9973, loss [-0.21574041, -0.25479686, 0.03905645]\n",
      "Iter 9974, loss [-0.20701157, -0.2496449, 0.042633336]\n",
      "Iter 9975, loss [-0.22717552, -0.26319817, 0.036022644]\n",
      "Iter 9976, loss [-0.22363007, -0.26181132, 0.03818124]\n",
      "Iter 9977, loss [-0.23327483, -0.26769036, 0.03441553]\n",
      "Iter 9978, loss [-0.2224167, -0.2612227, 0.03880599]\n",
      "Iter 9979, loss [-0.2254513, -0.2608153, 0.035363983]\n",
      "Iter 9980, loss [-0.21713181, -0.25605685, 0.038925033]\n",
      "Iter 9981, loss [-0.21868367, -0.25608996, 0.03740628]\n",
      "Iter 9982, loss [-0.21844387, -0.25896767, 0.040523805]\n",
      "Iter 9983, loss [-0.1862864, -0.23373882, 0.04745242]\n",
      "Iter 9984, loss [-0.22570054, -0.2639571, 0.038256567]\n",
      "Iter 9985, loss [-0.22621964, -0.264203, 0.037983373]\n",
      "Iter 9986, loss [-0.20787834, -0.24697575, 0.039097413]\n",
      "Iter 9987, loss [-0.2100977, -0.2520092, 0.041911513]\n",
      "Iter 9988, loss [-0.22456211, -0.2629626, 0.03840051]\n",
      "Iter 9989, loss [-0.19408748, -0.24384092, 0.049753442]\n",
      "Iter 9990, loss [-0.2254641, -0.2637073, 0.03824321]\n",
      "Iter 9991, loss [-0.2297816, -0.26685736, 0.037075765]\n",
      "Iter 9992, loss [-0.22372423, -0.26328552, 0.039561283]\n",
      "Iter 9993, loss [-0.22541305, -0.26145667, 0.036043614]\n",
      "Iter 9994, loss [-0.22389174, -0.26096627, 0.03707453]\n",
      "Iter 9995, loss [-0.22994988, -0.26874372, 0.038793847]\n",
      "Iter 9996, loss [-0.225763, -0.2630458, 0.037282802]\n",
      "Iter 9997, loss [-0.23235273, -0.26852423, 0.03617149]\n",
      "Iter 9998, loss [-0.21779887, -0.25806117, 0.040262297]\n",
      "Iter 9999, loss [-0.21508679, -0.25302178, 0.037934985]\n",
      "Iter 10000, loss [-0.22272964, -0.25998193, 0.037252296]\n",
      "Iter 10001, loss [-0.21959834, -0.25827837, 0.03868003]\n",
      "Iter 10002, loss [-0.22635236, -0.2638763, 0.037523918]\n",
      "Iter 10003, loss [-0.2229504, -0.26219678, 0.03924638]\n",
      "Iter 10004, loss [-0.21619254, -0.25609142, 0.03989887]\n",
      "Iter 10005, loss [-0.15168321, -0.20341022, 0.051727008]\n",
      "Iter 10006, loss [-0.14254513, -0.20106822, 0.058523096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10007, loss [-0.22265798, -0.260463, 0.037805013]\n",
      "Iter 10008, loss [-0.23281395, -0.26651132, 0.03369736]\n",
      "Iter 10009, loss [-0.21997279, -0.25639072, 0.03641794]\n",
      "Iter 10010, loss [-0.2192571, -0.2557965, 0.03653939]\n",
      "Iter 10011, loss [-0.20197183, -0.24451146, 0.042539626]\n",
      "Iter 10012, loss [-0.2255739, -0.26557794, 0.04000404]\n",
      "Iter 10013, loss [-0.16739509, -0.22508596, 0.05769087]\n",
      "Iter 10014, loss [-0.17246199, -0.22766024, 0.055198245]\n",
      "Iter 10015, loss [-0.22794604, -0.2666938, 0.03874775]\n",
      "Iter 10016, loss [-0.22690286, -0.26600173, 0.03909887]\n",
      "Iter 10017, loss [-0.21679448, -0.2566514, 0.039856922]\n",
      "Iter 10018, loss [-0.2254168, -0.26302642, 0.03760962]\n",
      "Iter 10019, loss [-0.22775117, -0.26377285, 0.036021687]\n",
      "Iter 10020, loss [-0.22934034, -0.26622024, 0.03687989]\n",
      "Iter 10021, loss [-0.22259307, -0.25900865, 0.036415573]\n",
      "Iter 10022, loss [-0.22272559, -0.26111895, 0.038393363]\n",
      "Iter 10023, loss [-0.22601008, -0.26665184, 0.040641755]\n",
      "Iter 10024, loss [-0.21163025, -0.2539957, 0.04236543]\n",
      "Iter 10025, loss [-0.22230366, -0.25955883, 0.037255168]\n",
      "Iter 10026, loss [-0.22798315, -0.26600707, 0.03802391]\n",
      "Iter 10027, loss [-0.2213355, -0.26045036, 0.039114866]\n",
      "Iter 10028, loss [-0.22989899, -0.2669845, 0.03708551]\n",
      "Iter 10029, loss [-0.22039163, -0.25971, 0.039318386]\n",
      "Iter 10030, loss [-0.22894293, -0.26480314, 0.035860203]\n",
      "Iter 10031, loss [-0.2256302, -0.26214406, 0.036513872]\n",
      "Iter 10032, loss [-0.2229952, -0.26027808, 0.03728287]\n",
      "Iter 10033, loss [-0.21990724, -0.2583233, 0.038416073]\n",
      "Iter 10034, loss [-0.22499958, -0.26179707, 0.036797486]\n",
      "Iter 10035, loss [-0.195759, -0.24231556, 0.046556555]\n",
      "Iter 10036, loss [-0.22318628, -0.26234388, 0.039157595]\n",
      "Iter 10037, loss [-0.23263657, -0.2670543, 0.034417722]\n",
      "Iter 10038, loss [-0.22176081, -0.25892776, 0.03716696]\n",
      "Iter 10039, loss [-0.22415668, -0.2616221, 0.03746542]\n",
      "Iter 10040, loss [-0.22108272, -0.26042125, 0.039338537]\n",
      "Iter 10041, loss [-0.2284948, -0.26579434, 0.037299544]\n",
      "Iter 10042, loss [-0.22853625, -0.26673254, 0.03819629]\n",
      "Iter 10043, loss [-0.22691329, -0.26235005, 0.035436764]\n",
      "Iter 10044, loss [-0.17275909, -0.22686088, 0.05410179]\n",
      "Iter 10045, loss [-0.22866993, -0.2649195, 0.036249563]\n",
      "Iter 10046, loss [-0.22292687, -0.25968304, 0.036756173]\n",
      "Iter 10047, loss [-0.22158143, -0.2591889, 0.037607457]\n",
      "Iter 10048, loss [-0.21800928, -0.2544976, 0.036488306]\n",
      "Iter 10049, loss [-0.2222808, -0.26274928, 0.040468484]\n",
      "Iter 10050, loss [-0.21539238, -0.2559526, 0.040560216]\n",
      "Iter 10051, loss [-0.21939832, -0.25925666, 0.03985835]\n",
      "Iter 10052, loss [-0.21744397, -0.25820434, 0.040760368]\n",
      "Iter 10053, loss [-0.19758613, -0.242523, 0.04493686]\n",
      "Iter 10054, loss [-0.23465015, -0.26951107, 0.03486092]\n",
      "Iter 10055, loss [-0.18891115, -0.23613878, 0.047227617]\n",
      "Iter 10056, loss [-0.22743452, -0.2663987, 0.038964182]\n",
      "Iter 10057, loss [-0.22782047, -0.26524612, 0.037425656]\n",
      "Iter 10058, loss [-0.2235662, -0.26213664, 0.038570434]\n",
      "Iter 10059, loss [-0.22387269, -0.26194972, 0.038077023]\n",
      "Iter 10060, loss [-0.17314778, -0.22699316, 0.053845376]\n",
      "Iter 10061, loss [-0.22352713, -0.26136893, 0.037841797]\n",
      "Iter 10062, loss [-0.20506479, -0.2421199, 0.0370551]\n",
      "Iter 10063, loss [-0.21830684, -0.25635597, 0.038049128]\n",
      "Iter 10064, loss [-0.21394639, -0.2520018, 0.038055405]\n",
      "Iter 10065, loss [-0.22192025, -0.25968778, 0.03776753]\n",
      "Iter 10066, loss [-0.2207843, -0.2609882, 0.04020389]\n",
      "Iter 10067, loss [-0.2321135, -0.26994112, 0.037827622]\n",
      "Iter 10068, loss [-0.2250056, -0.26318023, 0.03817463]\n",
      "Iter 10069, loss [-0.22567719, -0.26349327, 0.037816077]\n",
      "Iter 10070, loss [-0.2189736, -0.25734574, 0.03837212]\n",
      "Iter 10071, loss [-0.2166034, -0.25582498, 0.03922158]\n",
      "Iter 10072, loss [-0.18682481, -0.23533586, 0.048511043]\n",
      "Iter 10073, loss [-0.22022116, -0.2575454, 0.037324257]\n",
      "Iter 10074, loss [-0.22806041, -0.26404262, 0.035982203]\n",
      "Iter 10075, loss [-0.2221292, -0.26138932, 0.03926012]\n",
      "Iter 10076, loss [-0.23194164, -0.26811215, 0.03617052]\n",
      "Iter 10077, loss [-0.22770393, -0.26549762, 0.03779369]\n",
      "Iter 10078, loss [-0.232562, -0.27116102, 0.03859901]\n",
      "Iter 10079, loss [-0.21937782, -0.25936487, 0.03998705]\n",
      "Iter 10080, loss [-0.23143378, -0.26704943, 0.03561565]\n",
      "Iter 10081, loss [-0.2189391, -0.25860852, 0.039669417]\n",
      "Iter 10082, loss [-0.21468319, -0.25348118, 0.038797986]\n",
      "Iter 10083, loss [-0.2266649, -0.26109043, 0.034425527]\n",
      "Iter 10084, loss [-0.22534207, -0.26310408, 0.037762012]\n",
      "Iter 10085, loss [-0.22766586, -0.26550364, 0.03783779]\n",
      "Iter 10086, loss [-0.23172303, -0.2679565, 0.03623347]\n",
      "Iter 10087, loss [-0.21513784, -0.2558726, 0.040734768]\n",
      "Iter 10088, loss [-0.22205363, -0.26202494, 0.039971303]\n",
      "Iter 10089, loss [-0.23501644, -0.27104917, 0.036032744]\n",
      "Iter 10090, loss [-0.22854266, -0.26518825, 0.0366456]\n",
      "Iter 10091, loss [-0.20600921, -0.24831824, 0.042309027]\n",
      "Iter 10092, loss [-0.20083392, -0.24535643, 0.044522505]\n",
      "Iter 10093, loss [-0.21819258, -0.25330284, 0.035110258]\n",
      "Iter 10094, loss [-0.223023, -0.25750056, 0.034477554]\n",
      "Iter 10095, loss [-0.22001965, -0.25948486, 0.039465204]\n",
      "Iter 10096, loss [-0.22089456, -0.26239905, 0.04150449]\n",
      "Iter 10097, loss [-0.22641802, -0.26632768, 0.039909665]\n",
      "Iter 10098, loss [-0.21565416, -0.25605798, 0.04040382]\n",
      "Iter 10099, loss [-0.2275664, -0.26479897, 0.037232563]\n",
      "Iter 10100, loss [-0.22457288, -0.2607945, 0.036221612]\n",
      "Iter 10101, loss [-0.21689135, -0.25514957, 0.038258217]\n",
      "Iter 10102, loss [-0.2215049, -0.25822574, 0.036720835]\n",
      "Iter 10103, loss [-0.16170691, -0.21905828, 0.057351362]\n",
      "Iter 10104, loss [-0.22225668, -0.26144868, 0.039192002]\n",
      "Iter 10105, loss [-0.21729329, -0.25859466, 0.041301366]\n",
      "Iter 10106, loss [-0.2291877, -0.2662418, 0.03705409]\n",
      "Iter 10107, loss [-0.22107324, -0.25915068, 0.03807745]\n",
      "Iter 10108, loss [-0.22303545, -0.26089033, 0.03785488]\n",
      "Iter 10109, loss [-0.21223137, -0.2523407, 0.04010933]\n",
      "Iter 10110, loss [-0.21711428, -0.2556149, 0.038500622]\n",
      "Iter 10111, loss [-0.22979951, -0.26647922, 0.03667972]\n",
      "Iter 10112, loss [-0.22967416, -0.26698762, 0.037313465]\n",
      "Iter 10113, loss [-0.21450372, -0.25586915, 0.041365433]\n",
      "Iter 10114, loss [-0.22853427, -0.26643974, 0.037905466]\n",
      "Iter 10115, loss [-0.22644901, -0.26497146, 0.038522452]\n",
      "Iter 10116, loss [-0.17870855, -0.22018516, 0.041476615]\n",
      "Iter 10117, loss [-0.21484786, -0.25376698, 0.03891912]\n",
      "Iter 10118, loss [-0.21786678, -0.25384548, 0.035978705]\n",
      "Iter 10119, loss [-0.21632269, -0.2558394, 0.039516725]\n",
      "Iter 10120, loss [-0.22645937, -0.26338843, 0.036929056]\n",
      "Iter 10121, loss [-0.22934194, -0.26403636, 0.03469442]\n",
      "Iter 10122, loss [-0.20751405, -0.24729586, 0.0397818]\n",
      "Iter 10123, loss [-0.22036213, -0.2589592, 0.038597077]\n",
      "Iter 10124, loss [-0.21644829, -0.25674713, 0.040298834]\n",
      "Iter 10125, loss [-0.22733589, -0.26402032, 0.03668444]\n",
      "Iter 10126, loss [-0.21872954, -0.2605506, 0.041821044]\n",
      "Iter 10127, loss [-0.22816783, -0.26647434, 0.038306497]\n",
      "Iter 10128, loss [-0.22443321, -0.2614884, 0.03705519]\n",
      "Iter 10129, loss [-0.22305495, -0.2616669, 0.038611956]\n",
      "Iter 10130, loss [-0.22643158, -0.2638601, 0.037428528]\n",
      "Iter 10131, loss [-0.1500864, -0.2079513, 0.05786491]\n",
      "Iter 10132, loss [-0.23495658, -0.2703489, 0.035392333]\n",
      "Iter 10133, loss [-0.21164179, -0.25368214, 0.042040356]\n",
      "Iter 10134, loss [-0.20939218, -0.24682611, 0.037433933]\n",
      "Iter 10135, loss [-0.22632141, -0.26288304, 0.036561623]\n",
      "Iter 10136, loss [-0.23021132, -0.2672458, 0.03703448]\n",
      "Iter 10137, loss [-0.20330489, -0.2449973, 0.041692406]\n",
      "Iter 10138, loss [-0.22400123, -0.26160508, 0.037603848]\n",
      "Iter 10139, loss [-0.22233328, -0.25985125, 0.037517972]\n",
      "Iter 10140, loss [-0.21077535, -0.24990582, 0.039130475]\n",
      "Iter 10141, loss [-0.1474062, -0.20305611, 0.055649906]\n",
      "Iter 10142, loss [-0.21371469, -0.25495902, 0.041244335]\n",
      "Iter 10143, loss [-0.22016452, -0.25989243, 0.03972791]\n",
      "Iter 10144, loss [-0.2306593, -0.2678248, 0.037165485]\n",
      "Iter 10145, loss [-0.22265646, -0.26232615, 0.039669693]\n",
      "Iter 10146, loss [-0.2291184, -0.26680243, 0.037684016]\n",
      "Iter 10147, loss [-0.2154584, -0.25287068, 0.037412286]\n",
      "Iter 10148, loss [-0.22946359, -0.26324907, 0.033785474]\n",
      "Iter 10149, loss [-0.21720323, -0.2552179, 0.038014688]\n",
      "Iter 10150, loss [-0.22195876, -0.259518, 0.03755924]\n",
      "Iter 10151, loss [-0.22926761, -0.26576918, 0.03650157]\n",
      "Iter 10152, loss [-0.20129094, -0.24020131, 0.03891037]\n",
      "Iter 10153, loss [-0.2153041, -0.2559583, 0.040654186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10154, loss [-0.23085266, -0.26697662, 0.03612397]\n",
      "Iter 10155, loss [-0.22837782, -0.26463345, 0.03625562]\n",
      "Iter 10156, loss [-0.16051082, -0.21651824, 0.056007415]\n",
      "Iter 10157, loss [-0.22618869, -0.2625604, 0.036371708]\n",
      "Iter 10158, loss [-0.21353637, -0.25329718, 0.03976081]\n",
      "Iter 10159, loss [-0.21177109, -0.25272492, 0.040953826]\n",
      "Iter 10160, loss [-0.22010022, -0.2599328, 0.03983256]\n",
      "Iter 10161, loss [-0.21730304, -0.2577351, 0.04043207]\n",
      "Iter 10162, loss [-0.2256236, -0.2627943, 0.03717069]\n",
      "Iter 10163, loss [-0.21980026, -0.2585181, 0.038717844]\n",
      "Iter 10164, loss [-0.18627581, -0.23243628, 0.046160482]\n",
      "Iter 10165, loss [-0.21696219, -0.2570234, 0.040061206]\n",
      "Iter 10166, loss [-0.22704896, -0.26201287, 0.034963906]\n",
      "Iter 10167, loss [-0.22292477, -0.26043227, 0.037507504]\n",
      "Iter 10168, loss [-0.21812753, -0.25831163, 0.040184096]\n",
      "Iter 10169, loss [-0.21887015, -0.25874463, 0.03987448]\n",
      "Iter 10170, loss [-0.22640808, -0.26386935, 0.037461266]\n",
      "Iter 10171, loss [-0.22910847, -0.26724166, 0.03813319]\n",
      "Iter 10172, loss [-0.22076398, -0.25931644, 0.03855247]\n",
      "Iter 10173, loss [-0.22825955, -0.26598933, 0.037729785]\n",
      "Iter 10174, loss [-0.224383, -0.26086295, 0.036479943]\n",
      "Iter 10175, loss [-0.23028472, -0.2665959, 0.036311187]\n",
      "Iter 10176, loss [-0.22192627, -0.26070043, 0.038774155]\n",
      "Iter 10177, loss [-0.21584213, -0.25310513, 0.037263]\n",
      "Iter 10178, loss [-0.21914753, -0.25832295, 0.039175425]\n",
      "Iter 10179, loss [-0.22476308, -0.26225868, 0.0374956]\n",
      "Iter 10180, loss [-0.19840434, -0.24400675, 0.045602404]\n",
      "Iter 10181, loss [-0.2230487, -0.26127836, 0.03822966]\n",
      "Iter 10182, loss [-0.22111166, -0.2594871, 0.03837543]\n",
      "Iter 10183, loss [-0.21642993, -0.2561749, 0.039744955]\n",
      "Iter 10184, loss [-0.22712426, -0.26429778, 0.037173524]\n",
      "Iter 10185, loss [-0.19659477, -0.23930725, 0.042712472]\n",
      "Iter 10186, loss [-0.22186118, -0.25947717, 0.037615992]\n",
      "Iter 10187, loss [-0.235289, -0.27041322, 0.03512422]\n",
      "Iter 10188, loss [-0.21304211, -0.25405154, 0.04100943]\n",
      "Iter 10189, loss [-0.19938746, -0.24594223, 0.04655477]\n",
      "Iter 10190, loss [-0.22524709, -0.26396653, 0.038719453]\n",
      "Iter 10191, loss [-0.22434068, -0.26495832, 0.040617637]\n",
      "Iter 10192, loss [-0.22728781, -0.26664355, 0.039355736]\n",
      "Iter 10193, loss [-0.21890251, -0.25833505, 0.039432537]\n",
      "Iter 10194, loss [-0.2095646, -0.25059912, 0.041034512]\n",
      "Iter 10195, loss [-0.21664897, -0.25514197, 0.038493015]\n",
      "Iter 10196, loss [-0.2253418, -0.2623646, 0.0370228]\n",
      "Iter 10197, loss [-0.18747005, -0.23573494, 0.048264887]\n",
      "Iter 10198, loss [-0.21134356, -0.25182047, 0.04047692]\n",
      "Iter 10199, loss [-0.19842157, -0.24245827, 0.044036698]\n",
      "Iter 10200, loss [-0.22580263, -0.26119673, 0.0353941]\n",
      "Iter 10201, loss [-0.22315103, -0.26092306, 0.037772022]\n",
      "Iter 10202, loss [-0.22546728, -0.26370907, 0.03824179]\n",
      "Iter 10203, loss [-0.21703719, -0.25626653, 0.03922935]\n",
      "Iter 10204, loss [-0.22520535, -0.26357108, 0.038365737]\n",
      "Iter 10205, loss [-0.23048756, -0.2648067, 0.034319133]\n",
      "Iter 10206, loss [-0.22624555, -0.2622307, 0.03598515]\n",
      "Iter 10207, loss [-0.22029005, -0.2584789, 0.03818886]\n",
      "Iter 10208, loss [-0.22747585, -0.26326767, 0.03579182]\n",
      "Iter 10209, loss [-0.22604269, -0.26364347, 0.03760078]\n",
      "Iter 10210, loss [-0.22395793, -0.26299903, 0.0390411]\n",
      "Iter 10211, loss [-0.22060324, -0.25985268, 0.03924943]\n",
      "Iter 10212, loss [-0.22380532, -0.26289597, 0.03909065]\n",
      "Iter 10213, loss [-0.21667494, -0.25528324, 0.038608298]\n",
      "Iter 10214, loss [-0.22999388, -0.26531568, 0.03532181]\n",
      "Iter 10215, loss [-0.21808706, -0.25706163, 0.03897457]\n",
      "Iter 10216, loss [-0.22407463, -0.25850525, 0.034430623]\n",
      "Iter 10217, loss [-0.21948871, -0.2577365, 0.0382478]\n",
      "Iter 10218, loss [-0.16083658, -0.21893327, 0.058096692]\n",
      "Iter 10219, loss [-0.22810504, -0.26430988, 0.036204845]\n",
      "Iter 10220, loss [-0.22387555, -0.26204833, 0.03817279]\n",
      "Iter 10221, loss [-0.21672691, -0.25689197, 0.04016505]\n",
      "Iter 10222, loss [-0.22717322, -0.263634, 0.036460772]\n",
      "Iter 10223, loss [-0.2178626, -0.2590454, 0.041182794]\n",
      "Iter 10224, loss [-0.2204539, -0.2583023, 0.037848398]\n",
      "Iter 10225, loss [-0.22387242, -0.26448983, 0.040617414]\n",
      "Iter 10226, loss [-0.22629228, -0.26176032, 0.035468034]\n",
      "Iter 10227, loss [-0.221455, -0.26025817, 0.038803175]\n",
      "Iter 10228, loss [-0.22735384, -0.2642459, 0.03689205]\n",
      "Iter 10229, loss [-0.22724122, -0.26269612, 0.035454907]\n",
      "Iter 10230, loss [-0.22932175, -0.26534694, 0.036025193]\n",
      "Iter 10231, loss [-0.19353575, -0.23708475, 0.043548997]\n",
      "Iter 10232, loss [-0.219898, -0.25672558, 0.03682758]\n",
      "Iter 10233, loss [-0.23002234, -0.26597196, 0.035949625]\n",
      "Iter 10234, loss [-0.21960476, -0.25668222, 0.037077464]\n",
      "Iter 10235, loss [-0.22651312, -0.26272818, 0.03621506]\n",
      "Iter 10236, loss [-0.21586074, -0.25448936, 0.03862862]\n",
      "Iter 10237, loss [-0.22668844, -0.26201308, 0.035324637]\n",
      "Iter 10238, loss [-0.23235191, -0.2664332, 0.034081295]\n",
      "Iter 10239, loss [-0.2308824, -0.26766342, 0.036781017]\n",
      "Iter 10240, loss [-0.23206657, -0.2690357, 0.03696912]\n",
      "Iter 10241, loss [-0.21655497, -0.2571421, 0.040587123]\n",
      "Iter 10242, loss [-0.2250725, -0.2640635, 0.038991004]\n",
      "Iter 10243, loss [-0.21642336, -0.25719398, 0.040770616]\n",
      "Iter 10244, loss [-0.22746447, -0.264233, 0.036768533]\n",
      "Iter 10245, loss [-0.22465834, -0.26462957, 0.039971236]\n",
      "Iter 10246, loss [-0.22292946, -0.26024434, 0.037314877]\n",
      "Iter 10247, loss [-0.21928078, -0.25795314, 0.038672358]\n",
      "Iter 10248, loss [-0.2265805, -0.26294315, 0.036362655]\n",
      "Iter 10249, loss [-0.2228203, -0.2618693, 0.039049014]\n",
      "Iter 10250, loss [-0.22511275, -0.26375887, 0.038646113]\n",
      "Iter 10251, loss [-0.21509996, -0.25604466, 0.040944688]\n",
      "Iter 10252, loss [-0.22126076, -0.2610702, 0.039809432]\n",
      "Iter 10253, loss [-0.2169502, -0.25657803, 0.03962784]\n",
      "Iter 10254, loss [-0.2226602, -0.26081926, 0.038159057]\n",
      "Iter 10255, loss [-0.2280742, -0.26241338, 0.034339193]\n",
      "Iter 10256, loss [-0.2155204, -0.25410306, 0.038582668]\n",
      "Iter 10257, loss [-0.22411773, -0.2616716, 0.037553884]\n",
      "Iter 10258, loss [-0.21701774, -0.2566296, 0.039611842]\n",
      "Iter 10259, loss [-0.23144382, -0.26646733, 0.035023518]\n",
      "Iter 10260, loss [-0.22593427, -0.26394403, 0.038009766]\n",
      "Iter 10261, loss [-0.22511211, -0.2632892, 0.03817711]\n",
      "Iter 10262, loss [-0.22138771, -0.26132077, 0.039933063]\n",
      "Iter 10263, loss [-0.21161461, -0.25060606, 0.038991444]\n",
      "Iter 10264, loss [-0.22107562, -0.26180276, 0.04072714]\n",
      "Iter 10265, loss [-0.22889288, -0.26517323, 0.036280353]\n",
      "Iter 10266, loss [-0.22683069, -0.26540563, 0.038574927]\n",
      "Iter 10267, loss [-0.22569954, -0.2619793, 0.036279768]\n",
      "Iter 10268, loss [-0.22674048, -0.2642725, 0.037532035]\n",
      "Iter 10269, loss [-0.23013307, -0.26351285, 0.03337978]\n",
      "Iter 10270, loss [-0.23170826, -0.26764393, 0.035935678]\n",
      "Iter 10271, loss [-0.22445527, -0.26483846, 0.04038319]\n",
      "Iter 10272, loss [-0.22466055, -0.2628365, 0.038175933]\n",
      "Iter 10273, loss [-0.22850995, -0.26405618, 0.035546225]\n",
      "Iter 10274, loss [-0.22296399, -0.25995103, 0.03698703]\n",
      "Iter 10275, loss [-0.23055768, -0.26483867, 0.034280986]\n",
      "Iter 10276, loss [-0.22077808, -0.25813204, 0.037353963]\n",
      "Iter 10277, loss [-0.23142058, -0.2694661, 0.038045533]\n",
      "Iter 10278, loss [-0.22255898, -0.26099518, 0.03843621]\n",
      "Iter 10279, loss [-0.2181163, -0.25907308, 0.04095678]\n",
      "Iter 10280, loss [-0.20975971, -0.25231716, 0.042557444]\n",
      "Iter 10281, loss [-0.21976876, -0.25910816, 0.039339397]\n",
      "Iter 10282, loss [-0.22897923, -0.26497647, 0.03599725]\n",
      "Iter 10283, loss [-0.22636127, -0.26280335, 0.036442064]\n",
      "Iter 10284, loss [-0.2313799, -0.26637912, 0.034999218]\n",
      "Iter 10285, loss [-0.22591238, -0.26185957, 0.03594719]\n",
      "Iter 10286, loss [-0.2235818, -0.2614332, 0.037851404]\n",
      "Iter 10287, loss [-0.2263909, -0.26475713, 0.03836623]\n",
      "Iter 10288, loss [-0.21988973, -0.2585983, 0.03870856]\n",
      "Iter 10289, loss [-0.22340462, -0.26105696, 0.03765234]\n",
      "Iter 10290, loss [-0.22631499, -0.26528022, 0.038965225]\n",
      "Iter 10291, loss [-0.22459278, -0.26427376, 0.039680995]\n",
      "Iter 10292, loss [-0.22181776, -0.25896758, 0.03714981]\n",
      "Iter 10293, loss [-0.22434586, -0.25969568, 0.03534982]\n",
      "Iter 10294, loss [-0.22629464, -0.2654024, 0.039107777]\n",
      "Iter 10295, loss [-0.2304251, -0.26590756, 0.03548245]\n",
      "Iter 10296, loss [-0.22507139, -0.26462072, 0.039549336]\n",
      "Iter 10297, loss [-0.22638556, -0.26439378, 0.03800821]\n",
      "Iter 10298, loss [-0.23463775, -0.27048588, 0.035848126]\n",
      "Iter 10299, loss [-0.2242761, -0.2635365, 0.039260425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10300, loss [-0.21200672, -0.25113374, 0.039127015]\n",
      "Iter 10301, loss [-0.21985626, -0.2573577, 0.037501432]\n",
      "Iter 10302, loss [-0.18670931, -0.2317223, 0.045012973]\n",
      "Iter 10303, loss [-0.21753341, -0.2573722, 0.039838783]\n",
      "Iter 10304, loss [-0.22391708, -0.26289564, 0.038978565]\n",
      "Iter 10305, loss [-0.21296254, -0.25379902, 0.04083648]\n",
      "Iter 10306, loss [-0.21275017, -0.25531414, 0.042563975]\n",
      "Iter 10307, loss [-0.16181518, -0.2201339, 0.058318716]\n",
      "Iter 10308, loss [-0.18374637, -0.23308788, 0.049341522]\n",
      "Iter 10309, loss [-0.22674616, -0.26434964, 0.03760348]\n",
      "Iter 10310, loss [-0.18552466, -0.23463745, 0.049112793]\n",
      "Iter 10311, loss [-0.21804051, -0.2587603, 0.04071979]\n",
      "Iter 10312, loss [-0.2284095, -0.26645547, 0.03804597]\n",
      "Iter 10313, loss [-0.22298005, -0.26087716, 0.037897106]\n",
      "Iter 10314, loss [-0.16691613, -0.2219476, 0.05503146]\n",
      "Iter 10315, loss [-0.16350096, -0.21523152, 0.051730566]\n",
      "Iter 10316, loss [-0.2287794, -0.26476467, 0.03598526]\n",
      "Iter 10317, loss [-0.18574703, -0.23462886, 0.04888182]\n",
      "Iter 10318, loss [-0.22313929, -0.26198426, 0.038844973]\n",
      "Iter 10319, loss [-0.2244054, -0.26417524, 0.03976984]\n",
      "Iter 10320, loss [-0.23229943, -0.2670253, 0.034725863]\n",
      "Iter 10321, loss [-0.22711752, -0.2632454, 0.036127876]\n",
      "Iter 10322, loss [-0.22453335, -0.2610678, 0.036534466]\n",
      "Iter 10323, loss [-0.22057715, -0.26152882, 0.040951677]\n",
      "Iter 10324, loss [-0.21897566, -0.25871864, 0.039742984]\n",
      "Iter 10325, loss [-0.2208977, -0.26217192, 0.041274216]\n",
      "Iter 10326, loss [-0.17008409, -0.22079675, 0.05071266]\n",
      "Iter 10327, loss [-0.2258197, -0.26046738, 0.034647673]\n",
      "Iter 10328, loss [-0.23377031, -0.26762053, 0.033850223]\n",
      "Iter 10329, loss [-0.23153663, -0.26798165, 0.036445014]\n",
      "Iter 10330, loss [-0.21306786, -0.25237578, 0.039307922]\n",
      "Iter 10331, loss [-0.22250739, -0.26105082, 0.03854343]\n",
      "Iter 10332, loss [-0.2193486, -0.26108712, 0.041738525]\n",
      "Iter 10333, loss [-0.19266847, -0.23996526, 0.047296792]\n",
      "Iter 10334, loss [-0.22954015, -0.26757553, 0.03803538]\n",
      "Iter 10335, loss [-0.2331827, -0.27097517, 0.037792474]\n",
      "Iter 10336, loss [-0.224266, -0.2623081, 0.038042106]\n",
      "Iter 10337, loss [-0.22551212, -0.2622194, 0.036707275]\n",
      "Iter 10338, loss [-0.22475387, -0.26182297, 0.037069097]\n",
      "Iter 10339, loss [-0.22950368, -0.26562637, 0.036122695]\n",
      "Iter 10340, loss [-0.22607233, -0.26265702, 0.036584686]\n",
      "Iter 10341, loss [-0.2211591, -0.25974974, 0.038590647]\n",
      "Iter 10342, loss [-0.22241579, -0.26129675, 0.03888096]\n",
      "Iter 10343, loss [-0.22521663, -0.2630455, 0.03782887]\n",
      "Iter 10344, loss [-0.2286546, -0.26622334, 0.03756874]\n",
      "Iter 10345, loss [-0.21801233, -0.25787953, 0.039867185]\n",
      "Iter 10346, loss [-0.2191182, -0.2574206, 0.038302407]\n",
      "Iter 10347, loss [-0.22507304, -0.2609259, 0.035852857]\n",
      "Iter 10348, loss [-0.15023908, -0.20669961, 0.056460522]\n",
      "Iter 10349, loss [-0.22302258, -0.26085252, 0.037829943]\n",
      "Iter 10350, loss [-0.2224625, -0.26067924, 0.038216732]\n",
      "Iter 10351, loss [-0.21702068, -0.25529876, 0.038278084]\n",
      "Iter 10352, loss [-0.21419013, -0.25428092, 0.040090792]\n",
      "Iter 10353, loss [-0.21710196, -0.25586638, 0.038764417]\n",
      "Iter 10354, loss [-0.2251841, -0.2628856, 0.037701502]\n",
      "Iter 10355, loss [-0.2095517, -0.25082126, 0.041269552]\n",
      "Iter 10356, loss [-0.22405392, -0.2611187, 0.0370648]\n",
      "Iter 10357, loss [-0.21834278, -0.25765705, 0.03931427]\n",
      "Iter 10358, loss [-0.21552798, -0.25599366, 0.04046569]\n",
      "Iter 10359, loss [-0.22398639, -0.2613592, 0.037372828]\n",
      "Iter 10360, loss [-0.19302598, -0.24019092, 0.04716494]\n",
      "Iter 10361, loss [-0.2272824, -0.26399735, 0.036714934]\n",
      "Iter 10362, loss [-0.22332124, -0.26131666, 0.037995413]\n",
      "Iter 10363, loss [-0.22652225, -0.2619102, 0.035387944]\n",
      "Iter 10364, loss [-0.2189689, -0.25549874, 0.036529846]\n",
      "Iter 10365, loss [-0.22778702, -0.26350468, 0.035717666]\n",
      "Iter 10366, loss [-0.21665227, -0.2567997, 0.04014742]\n",
      "Iter 10367, loss [-0.22513932, -0.26218048, 0.037041157]\n",
      "Iter 10368, loss [-0.22973919, -0.26772463, 0.037985448]\n",
      "Iter 10369, loss [-0.22664954, -0.26400596, 0.037356425]\n",
      "Iter 10370, loss [-0.2337008, -0.2691678, 0.03546701]\n",
      "Iter 10371, loss [-0.2167263, -0.25686958, 0.040143277]\n",
      "Iter 10372, loss [-0.22428286, -0.262692, 0.03840915]\n",
      "Iter 10373, loss [-0.22806129, -0.26376426, 0.035702974]\n",
      "Iter 10374, loss [-0.22094464, -0.25897154, 0.038026895]\n",
      "Iter 10375, loss [-0.23177691, -0.26712927, 0.035352364]\n",
      "Iter 10376, loss [-0.22388706, -0.26227498, 0.038387924]\n",
      "Iter 10377, loss [-0.22453356, -0.26240733, 0.037873782]\n",
      "Iter 10378, loss [-0.21754977, -0.2580708, 0.040521033]\n",
      "Iter 10379, loss [-0.22105509, -0.2595878, 0.03853271]\n",
      "Iter 10380, loss [-0.20850462, -0.25201857, 0.043513946]\n",
      "Iter 10381, loss [-0.21829663, -0.25759816, 0.03930153]\n",
      "Iter 10382, loss [-0.21285883, -0.25499985, 0.042141017]\n",
      "Iter 10383, loss [-0.23055194, -0.26493326, 0.03438131]\n",
      "Iter 10384, loss [-0.15751341, -0.21217817, 0.054664753]\n",
      "Iter 10385, loss [-0.22349998, -0.25992027, 0.03642028]\n",
      "Iter 10386, loss [-0.2298955, -0.26599732, 0.036101826]\n",
      "Iter 10387, loss [-0.2157538, -0.25333917, 0.037585378]\n",
      "Iter 10388, loss [-0.22499976, -0.26070908, 0.03570933]\n",
      "Iter 10389, loss [-0.22363883, -0.26382896, 0.040190127]\n",
      "Iter 10390, loss [-0.21821962, -0.25759065, 0.039371025]\n",
      "Iter 10391, loss [-0.2149348, -0.25789696, 0.042962156]\n",
      "Iter 10392, loss [-0.22699659, -0.2654889, 0.038492303]\n",
      "Iter 10393, loss [-0.22340873, -0.26086438, 0.037455656]\n",
      "Iter 10394, loss [-0.21932924, -0.2600025, 0.040673252]\n",
      "Iter 10395, loss [-0.21285556, -0.2520571, 0.03920154]\n",
      "Iter 10396, loss [-0.22566783, -0.262172, 0.036504187]\n",
      "Iter 10397, loss [-0.21195012, -0.25045517, 0.038505044]\n",
      "Iter 10398, loss [-0.2303751, -0.26441717, 0.03404207]\n",
      "Iter 10399, loss [-0.21783952, -0.25880876, 0.040969234]\n",
      "Iter 10400, loss [-0.20413731, -0.24512134, 0.040984035]\n",
      "Iter 10401, loss [-0.22864859, -0.26489344, 0.03624485]\n",
      "Iter 10402, loss [-0.22658867, -0.26365125, 0.03706259]\n",
      "Iter 10403, loss [-0.22454116, -0.26214433, 0.037603166]\n",
      "Iter 10404, loss [-0.22321272, -0.26171255, 0.038499825]\n",
      "Iter 10405, loss [-0.2284067, -0.26487556, 0.03646887]\n",
      "Iter 10406, loss [-0.22922243, -0.2672744, 0.038051978]\n",
      "Iter 10407, loss [-0.22373132, -0.26389122, 0.040159892]\n",
      "Iter 10408, loss [-0.17889139, -0.22577518, 0.046883784]\n",
      "Iter 10409, loss [-0.22220765, -0.2614055, 0.039197847]\n",
      "Iter 10410, loss [-0.22628209, -0.26269433, 0.03641223]\n",
      "Iter 10411, loss [-0.21721977, -0.2554527, 0.038232923]\n",
      "Iter 10412, loss [-0.22239414, -0.25899017, 0.036596023]\n",
      "Iter 10413, loss [-0.2237781, -0.2614589, 0.037680812]\n",
      "Iter 10414, loss [-0.23469958, -0.270245, 0.035545412]\n",
      "Iter 10415, loss [-0.22205037, -0.260096, 0.03804564]\n",
      "Iter 10416, loss [-0.22086376, -0.26134467, 0.040480904]\n",
      "Iter 10417, loss [-0.22182947, -0.2623229, 0.040493432]\n",
      "Iter 10418, loss [-0.22822233, -0.2658333, 0.037610963]\n",
      "Iter 10419, loss [-0.20859733, -0.2521476, 0.04355026]\n",
      "Iter 10420, loss [-0.22266516, -0.26137164, 0.03870648]\n",
      "Iter 10421, loss [-0.21770021, -0.25601083, 0.038310625]\n",
      "Iter 10422, loss [-0.21580613, -0.25396845, 0.038162313]\n",
      "Iter 10423, loss [-0.2228301, -0.25898674, 0.036156643]\n",
      "Iter 10424, loss [-0.16817002, -0.22391616, 0.055746138]\n",
      "Iter 10425, loss [-0.21813442, -0.25913826, 0.041003834]\n",
      "Iter 10426, loss [-0.2180124, -0.25894585, 0.04093344]\n",
      "Iter 10427, loss [-0.22681786, -0.26411816, 0.037300304]\n",
      "Iter 10428, loss [-0.2195881, -0.25974575, 0.04015765]\n",
      "Iter 10429, loss [-0.2201573, -0.2592176, 0.039060302]\n",
      "Iter 10430, loss [-0.23274964, -0.26798663, 0.035236984]\n",
      "Iter 10431, loss [-0.21809396, -0.2564004, 0.038306452]\n",
      "Iter 10432, loss [-0.2174225, -0.25787875, 0.040456247]\n",
      "Iter 10433, loss [-0.2253767, -0.26372084, 0.03834414]\n",
      "Iter 10434, loss [-0.22462171, -0.26281402, 0.0381923]\n",
      "Iter 10435, loss [-0.2241398, -0.26451838, 0.04037858]\n",
      "Iter 10436, loss [-0.2283488, -0.2650166, 0.03666778]\n",
      "Iter 10437, loss [-0.22315937, -0.26106837, 0.037909]\n",
      "Iter 10438, loss [-0.22059, -0.2589853, 0.038395323]\n",
      "Iter 10439, loss [-0.21790902, -0.25206807, 0.034159046]\n",
      "Iter 10440, loss [-0.22015908, -0.25906464, 0.038905565]\n",
      "Iter 10441, loss [-0.22522807, -0.2654395, 0.040211435]\n",
      "Iter 10442, loss [-0.21962732, -0.25930855, 0.039681226]\n",
      "Iter 10443, loss [-0.22045629, -0.2604576, 0.040001318]\n",
      "Iter 10444, loss [-0.21614176, -0.25850558, 0.042363815]\n",
      "Iter 10445, loss [-0.22193153, -0.26017085, 0.03823932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10446, loss [-0.22234017, -0.2596955, 0.03735533]\n",
      "Iter 10447, loss [-0.19659597, -0.24282147, 0.04622551]\n",
      "Iter 10448, loss [-0.22650675, -0.26236972, 0.035862967]\n",
      "Iter 10449, loss [-0.22828394, -0.2645878, 0.036303855]\n",
      "Iter 10450, loss [-0.22708255, -0.26298726, 0.0359047]\n",
      "Iter 10451, loss [-0.23446622, -0.27054983, 0.036083616]\n",
      "Iter 10452, loss [-0.2147541, -0.25552097, 0.04076687]\n",
      "Iter 10453, loss [-0.18733972, -0.23410222, 0.046762504]\n",
      "Iter 10454, loss [-0.22142988, -0.25955003, 0.038120158]\n",
      "Iter 10455, loss [-0.21720621, -0.25744855, 0.040242337]\n",
      "Iter 10456, loss [-0.20786494, -0.2504314, 0.04256645]\n",
      "Iter 10457, loss [-0.22347152, -0.26146165, 0.037990123]\n",
      "Iter 10458, loss [-0.1571382, -0.21088104, 0.05374285]\n",
      "Iter 10459, loss [-0.22529382, -0.26200622, 0.036712416]\n",
      "Iter 10460, loss [-0.23262855, -0.2668474, 0.03421884]\n",
      "Iter 10461, loss [-0.22734919, -0.2638844, 0.036535196]\n",
      "Iter 10462, loss [-0.2024669, -0.24477725, 0.04231035]\n",
      "Iter 10463, loss [-0.21911548, -0.25792375, 0.038808268]\n",
      "Iter 10464, loss [-0.21941708, -0.25892985, 0.039512765]\n",
      "Iter 10465, loss [-0.2245201, -0.26085427, 0.03633417]\n",
      "Iter 10466, loss [-0.22333667, -0.26129246, 0.037955787]\n",
      "Iter 10467, loss [-0.2326075, -0.2699071, 0.037299592]\n",
      "Iter 10468, loss [-0.22348998, -0.260485, 0.036995012]\n",
      "Iter 10469, loss [-0.19405894, -0.24251962, 0.048460674]\n",
      "Iter 10470, loss [-0.22725585, -0.2628315, 0.035575654]\n",
      "Iter 10471, loss [-0.16180676, -0.22338408, 0.061577313]\n",
      "Iter 10472, loss [-0.2204876, -0.25887942, 0.038391825]\n",
      "Iter 10473, loss [-0.19259413, -0.23771445, 0.045120325]\n",
      "Iter 10474, loss [-0.2239829, -0.25781175, 0.033828855]\n",
      "Iter 10475, loss [-0.22981751, -0.2661518, 0.036334272]\n",
      "Iter 10476, loss [-0.22340901, -0.2623692, 0.03896017]\n",
      "Iter 10477, loss [-0.22719276, -0.2651039, 0.03791114]\n",
      "Iter 10478, loss [-0.23062962, -0.26469815, 0.03406853]\n",
      "Iter 10479, loss [-0.22966835, -0.26665843, 0.03699007]\n",
      "Iter 10480, loss [-0.22745317, -0.26531166, 0.037858486]\n",
      "Iter 10481, loss [-0.20764409, -0.25196022, 0.044316128]\n",
      "Iter 10482, loss [-0.2168015, -0.2571309, 0.040329404]\n",
      "Iter 10483, loss [-0.22045691, -0.25733304, 0.03687613]\n",
      "Iter 10484, loss [-0.22813854, -0.2637759, 0.035637356]\n",
      "Iter 10485, loss [-0.22552778, -0.2626089, 0.037081107]\n",
      "Iter 10486, loss [-0.16774793, -0.22513391, 0.057385977]\n",
      "Iter 10487, loss [-0.1654549, -0.21832258, 0.05286768]\n",
      "Iter 10488, loss [-0.23140989, -0.26780134, 0.036391452]\n",
      "Iter 10489, loss [-0.2235623, -0.26173636, 0.038174056]\n",
      "Iter 10490, loss [-0.22580506, -0.26504448, 0.039239418]\n",
      "Iter 10491, loss [-0.23073584, -0.2688366, 0.03810074]\n",
      "Iter 10492, loss [-0.21968724, -0.25855532, 0.038868085]\n"
     ]
    }
   ],
   "source": [
    "start_iter = 0\n",
    "print(start_iter)\n",
    "n_train_iters = 50000\n",
    "vol_gen = ds.gen_vols_batch(['labeled_train', 'unlabeled_train'], batch_size=1, randomize=True)\n",
    "print(ds.files_labeled_train + ds.files_unlabeled_train)\n",
    "#vol_gen = data_utils.gen_batch(X_unlabeled, X_unlabeled, batch_size=1, randomize=True)\n",
    "target_X, _ = next(vol_gen)\n",
    "zeros_flow = np.zeros(target_X.shape[:-1] + (3,))\n",
    "\n",
    "for bi in range(n_train_iters + 1):\n",
    "    \n",
    "    target_X, _ = next(vol_gen)\n",
    "    # backward -- subject to atlas\n",
    "    vm_losses = vm_new_model.train_on_batch([target_X, source_X], [source_X, zeros_flow])\n",
    "    print('Iter {}, loss {}'.format(bi, vm_losses))\n",
    "    \n",
    "    if bi > 0 and bi % 2000 == 0:\n",
    "        vm_new_model.save('./experiments/voxelmorph/vm2_cc_UMStoCS_52k_1k-ul_xy_iter{}.h5'.format(start_iter + bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save a voxelmorph wrapper\n",
    "# import sys\n",
    "# sys.path.append('../voxelmorph-sandbox')\n",
    "# import voxelmorph.networks as vm_networks\n",
    "# import tensorflow as tf\n",
    "# from voxelmorph import dense_3D_spatial_transformer\n",
    "# from keras.models import load_model\n",
    " \n",
    "# sys.path.append('../neuron')\n",
    "# import neuron.layers as nrn_layers\n",
    "# import neuron.utils as nrn_utils\n",
    "# sys.path.append('../voxelmorph-sandbox')\n",
    "# import voxelmorph.networks as vm_networks\n",
    "# from voxelmorph.dense_3D_spatial_transformer import Dense3DSpatialTransformer\n",
    "\n",
    "                                \n",
    "# vm_diffeo_model = load_model(\n",
    "#     #'/afs/csail.mit.edu/u/x/xamyzhao/voxelmorph/models/vm2_cc.h5',\n",
    "#     './experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter10000.h5',#.format(start_iter),\n",
    "#     custom_objects={'Dense3DSpatialTransformer': dense_3D_spatial_transformer.Dense3DSpatialTransformer, \n",
    "#                     'interp_upsampling': vm_networks.interp_upsampling,\n",
    "#                     'meshgrid': vm_networks.meshgrid,\n",
    "#                     'tf': tf,\n",
    "                    \n",
    "#                     'VecInt': nrn_layers.VecInt,\n",
    "#                     'SpatialTransformer': nrn_layers.SpatialTransformer,\n",
    "#                     'nrn_utils': nrn_utils,\n",
    "#                     'nrn_layers': nrn_layers,\n",
    "#                    },\n",
    "#     compile=False,\n",
    "# )\n",
    "\n",
    "# from keras.layers import Input, Lambda\n",
    "# from keras.models import Model\n",
    "\n",
    "# vol_shape = (160, 192, 224, 1)\n",
    "# input_src = Input(vol_shape)\n",
    "# input_tgt = Input(vol_shape)\n",
    "\n",
    "# warped, backwarped, _ = vm_diffeo_model([input_src, input_tgt])\n",
    "# flow = vm_diffeo_model.get_layer('diffflow').output\n",
    "\n",
    "# wrapper_model = Model(inputs=[input_src, input_tgt], outputs=[flow, warped], name='vmmiccai_bidir_cc_wrapper')\n",
    "# wrapper_model.summary()\n",
    "# wrapper_model.save('./experiments/voxelmorph/vm2_cc_AtoUMS_newdataset_100k_bidir_iter10000_wrapper.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
